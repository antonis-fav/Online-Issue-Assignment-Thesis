[
   {
      "_id": "13326258",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337340",
            "id": "12337340",
            "name": "Test/dtest/java"
         }
      ],
      "created": "2020-09-07 07:49:30",
      "description": "We update the node count when setting the node id topology in in-jvm dtests, this should only happen if node count is smaller than the node id topology, otherwise bootstrap tests error out.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't adjust nodeCount when setting node id topology in in-jvm dtests"
   },
   {
      "_id": "13325867",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337340",
            "id": "12337340",
            "name": "Test/dtest/java"
         }
      ],
      "created": "2020-09-03 07:55:11",
      "description": "We should assert that we don't throw any uncaught exceptions when running in-jvm dtests",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Make sure we don't throw any uncaught exceptions during in-jvm dtests"
   },
   {
      "_id": "13325605",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2020-09-01 20:20:44",
      "description": "We have two recent failures for this test on trunk: \r\n\r\n1.) https://app.circleci.com/pipelines/github/maedhroz/cassandra/102/workflows/37ed8dab-9da4-4730-a883-20b7a99d88b4/jobs/518/tests (CASSANDRA-15909)\r\n2.) https://app.circleci.com/pipelines/github/jolynch/cassandra/6/workflows/41e080e0-d7ff-4256-899e-b4010c6ef5ab/jobs/716/tests (CASSANDRA-15379)\r\n\r\nThe test expects there to be mismatches and then read repair executed on a following SELECT, but either those mismatches aren\u2019t there, read repair isn\u2019t happening, or both.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest",
         "incremental_repair",
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Avoid marking shutting down nodes as up after receiving gossip shutdown message"
   },
   {
      "_id": "13309380",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337340",
            "id": "12337340",
            "name": "Test/dtest/java"
         }
      ],
      "created": "2020-06-04 07:46:47",
      "description": "Old python dtests support byteman, but that is quite horrible to work with, [bytebuddy|https://bytebuddy.net/#/] is much better, so we should add support for that in the in-jvm dtests.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Add bytebuddy support for in-jvm dtests"
   },
   {
      "_id": "13279543",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337007",
            "id": "12337007",
            "name": "CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337340",
            "id": "12337340",
            "name": "Test/dtest/java"
         }
      ],
      "created": "2020-01-15 09:50:09",
      "description": "We should run the in-jvm upgrade dtests in circleci",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Run in-jvm upgrade dtests in circleci"
   },
   {
      "_id": "13265329",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337340",
            "id": "12337340",
            "name": "Test/dtest/java"
         }
      ],
      "created": "2019-10-30 15:59:58",
      "description": "We should default to using 3 data directories when running the in-jvm dtests.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Use multiple data directories in the in-jvm dtests"
   },
   {
      "_id": "13194386",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2018-10-26 11:24:57",
      "description": "We also need to close the executor service",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "fqltool",
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Make it possible to connect with user/pass + port in fqltool replay"
   },
   {
      "_id": "13183061",
      "assignee": "krummas",
      "components": [],
      "created": "2018-09-05 07:34:28",
      "description": "We should add some basic round-trip dtests for {{fqltool replay}} and {{compare}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "fqltool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Add dtests for fqltool replay/compare"
   },
   {
      "_id": "13181958",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2018-08-29 17:41:40",
      "description": "FQL doesn't currently log the actual timestamp - in microseconds - if it's been server generated, nor the nowInSeconds value. It needs to, to allow for - in conjunction with CASSANDRA-14664 and CASSANDRA-14671 - deterministic playback tests.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "fqltool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Log the actual (if server-generated) timestamp and nowInSeconds used by queries in FQL"
   },
   {
      "_id": "13181627",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2018-08-28 14:56:08",
      "description": "We don't currently use consistent values of {{nowInSeconds}} and {{timestamp}} in the codebase, and sometimes generate several server-side timestamps for each in the same request. {{QueryState}} should cache the values it generated so that the same values are used for the duration of write/read.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "fqltool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Use consistent nowInSeconds and timestamps values within a request"
   },
   {
      "_id": "13181056",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2018-08-24 20:57:29",
      "description": "For FQL replay testing, to allow for deterministic and repeatable workload replay comparisons, we need to be able to set custom nowInSeconds via native protocol - primarily to control TTL expiration, both on read and write paths.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "fqltool",
         "protocolv5"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow providing and overriding nowInSeconds via native protocol"
   },
   {
      "_id": "13179969",
      "assignee": "krummas",
      "components": [],
      "created": "2018-08-20 14:12:52",
      "description": "If the full query log is enabled and a set of clients have already executed \"USE <ks>\" we can't figure out which keyspace the following queries are executed against.\r\n\r\nWe need this for CASSANDRA-14618",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "fqltool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Full query log needs to log the keyspace"
   },
   {
      "_id": "13177705",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2018-08-08 15:39:38",
      "description": "{{ChunkCache}} added {{CacheMissMetrics}} which is an almost exact duplicate of pre-existing {{CacheMetrics}}. I believe it was done initially because the authors thought there was no way to register hits with {{Caffeine}}, only misses, but that's not quite true. All we need is to provide a {{StatsCounter}} object when building the cache and update our metrics from there.\r\n\r\nThe patch removes the redundant code and streamlines chunk cache metrics to use more idiomatic tracking.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "virtual-tables"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Clean up cache-related metrics"
   },
   {
      "_id": "13177410",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2018-08-07 13:43:52",
      "description": "As noted by [~blerer] in CASSANDRA-14538, we should expose buffer cache metrics in the caches virtual table.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "virtual-tables"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Expose buffer cache metrics in caches virtual table"
   },
   {
      "_id": "13176473",
      "assignee": "krummas",
      "components": [],
      "created": "2018-08-02 17:06:02",
      "description": "We need a {{fqltool compare}} command that can take the recorded runs from CASSANDRA-14618 and compares them, it should output any differences and potentially all queries against the mismatching partition up until the mismatch",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "fqltool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Create fqltool compare command"
   },
   {
      "_id": "13176472",
      "assignee": "krummas",
      "components": [],
      "created": "2018-08-02 17:04:29",
      "description": "Make it possible to replay the full query logs from CASSANDRA-13983 against one or several clusters. The goal is to be able to compare different runs of production traffic against different versions/configurations of Cassandra.\r\n\r\n* It should be possible to take logs from several machines and replay them in \"order\" by the timestamps recorded\r\n* Record the results from each run to be able to compare different runs (against different clusters/versions/etc)\r\n* If {{fqltool replay}} is run against 2 or more clusters, the results should be compared as we go",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "fqltool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Create fqltool replay command"
   },
   {
      "_id": "13175351",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334946",
            "id": "12334946",
            "name": "Tool/nodetool"
         }
      ],
      "created": "2018-07-28 17:48:36",
      "description": "@jay zhuang observed nodetool_test.TestNodetool.test_describecluster_more_information_three_datacenters being flaky in Apache Jenkins. I ran locally and got a different flaky behavior:\r\n\r\n{noformat}\r\n        out_node1_dc3, err, _ = node1_dc3.nodetool('describecluster')\r\n        assert 0 == len(err), err\r\n>       assert out_node1_dc1 == out_node1_dc3\r\nE       AssertionError: assert 'Cluster Info...1=3, dc3=1}\\n' == 'Cluster Infor...1=3, dc3=1}\\n'\r\nE           Cluster Information:\r\nE           \tName: test\r\nE           \tSnitch: org.apache.cassandra.locator.PropertyFileSnitch\r\nE           \tDynamicEndPointSnitch: enabled\r\nE           \tPartitioner: org.apache.cassandra.dht.Murmur3Partitioner\r\nE           \tSchema versions:\r\nE           \t\tfc9ec7cd-80ba-3f27-87af-fc0bafcf7a03: [127.0.0.6, 127.0.0.5, 127.0.0.4, 127.0.0.3, 127.0.0.2, 127.0.0.1]...\r\nE         \r\nE         ...Full output truncated (26 lines hidden), use '-vv' to show\r\n\r\n\r\n09:58:14,357 ccm DEBUG Log-watching thread exiting.\r\n===Flaky Test Report===\r\n\r\ntest_describecluster_more_information_three_datacenters failed and was not selected for rerun.\r\n\t<class 'AssertionError'>\r\n\tassert 'Cluster Info...1=3, dc3=1}\\n' == 'Cluster Infor...1=3, dc3=1}\\n'\r\n    Cluster Information:\r\n    \tName: test\r\n    \tSnitch: org.apache.cassandra.locator.PropertyFileSnitch\r\n    \tDynamicEndPointSnitch: enabled\r\n    \tPartitioner: org.apache.cassandra.dht.Murmur3Partitioner\r\n    \tSchema versions:\r\n    \t\tfc9ec7cd-80ba-3f27-87af-fc0bafcf7a03: [127.0.0.6, 127.0.0.5, 127.0.0.4, 127.0.0.3, 127.0.0.2, 127.0.0.1]...\r\n  \r\n  ...Full output truncated (26 lines hidden), use '-vv' to show\r\n\t[<TracebackEntry /opt/orig/1/opt/dev/cassandra-dtest/nodetool_test.py:373>]\r\n\r\n===End Flaky Test Report===\r\n{noformat}\r\n\r\nAs this test is for a patch that was introduced for 4.0, this dtest (should) only be failing on trunk.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Flaky dtest: nodetool_test.TestNodetool.test_describecluster_more_information_three_datacenters"
   },
   {
      "_id": "13174881",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2018-07-26 14:59:46",
      "description": "consistently failing dtest on 3.0 (no other branches). Output from pytest:\r\n\r\n{noformat}\r\n        output, _, rc = node1.run_sstableofflinerelevel(\"keyspace1\", \"standard1\")\r\n>       assert re.search(\"L0=1\", output)\r\nE       AssertionError: assert None\r\nE        +  where None = <function search at 0x7f99afffbe18>('L0=1', 'New leveling: \\nL0=0\\nL1 10\\n')\r\nE        +    where <function search at 0x7f99afffbe18> = re.search\r\n\r\noffline_tools_test.py:160: AssertionError\r\n{noformat}\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "[dtest] test_sstableofflinerelevel - offline_tools_test.TestOfflineTools"
   },
   {
      "_id": "13174868",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2018-07-26 14:32:40",
      "description": "dtest fails all the time on 3.0, but not other branches. Error from pytest output:\r\n\r\n{code}\r\ntest teardown failure\r\nUnexpected error found in node logs (see stdout for full details). Errors: [WARN  [main] 2018-07-23 18:53:10,075 Uns.java:169 - Failed to load Java8 implementation ohc-core-j8 : java.lang.NoSuchMethodException: org.caffinitas.ohc.linked.UnsExt8.<init>(java.lang.Class), WARN  [main] 2018-07-23 18:53:56,966 Uns.java:169 - Failed to load Java8 implementation ohc-core-j8 : java.lang.NoSuchMethodException: org.caffinitas.ohc.linked.UnsExt8.<init>(java.lang.Class), WARN  [main] 2018-07-23 18:55:54,508 Uns.java:169 - Failed to load Java8 implementation ohc-core-j8 : java.lang.NoSuchMethodException: org.caffinitas.ohc.linked.UnsExt8.<init>(java.lang.Class), WARN  [main] 2018-07-23 18:56:42,688 Uns.java:169 - Failed to load Java8 implementation ohc-core-j8 : java.lang.NoSuchMethodException: org.caffinitas.ohc.linked.UnsExt8.<init>(java.lang.Class), WARN  [main] 2018-07-23 18:53:10,075 Uns.java:169 - Failed to load Java8 implementation ohc-core-j8 : java.lang.NoSuchMethodException: org.caffinitas.ohc.linked.UnsExt8.<init>(java.lang.Class)]\r\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "[dtest] test_functional - global_row_key_cache_test.TestGlobalRowKeyCache"
   },
   {
      "_id": "13173740",
      "assignee": "krummas",
      "components": [],
      "created": "2018-07-23 08:02:33",
      "description": "seems it needs a {{WITH COMPACT STORAGE}} to avoid failing like this:\r\n{code}\r\nwrite_failures_test.py::TestWriteFailures::test_thrift swapoff: Not superuser.\r\n01:23:57,245 ccm DEBUG Log-watching thread starting.\r\n\r\nINTERNALERROR> Traceback (most recent call last):\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/main.py\", line 178, in wrap_session\r\nINTERNALERROR>     session.exitstatus = doit(config, session) or 0\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/main.py\", line 215, in _main\r\nINTERNALERROR>     config.hook.pytest_runtestloop(session=session)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 617, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 222, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 216, in <lambda>\r\nINTERNALERROR>     firstresult=hook.spec_opts.get('firstresult'),\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 201, in _multicall\r\nINTERNALERROR>     return outcome.get_result()\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 76, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 180, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/main.py\", line 236, in pytest_runtestloop\r\nINTERNALERROR>     item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 617, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 222, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 216, in <lambda>\r\nINTERNALERROR>     firstresult=hook.spec_opts.get('firstresult'),\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 201, in _multicall\r\nINTERNALERROR>     return outcome.get_result()\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 76, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 180, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/flaky/flaky_pytest_plugin.py\", line 81, in pytest_runtest_protocol\r\nINTERNALERROR>     self.runner.pytest_runtest_protocol(item, nextitem)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/runner.py\", line 64, in pytest_runtest_protocol\r\nINTERNALERROR>     runtestprotocol(item, nextitem=nextitem)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/runner.py\", line 79, in runtestprotocol\r\nINTERNALERROR>     reports.append(call_and_report(item, \"call\", log))\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/flaky/flaky_pytest_plugin.py\", line 120, in call_and_report\r\nINTERNALERROR>     report = hook.pytest_runtest_makereport(item=item, call=call)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 617, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 222, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/__init__.py\", line 216, in <lambda>\r\nINTERNALERROR>     firstresult=hook.spec_opts.get('firstresult'),\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 196, in _multicall\r\nINTERNALERROR>     gen.send(outcome)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/skipping.py\", line 123, in pytest_runtest_makereport\r\nINTERNALERROR>     rep = outcome.get_result()\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 76, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/pluggy/callers.py\", line 180, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/runner.py\", line 331, in pytest_runtest_makereport\r\nINTERNALERROR>     longrepr = item.repr_failure(excinfo)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/python.py\", line 675, in repr_failure\r\nINTERNALERROR>     return self._repr_failure_py(excinfo, style=style)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/python.py\", line 668, in _repr_failure_py\r\nINTERNALERROR>     return super(FunctionMixin, self)._repr_failure_py(excinfo, style=style)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/nodes.py\", line 295, in _repr_failure_py\r\nINTERNALERROR>     tbfilter=tbfilter,\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/_code/code.py\", line 476, in getrepr\r\nINTERNALERROR>     return fmt.repr_excinfo(self)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/_code/code.py\", line 717, in repr_excinfo\r\nINTERNALERROR>     reprtraceback = self.repr_traceback(excinfo)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/_code/code.py\", line 664, in repr_traceback\r\nINTERNALERROR>     reprentry = self.repr_traceback_entry(entry, einfo)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/_code/code.py\", line 624, in repr_traceback_entry\r\nINTERNALERROR>     s = self.get_source(source, line_index, excinfo, short=short)\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/_code/code.py\", line 568, in get_source\r\nINTERNALERROR>     lines.extend(self.get_exconly(excinfo, indent=indent, markall=True))\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/_code/code.py\", line 575, in get_exconly\r\nINTERNALERROR>     exlines = excinfo.exconly(tryshort=True).split(\"\\n\")\r\nINTERNALERROR>   File \"/home/cassandra/cassandra/venv/lib/python3.6/site-packages/_pytest/_code/code.py\", line 426, in exconly\r\nINTERNALERROR>     lines = format_exception_only(self.type, self.value)\r\nINTERNALERROR>   File \"/usr/lib/python3.6/traceback.py\", line 136, in format_exception_only\r\nINTERNALERROR>     return list(TracebackException(etype, value, None).format_exception_only())\r\nINTERNALERROR>   File \"/usr/lib/python3.6/traceback.py\", line 462, in __init__\r\nINTERNALERROR>     _seen.add(exc_value)\r\nINTERNALERROR> TypeError: unhashable type: 'InvalidRequestException'\r\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "[DTEST] fix write_failures_test.py::TestWriteFailures::test_thrift"
   },
   {
      "_id": "13161703",
      "assignee": "krummas",
      "components": [],
      "created": "2018-05-24 08:56:33",
      "description": "We should add an option to do a quick sanity check of tombstones on reads + compaction. It should either log the error or throw an exception.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add option to sanity check tombstones on reads/compaction"
   },
   {
      "_id": "13156112",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337007",
            "id": "12337007",
            "name": "CI"
         }
      ],
      "created": "2018-04-30 13:58:30",
      "description": "We should run ant eclipse-warnings in circle-ci",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Run ant eclipse-warnings in circleci"
   },
   {
      "_id": "13152896",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2018-04-17 05:43:58",
      "description": "To be able to actually set max/min_threshold in compaction options we need to remove it from the options map when validating.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix setting min/max compaction threshold with LCS"
   },
   {
      "_id": "13138972",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2018-02-16 04:54:28",
      "description": "The unittest is flaky\r\n{noformat}\r\n    [junit] Testcase: testBlacklistingWithSizeTieredCompactionStrategy(org.apache.cassandra.db.compaction.BlacklistingCompactionsTest): FAILED\r\n    [junit] expected:<8> but was:<25>\r\n    [junit] junit.framework.AssertionFailedError: expected:<8> but was:<25>\r\n    [junit]     at org.apache.cassandra.db.compaction.BlacklistingCompactionsTest.testBlacklisting(BlacklistingCompactionsTest.java:170)\r\n    [junit]     at org.apache.cassandra.db.compaction.BlacklistingCompactionsTest.testBlacklistingWithSizeTieredCompactionStrategy(BlacklistingCompactionsTest.java:71)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "testing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Flaky Unittest: org.apache.cassandra.db.compaction.BlacklistingCompactionsTest"
   },
   {
      "_id": "13133040",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2018-01-23 12:53:45",
      "description": "Getting all rows from a node times out.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "[DTEST] repair_tests/repair_test.py:TestRepair.simple_sequential_repair_test"
   },
   {
      "_id": "13129753",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2018-01-10 04:39:35",
      "description": "DTest* TestTopology.test_movement* is flaky. All of the testing so far (and thus all of the current known observed failures) have been when running against trunk. When the test fails, it always due to the assert_almost_equal assert.\r\n\r\n{code}\r\nAssertionError: values not within 16.00% of the max: (851.41, 713.26) ()\r\n{code}\r\n\r\nThe following CircleCI runs are 2 examples with dtests runs that failed due to this test failing it's assert:\r\n[https://circleci.com/gh/mkjellman/cassandra/487]\r\n[https://circleci.com/gh/mkjellman/cassandra/526]\r\n\r\n*p.s.* assert_almost_equal has a comment \"@params error Optional margin of error. Default 0.16\". I don't see any obvious notes for why the default is this magical 16% number. It looks like it was committed as part of a big bulk commit by Sean McCarthy (who I can't find on JIRA). If anyone has any history on the magic 16% allowed delta please share!\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "[DTEST] [TRUNK] TestTopology.movement_test is flaky; fails assert \"values not within 16.00% of the max: (851.41, 713.26)\""
   },
   {
      "_id": "13108030",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2017-10-09 17:23:02",
      "description": "I recently upgraded from 2.2.6 to 3.11.0.\r\n\r\nI am seeing Cassandra loop infinitely compacting the same data over and over. Attaching logs.\r\n\r\nIt is compacting two tables, one on /srv/disk10, the other on /srv/disk1. It does create new SSTables but immediately recompacts again. Note that I am not inserting anything at the moment, there is no flushing happening on this table (Memtable switch count has not changed).\r\n\r\nMy theory is that it somehow thinks those should be compaction candidates. But they shouldn't be, they are on different disks and I ran nodetool relocatesstables as well as nodetool compact. So, it tries to compact them together, but the compaction results in the exact same 2 SSTables on the 2 disks, because the keys are split by data disk.\r\n\r\nThis is pretty serious, because all our nodes right now are consuming CPU doing this for multiple tables, it seems.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "jbod-aware-compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Infinite compaction of L0 SSTables in JBOD"
   },
   {
      "_id": "13099785",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2017-09-05 09:32:13",
      "description": "batch_test.TestBatch.batchlog_replay_compatibility_1_test and batch_test.TestBatch.batchlog_replay_compatibility_4_test are failing:\nhttp://cassci.datastax.com/view/cassandra-3.11/job/cassandra-3.11_dtest/160/testReport/batch_test/TestBatch/batchlog_replay_compatibility_1_test/\nhttp://cassci.datastax.com/view/cassandra-3.11/job/cassandra-3.11_dtest/160/testReport/batch_test/TestBatch/batchlog_replay_compatibility_4_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure: batch_test.TestBatch.batchlog_replay_compatibility_?_test"
   },
   {
      "_id": "13097635",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337007",
            "id": "12337007",
            "name": "CI"
         }
      ],
      "created": "2017-08-25 15:21:48",
      "description": "Followup from CASSANDRA-13775 - my fix with {{ant eclipse-warnings}} obviously does not work since it doesn't generate any xml files\n\nPush a new fix here: https://github.com/krummas/cassandra/commits/marcuse/fix_circle_3.0 which only collects the xml file from the first 3 containers\nTest running here: https://circleci.com/gh/krummas/cassandra/86",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CircleCI fix - only collect the xml file from containers where it exists"
   },
   {
      "_id": "13097299",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2017-08-24 12:36:26",
      "description": "Discovered by [~benedict] while reviewing CASSANDRA-13747:\n\n{quote}\nWhile reviewing I got a little suspicious of the modified line {{DataResolver}} :479, as it seemed that n and x were the wrong way around... and, reading the comment of intent directly above, and reproducing the calculation, they are indeed.\n\nThis is probably a significant enough bug that it warrants its own ticket for record keeping, though I'm fairly agnostic on that decision.\n\nI'm a little concerned about our current short read behaviour, as right now it seems we should be requesting exactly one row, for any size of under-read, which could mean extremely poor performance in case of large under-reads.\n\nI would suggest that the outer unconditional {{Math.max}} is a bad idea, has been (poorly) insulating us from this error, and that we should first be asserting that the calculation yields a value >= 0 before setting to 1.\n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Correctness"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix short read protection logic for querying more rows"
   },
   {
      "_id": "13097281",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2017-08-24 09:56:40",
      "description": "The goal of the fix of CASSANDRA-6069 was to make sure that collection tombstones in an update in CAS were using {{t-1}} because at least in {{INSERT}} collection tombstones are used to delete data prior to the update but shouldn't delete the newly inserted data itself. Because in 2.x the collection tombstones are normal range tombstones and thus part of the {{DeletionInfo}}, we went with the easy solution of using {{t-1}} for all of {{DeletionInfo}}.\n\nWhen moving that code to 3.0, this was migrated too literally however and only the {{DeletionInfo}} got the {{t -1}}. But in 3.0, range tombstones are not part of {{DeletionInfo}} anymore, and so this is broken.\n\nThanks to [~aweisberg] for noticing this.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Regression in 3.0, breaking the fix from CASSANDRA-6069"
   },
   {
      "_id": "13092855",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2017-08-07 11:15:20",
      "description": "{{ShortReadRowProtection.moreContents()}} expects that by the time we get to that method, the global post-reconciliation counter was already applied to the current partition. However, sometimes it won\u2019t get applied, and the global counter continues counting with {{rowInCurrentPartition}} value not reset from previous partition, which in the most obvious case would trigger the assertion we are observing - {{assert !postReconciliationCounter.isDoneForPartition();}}. In other cases it\u2019s possible because of this lack of reset to query a node for too few extra rows, causing unnecessary SRP data requests.\n\nWhy is the counter not always applied to the current partition?\n\nThe merged {{PartitionIterator}} returned from {{DataResolver.resolve()}} has two transformations applied to it, in the following order:\n{{Filter}} - to purge non-live data from partitions, and to discard empty partitions altogether (except for Thrift)\n{{Counter}}, to count and stop iteration\n\nProblem is, {{Filter}} \u2019s {{applyToPartition()}} code that discards empty partitions ({{closeIfEmpty()}} method) would sometimes consume the iterator, triggering short read protection *before* {{Counter}} \u2019s {{applyToPartition()}} gets called and resets its {{rowInCurrentPartition}} sub-counter.\n\nWe should not be consuming iterators until all transformations are applied to them. For transformations it means that they cannot consume iterators unless they are the last transformation on the stack.\n\nThe linked branch fixes the problem by splitting {{Filter}} into two transformations. The original - {{Filter}} - that does filtering within partitions - and a separate {{EmptyPartitionsDiscarder}}, that discards empty partitions from {{PartitionIterators}}. Thus {{DataResolve.resolve()}}, when constructing its {{PartitionIterator}}, now does merge first, then applies {{Filter}}, then {{Counter}}, and only then, as its last (third) transformation - the {{EmptyPartitionsDiscarder}}. Being the last one applied, it\u2019s legal for it to consume the iterator, and triggering {{moreContents()}} is now no longer a problem.\n\nFixes: [3.0|https://github.com/iamaleksey/cassandra/commits/13747-3.0], [3.11|https://github.com/iamaleksey/cassandra/commits/13747-3.11], [4.0|https://github.com/iamaleksey/cassandra/commits/13747-4.0]. dtest [here|https://github.com/iamaleksey/cassandra-dtest/commits/13747].",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Correctness"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix AssertionError in short read protection"
   },
   {
      "_id": "13087066",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2017-07-14 02:04:09",
      "description": "We stopped generating local shards in C* 2.1, after CASSANDRA-6504 (Counters 2.0). But it\u2019s still possible to have counter cell values\naround, remaining from 2.0 times, on 2.1, 3.0, 3.11, and even trunk nodes, if they\u2019ve never been overwritten.\n\nIn 2.1, we used two classes for two kinds of counter columns:\n{{CounterCell}} class to store counters - internally as collections of {{CounterContext}} blobs, encoding collections of (host id, count, clock) tuples\n{{CounterUpdateCell}} class to represent unapplied increments - essentially a single long value; this class was never written to commit log, memtables, or sstables, and was only used inside {{Mutation}} object graph - in memory, and marshalled over network in cases when counter write coordinator and counter write leader were different nodes\n3.0 got rid of {{CounterCell}} and {{CounterUpdateCell}}, among other {{Cell}} classes. In order to represent these unapplied increments - equivalents of 2.1 {{CounterUpdateCell}} - in 3.0 we encode them as regular counter columns, with a \u2018special\u2019 {{CounterContext}} value. I.e. a counter context with a single local shard. We do that so that we can reuse local shard reconcile logic (summing up) to seamlessly support counters with same names collapsing to single increments in batches. See {{UpdateParameters.addCounter()}} method comments [here|https://github.com/apache/cassandra/blob/cassandra-3.0.14/src/java/org/apache/cassandra/cql3/UpdateParameters.java#L157-L171] for details. It also assumes that nothing else can generate a counter with local shards.\n\nIt works fine in pure 3.0 clusters, and in mixed 2.1/3.0 clusters, assuming that there are no counters with legacy local shards remaining from 2.0 era. It breaks down badly if there are.\n\n{{LegacyLayout.serializeAsLegacyPartition()}} and consequently {{LegacyCell.isCounterUpdate()}} - classes responsible for serializing and deserialising in 2.1 format for compatibility - use the following logic to tell if a cell of {{COUNTER}} kind is a regular final counter or an unapplied increment:\n\n{code}\nprivate boolean isCounterUpdate()\n{\n    // See UpdateParameters.addCounter() for more details on this\n    return isCounter() && CounterContext.instance().isLocal(value);\n}\n{code}\n\n{{CounterContext.isLocal()}} method here looks at the first shard of the collection of tuples and returns true if it\u2019s a local one.\n\nThis method would correctly identify a cell generated by {{UpdateParameters.addCounter()}} as a counter update and serialize it correctly as a 2.1 {{CounterUpdateCell}}. However, it would also incorrectly flag any regular counter cell that just so happens to have a local shard as the first tuple of the counter context as a counter update. If a 2.1 node as a coordinator of a read requests fetches such a value from a 3.0 node, during a rolling upgrade, instead of the expected {{CounterCell}} object it will receive a {{CounterUpdateCell}}, breaking all the things. In the best case scenario it will cause an assert in {{AbstractCell.reconcileCounter()}} to be raised.\n\nTo fix the problem we must find an unambiguous way, without false positives or false negatives, to represent and identify unapplied counter updates on 3.0 side. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "counters",
         "upgrade"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix incorrect [2.1 <\u2014 3.0] serialization of counter cells with pre-2.1 local shards"
   },
   {
      "_id": "13079423",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2017-06-13 09:20:32",
      "description": "It seems that short read protection doesn't work when the short read is done at the end of a partition in a range query. The final assertion of this dtest fails:\n{code}\ndef short_read_partitions_delete_test(self):\n        cluster = self.cluster\n        cluster.set_configuration_options(values={'hinted_handoff_enabled': False})\n        cluster.set_batch_commitlog(enabled=True)\n        cluster.populate(2).start(wait_other_notice=True)\n        node1, node2 = self.cluster.nodelist()\n\n        session = self.patient_cql_connection(node1)\n        create_ks(session, 'ks', 2)\n        session.execute(\"CREATE TABLE t (k int, c int, PRIMARY KEY(k, c)) WITH read_repair_chance = 0.0\")\n\n        # we write 1 and 2 in a partition: all nodes get it.\n        session.execute(SimpleStatement(\"INSERT INTO t (k, c) VALUES (1, 1)\", consistency_level=ConsistencyLevel.ALL))\n        session.execute(SimpleStatement(\"INSERT INTO t (k, c) VALUES (2, 1)\", consistency_level=ConsistencyLevel.ALL))\n\n        # we delete partition 1: only node 1 gets it.\n        node2.flush()\n        node2.stop(wait_other_notice=True)\n        session = self.patient_cql_connection(node1, 'ks', consistency_level=ConsistencyLevel.ONE)\n        session.execute(SimpleStatement(\"DELETE FROM t WHERE k = 1\"))\n        node2.start(wait_other_notice=True)\n\n        # we delete partition 2: only node 2 gets it.\n        node1.flush()\n        node1.stop(wait_other_notice=True)\n        session = self.patient_cql_connection(node2, 'ks', consistency_level=ConsistencyLevel.ONE)\n        session.execute(SimpleStatement(\"DELETE FROM t WHERE k = 2\"))\n        node1.start(wait_other_notice=True)\n\n        # read from both nodes\n        session = self.patient_cql_connection(node1, 'ks', consistency_level=ConsistencyLevel.ALL)\n        assert_none(session, \"SELECT * FROM t LIMIT 1\")\n{code}\nHowever, the dtest passes if we remove the {{LIMIT 1}}.\n\nShort read protection [uses a {{SinglePartitionReadCommand}}|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/service/DataResolver.java#L484], maybe it should use a {{PartitionRangeReadCommand}} instead?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Correctness"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Implement short read protection on partition boundaries"
   },
   {
      "_id": "13078100",
      "assignee": "krummas",
      "components": [],
      "created": "2017-06-07 20:06:48",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/524/testReport/rebuild_test/TestRebuild/disallow_rebuild_from_nonreplica_test\n\n{noformat}\nError Message\n\nToolError not raised\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: Python driver version in use: 3.10\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-0tUjhX\ndtest: DEBUG: Done setting configuration options:\n{   'num_tokens': None,\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.3 DC1> discovered\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.2 DC1> discovered\n--------------------- >> end captured logging << ---------------------\n{noformat}\n\n\n{noformat}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 48, in wrappedtestrebuild\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/rebuild_test.py\", line 357, in disallow_rebuild_from_nonreplica_test\n    node1.nodetool('rebuild -ks ks1 -ts (%s,%s] -s %s' % (node3_token, node1_token, node3_address))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 116, in __exit__\n    \"{0} not raised\".format(exc_name))\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "test failure in rebuild_test.TestRebuild.disallow_rebuild_from_nonreplica_test"
   },
   {
      "_id": "13077785",
      "assignee": "krummas",
      "components": [],
      "created": "2017-06-06 20:18:09",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/445/testReport/bootstrap_test/TestBootstrap/consistent_range_movement_false_with_rf1_should_succeed_test\n\n{noformat}\nError Message\n31 May 2017 04:28:09 [node3] Missing: ['Starting listening for CQL clients']:\nINFO  [main] 2017-05-31 04:18:01,615 YamlConfigura.....\nSee system.log for remainder\n{noformat}\n\n{noformat}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/bootstrap_test.py\", line 236, in consistent_range_movement_false_with_rf1_should_succeed_test\n    self._bootstrap_test_with_replica_down(False, rf=1)\n  File \"/home/automaton/cassandra-dtest/bootstrap_test.py\", line 278, in _bootstrap_test_with_replica_down\n    jvm_args=[\"-Dcassandra.consistent.rangemovement={}\".format(consistent_range_movement)])\n  File \"/home/automaton/venv/local/lib/python2.7/site-packages/ccmlib/node.py\", line 696, in start\n    self.wait_for_binary_interface(from_mark=self.mark)\n  File \"/home/automaton/venv/local/lib/python2.7/site-packages/ccmlib/node.py\", line 514, in wait_for_binary_interface\n    self.watch_log_for(\"Starting listening for CQL clients\", **kwargs)\n  File \"/home/automaton/venv/local/lib/python2.7/site-packages/ccmlib/node.py\", line 471, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"31 May 2017 04:28:09 [node3] Missing: ['Starting listening for CQL clients']:\\nINFO  [main] 2017-05-31 04:18:01,615 YamlConfigura.....\\n\n{noformat}\n\n{noformat}\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-PKphwD\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'memtable_allocation_type': 'offheap_objects',\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ncassandra.policies: INFO: Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes\\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.2 datacenter1> discovered\\ncassandra.protocol: WARNING: Server warning: When increasing replication factor you need to run a full (-full) repair to distribute the data.\\ncassandra.connection: WARNING: Heartbeat failed for connection (139927174110160) to 127.0.0.2\\ncassandra.cluster: WARNING: Host 127.0.0.2 has been marked down\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 2.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 4.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 8.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 16.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 32.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 64.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 128.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 256.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\ncassandra.pool: WARNING: Error attempting to reconnect to 127.0.0.2, scheduling retry in 512.0 seconds: [Errno 111] Tried connecting to [('127.0.0.2', 9042)]. Last error: Connection refused\\n--------------------- >> end captured logging << ---------------------\"\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "test failure in bootstrap_test.TestBootstrap.consistent_range_movement_false_with_rf1_should_succeed_test"
   },
   {
      "_id": "13061719",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337007",
            "id": "12337007",
            "name": "CI"
         }
      ],
      "created": "2017-04-05 12:33:18",
      "description": "Currently we only run {{ant test}} on circleci, we should use all the (free) containers we have and run more targets in parallel.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Run more test targets on CircleCI"
   },
   {
      "_id": "13058179",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2017-03-22 10:54:31",
      "description": "When importing data with the _COPY_ command into a column family that has a _map<text, frozen<list<text>>>_ field, I get a _unhashable type: 'list'_ error. Here is how to reproduce:\n\n{code}\nCREATE TABLE table1 (\n    col1 int PRIMARY KEY,\n    col2map map<text, frozen<list<text>>>\n);\n\ninsert into table1 (col1, col2map) values (1, {'key': ['value1']});\n\ncqlsh:ks> copy table1 to 'table1.csv';\n\n\ntable1.csv file content:\n1,{'key': ['value1']}\n\n\ncqlsh:ks> copy table1 from 'table1.csv';\n...\nFailed to import 1 rows: ParseError - Failed to parse {'key': ['value1']} : unhashable type: 'list',  given up without retries\nFailed to process 1 rows; failed rows written to kv_table1.err\nProcessed: 1 rows; Rate:       2 rows/s; Avg. rate:       2 rows/s\n1 rows imported from 1 files in 0.420 seconds (0 skipped).\n{code}\n\nBut it works fine for Map<String, Set<String>>.\n\n{code}\nCREATE TABLE table2 (\n    col1 int PRIMARY KEY,\n    col2map map<text, frozen<set<text>>>\n);\n\ninsert into table2 (col1, col2map) values (1, {'key': {'value1'}});\n\ncqlsh:ks> copy table2 to 'table2.csv';\n\n\ntable2.csv file content:\n1,{'key': {'value1'}}\n\n\ncqlsh:ks> copy table2 from 'table2.csv';\nProcessed: 1 rows; Rate:       2 rows/s; Avg. rate:       2 rows/s\n1 rows imported from 1 files in 0.417 seconds (0 skipped).\n{code}\n\nThe exception seems to arrive in _convert_map_ function in _ImportConversion_ class inside _copyutil.py_.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Cqlsh COPY fails importing Map<String,List<String>>, ParseError unhashable type list"
   },
   {
      "_id": "13058159",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2017-03-22 09:22:14",
      "description": "Constantly see this error in the log without any additional information or a stack trace.\n\n{code}\nException in thread Thread[MessagingService-Incoming-/10.0.1.26,5,main]\n{code}\n\n{code}\njava.lang.ArrayIndexOutOfBoundsException: null\n{code}\n\nLogger: org.apache.cassandra.service.CassandraDaemon\nThrdead: MessagingService-Incoming-/10.0.1.12\nMethod: uncaughtException\nFile: CassandraDaemon.java\nLine: 229",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix racy read command serialization"
   },
   {
      "_id": "13029162",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-12-19 15:07:11",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest_upgrade/lastCompletedBuild/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_x_To_indev_trunk/cql3_insert_thrift_test_2/\n\n{code}\nUnexpected error in node1 log, error: \nERROR [main] 2016-12-17 14:48:28,471 CassandraDaemon.java:708 - Exception encountered during startup: Invalid yaml. Please remove properties [start_rpc] from your cassandra.yaml\n{code}\n\nRelated failures:\nhttp://cassci.datastax.com/job/trunk_dtest_upgrade/lastCompletedBuild/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_x_To_indev_trunk/cql3_non_compound_range_tombstones_test_2/\nhttp://cassci.datastax.com/job/trunk_dtest_upgrade/lastCompletedBuild/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_x_To_indev_trunk/rename_test_2/\n\nThese failures are also happening in the different # node & RF variants, as well as in 3.0.X -> trunk upgrades.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failures in upgrade_tests.cql_tests.TestCQLNodes3RF3_Upgrade_current_3_x_To_indev_trunk.cql3_insert_thrift_test"
   },
   {
      "_id": "13027048",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-12-09 17:04:45",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.X_dtest_upgrade/28/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_x_To_indev_3_x/static_columns_with_distinct_test\n\n{code}\nError Message\n\n<Error from server: code=0000 [Server error] message=\"java.io.IOError: java.io.IOException: Corrupt empty row found in unfiltered partition\">\n{code}{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 46, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 4010, in static_columns_with_distinct_test\n    rows = list(cursor.execute(\"SELECT DISTINCT k, s1 FROM test2\"))\n  File \"/home/automaton/src/cassandra-driver/cassandra/cluster.py\", line 1998, in execute\n    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state).result()\n  File \"/home/automaton/src/cassandra-driver/cassandra/cluster.py\", line 3784, in result\n    raise self._final_exception\n{code}{code}\nStandard Output\n\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:7eac22dd41cb09e6d64fb5ac48b2cca3c8840cc8\nUnexpected error in node2 log, error: \nERROR [Native-Transport-Requests-2] 2016-12-08 03:20:04,861 Message.java:617 - Unexpected exception during request; channel = [id: 0xf4c13f2c, L:/127.0.0.2:9042 - R:/127.0.0.1:52112]\njava.io.IOError: java.io.IOException: Corrupt empty row found in unfiltered partition\n\tat org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer$1.computeNext(UnfilteredRowIteratorSerializer.java:224) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer$1.computeNext(UnfilteredRowIteratorSerializer.java:212) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:133) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.statements.SelectStatement.processPartition(SelectStatement.java:779) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.statements.SelectStatement.process(SelectStatement.java:741) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.statements.SelectStatement.processResults(SelectStatement.java:408) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:273) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:232) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:76) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:188) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:219) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:204) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:115) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:513) [apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:407) [apache-cassandra-3.9.jar:3.9]\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.39.Final.jar:4.0.39.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:366) [netty-all-4.0.39.Final.jar:4.0.39.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.39.Final.jar:4.0.39.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:357) [netty-all-4.0.39.Final.jar:4.0.39.Final]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_51]\n\tat org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) [apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.9.jar:3.9]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]\nCaused by: java.io.IOException: Corrupt empty row found in unfiltered partition\n\tat org.apache.cassandra.db.rows.UnfilteredSerializer.deserialize(UnfilteredSerializer.java:430) ~[apache-cassandra-3.9.jar:3.9]\n\tat org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer$1.computeNext(UnfilteredRowIteratorSerializer.java:219) ~[apache-cassandra-3.9.jar:3.9]\n\t... 23 common frames omitted\n{code}\n\nRelated failures: (~25)\nhttp://cassci.datastax.com/job/cassandra-3.X_dtest_upgrade/28/testReport/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes3RF3_Upgrade_current_3_x_To_indev_3_x.static_columns_with_distinct_test"
   },
   {
      "_id": "13025644",
      "assignee": "slebresne",
      "components": [],
      "created": "2016-12-05 14:20:50",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_testall/1298/testReport/org.apache.cassandra.cql3.validation.operations/AlterTest/testDropListAndAddListWithSameName\n\n{code}\nError Message\n\nInvalid value for row 0 column 2 (mycollection of type list<text>), expected <null> but got <[first element]>\n{code}{code}Stacktrace\n\njunit.framework.AssertionFailedError: Invalid value for row 0 column 2 (mycollection of type list<text>), expected <null> but got <[first element]>\n\tat org.apache.cassandra.cql3.CQLTester.assertRows(CQLTester.java:908)\n\tat org.apache.cassandra.cql3.validation.operations.AlterTest.testDropListAndAddListWithSameName(AlterTest.java:87)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "testall"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Use timestamp from ClientState by default in AlterTableStatement"
   },
   {
      "_id": "13023763",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-11-28 15:32:39",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_jdk8/321/testReport/snapshot_test/TestSnapshot/test_basic_snapshot_and_restore\n\n{code}\nError Message\n\nsstableloader command '/home/automaton/cassandra/bin/sstableloader -d 127.0.0.1 /tmp/tmpdtJ9V7/0/ks/cf' failed; exit status: 1'; stdout: Established connection to initial hosts\nOpening sstables and calculating sections to stream\n; stderr: Exception in thread \"main\" java.lang.ExceptionInInitializerError\n\tat org.apache.cassandra.io.sstable.format.big.BigTableReader.getPosition(BigTableReader.java:240)\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.getPosition(SSTableReader.java:1572)\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.getPositionsForRanges(SSTableReader.java:1503)\n\tat org.apache.cassandra.io.sstable.SSTableLoader$1.accept(SSTableLoader.java:128)\n\tat java.io.File.list(File.java:1161)\n\tat org.apache.cassandra.io.sstable.SSTableLoader.openSSTables(SSTableLoader.java:79)\n\tat org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:161)\n\tat org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:99)\nCaused by: java.lang.RuntimeException: java.net.UnknownHostException: openstack-cassci-external-df85c4d-jenkins-cassandra-2: openstack-cassci-external-df85c4d-jenkins-cassandra-2: unknown error\n\tat org.apache.cassandra.utils.FBUtilities.getLocalAddress(FBUtilities.java:138)\n\tat org.apache.cassandra.tracing.Tracing.<init>(Tracing.java:82)\n\tat org.apache.cassandra.tracing.Tracing.<clinit>(Tracing.java:88)\n\t... 8 more\nCaused by: java.net.UnknownHostException: openstack-cassci-external-df85c4d-jenkins-cassandra-2: openstack-cassci-external-df85c4d-jenkins-cassandra-2: unknown error\n\tat java.net.InetAddress.getLocalHost(InetAddress.java:1484)\n\tat org.apache.cassandra.utils.FBUtilities.getLocalAddress(FBUtilities.java:133)\n\t... 10 more\nCaused by: java.net.UnknownHostException: openstack-cassci-external-df85c4d-jenkins-cassandra-2: unknown error\n\tat java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n\tat java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:907)\n\tat java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1302)\n\tat java.net.InetAddress.getLocalHost(InetAddress.java:1479)\n\t... 11 more\n{code}{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/snapshot_test.py\", line 100, in test_basic_snapshot_and_restore\n    self.restore_snapshot(snapshot_dir, node1, 'ks', 'cf')\n  File \"/home/automaton/cassandra-dtest/snapshot_test.py\", line 72, in restore_snapshot\n    (\" \".join(args), exit_status, stdout, stderr))\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in snapshot_test.TestSnapshot.test_basic_snapshot_and_restore"
   },
   {
      "_id": "13021601",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-11-17 21:46:08",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.X_dtest/37/testReport/batch_test/TestBatch/logged_batch_doesnt_throw_uae_test\n\n{noformat}\nError Message\n\nError from server: code=1000 [Unavailable exception] message=\"Cannot achieve consistency level ALL\" info={'required_replicas': 3, 'alive_replicas': 2, 'consistency': 'ALL'}\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-Ysb5Cf\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ncassandra.policies: INFO: Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.3 datacenter1> discovered\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.2 datacenter1> discovered\ndtest: DEBUG: Creating schema...\ndtest: DEBUG: Retrying request after UE. Attempt #0\ndtest: DEBUG: Retrying request after UE. Attempt #1\ndtest: DEBUG: Retrying request after UE. Attempt #2\ndtest: DEBUG: Retrying request after UE. Attempt #3\ndtest: DEBUG: Retrying request after UE. Attempt #4\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/batch_test.py\", line 193, in logged_batch_doesnt_throw_uae_test\n    cl=ConsistencyLevel.ALL)\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 164, in assert_all\n    res = session.execute(simple_query)\n  File \"/home/automaton/src/cassandra-driver/cassandra/cluster.py\", line 1998, in execute\n    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state).result()\n  File \"/home/automaton/src/cassandra-driver/cassandra/cluster.py\", line 3784, in result\n    raise self._final_exception\n'Error from server: code=1000 [Unavailable exception] message=\"Cannot achieve consistency level ALL\" info={\\'required_replicas\\': 3, \\'alive_replicas\\': 2, \\'consistency\\': \\'ALL\\'}\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-Ysb5Cf\\ndtest: DEBUG: Done setting configuration options:\\n{   \\'initial_token\\': None,\\n    \\'num_tokens\\': \\'32\\',\\n    \\'phi_convict_threshold\\': 5,\\n    \\'range_request_timeout_in_ms\\': 10000,\\n    \\'read_request_timeout_in_ms\\': 10000,\\n    \\'request_timeout_in_ms\\': 10000,\\n    \\'truncate_request_timeout_in_ms\\': 10000,\\n    \\'write_request_timeout_in_ms\\': 10000}\\ncassandra.policies: INFO: Using datacenter \\'datacenter1\\' for DCAwareRoundRobinPolicy (via host \\'127.0.0.1\\'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes\\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.3 datacenter1> discovered\\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.2 datacenter1> discovered\\ndtest: DEBUG: Creating schema...\\ndtest: DEBUG: Retrying request after UE. Attempt #0\\ndtest: DEBUG: Retrying request after UE. Attempt #1\\ndtest: DEBUG: Retrying request after UE. Attempt #2\\ndtest: DEBUG: Retrying request after UE. Attempt #3\\ndtest: DEBUG: Retrying request after UE. Attempt #4\\n--------------------- >> end captured logging << ---------------------'\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in batch_test.TestBatch.logged_batch_doesnt_throw_uae_test"
   },
   {
      "_id": "13021561",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-11-17 19:12:23",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_large_dtest/40/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_3_0_x_To_indev_3_x/bootstrap_test\n\n[^upgrade_test.consoleout.txt]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.upgrade_through_versions_test.TestUpgrade_current_3_0_x_To_indev_3_x.bootstrap_test"
   },
   {
      "_id": "13021172",
      "assignee": "krummas",
      "components": [],
      "created": "2016-11-16 15:31:37",
      "description": "SplitterTest is a randomized test - it generates random tokens and splits the ranges in equal parts. Since it is random we sometimes get very big vnodes right where we want a split and that makes the split unbalanced\n\nBumping the error margin a bit will avoid these false positives.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Increase error margin in SplitterTest"
   },
   {
      "_id": "13019612",
      "assignee": "krummas",
      "components": [],
      "created": "2016-11-09 19:01:36",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1418/testReport/disk_balance_test/TestDiskBalance/disk_balance_stress_test\n\n{noformat}\nError Message\n\n'float' object has no attribute '2f'\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-lxr8Vr\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/disk_balance_test.py\", line 31, in disk_balance_stress_test\n    self.assert_balanced(node)\n  File \"/home/automaton/cassandra-dtest/disk_balance_test.py\", line 120, in assert_balanced\n    assert_almost_equal(*sums, error=0.1, error_message=node.name)\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 187, in assert_almost_equal\n    assert vmin > vmax * (1.0 - error) or vmin == vmax, \"values not within {.2f}% of the max: {} ({})\".format(error * 100, args, error_message)\n\"'float' object has no attribute '2f'\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-lxr8Vr\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\n--------------------- >> end captured logging << ---------------------\"\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in disk_balance_test.TestDiskBalance.disk_balance_stress_test"
   },
   {
      "_id": "13019606",
      "assignee": "krummas",
      "components": [],
      "created": "2016-11-09 18:38:33",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_testall/602/testReport/org.apache.cassandra.db.compaction/NeverPurgeTest/minorNeverPurgeTombstonesTest_compression\n\n{noformat}\nError Message\n\nMemory was freed by Thread[NonPeriodicTasks:1,5,main]\nStacktrace\n\njunit.framework.AssertionFailedError: Memory was freed by Thread[NonPeriodicTasks:1,5,main]\n\tat org.apache.cassandra.io.util.SafeMemory.checkBounds(SafeMemory.java:103)\n\tat org.apache.cassandra.io.util.Memory.getLong(Memory.java:260)\n\tat org.apache.cassandra.io.compress.CompressionMetadata.chunkFor(CompressionMetadata.java:223)\n\tat org.apache.cassandra.io.compress.CompressedRandomAccessReader.reBufferMmap(CompressedRandomAccessReader.java:168)\n\tat org.apache.cassandra.io.compress.CompressedRandomAccessReader.reBuffer(CompressedRandomAccessReader.java:226)\n\tat org.apache.cassandra.io.util.RandomAccessReader.read(RandomAccessReader.java:303)\n\tat org.apache.cassandra.io.util.AbstractDataInput.readInt(AbstractDataInput.java:202)\n\tat org.apache.cassandra.io.util.AbstractDataInput.readLong(AbstractDataInput.java:264)\n\tat org.apache.cassandra.db.ColumnSerializer.deserializeColumnBody(ColumnSerializer.java:131)\n\tat org.apache.cassandra.db.OnDiskAtom$Serializer.deserializeFromSSTable(OnDiskAtom.java:92)\n\tat org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:52)\n\tat org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:46)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n\tat org.apache.cassandra.io.sstable.SSTableIdentityIterator.hasNext(SSTableIdentityIterator.java:169)\n\tat org.apache.cassandra.db.compaction.NeverPurgeTest.verifyContainsTombstones(NeverPurgeTest.java:114)\n\tat org.apache.cassandra.db.compaction.NeverPurgeTest.minorNeverPurgeTombstonesTest(NeverPurgeTest.java:85)\nStandard Output\n\nWARN  20:06:47 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:47 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:49 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:49 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:49 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:49 You a\n...[truncated 2456 chars]...\n this is dangerous!\nWARN  20:06:56 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:56 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:56 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:56 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\nWARN  20:06:56 You are running with -Dcassandra.never_purge_tombstones=true, this is dangerous!\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "testall failure in org.apache.cassandra.db.compaction.NeverPurgeTest.minorNeverPurgeTombstonesTest-compression"
   },
   {
      "_id": "13019604",
      "assignee": "slebresne",
      "components": [],
      "created": "2016-11-09 18:32:12",
      "description": "This failed in both 'test' and 'test-compression' targets.\n\nexample failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_testall/602/testReport/org.apache.cassandra.db/ColumnFamilyStoreTest/testSliceByNamesCommandOldMetadata\nhttp://cassci.datastax.com/job/cassandra-2.2_testall/602/testReport/org.apache.cassandra.db/ColumnFamilyStoreTest/testSliceByNamesCommandOldMetadata_compression/\n\n\n{noformat}\nStacktrace\n\njunit.framework.AssertionFailedError\n\tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:171)\n\tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:166)\n\tat org.apache.cassandra.io.sstable.format.SSTableWriter.rename(SSTableWriter.java:266)\n\tat org.apache.cassandra.db.ColumnFamilyStore.loadNewSSTables(ColumnFamilyStore.java:791)\n\tat org.apache.cassandra.db.ColumnFamilyStoreTest.testSliceByNamesCommandOldMetadata(ColumnFamilyStoreTest.java:1158)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "testall failure in org.apache.cassandra.db.ColumnFamilyStoreTest.testSliceByNamesCommandOldMetadata"
   },
   {
      "_id": "13017692",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-11-03 15:27:53",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/316/testReport/materialized_views_test/TestMaterializedViews/populate_mv_after_insert_wide_rows_test\n\n{code}\nError Message\n\nExpected [[0, 0]] from SELECT * FROM t_by_v WHERE id = 0 AND v = 0, but got []\n{code}{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/materialized_views_test.py\", line 211, in populate_mv_after_insert_wide_rows_test\n    assert_one(session, \"SELECT * FROM t_by_v WHERE id = {} AND v = {}\".format(i, j), [j, i])\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 130, in assert_one\n    assert list_res == [expected], \"Expected {} from {}, but got {}\".format([expected], query, list_res)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.populate_mv_after_insert_wide_rows_test"
   },
   {
      "_id": "13017430",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2016-11-02 21:50:45",
      "description": "We are seeing an issue with paging reads missing some small number of columns when we do paging/limit reads. We get this on a single DC cluster itself when both reads and writes are happening with QUORUM. Paging/limit reads see this issue. I have attached the ccm based script which reproduces the problem.\n\n* Keyspace RF - 3\n* Table (id int, course text, marks int, primary key(id, course))\n* replicas for partition key 1 - r1, r2 and r3\n* insert (1, '1', 1) ,  (1, '2', 2),  (1, '3', 3),  (1, '4', 4),  (1, '5', 5) - succeeded on all 3 replicas\n* insert (1, '6', 6) succeeded on r1 and r3, failed on r2\n* delete (1, '2'), (1, '3'), (1, '4'), (1, '5') succeeded on r1 and r2, failed on r3\n* insert (1, '7', 7) succeeded on r1 and r2, failed on r3\n\nLocal data on 3 nodes looks like as below now\n\nr1: (1, '1', 1), tombstone(2-5 records), (1, '6', 6), (1, '7', 7)\nr2: (1, '1', 1), tombstone(2-5 records), (1, '7', 7)\nr3: (1, '1', 1),  (1, '2', 2),  (1, '3', 3),  (1, '4', 4),  (1, '5', 5), (1, '6', 6)\n\nIf we do a paging read with page_size 2, and if it gets data from r2 and r3, then it will only get the data (1, '1', 1) and (1, '7', 7) skipping record 6. This problem would happen if the same query is not doing paging but limit set to 2 records.\n\nResolution code for reads works same for paging queries and normal queries. Co-ordinator shouldn't respond back to client with records/columns that it didn't have complete visibility on all required replicas (in this case 2 replicas). In above case, it is sending back record (1, '7', 7) back to client, but its visibility on r3 is limited up to (1, '2', 2) and it is relying on just r2 data to assume (1, '6', 6) doesn't exist, which is wrong. End of the resolution all it can conclusively say any thing about is (1, '1',  and the other one is that we  and and and and and and the and the and the and d and the other is and 1), which exists and (1, '2', 2), which is deleted.\n\nIdeally we should have different resolution implementation for paging/limit queries.\n\nWe could reproduce this on 2.0.17, 2.1.16 and 3.0.9.\n\nSeems like 3.0.9 we have ShortReadProtection transformation on list queries. I assume that is to protect against the cases like above. But, we can reproduce the issue in 3.0.9 as well.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Correctness"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix short read protection when more than one row is missing"
   },
   {
      "_id": "13016172",
      "assignee": "stefania",
      "components": [],
      "created": "2016-10-28 14:24:59",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/280/testReport/replication_test/SnitchConfigurationUpdateTest/test_cannot_restart_with_different_rack\n\n{code}\nError Message\n\nProblem stopping node node1\n{code}{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/replication_test.py\", line 630, in test_cannot_restart_with_different_rack\n    node1.stop(wait_other_notice=True)\n  File \"/usr/local/lib/python2.7/dist-packages/ccmlib/node.py\", line 727, in stop\n    raise NodeError(\"Problem stopping node %s\" % self.name)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in replication_test.SnitchConfigurationUpdateTest.test_cannot_restart_with_different_rack"
   },
   {
      "_id": "13015430",
      "assignee": "krummas",
      "components": [],
      "created": "2016-10-26 14:16:15",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_testall/597/testReport/org.apache.cassandra.db.compaction/NeverPurgeTest/minorNeverPurgeTombstonesTest_compression/\n\n{code}\nError Message\n\nMemory was freed by Thread[NonPeriodicTasks:1,5,main]\n{code}{code}\nStacktrace\n\njunit.framework.AssertionFailedError: Memory was freed by Thread[NonPeriodicTasks:1,5,main]\n\tat org.apache.cassandra.io.util.SafeMemory.checkBounds(SafeMemory.java:103)\n\tat org.apache.cassandra.io.util.Memory.getLong(Memory.java:260)\n\tat org.apache.cassandra.io.compress.CompressionMetadata.chunkFor(CompressionMetadata.java:223)\n\tat org.apache.cassandra.io.compress.CompressedRandomAccessReader.reBufferMmap(CompressedRandomAccessReader.java:168)\n\tat org.apache.cassandra.io.compress.CompressedRandomAccessReader.reBuffer(CompressedRandomAccessReader.java:226)\n\tat org.apache.cassandra.io.util.RandomAccessReader.read(RandomAccessReader.java:303)\n\tat org.apache.cassandra.io.util.AbstractDataInput.readInt(AbstractDataInput.java:202)\n\tat org.apache.cassandra.io.util.AbstractDataInput.readLong(AbstractDataInput.java:264)\n\tat org.apache.cassandra.db.ColumnSerializer.deserializeColumnBody(ColumnSerializer.java:131)\n\tat org.apache.cassandra.db.OnDiskAtom$Serializer.deserializeFromSSTable(OnDiskAtom.java:92)\n\tat org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:52)\n\tat org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:46)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n\tat org.apache.cassandra.io.sstable.SSTableIdentityIterator.hasNext(SSTableIdentityIterator.java:169)\n\tat org.apache.cassandra.db.compaction.NeverPurgeTest.verifyContainsTombstones(NeverPurgeTest.java:114)\n\tat org.apache.cassandra.db.compaction.NeverPurgeTest.minorNeverPurgeTombstonesTest(NeverPurgeTest.java:85)\n{code}\n\nRelated failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_testall/598/testReport/org.apache.cassandra.db.compaction/NeverPurgeTest/minorNeverPurgeTombstonesTest/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "testall"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "testall failure in org.apache.cassandra.db.compaction.NeverPurgeTest.minorNeverPurgeTombstonesTest-compression"
   },
   {
      "_id": "13015321",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2016-10-26 06:31:33",
      "description": "We already use 7 bits for the flags of the QUERY message, and since they are encoded with a fixed size byte, we may be forced to change the structure of the message soon, and I'd like to do this in version 5 but without wasting bytes on the wire. Therefore, I propose to convert fixed flag's bytes to unsigned vints, as defined in CASSANDRA-9499. The only exception would be the flags in the frame, which should stay as fixed size.\n\nUp to 7 bits, vints are encoded the same as bytes are, so no immediate change would be required in the drivers, although they should plan to support vint flags if supporting version 5. Moving forward, when a new flag is required for the QUERY message, and eventually when other flags reach 8 bits in other messages too, the flag's bitmaps would be automatically encoded with a size that is big enough to accommodate all flags, but no bigger than required. We can currently support up to 8 bytes with unsigned vints.\n\nThe downside is that drivers need to implement unsigned vint encoding for version 5, but this is already required by CASSANDRA-11873, and will most likely be required by CASSANDRA-11622 as well.\n\nI would also like to add the list of versions to the SUPPORTED message, in order to simplify the handshake for drivers that prefer to send an OPTION message, rather than rely on receiving an error for an unsupported version in the STARTUP message. Said error should also contain the full list of supported versions, not just the min and max, for clarity, and because the latest version is now a beta version.\n\nFinally, we currently store versions as integer constants in {{Server.java}}, and we still have a fair bit of hard-coded numbers in the code, especially in tests. I plan to clean this up by introducing a {{ProtocolVersion}} enum.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "protocolv5"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Extend native protocol flags and add supported versions to the SUPPORTED response"
   },
   {
      "_id": "13014742",
      "assignee": "slebresne",
      "components": [],
      "created": "2016-10-24 14:31:46",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_testall/1250/testReport/org.apache.cassandra.index.internal/CassandraIndexTest/indexOnFirstClusteringColumn/\n\n{code}\nError Message\n\nError setting schema for test (query was: CREATE INDEX c_index ON cql_test_keyspace.table_20(c))\n{code}{code}\nStacktrace\n\njava.lang.RuntimeException: Error setting schema for test (query was: CREATE INDEX c_index ON cql_test_keyspace.table_20(c))\n\tat org.apache.cassandra.cql3.CQLTester.schemaChange(CQLTester.java:705)\n\tat org.apache.cassandra.cql3.CQLTester.createIndex(CQLTester.java:627)\n\tat org.apache.cassandra.index.internal.CassandraIndexTest.access$400(CassandraIndexTest.java:56)\n\tat org.apache.cassandra.index.internal.CassandraIndexTest$TestScript.run(CassandraIndexTest.java:626)\n\tat org.apache.cassandra.index.internal.CassandraIndexTest.indexOnFirstClusteringColumn(CassandraIndexTest.java:86)\nCaused by: org.apache.cassandra.exceptions.InvalidRequestException: Index c_index already exists\n\tat org.apache.cassandra.cql3.statements.CreateIndexStatement.validate(CreateIndexStatement.java:133)\n\tat org.apache.cassandra.cql3.CQLTester.schemaChange(CQLTester.java:696)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "testall failure in org.apache.cassandra.index.internal.CassandraIndexTest.indexOnFirstClusteringColumn"
   },
   {
      "_id": "13014242",
      "assignee": "krummas",
      "components": [],
      "created": "2016-10-21 13:42:52",
      "description": "example failure:\nhttp://cassci.datastax.com/job/trunk_testall/1243/testReport/org.apache.cassandra.db.compaction/CompactionsCQLTest/testTriggerMinorCompactionDTCS_compression/\n\n{code}\nError Message\n\nNo minor compaction triggered in 5000ms\n{code}{code}\nStacktrace\n\njunit.framework.AssertionFailedError: No minor compaction triggered in 5000ms\n\tat org.apache.cassandra.db.compaction.CompactionsCQLTest.waitForMinor(CompactionsCQLTest.java:247)\n\tat org.apache.cassandra.db.compaction.CompactionsCQLTest.testTriggerMinorCompactionDTCS(CompactionsCQLTest.java:72)\n{code}\n\nRelated failure:\nhttp://cassci.datastax.com/job/cassandra-3.X_testall/47/testReport/org.apache.cassandra.db.compaction/CompactionsCQLTest/testTriggerMinorCompactionDTCS/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "testall failure in org.apache.cassandra.db.compaction.CompactionsCQLTest.testTriggerMinorCompactionDTCS-compression"
   },
   {
      "_id": "13013513",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2016-10-19 12:56:50",
      "description": "example failure:\nhttp://cassci.datastax.com/job/trunk_testall/1239/testReport/org.apache.cassandra.dht.tokenallocator/RandomReplicationAwareTokenAllocatorTest/testExistingCluster/\n\n{code}\nError Message\n\nExpected max unit size below 1.2500, was 1.2564\n{code}\n{code}\nStacktrace\n\njunit.framework.AssertionFailedError: Expected max unit size below 1.2500, was 1.2564\n\tat org.apache.cassandra.dht.tokenallocator.AbstractReplicationAwareTokenAllocatorTest.grow(AbstractReplicationAwareTokenAllocatorTest.java:657)\n\tat org.apache.cassandra.dht.tokenallocator.RandomReplicationAwareTokenAllocatorTest.grow(RandomReplicationAwareTokenAllocatorTest.java:26)\n\tat org.apache.cassandra.dht.tokenallocator.AbstractReplicationAwareTokenAllocatorTest.testExistingCluster(AbstractReplicationAwareTokenAllocatorTest.java:545)\n\tat org.apache.cassandra.dht.tokenallocator.AbstractReplicationAwareTokenAllocatorTest.testExistingCluster(AbstractReplicationAwareTokenAllocatorTest.java:518)\n\tat org.apache.cassandra.dht.tokenallocator.RandomReplicationAwareTokenAllocatorTest.testExistingCluster(RandomReplicationAwareTokenAllocatorTest.java:38)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "testall failure in org.apache.cassandra.dht.tokenallocator.RandomReplicationAwareTokenAllocatorTest.testExistingCluster"
   },
   {
      "_id": "13013504",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2016-10-19 12:47:37",
      "description": "example failure:\nhttp://cassci.datastax.com/job/cassandra-3.0_testall/706/testReport/org.apache.cassandra.db/ColumnFamilyStoreCQLHelperTest/testDynamicComposite/\n\n{code}\nStacktrace\n\njunit.framework.AssertionFailedError: \n\tat org.apache.cassandra.db.ColumnFamilyStoreCQLHelperTest.testDynamicComposite(ColumnFamilyStoreCQLHelperTest.java:636)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "testall failure in org.apache.cassandra.db.ColumnFamilyStoreCQLHelperTest.testDynamicComposite"
   },
   {
      "_id": "13013500",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-10-19 12:44:36",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/64/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_2_x_To_indev_3_0_x/boolean_test\n\n{code}\nError Message\n\nProblem starting node node1 due to [Errno 2] No such file or directory: '/tmp/dtest-QXmxBV/test/node1/cassandra.pid'\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 2206, in boolean_test\n    for is_upgraded, cursor in self.do_upgrade(cursor):\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_base.py\", line 153, in do_upgrade\n    node1.start(wait_for_binary_proto=True, wait_other_notice=True)\n  File \"/usr/local/lib/python2.7/dist-packages/ccmlib/node.py\", line 648, in start\n    self._update_pid(process)\n  File \"/usr/local/lib/python2.7/dist-packages/ccmlib/node.py\", line 1780, in _update_pid\n    raise NodeError('Problem starting node %s due to %s' % (self.name, e), process)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_2_x_To_indev_3_0_x.boolean_test"
   },
   {
      "_id": "13012889",
      "assignee": "cassandra-te",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2016-10-17 15:12:10",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1396/testReport/json_test/FromJsonSelectTests/select_using_secondary_index_test\n\n{code}\nError Message\n\nDoctest failed! Captured output:\n**********************************************************************\nLine 25, in select_using_secondary_index_test\nFailed example:\n    cqlsh_print('''\n    SELECT * from person_likes where name = fromJson('{\"first\":\"test\", \"middle\":\"guy\", \"last\":\"jones\"}')\n    ''')\nException raised:\n    Traceback (most recent call last):\n      File \"/usr/lib/python2.7/doctest.py\", line 1315, in __run\n        compileflags, 1) in test.globs\n      File \"<doctest select_using_secondary_index_test[4]>\", line 3, in <module>\n        ''')\n      File \"/home/automaton/cassandra-dtest/json_test.py\", line 105, in cqlsh_print\n        output = cqlsh(cmds, supress_err=supress_err)\n      File \"/home/automaton/cassandra-dtest/json_test.py\", line 95, in cqlsh\n        raise RuntimeError(\"Unexpected cqlsh error: {}\".format(err))\n    RuntimeError: Unexpected cqlsh error: <stdin>:4:'ResultSet' object has no attribute 'column_types'\n{code}\n\nThere are more tests which have failed with this error on this build.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in json_test.FromJsonSelectTests.select_using_secondary_index_test"
   },
   {
      "_id": "13011692",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-10-12 14:57:25",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.X_dtest/6/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_marking_test_not_intersecting_all_ranges\n\n{code}\nError Message\n\nSubprocess sstablemetadata on keyspace: keyspace1, column_family: None exited with non-zero status; exit status: 1; \nstdout: \nusage: Usage: sstablemetadata [--gc_grace_seconds n] <sstable filenames>\nDump contents of given SSTable to standard output in JSON format.\n    --gc_grace_seconds <arg>   The gc_grace_seconds to use when\n                               calculating droppable tombstones\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/repair_tests/incremental_repair_test.py\", line 369, in sstable_marking_test_not_intersecting_all_ranges\n    for out in (node.run_sstablemetadata(keyspace='keyspace1').stdout for node in cluster.nodelist()):\n  File \"/home/automaton/cassandra-dtest/repair_tests/incremental_repair_test.py\", line 369, in <genexpr>\n    for out in (node.run_sstablemetadata(keyspace='keyspace1').stdout for node in cluster.nodelist()):\n  File \"/usr/local/lib/python2.7/dist-packages/ccmlib/node.py\", line 1021, in run_sstablemetadata\n    return handle_external_tool_process(p, \"sstablemetadata on keyspace: {}, column_family: {}\".format(keyspace, column_families))\n  File \"/usr/local/lib/python2.7/dist-packages/ccmlib/node.py\", line 1983, in handle_external_tool_process\n    raise ToolError(cmd_args, rc, out, err)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.incremental_repair_test.TestIncRepair.sstable_marking_test_not_intersecting_all_ranges"
   },
   {
      "_id": "13011689",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328216",
            "id": "12328216",
            "name": "Legacy/Distributed Metadata",
            "description": "Gossip, Schema, Auth"
         }
      ],
      "created": "2016-10-12 14:52:38",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.X_dtest/4/testReport/pushed_notifications_test/TestPushedNotifications/restart_node_test\n\n{code}\nError Message\n\n[{'change_type': u'DOWN', 'address': ('127.0.0.2', 9042)}, {'change_type': u'UP', 'address': ('127.0.0.2', 9042)}, {'change_type': u'DOWN', 'address': ('127.0.0.2', 9042)}]\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/pushed_notifications_test.py\", line 181, in restart_node_test\n    self.assertEquals(expected_notifications, len(notifications), notifications)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Disable RPC_READY gossip flag when shutting down client servers"
   },
   {
      "_id": "13011682",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-10-12 14:35:49",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/13/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_1_x/in_order_by_without_selecting_test\n\n{code}\nError Message\n\nExpected [[3], [4], [5], [0], [1], [2]] from SELECT v FROM test WHERE k IN (1, 0), but got [[0], [1], [2], [3], [4], [5]]\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 46, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 4200, in in_order_by_without_selecting_test\n    assert_all(cursor, \"SELECT v FROM test WHERE k IN (1, 0)\", [[3], [4], [5], [0], [1], [2]])\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 169, in assert_all\n    assert list_res == expected, \"Expected {} from {}, but got {}\".format(expected, query, list_res)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_1_x.in_order_by_without_selecting_test"
   },
   {
      "_id": "13011680",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-10-12 14:32:12",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/13/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_0_x_To_indev_2_1_x/limit_multiget_test\n\n{code}\nError Message\n\nExpected [[48, 'http://foo.com', 42]] from SELECT * FROM clicks WHERE userid IN (48, 2) LIMIT 1, but got [[2, u'http://foo.com', 42]]\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 362, in limit_multiget_test\n    assert_one(cursor, \"SELECT * FROM clicks WHERE userid IN (48, 2) LIMIT 1\", [48, 'http://foo.com', 42])\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 130, in assert_one\n    assert list_res == [expected], \"Expected {} from {}, but got {}\".format([expected], query, list_res)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_0_x_To_indev_2_1_x.limit_multiget_test"
   },
   {
      "_id": "13009153",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-10-03 02:49:44",
      "description": "-If we bundle the driver to cqlsh using the 3.6.0 tag or cassandra_test head, some cqlsh copy tests hang, for example {{test_bulk_round_trip_blogposts}}. See CASSANDRA-12736 and CASSANDRA-11534 for some sample failures.-\n\nIf the driver fails to invoke a callback (either error or success), or if the server never answers to the driver, then the copy parent process will wait forever to receive an answer from child processes. We should put a cap to this. We should also use a very high timeout rather than None, so that the driver will notify us if there is no answer from the server.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh copy tests hang in case of no answer from the server or driver"
   },
   {
      "_id": "13008909",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-09-30 15:27:51",
      "description": "Trunk was recently updated to be version 4.0. The bundled python driver that cqlsh uses has a bug where it fails to connect to a C* server with a major version number greater than 3. The driver was fixed upstream, and we should pull in the fix.\n\n[~pauloricardomg] or [~stefania]?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Update the bundled python driver on trunk"
   },
   {
      "_id": "13008288",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-09-28 16:38:09",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest_upgrade/58/testReport/upgrade_tests.paging_test/TestPagingWithModifiersNodes2RF1_Upgrade_current_3_x_To_indev_3_x/test_with_allow_filtering\n\nThis is happening on many trunk upgrade tests. See : http://cassci.datastax.com/job/trunk_dtest_upgrade/58/testReport/\n\n{code}\nStandard Output\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:d45f323eb972c6fec146e5cfa84fdc47eb8aa5eb\nUnexpected error in node2 log, error: \nERROR [MessagingService-Incoming-/127.0.0.1] 2016-09-28 04:30:11,223 CassandraDaemon.java:217 - Exception in thread Thread[MessagingService-Incoming-/127.0.0.1,5,main]\njava.lang.RuntimeException: Unknown column cdc during deserialization\n\tat org.apache.cassandra.db.Columns$Serializer.deserialize(Columns.java:433) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.SerializationHeader$Serializer.deserializeForMessaging(SerializationHeader.java:407) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.deserializeHeader(UnfilteredRowIteratorSerializer.java:192) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.deserialize30(PartitionUpdate.java:668) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.deserialize(PartitionUpdate.java:656) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.Mutation$MutationSerializer.deserialize(Mutation.java:341) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.Mutation$MutationSerializer.deserialize(Mutation.java:350) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.service.MigrationManager$MigrationsSerializer.deserialize(MigrationManager.java:610) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.service.MigrationManager$MigrationsSerializer.deserialize(MigrationManager.java:593) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.net.MessageIn.read(MessageIn.java:114) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:190) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:178) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:92) ~[apache-cassandra-3.7.jar:3.7]\nUnexpected error in node2 log, error: \nERROR [MessagingService-Incoming-/127.0.0.1] 2016-09-28 04:30:11,270 CassandraDaemon.java:217 - Exception in thread Thread[MessagingService-Incoming-/127.0.0.1,5,main]\njava.lang.RuntimeException: Unknown column cdc during deserialization\n\tat org.apache.cassandra.db.Columns$Serializer.deserialize(Columns.java:433) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.SerializationHeader$Serializer.deserializeForMessaging(SerializationHeader.java:407) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.deserializeHeader(UnfilteredRowIteratorSerializer.java:192) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.deserialize30(PartitionUpdate.java:668) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.deserialize(PartitionUpdate.java:656) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.Mutation$MutationSerializer.deserialize(Mutation.java:341) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.Mutation$MutationSerializer.deserialize(Mutation.java:350) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.service.MigrationManager$MigrationsSerializer.deserialize(MigrationManager.java:610) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.service.MigrationManager$MigrationsSerializer.deserialize(MigrationManager.java:593) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.net.MessageIn.read(MessageIn.java:114) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:190) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:178) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:92) ~[apache-cassandra-3.7.jar:3.7]\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.paging_test.TestPagingWithModifiersNodes2RF1_Upgrade_current_3_x_To_indev_3_x.test_with_allow_filtering"
   },
   {
      "_id": "13008285",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-28 16:31:54",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/406/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_marking_test_not_intersecting_all_ranges\n\n{code}\nError Message\n\nSubprocess sstablemetadata on keyspace: keyspace1, column_family: None exited with non-zero status; exit status: 1; \nstdout: \nusage: Usage: sstablemetadata [--gc_grace_seconds n] <sstable filenames>\nDump contents of given SSTable to standard output in JSON format.\n    --gc_grace_seconds <arg>   The gc_grace_seconds to use when\n                               calculating droppable tombstones\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/repair_tests/incremental_repair_test.py\", line 366, in sstable_marking_test_not_intersecting_all_ranges\n    for out in (node.run_sstablemetadata(keyspace='keyspace1').stdout for node in cluster.nodelist()):\n  File \"/home/automaton/cassandra-dtest/repair_tests/incremental_repair_test.py\", line 366, in <genexpr>\n    for out in (node.run_sstablemetadata(keyspace='keyspace1').stdout for node in cluster.nodelist()):\n  File \"/usr/local/lib/python2.7/dist-packages/ccmlib/node.py\", line 1021, in run_sstablemetadata\n    return handle_external_tool_process(p, \"sstablemetadata on keyspace: {}, column_family: {}\".format(keyspace, column_families))\n  File \"/usr/local/lib/python2.7/dist-packages/ccmlib/node.py\", line 1983, in handle_external_tool_process\n    raise ToolError(cmd_args, rc, out, err)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.incremental_repair_test.TestIncRepair.sstable_marking_test_not_intersecting_all_ranges"
   },
   {
      "_id": "13008281",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-28 16:22:24",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/818/testReport/materialized_views_test/TestMaterializedViews/clustering_column_test\n\n{code}\nError Message\n\n'TestMaterializedViews' object has no attribute '_settled_stages'\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/materialized_views_test.py\", line 367, in clustering_column_test\n    self._insert_data(session)\n  File \"/home/automaton/cassandra-dtest/materialized_views_test.py\", line 96, in _insert_data\n    self._settle_nodes()\n  File \"/home/automaton/cassandra-dtest/materialized_views_test.py\", line 85, in _settle_nodes\n    while attempts > 0 and not self._settled_stages(node):\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.clustering_column_test"
   },
   {
      "_id": "13008278",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-09-28 16:18:50",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_1_x/in_order_by_without_selecting_test\n\n{code}\nError Message\n\nExpected [[3], [4], [5], [0], [1], [2]] from SELECT v FROM test WHERE k IN (1, 0), but got [[0], [1], [2], [3], [4], [5]]\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 46, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 4200, in in_order_by_without_selecting_test\n    assert_all(cursor, \"SELECT v FROM test WHERE k IN (1, 0)\", [[3], [4], [5], [0], [1], [2]])\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 169, in assert_all\n    assert list_res == expected, \"Expected {} from {}, but got {}\".format(expected, query, list_res)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_1_x.in_order_by_without_selecting_test"
   },
   {
      "_id": "13008275",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-28 16:15:14",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_0_x_To_indev_2_1_x/limit_multiget_test\n\n{code}\nError Message\n\nExpected [[48, 'http://foo.com', 42]] from SELECT * FROM clicks WHERE userid IN (48, 2) LIMIT 1, but got [[2, u'http://foo.com', 42]]\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 359, in limit_multiget_test\n    assert_one(cursor, \"SELECT * FROM clicks WHERE userid IN (48, 2) LIMIT 1\", [48, 'http://foo.com', 42])\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 130, in assert_one\n    assert list_res == [expected], \"Expected {} from {}, but got {}\".format([expected], query, list_res)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_0_x_To_indev_2_1_x.limit_multiget_test"
   },
   {
      "_id": "13007588",
      "assignee": "krummas",
      "components": [],
      "created": "2016-09-26 14:13:20",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/485/testReport/compaction_test/TestCompaction_with_DateTieredCompactionStrategy/bloomfilter_size_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/compaction_test.py\", line 153, in bloomfilter_size_test\n    self.assertLessEqual(bfSize, size_factor * max_bf_size)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 936, in assertLessEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"457864 not less than or equal to 400000.0\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_DateTieredCompactionStrategy.bloomfilter_size_test"
   },
   {
      "_id": "13007219",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328758",
            "id": "12328758",
            "name": "Legacy/Core",
            "description": "StorageEngine, Types, Serializers"
         }
      ],
      "created": "2016-09-23 18:31:13",
      "description": "Some tools schedule a lot of small subrange repairs which can lead to a lot of repairs constantly being run. These partitions can grow pretty big in theory. I dont think much reads from them which might help but its still kinda wasted disk space. I think a month TTL (longer than gc grace) and maybe a 1 day twcs window makes sense to me.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Repair history tables should have TTL and TWCS"
   },
   {
      "_id": "13006548",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-21 15:52:45",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/9/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_0_x_To_indev_2_1_x/conditional_update_test\n\n{code}\nError Message\n\n<Error from server: code=2000 [Syntax error in CQL query] message=\"line 1:35 no viable alternative at input 'IN'\">\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 3028, in conditional_update_test\n    assert_one(cursor, \"DELETE FROM test WHERE k = 0 IF v1 IN (null)\", [True])\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 128, in assert_one\n    res = session.execute(simple_query)\n  File \"cassandra/cluster.py\", line 1998, in cassandra.cluster.Session.execute (cassandra/cluster.c:34869)\n    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state).result()\n  File \"cassandra/cluster.py\", line 3781, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:73073)\n    raise self._final_exception\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_0_x_To_indev_2_1_x.conditional_update_test"
   },
   {
      "_id": "13005923",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-19 14:27:56",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/508/testReport/json_tools_test/TestJson/json_tools_test/\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/json_tools_test.py\", line 23, in json_tools_test\n    debug(\"Version: \" + cluster.version())\n\"cannot concatenate 'str' and 'instance' objects\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in json_tools_test.TestJson.json_tools_test"
   },
   {
      "_id": "13005445",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-16 13:49:19",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest-skipped-with-require/434/testReport/nose.failure/Failure/runTest\n\n{code}\nStacktrace\n\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/usr/local/lib/python2.7/dist-packages/nose/loader.py\", line 418, in loadTestsFromName\n    addr.filename, addr.module)\n  File \"/usr/local/lib/python2.7/dist-packages/nose/importer.py\", line 47, in importFromPath\n    return self.importFromDir(dir_path, fqname)\n  File \"/usr/local/lib/python2.7/dist-packages/nose/importer.py\", line 94, in importFromDir\n    mod = load_module(part_fqname, fh, filename, desc)\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/paging_test.py\", line 18, in <module>\n    from upgrade_base import UpgradeTester\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_base.py\", line 33, in <module>\n    class UpgradeTester(Tester):\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_base.py\", line 47, in UpgradeTester\n    if LooseVersion(CASSANDRA_VERSION_FROM_BUILD) < '2.2':\n  File \"/usr/lib/python2.7/distutils/version.py\", line 265, in __init__\n    self.parse(vstring)\n  File \"/usr/lib/python2.7/distutils/version.py\", line 274, in parse\n    self.component_re.split(vstring))\nTypeError: expected string or buffer\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in nose.failure.Failure.runTest"
   },
   {
      "_id": "13005008",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-09-14 21:29:30",
      "description": "In {{cqlsh}}, with authentication enabled, when sourcing a file with {{COPY}} commands in it:\n{noformat}\ntest.cql:2:Error for (None, None): Failed to connect to all replicas ['127.0.0.1'] for (None, None), errors: [\"NoHostAvailable - ('Unable to connect to any servers', {'127.0.0.1': AuthenticationFailed('Remote end requires authentication.',)})\"] (permanently given up after 0 rows and 5 attempts)\n{noformat}\n\n{{cqlsh}} creates a new {{Shell}} without passing all pertinent arguments. When {{copyutil}} creates new cluster connections, they are not initialized correctly.\n\nThis is only for the {{source}} command. As a workaround,  {{cqlsh -f <script>}}  works, since it does not create a new {{Shell}} instance.\n\nRepro:\n\n{code}\nccm create -v 3.7 -n 1 test\nccm updateconf \"authenticator: PasswordAuthenticator\" \"authorizer: CassandraAuthorizer\"\nccm start\n\necho \"copy system.local to 'something';\" > test.cql\n\necho \"source 'test.cql'\" | ccm node1 cqlsh\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh NoHostsAvailable/AuthenticationFailure when sourcing a file with COPY commands"
   },
   {
      "_id": "13004628",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-13 15:02:41",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/478/testReport/repair_tests.repair_test/TestRepairDataSystemTable/repair_parent_table_test\n\n{code}\nstderr: WARN  02:48:18,362 No schema agreement from live replicas after 10 s. The schema may not be up to date on some nodes.\njava.lang.RuntimeException: Encountered exception creating schema\n\tat org.apache.cassandra.stress.settings.SettingsSchema.createKeySpacesNative(SettingsSchema.java:101)\n\tat org.apache.cassandra.stress.settings.SettingsSchema.createKeySpaces(SettingsSchema.java:69)\n\tat org.apache.cassandra.stress.settings.StressSettings.maybeCreateKeyspaces(StressSettings.java:228)\n\tat org.apache.cassandra.stress.StressAction.run(StressAction.java:59)\n\tat org.apache.cassandra.stress.Stress.run(Stress.java:143)\n\tat org.apache.cassandra.stress.Stress.main(Stress.java:62)\nCaused by: com.datastax.driver.core.exceptions.InvalidQueryException: Keyspace 'keyspace1' does not exist\n\tat com.datastax.driver.core.exceptions.InvalidQueryException.copy(InvalidQueryException.java:50)\n\tat com.datastax.driver.core.DriverThrowables.propagateCause(DriverThrowables.java:37)\n\tat com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:245)\n\tat com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:63)\n\tat org.apache.cassandra.stress.util.JavaDriverClient.execute(JavaDriverClient.java:183)\n\tat org.apache.cassandra.stress.settings.SettingsSchema.createKeySpacesNative(SettingsSchema.java:86)\n\t... 5 more\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 320, in run\n    self.setUp()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 32, in wrapped_setUp\n    orig_setUp(obj, *args, **kwargs)\n  File \"/home/automaton/cassandra-dtest/repair_tests/repair_test.py\", line 1082, in setUp\n    self.node1.stress(stress_options=['write', 'n=5K', 'no-warmup', 'cl=ONE', '-schema', 'replication(factor=3)'])\n  File \"/home/automaton/src/ccm/ccmlib/node.py\", line 1256, in stress\n    return handle_external_tool_process(p, ['stress'] + stress_options)\n  File \"/home/automaton/src/ccm/ccmlib/node.py\", line 1985, in handle_external_tool_process\n    raise ToolError(cmd_args, rc, out, err)\n{code}\n\nThere are no logs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.repair_test.TestRepairDataSystemTable.repair_parent_table_test"
   },
   {
      "_id": "13004611",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-13 14:47:11",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest_upgrade/31/testReport/upgrade_tests.storage_engine_upgrade_test/TestBootstrapAfterUpgrade/upgrade_with_range_tombstone_eoc_0_test\n\n{code}\nError Message\n\nExpected [] to have length 2, but instead is of length 0\n\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/storage_engine_upgrade_test.py\", line 421, in upgrade_with_range_tombstone_eoc_0_test\n    assert_length_equal(ret, 2)\n  File \"/home/automaton/cassandra-dtest/tools/assertions.py\", line 249, in assert_length_equal\n    expected_length, len(object_with_length)))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n{code}\n\nRelated failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest_upgrade/31/testReport/upgrade_tests.storage_engine_upgrade_test/TestStorageEngineUpgrade/upgrade_with_range_tombstone_eoc_0_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.storage_engine_upgrade_test.TestBootstrapAfterUpgrade.upgrade_with_range_tombstone_eoc_0_test"
   },
   {
      "_id": "13004610",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-13 14:42:31",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_novnode_dtest/48/testReport/replace_address_test/TestReplaceAddress/insert_data_during_replace_same_address_test\n\n{code}\nError Message\n\n13 Sep 2016 05:42:44 [replacement] Missing: ['Writes will not be forwarded to this node during replacement']:\nINFO  [main] 2016-09-13 05:41:07,618 YamlConfigura.....\nSee system.log for remainder\n\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 48, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/replace_address_test.py\", line 422, in insert_data_during_replace_same_address_test\n    self._test_insert_data_during_replace(same_address=True)\n  File \"/home/automaton/cassandra-dtest/replace_address_test.py\", line 217, in _test_insert_data_during_replace\n    self._do_replace(same_address=same_address, extra_jvm_args=[\"-Dcassandra.write_survey=true\"])\n  File \"/home/automaton/cassandra-dtest/replace_address_test.py\", line 112, in _do_replace\n    timeout=60)\n  File \"/home/automaton/src/ccm/ccmlib/node.py\", line 450, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in replace_address_test.TestReplaceAddress.insert_data_during_replace_same_address_test"
   },
   {
      "_id": "13004607",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-13 14:36:41",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_novnode_dtest/48/testReport/replace_address_test/TestReplaceAddress/insert_data_during_replace_different_address_test\n\n{code}\nError Message\n\nSubprocess ['nodetool', '-h', 'localhost', '-p', '7400', ['join']] exited with non-zero status; exit status: 1; \nstdout: nodetool: This node has already joined the ring.\n\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 48, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/replace_address_test.py\", line 430, in insert_data_during_replace_different_address_test\n    self._test_insert_data_during_replace(same_address=False)\n  File \"/home/automaton/cassandra-dtest/replace_address_test.py\", line 228, in _test_insert_data_during_replace\n    self.replacement_node.nodetool(\"join\")\n  File \"/home/automaton/src/ccm/ccmlib/node.py\", line 756, in nodetool\n    return handle_external_tool_process(p, ['nodetool', '-h', 'localhost', '-p', str(self.jmx_port), cmd.split()])\n  File \"/home/automaton/src/ccm/ccmlib/node.py\", line 1985, in handle_external_tool_process\n    raise ToolError(cmd_args, rc, out, err)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in replace_address_test.TestReplaceAddress.insert_data_during_replace_different_address_test"
   },
   {
      "_id": "13004603",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-09-13 14:32:19",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_novnode_dtest/48/testReport/thrift_tests/TestMutations/test_range_tombstone_eoc_0\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/thrift_tests.py\", line 2588, in test_range_tombstone_eoc_0\n    self.assertEquals(2, len(ret))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n'2 != 0\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in thrift_tests.TestMutations.test_range_tombstone_eoc_0"
   },
   {
      "_id": "13002396",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-09-02 15:56:17",
      "description": "This failure is happening on many different tests in [trunk_offheap_dtest #389|http://cassci.datastax.com/job/trunk_offheap_dtest/389/].\n\nOne example:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/389/testReport/auth_test/TestAuth/auth_metrics_test/\n\nFrom the logs:\n{code}\nERROR [main] 2016-09-02 01:13:43,688 CassandraDaemon.java:752 - Local host name unknown: java.net.UnknownHostException: openstack-cassci-external-df85c4d-jenkins-trunk-offheap-dtest-3: openstack-cassci-external-df85c4d-jenkins-trunk-offheap-dtest-3: unknown error\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in auth_test.TestAuth.auth_metrics_test"
   },
   {
      "_id": "13002387",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-09-02 15:31:06",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/687/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_pep8_compliance\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 48, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_tests.py\", line 67, in test_pep8_compliance\n    p = subprocess.Popen(cmds, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n  File \"/usr/lib/python2.7/subprocess.py\", line 710, in __init__\n    errread, errwrite)\n  File \"/usr/lib/python2.7/subprocess.py\", line 1335, in _execute_child\n    raise child_exception\n\"[Errno 2] No such file or directory\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_tests.TestCqlsh.test_pep8_compliance"
   },
   {
      "_id": "13001795",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2016-08-31 19:12:10",
      "description": "We ran into an issue on production where reads began to fail for certain queries, depending on the range within the relation for those queries. Cassandra system log showed an unhandled {{CorruptSSTableException}} exception.\n\nCQL read failure:\n{code}\nReadFailure: code=1300 [Replica(s) failed to execute read] message=\"Operation failed - received 0 responses and 1 failures\" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}\n{code}\n\nCassandra exception:\n{code}\nWARN  [SharedPool-Worker-2] 2016-08-31 12:49:27,979 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[SharedPool-Worker-2,5,main]: {}\njava.lang.RuntimeException: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db\n  at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2453) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_72]\n  at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-3.0.8.jar:3.0.8]\n  at java.lang.Thread.run(Thread.java:745) [na:1.8.0_72]\nCaused by: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db\n  at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator$1.initializeIterator(BigTableScanner.java:343) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.maybeInit(LazilyInitializedUnfilteredRowIterator.java:48) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.isReverseOrder(LazilyInitializedUnfilteredRowIterator.java:65) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.isReverseOrder(LazilyInitializedUnfilteredRowIterator.java:66) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:62) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:24) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:96) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:295) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:134) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.ReadResponse$LocalDataResponse.<init>(ReadResponse.java:127) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.ReadResponse$LocalDataResponse.<init>(ReadResponse.java:123) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:65) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:289) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1796) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2449) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  ... 5 common frames omitted\nCaused by: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /usr/local/apache-cassandra-3.0.8/data/data/issue309/apples_by_tree-006748a06fa311e6a7f8ef8b642e977b/mb-1-big-Data.db\n  at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.<init>(AbstractSSTableIterator.java:130) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.columniterator.SSTableIterator.<init>(SSTableIterator.java:46) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.io.sstable.format.big.BigTableReader.iterator(BigTableReader.java:69) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator$1.initializeIterator(BigTableScanner.java:338) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  ... 19 common frames omitted\nCaused by: java.io.IOException: Corrupt (negative) value length encountered\n  at org.apache.cassandra.db.marshal.AbstractType.readValue(AbstractType.java:399) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.rows.BufferCell$Serializer.deserialize(BufferCell.java:302) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.rows.UnfilteredSerializer.readSimpleColumn(UnfilteredSerializer.java:462) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeRowBody(UnfilteredSerializer.java:440) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeStaticRow(UnfilteredSerializer.java:381) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.readStaticRow(AbstractSSTableIterator.java:179) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.<init>(AbstractSSTableIterator.java:103) ~[apache-cassandra-3.0.8.jar:3.0.8]\n  ... 22 common frames omitted\n{code}\n\nAfter debugging, it appears that a previously dropped static column (weeks prior) was the instigator of the issue. As a workaround we added back the column, restarted all cassandra processes within the cluster, and the read error and corruption exception went away.\n\nAttached is a script to reproduce with a simple schema.\n\nAlso noteworthy (and shown in the script) is that when in this state, compaction silently failed (exit 0) to remove the dropped static columns from the \"corrupted\" sstable.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "corruption",
         "drop",
         "read",
         "static"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Removing static column results in ReadFailure due to CorruptSSTableException"
   },
   {
      "_id": "13001685",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-31 14:45:12",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/50/testReport/cql_tracing_test/TestCqlTracing/tracing_default_impl_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 48, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cql_tracing_test.py\", line 163, in tracing_default_impl_test\n    errs[0][1])\n'list index out of range\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tracing_test.TestCqlTracing.tracing_default_impl_test"
   },
   {
      "_id": "13001682",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-31 14:42:59",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/50/testReport/repair_tests.repair_test/TestRepair/nonexistent_table_repair_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/repair_tests/repair_test.py\", line 210, in nonexistent_table_repair_test\n    self.assertFalse(t.isAlive(), 'Repair thread on inexistent table is still running')\n  File \"/usr/lib/python2.7/unittest/case.py\", line 416, in assertFalse\n    raise self.failureException(msg)\n\"Repair thread on inexistent table is still running\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.repair_test.TestRepair.nonexistent_table_repair_test"
   },
   {
      "_id": "13001679",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-31 14:37:15",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/301/testReport/materialized_views_test/TestMaterializedViews/add_dc_after_mv_simple_replication_test/\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/materialized_views_test.py\", line 389, in add_dc_after_mv_simple_replication_test\n    self._add_dc_after_mv_test(1)\n  File \"/home/automaton/cassandra-dtest/materialized_views_test.py\", line 363, in _add_dc_after_mv_test\n    node5.start(jvm_args=[\"-Dcassandra.migration_task_wait_in_seconds={}\".format(MIGRATION_WAIT)])\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 636, in start\n    self._update_pid(process)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 1770, in _update_pid\n    raise NodeError('Problem starting node %s due to %s' % (self.name, e), process)\n\"Problem starting node node5 due to [Errno 2] No such file or directory: '/tmp/dtest-S4bmF0/test/node5/cassandra.pid'\n{code}\n\nRelated failure:\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/301/testReport/materialized_views_test/TestMaterializedViews/add_dc_after_mv_network_replication_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.add_dc_after_mv_simple_replication_test"
   },
   {
      "_id": "13001382",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-08-30 16:34:53",
      "description": "In commit c7f0032912798b5e53b64d8391e3e3d7e4121165, when client_timeout became request_timeout, the logic was changed so that you can no longer use a timeout of None, despite the docs saying that you can:\n\nhttps://docs.datastax.com/en/cql/3.3/cql/cql_reference/cqlshUsingCqlshrc.html#cqlshUsingCqlshrc__request-timeout",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "doc-impacting",
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh lost the ability to have a request wait indefinitely"
   },
   {
      "_id": "13001054",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-29 17:41:46",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/385/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_bulk_round_trip_with_backoff\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 1123, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/tools/decorators.py\", line 48, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2565, in test_bulk_round_trip_with_backoff\n    copy_from_options={'MAXINFLIGHTMESSAGES': 64, 'MAXPENDINGCHUNKS': 1})\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2454, in _test_bulk_round_trip\n    sum(1 for _ in open(tempfile2.name)))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"250000 != 249714\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_bulk_round_trip_with_backoff"
   },
   {
      "_id": "13000352",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-26 12:27:12",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/49/testReport/paging_test/TestPagingDatasetChanges/test_cell_TTL_expiry_during_paging\n\n{code}\nError Message\n\nError from server: code=2200 [Invalid query] message=\"unconfigured table paging_test\"\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-V_YoOr\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\n--------------------- >> end captured logging << ---------------------\n\n{code}\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/paging_test.py\", line 2660, in test_cell_TTL_expiry_during_paging\n    session, 'paging_test', cl=CL.ALL, format_funcs={'id': int, 'mytext': random_txt}\n  File \"/home/automaton/cassandra-dtest/datahelp.py\", line 130, in create_rows\n    vals=', '.join('?' for k in dicts[0].keys()), postfix=postfix)\n  File \"cassandra/cluster.py\", line 2162, in cassandra.cluster.Session.prepare (cassandra/cluster.c:37231)\n    raise\n  File \"cassandra/cluster.py\", line 2159, in cassandra.cluster.Session.prepare (cassandra/cluster.c:37087)\n    query_id, bind_metadata, pk_indexes, result_metadata = future.result()\n  File \"cassandra/cluster.py\", line 3665, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:70216)\n    raise self._final_exception\n'Error from server: code=2200 [Invalid query] message=\"unconfigured table paging_test\"\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-V_YoOr\\ndtest: DEBUG: Done setting configuration options:\\n{   \\'initial_token\\': None,\\n    \\'num_tokens\\': \\'32\\',\\n    \\'phi_convict_threshold\\': 5,\\n    \\'range_request_timeout_in_ms\\': 10000,\\n    \\'read_request_timeout_in_ms\\': 10000,\\n    \\'request_timeout_in_ms\\': 10000,\\n    \\'truncate_request_timeout_in_ms\\': 10000,\\n    \\'write_request_timeout_in_ms\\': 10000}\\n--------------------- >> end captured logging << ---------------------'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in paging_test.TestPagingDatasetChanges.test_cell_TTL_expiry_during_paging"
   },
   {
      "_id": "13000022",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-25 13:55:10",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1350/testReport/cdc_test/TestCDC/test_cdc_data_available_in_cdc_raw/\n\n{code}\nError Message\n\n25 Aug 2016 04:01:25 [node2] Missing: ['Starting listening for CQL clients']:\nINFO  [main] 2016-08-25 03:51:25,259 YamlConfigura.....\nSee system.log for remainder\n\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cdc_test.py\", line 515, in test_cdc_data_available_in_cdc_raw\n    loading_node.start(wait_for_binary_proto=True)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 655, in start\n    self.wait_for_binary_interface(from_mark=self.mark)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 493, in wait_for_binary_interface\n    self.watch_log_for(\"Starting listening for CQL clients\", **kwargs)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 450, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cdc_test.TestCDC.test_cdc_data_available_in_cdc_raw"
   },
   {
      "_id": "12999380",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2016-08-23 22:03:34",
      "description": "I'm using the latest trunk (as of August 2016, which probably is going to be 3.10) to run some experiments on LeveledCompactionStrategy and noticed this inefficiency.\n\nThe test data is generated using cassandra-stress default parameters (keyspace1.standard1), so as you can imagine, it consists of a ton of newly inserted partitions that will never merge in compactions, which is probably the worst kind of workload for LCS (however, I'll detail later why this scenario should not be ignored as a corner case; for now, let's just assume we still want to handle this scenario efficiently).\n\nAfter the compaction test is done, I scrubbed debug.log for patterns that match  the \"Compacted\" summary so that I can see how long each individual compaction took and how many bytes they processed. The search pattern is like the following:\n\n{noformat}\ngrep 'Compacted.*standard1' debug.log\n{noformat}\n\nInterestingly, I noticed a lot of the finished compactions are marked as having *only one* SSTable involved. With the workload mentioned above, the \"single SSTable\" compactions actually consist of the majority of all compactions (as shown below), so its efficiency can affect the overall compaction throughput quite a bit.\n\n{noformat}\nautomaton@0ce59d338-1:~/cassandra-trunk/logs$ grep 'Compacted.*standard1' debug.log-test1 | wc -l\n243\nautomaton@0ce59d338-1:~/cassandra-trunk/logs$ grep 'Compacted.*standard1' debug.log-test1 | grep \") 1 sstable\" | wc -l\n218\n{noformat}\n\nBy looking at the code, it appears that there's a way to directly edit the level of a particular SSTable like the following:\n\n{code}\nsstable.descriptor.getMetadataSerializer().mutateLevel(sstable.descriptor, targetLevel);\nsstable.reloadSSTableMetadata();\n{code}\n\nTo be exact, I summed up the time spent for these single-SSTable compactions (the total data size is 60GB) and found that if each compaction only needs to spend 100ms for only the metadata change (instead of the 10+ second they're doing now), it can already achieve 22.75% saving on total compaction time.\n\nCompared to what we have now (reading the whole single-SSTable from old level and writing out the same single-SSTable at the new level), the only difference I could think of by using this approach is that the new SSTable will have the same file name (sequence number) as the old one's, which could break some assumptions on some other part of the code. However, not having to go through the full read/write IO, and not having to bear the overhead of cleaning up the old file, creating the new file, creating more churns in heap and file buffer, it seems the benefits outweigh the inconvenience. So I'd argue this JIRA belongs to LHF and should be made available in 3.0.x as well.\n\nAs mentioned in the 2nd paragraph, I'm also going to address why this kind of all-new-partition workload should not be ignored as a corner case. Basically, for the main use case of LCS where you need to frequently merge partitions to optimize read and eliminate tombstones and expired data sooner, LCS can be perfectly happy and efficiently perform the partition merge and tombstone elimination for a long time. However, as soon as the node becomes a bit unhealthy for various reasons (could be a bad disk so it's missing a whole bunch of mutations and need repair, could be the user chooses to ingest way more data than it usually takes and exceeds its capability, or god-forbidden, some DBA chooses to run offline sstablelevelreset), you will have to handle this kind of \"all-new-partition with a lot of SSTables in L0\" scenario, and once all L0 SSTables finally gets up-leveled to L1, you will likely see a lot of such single-SSTable compactions, which is the situation this JIRA is intended to address.\n\nActually, when I think more about this, to make this kind of single SSTable up-level more efficient will not only help the all-new-partition scenario, but also help in general any time when there is a big backlog of L0 SSTables due to too many flushes or excessive repair streaming with vnode. In those situations, by default STCS_in_L0 will be triggered, and you will end up getting a bunch of much bigger L0 SSTables after STCS is done. When it's time to up-level those much bigger L0 SSTables most likely they will overlap among themselves and you will add them all into your compaction session (along with all overlapped L1 SSTables). For these much bigger L0 SSTables, they have gone through a few rounds of STCS compactions, so if there's partition merge that needs to be done because fragments of the same partition are dispersed in smaller L0 SSTables earlier, after those STCS rounds, what you end up having in those much bigger L0 SSTables (generated by STCS) will not have much more opportunity for partition merge to happen, so we're in a scenario very similar to L0 data \"consists of a ton of newly inserted partitions that will never merge in compactions\" mentioned earlier.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "lcs",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "For LCS, single SSTable up-level is handled inefficiently"
   },
   {
      "_id": "12998917",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-22 14:59:50",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest_upgrade/30/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_3_x_To_indev_3_x/select_with_alias_test\n\n{code}\nError Message\n\nRegexp didn't match: \"Aliases aren't allowed in the where clause\" not found in 'Error from server: code=2200 [Invalid query] message=\"Undefined column name user_id\"'\n{code}\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 3189, in select_with_alias_test\n    assert_invalid(cursor, 'SELECT id AS user_id, name AS user_name FROM users WHERE user_id = 0', matching=error_msg)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 92, in assert_invalid\n    assert_exception(session, query, matching=matching, expected=expected)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 65, in assert_exception\n    _assert_exception(session.execute, query, matching=matching, expected=expected)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 54, in _assert_exception\n    assert_regexp_matches(str(e), matching)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 1002, in assertRegexpMatches\n    raise self.failureException(msg)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_3_x_To_indev_3_x.select_with_alias_test"
   },
   {
      "_id": "12998879",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-22 12:53:34",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/680/testReport/cql_tests/SlowQueryTester/remote_query_test\n\n{code}\nError Message\n\n22 Aug 2016 04:05:15 [node1] Missing: ['Starting listening for CQL clients']:\nERROR [main] 2016-08-22 03:55:13,422 CassandraDaem.....\nSee system.log for remainder\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-qeHpYA\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cql_tests.py\", line 879, in remote_query_test\n    node1.start(wait_for_binary_proto=True, join_ring=False)  # ensure other node executes queries\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 655, in start\n    self.wait_for_binary_interface(from_mark=self.mark)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 493, in wait_for_binary_interface\n    self.watch_log_for(\"Starting listening for CQL clients\", **kwargs)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 450, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"22 Aug 2016 04:05:15 [node1] Missing: ['Starting listening for CQL clients']:\\nERROR [main] 2016-08-22 03:55:13,422 CassandraDaem.....\\nSee system.log for remainder\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-qeHpYA\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tests.SlowQueryTester.remote_query_test"
   },
   {
      "_id": "12998874",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-22 12:38:54",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/680/testReport/cql_tests/SlowQueryTester/disable_slow_query_log_test\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/680/testReport/cql_tests/SlowQueryTester/local_query_test/\n\n{code}\nError Message\n\nError starting node1.\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-rDW1JQ\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cql_tests.py\", line 945, in disable_slow_query_log_test\n    \"-Dcassandra.test.read_iteration_delay_ms=50\"])\n  File \"/home/automaton/ccm/ccmlib/cluster.py\", line 414, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\n\"Error starting node1.\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-rDW1JQ\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\n--------------------- >> end captured logging << ---------------------\"\nStandard Output\n\n[node1 ERROR] org.apache.cassandra.exceptions.ConfigurationException: Invalid yaml. Please remove properties [slow_query_log_timeout_in_ms] from your cassandra.yaml\n\tat org.apache.cassandra.config.YamlConfigurationLoader$MissingPropertiesChecker.check(YamlConfigurationLoader.java:146)\n\tat org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:113)\n\tat org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:85)\n\tat org.apache.cassandra.config.DatabaseDescriptor.loadConfig(DatabaseDescriptor.java:135)\n\tat org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:119)\n\tat org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:507)\n\tat org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:641)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tests.SlowQueryTester.disable_slow_query_log_test"
   },
   {
      "_id": "12998217",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-18 14:43:59",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/376/testReport/topology_test/TestTopology/crash_during_decommission_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 358, in run\n    self.tearDown()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 673, in tearDown\n    raise AssertionError('Unexpected error in log, see stdout')\n\"Unexpected error in log, see stdout\n{code}\n\n{code}\nStandard Output\n\nUnexpected error in node1 log, error: \nERROR [RMI TCP Connection(2)-127.0.0.1] 2016-08-18 02:15:31,444 StorageService.java:3719 - Error while decommissioning node \norg.apache.cassandra.streaming.StreamException: Stream failed\n\tat org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:215) ~[main/:na]\n\tat org.apache.cassandra.streaming.StreamResultFuture.handleSessionComplete(StreamResultFuture.java:191) ~[main/:na]\n\tat org.apache.cassandra.streaming.StreamSession.closeSession(StreamSession.java:448) ~[main/:na]\n\tat org.apache.cassandra.streaming.StreamSession.onError(StreamSession.java:551) ~[main/:na]\n\tat org.apache.cassandra.streaming.StreamSession.start(StreamSession.java:249) ~[main/:na]\n\tat org.apache.cassandra.streaming.StreamCoordinator$StreamSessionConnector.run(StreamCoordinator.java:263) ~[main/:na]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_45]\n\tat java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_45]\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in topology_test.TestTopology.crash_during_decommission_test"
   },
   {
      "_id": "12998216",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-18 14:40:52",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/458/testReport/auth_test/TestAuth/conditional_create_drop_user_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/auth_test.py\", line 348, in conditional_create_drop_user_test\n    self.prepare()\n  File \"/home/automaton/cassandra-dtest/auth_test.py\", line 978, in prepare\n    n = self.wait_for_any_log(self.cluster.nodelist(), 'Created default superuser', 25)\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 760, in wait_for_any_log\n    found = node.grep_log(pattern, filename=filename)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 347, in grep_log\n    with open(os.path.join(self.get_path(), 'logs', filename)) as f:\n\"[Errno 2] No such file or directory: '/tmp/dtest-XmnSYI/test/node1/logs/system.log'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in auth_test.TestAuth.conditional_create_drop_user_test"
   },
   {
      "_id": "12998100",
      "assignee": "cassandra-te",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-08-18 05:36:12",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest_upgrade/25/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_x/cql3_non_compound_range_tombstones_test/\n\nIt looks like this is failing with a TimedOutException.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_x.cql3_non_compound_range_tombstones_test"
   },
   {
      "_id": "12997932",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-17 15:17:36",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest_upgrade/29/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_3_x_To_indev_3_x/select_with_alias_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 3184, in select_with_alias_test\n    assert_invalid(cursor, 'SELECT id AS user_id, name AS user_name FROM users WHERE user_id = 0', matching=error_msg)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 92, in assert_invalid\n    assert_exception(session, query, matching=matching, expected=expected)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 65, in assert_exception\n    _assert_exception(session.execute, query, matching=matching, expected=expected)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 54, in _assert_exception\n    assert_regexp_matches(str(e), matching)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 1002, in assertRegexpMatches\n    raise self.failureException(msg)\n'Regexp didn\\'t match: \"Aliases aren\\'t allowed in the where clause\" not found in \\'Error from server: code=2200 [Invalid query] message=\"Undefined column name user_id\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_3_x_To_indev_3_x.select_with_alias_test"
   },
   {
      "_id": "12997931",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-08-17 15:14:53",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_cqlsh_tests/29/testReport/cqlshlib.test.test_cqlsh_output/TestCqlshOutput/test_describe_keyspace_output\n\n{code}\nError Message\n\nerrors={'127.0.0.1': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.1\n\n{code}\n\nhttp://cassci.datastax.com/job/cassandra-3.0_cqlsh_tests/lastCompletedBuild/cython=no,label=ctool-lab/testReport/cqlshlib.test.test_cqlsh_output/TestCqlshOutput/test_describe_keyspace_output/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlshlib.test.test_cqlsh_output.TestCqlshOutput.test_describe_keyspace_output"
   },
   {
      "_id": "12997928",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-17 14:52:23",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/382/testReport/rebuild_test/TestRebuild/simple_rebuild_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/rebuild_test.py\", line 75, in simple_rebuild_test\n    session.execute(\"ALTER KEYSPACE system_auth WITH REPLICATION = {'class':'NetworkTopologyStrategy', 'dc1':1, 'dc2':1};\")\n  File \"cassandra/cluster.py\", line 1972, in cassandra.cluster.Session.execute (cassandra/cluster.c:34423)\n    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile).result()\n  File \"cassandra/cluster.py\", line 3665, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:70216)\n    raise self._final_exception\n'Error from server: code=2200 [Invalid query] message=\"Unknown keyspace system_auth\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in rebuild_test.TestRebuild.simple_rebuild_test"
   },
   {
      "_id": "12997924",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-08-17 14:43:24",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_offheap_dtest/447/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_bulk_round_trip_non_prepared_statements\n\n{code}\nError Message\n\n100000 != 96848\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-BryYNs\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'memtable_allocation_type': 'offheap_objects',\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Running stress without any user profile\ndtest: DEBUG: Generated 100000 records\ndtest: DEBUG: Exporting to csv file: /tmp/tmpREOhBZ\ndtest: DEBUG: CONSISTENCY ALL; COPY keyspace1.standard1 TO '/tmp/tmpREOhBZ' WITH PAGETIMEOUT = 10 AND PAGESIZE = 1000\ndtest: DEBUG: COPY TO took 0:00:04.598829 to export 100000 records\ndtest: DEBUG: Truncating keyspace1.standard1...\ndtest: DEBUG: Importing from csv file: /tmp/tmpREOhBZ\ndtest: DEBUG: COPY keyspace1.standard1 FROM '/tmp/tmpREOhBZ' WITH PREPAREDSTATEMENTS = False\ndtest: DEBUG: COPY FROM took 0:00:10.348123 to import 100000 records\ndtest: DEBUG: Exporting to csv file: /tmp/tmpeXLPtz\ndtest: DEBUG: CONSISTENCY ALL; COPY keyspace1.standard1 TO '/tmp/tmpeXLPtz' WITH PAGETIMEOUT = 10 AND PAGESIZE = 1000\ndtest: DEBUG: COPY TO took 0:00:11.681829 to export 100000 records\n--------------------- >> end captured logging << ---------------------\n{code}\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2482, in test_bulk_round_trip_non_prepared_statements\n    copy_from_options={'PREPAREDSTATEMENTS': False})\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2461, in _test_bulk_round_trip\n    sum(1 for _ in open(tempfile2.name)))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"100000 != 96848\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-BryYNs\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'memtable_allocation_type': 'offheap_objects',\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Running stress without any user profile\\ndtest: DEBUG: Generated 100000 records\\ndtest: DEBUG: Exporting to csv file: /tmp/tmpREOhBZ\\ndtest: DEBUG: CONSISTENCY ALL; COPY keyspace1.standard1 TO '/tmp/tmpREOhBZ' WITH PAGETIMEOUT = 10 AND PAGESIZE = 1000\\ndtest: DEBUG: COPY TO took 0:00:04.598829 to export 100000 records\\ndtest: DEBUG: Truncating keyspace1.standard1...\\ndtest: DEBUG: Importing from csv file: /tmp/tmpREOhBZ\\ndtest: DEBUG: COPY keyspace1.standard1 FROM '/tmp/tmpREOhBZ' WITH PREPAREDSTATEMENTS = False\\ndtest: DEBUG: COPY FROM took 0:00:10.348123 to import 100000 records\\ndtest: DEBUG: Exporting to csv file: /tmp/tmpeXLPtz\\ndtest: DEBUG: CONSISTENCY ALL; COPY keyspace1.standard1 TO '/tmp/tmpeXLPtz' WITH PAGETIMEOUT = 10 AND PAGESIZE = 1000\\ndtest: DEBUG: COPY TO took 0:00:11.681829 to export 100000 records\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_bulk_round_trip_non_prepared_statements"
   },
   {
      "_id": "12997888",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-08-17 11:46:11",
      "description": "I have a simple counter table \n\n{noformat}\nCREATE TABLE test (\n    a int PRIMARY KEY,\n    b counter,\n    c counter\n) ;\n{noformat}\n\nI have updated b column value with \n\n{noformat}\nUPDATE test SET b = b + 1 WHERE a = 1;\n{noformat}\n\nNow I have export the data with \n\n{noformat}\nCOPY test TO 'test.csv';\n{noformat}\n\nAnd Import it with \n\n{noformat}\nCOPY test FROM 'test.csv';\n{noformat}\n\nI get this Error\n\n{noformat}\nFailed to import 1 rows: SyntaxException - line 1:34 no viable alternative at input 'WHERE' (...=b+1,c=c+ [WHERE]...) -  will retry later, attempt 1 of 5\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "SyntaxException when COPY FROM Counter Table with Null value"
   },
   {
      "_id": "12997623",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-16 15:57:41",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest_upgrade/24/testReport/upgrade_tests.repair_test/TestUpgradeRepair/repair_after_upgrade_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.repair_test.TestUpgradeRepair.repair_after_upgrade_test"
   },
   {
      "_id": "12997598",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-16 14:33:45",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/456/testReport/pending_range_test/TestPendingRangeMovements/pending_range_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/pending_range_test.py\", line 63, in pending_range_test\n    self.assertRegexpMatches(out, '127\\.0\\.0\\.1.*?Down.*?Moving')\n  File \"/usr/lib/python2.7/unittest/case.py\", line 1002, in assertRegexpMatches\n    raise self.failureException(msg)\n\"Regexp didn't match: '127\\\\\\\\.0\\\\\\\\.0\\\\\\\\.1.*?Down.*?Moving' not found in '\\\\nDatacenter: datacenter1\\\\n==========\\\\nAddress    Rack        Status State   Load            Owns                Token                                       \\\\n                                                                          5534023222112865484                         \\\\n127.0.0.2  rack1       Up     Normal  200.01 KiB      73.44%              -5534023222112865485                        \\\\n127.0.0.3  rack1       Up     Normal  162.37 KiB      80.00%              -1844674407370955162                        \\\\n127.0.0.1  rack1       Down   Normal  147.05 KiB      66.56%              -634023222112864484                         \\\\n127.0.0.4  rack1       Up     Normal  164.85 KiB      40.00%              1844674407370955161                         \\\\n127.0.0.5  rack1       Up     Normal  164.99 KiB      40.00%              5534023222112865484  \n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in pending_range_test.TestPendingRangeMovements.pending_range_test"
   },
   {
      "_id": "12997596",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-16 14:27:31",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/285/testReport/jmx_test/TestJMX/netstats_test\n\n{code}\nError Message\n\n\"ConnectException: 'Connection refused'.\" does not match \"Subprocess ['nodetool', '-h', 'localhost', '-p', '7100', ['netstats']] exited with non-zero status; exit status: 1; \nstdout: Starting NodeTool\n; \nstderr: nodetool: Failed to connect to 'localhost:7100' - ConnectException: 'Connection refused: connect'.\n\"\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: d:\\temp\\2\\dtest-dbbq3u\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\n--------------------- >> end captured logging << ---------------------\n\n{code}\n\n{code}\nStacktrace\n\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 329, in run\n    testMethod()\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\jmx_test.py\", line 35, in netstats_test\n    node1.nodetool('netstats')\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 127, in __exit__\n    (expected_regexp.pattern, str(exc_value)))\n'\"ConnectException: \\'Connection refused\\'.\" does not match \"Subprocess [\\'nodetool\\', \\'-h\\', \\'localhost\\', \\'-p\\', \\'7100\\', [\\'netstats\\']] exited with non-zero status; exit status: 1; \\nstdout: Starting NodeTool\\n; \\nstderr: nodetool: Failed to connect to \\'localhost:7100\\' - ConnectException: \\'Connection refused: connect\\'.\\n\"\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\2\\\\dtest-dbbq3u\\ndtest: DEBUG: Done setting configuration options:\\n{   \\'initial_token\\': None,\\n    \\'num_tokens\\': \\'32\\',\\n    \\'phi_convict_threshold\\': 5,\\n    \\'range_request_timeout_in_ms\\': 10000,\\n    \\'read_request_timeout_in_ms\\': 10000,\\n    \\'request_timeout_in_ms\\': 10000,\\n    \\'truncate_request_timeout_in_ms\\': 10000,\\n    \\'write_request_timeout_in_ms\\': 10000}\\n--------------------- >> end captured logging << ---------------------'\nStandard Error\n\nStarted: node1 with pid: 6288\nStarted: node3 with pid: 2280\nStarted: node2 with pid: 6980\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in jmx_test.TestJMX.netstats_test"
   },
   {
      "_id": "12997307",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-15 14:55:19",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest_upgrade/lastCompletedBuild/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_3_x/bug_5732_test\n\n{code}\nStandard Output\n\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:2143805eef1fc93d9cd53f4415158e469c473730\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-15 02:42:18,863 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@147fec06) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@448270585:[Memory@[0..4), Memory@[0..a)] was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-15 02:42:18,864 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@1e878776) to class org.apache.cassandra.io.util.MmappedSegmentedFile$Cleanup@1535449794:/mnt/tmp/dtest-mrsh87/test/node1/data2/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-2-Index.db was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-15 02:42:18,866 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@3071c268) to class org.apache.cassandra.io.sstable.SSTableReader$DescriptorTypeTidy@1779704647:/mnt/tmp/dtest-mrsh87/test/node1/data2/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-2 was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-15 02:42:18,877 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@480aa544) to class org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Cleanup@1001055629:/mnt/tmp/dtest-mrsh87/test/node1/data2/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-2-Data.db was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-15 02:42:18,877 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@5760212) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@1320355808:[[OffHeapBitSet]] was not released before the reference was garbage collected\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_3_x.bug_5732_test"
   },
   {
      "_id": "12997291",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-15 13:52:45",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/290/testReport/junit/(root)/TestMutations_setUpClass/TestMutations_setUpClass/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in TestMutations:setUpClass.TestMutations:setUpClass"
   },
   {
      "_id": "12997284",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-15 13:21:00",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/792/testReport/batch_test/TestBatch/logged_batch_compatibility_3_test\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/792/testReport/batch_test/TestBatch/logged_batch_compatibility_2_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/792/testReport/batch_test/TestBatch/logged_batch_compatibility_5_test/\n\n{code}\nError Message\n\n('Unable to connect to any servers', {'127.0.0.1': DriverException('ProtocolError returned from server while using explicitly set client protocol_version 4',)})\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-Ob2TdU\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Testing with 1 node(s) at version 'git:cassandra-2.1', 2 node(s) at current version\nccm: INFO: Fetching Cassandra updates...\ndtest: DEBUG: Set cassandra dir for node1 to /home/automaton/.ccm/repository/gitCOLONcassandra-2.1\nccm: INFO: Fetching Cassandra updates...\ndtest: DEBUG: Set cassandra dir for node2 to /home/automaton/.ccm/repository/gitCOLONcassandra-2.1\nccm: INFO: Fetching Cassandra updates...\ndtest: DEBUG: Set cassandra dir for node3 to /home/automaton/.ccm/repository/gitCOLONcassandra-2.1\n--------------------- >> end captured logging << ---------------------\n{code}\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 290, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/batch_test.py\", line 318, in logged_batch_compatibility_3_test\n    self._logged_batch_compatibility_test(0, 2, 'git:cassandra-2.1', 1)\n  File \"/home/automaton/cassandra-dtest/batch_test.py\", line 340, in _logged_batch_compatibility_test\n    session = self.prepare_mixed(coordinator_idx, current_nodes, previous_version, previous_nodes)\n  File \"/home/automaton/cassandra-dtest/batch_test.py\", line 417, in prepare_mixed\n    self.prepare(previous_nodes + current_nodes, compression, previous_version)\n  File \"/home/automaton/cassandra-dtest/batch_test.py\", line 383, in prepare\n    session = self.patient_cql_connection(node1)\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 545, in patient_cql_connection\n    bypassed_exception=NoHostAvailable\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 219, in retry_till_success\n    return fun(*args, **kwargs)\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 478, in cql_connection\n    protocol_version, port=port, ssl_opts=ssl_opts)\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 506, in _create_session\n    session = cluster.connect()\n  File \"cassandra/cluster.py\", line 1156, in cassandra.cluster.Cluster.connect (cassandra/cluster.c:17387)\n    with self._lock:\n  File \"cassandra/cluster.py\", line 1189, in cassandra.cluster.Cluster.connect (cassandra/cluster.c:17208)\n    raise\n  File \"cassandra/cluster.py\", line 1176, in cassandra.cluster.Cluster.connect (cassandra/cluster.c:16911)\n    self.control_connection.connect()\n  File \"cassandra/cluster.py\", line 2521, in cassandra.cluster.ControlConnection.connect (cassandra/cluster.c:45182)\n    self._set_new_connection(self._reconnect_internal())\n  File \"cassandra/cluster.py\", line 2558, in cassandra.cluster.ControlConnection._reconnect_internal (cassandra/cluster.c:46079)\n    raise NoHostAvailable(\"Unable to connect to any servers\", errors)\n\"('Unable to connect to any servers', {'127.0.0.1': DriverException('ProtocolError returned from server while using explicitly set client protocol_version 4',)})\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-Ob2TdU\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Testing with 1 node(s) at version 'git:cassandra-2.1', 2 node(s) at current version\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: Set cassandra dir for node1 to /home/automaton/.ccm/repository/gitCOLONcassandra-2.1\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: Set cassandra dir for node2 to /home/automaton/.ccm/repository/gitCOLONcassandra-2.1\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: Set cassandra dir for node3 to /home/automaton/.ccm/repository/gitCOLONcassandra-2.1\\n--------------------- >> end captured logging << ---------------------\"\nStandard Output\n\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:cassandra-2.1\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:cassandra-2.1\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:cassandra-2.1\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in batch_test.TestBatch.logged_batch_compatibility_3_test"
   },
   {
      "_id": "12997278",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328322",
            "id": "12328322",
            "name": "Local/Startup and Shutdown",
            "description": "Startup and Shutdown"
         }
      ],
      "created": "2016-08-15 12:50:26",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_upgrade/16/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_2_x/bug_5732_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 358, in run\n    self.tearDown()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_base.py\", line 216, in tearDown\n    super(UpgradeTester, self).tearDown()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 666, in tearDown\n    raise AssertionError('Unexpected error in log, see stdout')\n\"Unexpected error in log, see stdout\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: Upgrade test beginning, setting CASSANDRA_VERSION to 2.1.15, and jdk to 8. (Prior values will be restored after test).\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-D8UF3i\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: [[Row(table_name=u'ks', index_name=u'test.testindex')], [Row(table_name=u'ks', index_name=u'test.testindex')]]\\ndtest: DEBUG: upgrading node1 to git:91f7387e1f785b18321777311a5c3416af0663c2\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: Querying upgraded node\\ndtest: DEBUG: Querying old node\\ndtest: DEBUG: removing ccm cluster test at: /mnt/tmp/dtest-D8UF3i\\ndtest: DEBUG: clearing ssl stores from [/mnt/tmp/dtest-D8UF3i] directory\\n--------------------- >> end captured logging << ---------------------\"\n{code}\n\n{code}\nStandard Output\n\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:91f7387e1f785b18321777311a5c3416af0663c2\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,581 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@73deb57f) to class org.apache.cassandra.io.sstable.SSTableReader$DescriptorTypeTidy@2098812276:/mnt/tmp/dtest-D8UF3i/test/node1/data1/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-4 was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,581 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@7926de0f) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@1009016655:[[OffHeapBitSet]] was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,581 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@3a5760f9) to class org.apache.cassandra.io.util.MmappedSegmentedFile$Cleanup@223486002:/mnt/tmp/dtest-D8UF3i/test/node1/data0/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-3-Index.db was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,582 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@42cb4131) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@1544265728:[Memory@[0..4), Memory@[0..a)] was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,582 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@5dda43d0) to class org.apache.cassandra.io.util.MmappedSegmentedFile$Cleanup@1100327913:/mnt/tmp/dtest-D8UF3i/test/node1/data1/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-4-Index.db was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,582 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@59cfa823) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@1480923322:[Memory@[0..4), Memory@[0..a)] was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,601 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@570e14a1) to class org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Cleanup@992487242:/mnt/tmp/dtest-D8UF3i/test/node1/data1/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-4-Data.db was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,602 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@1f021ebc) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@1878148398:[Memory@[0..4), Memory@[0..e)] was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,604 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@48feef6d) to class org.apache.cassandra.io.sstable.SSTableReader$DescriptorTypeTidy@848724815:/mnt/tmp/dtest-D8UF3i/test/node1/data0/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-3 was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,605 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@3dee8c5f) to class org.apache.cassandra.io.sstable.SSTableReader$DescriptorTypeTidy@1078490617:/mnt/tmp/dtest-D8UF3i/test/node1/data1/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-2 was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,614 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@7f726f1a) to class org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Cleanup@2037913408:/mnt/tmp/dtest-D8UF3i/test/node1/data0/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-3-Data.db was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,615 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@303df044) to class org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Cleanup@861514759:/mnt/tmp/dtest-D8UF3i/test/node1/data1/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-2-Data.db was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,616 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@5fbf0fc9) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@1715786089:[[OffHeapBitSet]] was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,616 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@3924b235) to class org.apache.cassandra.io.util.MmappedSegmentedFile$Cleanup@1197672578:/mnt/tmp/dtest-D8UF3i/test/node1/data1/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-2-Index.db was not released before the reference was garbage collected\nUnexpected error in node1 log, error: \nERROR [Reference-Reaper:1] 2016-08-13 01:34:34,616 Ref.java:199 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@600596e0) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@545967120:[[OffHeapBitSet]] was not released before the reference was garbage collected\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_2_x.bug_5732_test"
   },
   {
      "_id": "12997262",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-15 10:00:31",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/lastCompletedBuild/testReport/compaction_test/TestCompaction_with_SizeTieredCompactionStrategy/bloomfilter_size_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_SizeTieredCompactionStrategy.bloomfilter_size_test"
   },
   {
      "_id": "12996966",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-12 15:20:33",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1335/testReport/compaction_test/TestCompaction_with_SizeTieredCompactionStrategy/bloomfilter_size_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/compaction_test.py\", line 155, in bloomfilter_size_test\n    self.assertGreaterEqual(bfSize, size_factor * min_bf_size)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 948, in assertGreaterEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"125672 not greater than or equal to 300000\n{code}\n\nrelated failure:\nhttp://cassci.datastax.com/job/trunk_dtest/1335/testReport/compaction_test/TestCompaction_with_DateTieredCompactionStrategy/bloomfilter_size_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_SizeTieredCompactionStrategy.bloomfilter_size_test"
   },
   {
      "_id": "12996921",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-12 11:15:51",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/282/testReport/compaction_test/TestCompaction_with_DateTieredCompactionStrategy/bloomfilter_size_test\n\n{code}\nStacktrace\n\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 329, in run\n    testMethod()\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\compaction_test.py\", line 155, in bloomfilter_size_test\n    self.assertLessEqual(bfSize, size_factor * max_bf_size)\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 936, in assertLessEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"125456 not less than or equal to 50000.0\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\2\\\\dtest-kfylxp\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'start_rpc': 'true'}\\ndtest: DEBUG: sstable_count is: 1\\ndtest: DEBUG: dir_count is: 3\\ndtest: DEBUG: bloom filter size is: 125456\\ndtest: DEBUG: size factor = 0.333333333333\\n--------------------- >> end captured logging << ---------------------\"\n\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_DateTieredCompactionStrategy.bloomfilter_size_test"
   },
   {
      "_id": "12996629",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-11 14:17:50",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest_upgrade/20/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_x_To_indev_3_x/cas_simple_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 358, in run\n    self.tearDown()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_base.py\", line 216, in tearDown\n    super(UpgradeTester, self).tearDown()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 666, in tearDown\n    raise AssertionError('Unexpected error in log, see stdout')\n\"Unexpected error in log, see stdout\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: Upgrade test beginning, setting CASSANDRA_VERSION to 3.7, and jdk to 8. (Prior values will be restored after test).\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-jGuOLx\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Upgrade test beginning, setting CASSANDRA_VERSION to 3.7, and jdk to 8. (Prior values will be restored after test).\\ndtest: DEBUG: removing ccm cluster test at: /mnt/tmp/dtest-jGuOLx\\ndtest: DEBUG: clearing ssl stores from [/mnt/tmp/dtest-jGuOLx] directory\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-7LSAP2\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: upgrading node1 to git:15fd71f9a3b07bbac7a1182f2e6bffd32e79b955\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: Querying upgraded node\\ndtest: DEBUG: Querying old node\\ndtest: DEBUG: removing ccm cluster test at: /mnt/tmp/dtest-7LSAP2\\ndtest: DEBUG: clearing ssl stores from [/mnt/tmp/dtest-7LSAP2] directory\\n--------------------- >> end captured logging << ---------------------\"\n{code}\n\n{code}\nStandard Output\n\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:15fd71f9a3b07bbac7a1182f2e6bffd32e79b955\nUnexpected error in node1 log, error: \nERROR [CompactionExecutor:1] 2016-08-11 02:36:24,280 CassandraDaemon.java:217 - Exception in thread Thread[CompactionExecutor:1,1,main]\njava.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down\n\tat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:61) ~[apache-cassandra-3.7.jar:3.7]\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369) ~[na:1.8.0_51]\n\tat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:165) ~[apache-cassandra-3.7.jar:3.7]\n\tat java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:112) ~[na:1.8.0_51]\n\tat org.apache.cassandra.db.compaction.CompactionManager.submitBackground(CompactionManager.java:184) ~[apache-cassandra-3.7.jar:3.7]\n\tat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:270) ~[apache-cassandra-3.7.jar:3.7]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_51]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes3RF3_Upgrade_current_3_x_To_indev_3_x.cas_simple_test"
   },
   {
      "_id": "12996625",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-11 13:56:12",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_large_dtest/20/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_2_2_x_To_indev_3_0_x/rolling_upgrade_with_internode_ssl_test\n\n{code}\nError Message\n\nRan out of time waiting for queue size (1) to be 'le' to 0. Aborting.\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: Upgrade test beginning, setting CASSANDRA_VERSION to 2.2.7, and jdk to 8. (Prior values will be restored after test).\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-U_C4o2\nccm: DEBUG: Log-watching thread starting.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Setting extra configuration options:\n{   'partitioner': 'org.apache.cassandra.dht.Murmur3Partitioner'}\ndtest: DEBUG: Versions to test (<class 'upgrade_tests.upgrade_through_versions_test.TestUpgrade_current_2_2_x_To_indev_3_0_x'>): ['2.2.7', 'git:465def8e295b453dc22430dc4bb7039f6921151e']\ndtest: DEBUG: ***using internode ssl***\ndtest: DEBUG: generating keystore.jks in [/tmp/dtest-U_C4o2]\ndtest: DEBUG: exporting cert from keystore.jks in [/tmp/dtest-U_C4o2]\ndtest: DEBUG: importing cert into truststore.jks in [/tmp/dtest-U_C4o2]\ndtest: DEBUG: Creating cluster (2.2.7)\ndtest: DEBUG: Current upgrade path: ['***2.2.7***', 'git:465def8e295b453dc22430dc4bb7039f6921151e']\ndtest: DEBUG: rows written (but not verified) queue size is at 417, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 442, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 474, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 503, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 536, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 565, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 597, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 634, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 663, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size is at 690, target is to reach 'ge' 5000\ndtest: DEBUG: rows written (but not verified) queue size (5044) is 'ge' to 5000. Continuing.\ndtest: DEBUG: counters incremented (but not verified) queue size (5042) is 'ge' to 5000. Continuing.\ndtest: DEBUG: Upgrading ['node1'] to git:465def8e295b453dc22430dc4bb7039f6921151e\ndtest: DEBUG: JAVA_HOME: /usr/lib/jvm/jdk1.8.0_51\ndtest: DEBUG: Shutting down node: node1\nccm: INFO: Fetching Cassandra updates...\ndtest: DEBUG: Set new cassandra dir for node1: /home/automaton/.ccm/repository/gitCOLON465def8e295b453dc22430dc4bb7039f6921151e\ndtest: DEBUG: Starting node1 on new version (git:465def8e295b453dc22430dc4bb7039f6921151e)\ndtest: DEBUG: Successfully upgraded 1 of 3 nodes to git:465def8e295b453dc22430dc4bb7039f6921151e\ndtest: DEBUG: Upgrading ['node2'] to git:465def8e295b453dc22430dc4bb7039f6921151e\ndtest: DEBUG: JAVA_HOME: /usr/lib/jvm/jdk1.8.0_51\ndtest: DEBUG: Shutting down node: node2\nccm: INFO: Fetching Cassandra updates...\ndtest: DEBUG: Set new cassandra dir for node2: /home/automaton/.ccm/repository/gitCOLON465def8e295b453dc22430dc4bb7039f6921151e\ndtest: DEBUG: Starting node2 on new version (git:465def8e295b453dc22430dc4bb7039f6921151e)\ndtest: DEBUG: Successfully upgraded 2 of 3 nodes to git:465def8e295b453dc22430dc4bb7039f6921151e\ndtest: DEBUG: Upgrading ['node3'] to git:465def8e295b453dc22430dc4bb7039f6921151e\ndtest: DEBUG: JAVA_HOME: /usr/lib/jvm/jdk1.8.0_51\ndtest: DEBUG: Shutting down node: node3\nccm: INFO: Fetching Cassandra updates...\ndtest: DEBUG: Set new cassandra dir for node3: /home/automaton/.ccm/repository/gitCOLON465def8e295b453dc22430dc4bb7039f6921151e\ndtest: DEBUG: Starting node3 on new version (git:465def8e295b453dc22430dc4bb7039f6921151e)\ndtest: DEBUG: Successfully upgraded 3 of 3 nodes to git:465def8e295b453dc22430dc4bb7039f6921151e\nccm: INFO: Fetching Cassandra updates...\ndtest: DEBUG: writes pending verification queue size is at 46041, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 46013, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 45983, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 45952, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 45922, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 45893, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 45862, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 45829, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 45801, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 45771, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36705, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36675, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36649, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36620, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36592, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36564, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36536, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36507, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36474, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 36442, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27707, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27679, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27650, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27623, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27591, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27559, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27532, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27504, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27474, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 27441, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 18630, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 18601, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 18571, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 18543, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 18512, target is to reach 'le' 0\ndtest: DEBUG: writes pending verification queue size is at 18484, target is to reach 'le' 0\n\n{code}\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 298, in rolling_upgrade_with_internode_ssl_test\n    self.upgrade_scenario(rolling=True, internode_ssl=True)\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 366, in upgrade_scenario\n    self._wait_until_queue_condition('counters pending verification', incr_verify_queue, operator.le, 0, max_wait_s=1200)\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 551, in _wait_until_queue_condition\n    raise RuntimeError(\"Ran out of time waiting for queue size ({}) to be '{}' to {}. Aborting.\".format(qsize, opfunc.__name__, required_len))\n\"Ran out of time waiting for queue size (1) to be 'le' to 0. Aborting.\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: Upgrade test beginning, setting CASSANDRA_VERSION to 2.2.7, and jdk to 8. (Prior values will be restored after test).\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-U_C4o2\\nccm: DEBUG: Log-watching thread starting.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Setting extra configuration options:\\n{   'partitioner': 'org.apache.cassandra.dht.Murmur3Partitioner'}\\ndtest: DEBUG: Versions to test (<class 'upgrade_tests.upgrade_through_versions_test.TestUpgrade_current_2_2_x_To_indev_3_0_x'>): ['2.2.7', 'git:465def8e295b453dc22430dc4bb7039f6921151e']\\ndtest: DEBUG: ***using internode ssl***\\ndtest: DEBUG: generating keystore.jks in [/tmp/dtest-U_C4o2]\\ndtest: DEBUG: exporting cert from keystore.jks in [/tmp/dtest-U_C4o2]\\ndtest: DEBUG: importing cert into truststore.jks in [/tmp/dtest-U_C4o2]\\ndtest: DEBUG: Creating cluster (2.2.7)\\ndtest: DEBUG: Current upgrade path: ['***2.2.7***', 'git:465def8e295b453dc22430dc4bb7039f6921151e']\\ndtest: DEBUG: rows written (but not verified) queue size is at 417, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 442, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 474, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 503, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 536, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 565, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 597, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 634, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 663, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size is at 690, target is to reach 'ge' 5000\\ndtest: DEBUG: rows written (but not verified) queue size (5044) is 'ge' to 5000. Continuing.\\ndtest: DEBUG: counters incremented (but not verified) queue size (5042) is 'ge' to 5000. Continuing.\\ndtest: DEBUG: Upgrading ['node1'] to git:465def8e295b453dc22430dc4bb7039f6921151e\\ndtest: DEBUG: JAVA_HOME: /usr/lib/jvm/jdk1.8.0_51\\ndtest: DEBUG: Shutting down node: node1\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: Set new cassandra dir for node1: /home/automaton/.ccm/repository/gitCOLON465def8e295b453dc22430dc4bb7039f6921151e\\ndtest: DEBUG: Starting node1 on new version (git:465def8e295b453dc22430dc4bb7039f6921151e)\\ndtest: DEBUG: Successfully upgraded 1 of 3 nodes to git:465def8e295b453dc22430dc4bb7039f6921151e\\ndtest: DEBUG: Upgrading ['node2'] to git:465def8e295b453dc22430dc4bb7039f6921151e\\ndtest: DEBUG: JAVA_HOME: /usr/lib/jvm/jdk1.8.0_51\\ndtest: DEBUG: Shutting down node: node2\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: Set new cassandra dir for node2: /home/automaton/.ccm/repository/gitCOLON465def8e295b453dc22430dc4bb7039f6921151e\\ndtest: DEBUG: Starting node2 on new version (git:465def8e295b453dc22430dc4bb7039f6921151e)\\ndtest: DEBUG: Successfully upgraded 2 of 3 nodes to git:465def8e295b453dc22430dc4bb7039f6921151e\\ndtest: DEBUG: Upgrading ['node3'] to git:465def8e295b453dc22430dc4bb7039f6921151e\\ndtest: DEBUG: JAVA_HOME: /usr/lib/jvm/jdk1.8.0_51\\ndtest: DEBUG: Shutting down node: node3\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: Set new cassandra dir for node3: /home/automaton/.ccm/repository/gitCOLON465def8e295b453dc22430dc4bb7039f6921151e\\ndtest: DEBUG: Starting node3 on new version (git:465def8e295b453dc22430dc4bb7039f6921151e)\\ndtest: DEBUG: Successfully upgraded 3 of 3 nodes to git:465def8e295b453dc22430dc4bb7039f6921151e\\nccm: INFO: Fetching Cassandra updates...\\ndtest: DEBUG: writes pending verification queue size is at 46041, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 46013, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 45983, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 45952, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 45922, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 45893, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 45862, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 45829, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 45801, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 45771, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36705, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36675, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36649, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36620, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36592, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36564, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36536, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36507, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36474, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 36442, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 27707, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 27679, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 27650, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 27623, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 27591, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 27559, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 27532, target is to reach 'le' 0\\ndtest: DEBUG: writes pending verification queue size is at 27504, target is to reach 'le' 0\\ndtest: DEBUG\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.upgrade_through_versions_test.TestUpgrade_current_2_2_x_To_indev_3_0_x.rolling_upgrade_with_internode_ssl_test"
   },
   {
      "_id": "12996617",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-11 13:36:00",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/789/testReport/consistency_test/TestConsistency/readrepair_test\n\n{code}\nError Message\n\nError from server: code=1200 [Coordinator node timed out waiting for replica nodes' responses] message=\"Operation timed out - received only 1 responses.\" info={'received_responses': 1, 'required_responses': 2, 'consistency': 'QUORUM'}\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-ola0t8\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Retrying request after UE. Attempt #0\ndtest: DEBUG: Retrying request after UE. Attempt #1\ndtest: DEBUG: Retrying request after UE. Attempt #2\ndtest: DEBUG: Retrying request after UE. Attempt #3\ndtest: DEBUG: Retrying request after UE. Attempt #4\n--------------------- >> end captured logging << ---------------------\n{code}\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/consistency_test.py\", line 904, in readrepair_test\n    query_c1c2(session, n, ConsistencyLevel.QUORUM)\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 83, in query_c1c2\n    rows = list(session.execute(query))\n  File \"cassandra/cluster.py\", line 1941, in cassandra.cluster.Session.execute (cassandra/cluster.c:33653)\n    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile).result()\n  File \"cassandra/cluster.py\", line 3629, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:69380)\n    raise self._final_exception\n'Error from server: code=1200 [Coordinator node timed out waiting for replica nodes\\' responses] message=\"Operation timed out - received only 1 responses.\" info={\\'received_responses\\': 1, \\'required_responses\\': 2, \\'consistency\\': \\'QUORUM\\'}\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-ola0t8\\ndtest: DEBUG: Done setting configuration options:\\n{   \\'initial_token\\': None,\\n    \\'num_tokens\\': \\'32\\',\\n    \\'phi_convict_threshold\\': 5,\\n    \\'range_request_timeout_in_ms\\': 10000,\\n    \\'read_request_timeout_in_ms\\': 10000,\\n    \\'request_timeout_in_ms\\': 10000,\\n    \\'truncate_request_timeout_in_ms\\': 10000,\\n    \\'write_request_timeout_in_ms\\': 10000}\\ndtest: DEBUG: Retrying request after UE. Attempt #0\\ndtest: DEBUG: Retrying request after UE. Attempt #1\\ndtest: DEBUG: Retrying request after UE. Attempt #2\\ndtest: DEBUG: Retrying request after UE. Attempt #3\\ndtest: DEBUG: Retrying request after UE. Attempt #4\\n--------------------- >> end captured logging << ---------------------'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in consistency_test.TestConsistency.readrepair_test"
   },
   {
      "_id": "12996610",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-11 13:19:09",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_novnode_dtest/318/testReport/repair_tests.repair_test/TestRepair/test_multiple_concurrent_repairs\n\n{code}\nError Message\n\nERROR 15:43:07 Error creating pool to /127.0.0.3:9042\ncom.datastax.driver.core.TransportException: [/127.0.0.3:9042] Cannot connect\n\tat com.datastax.driver.core.Connection$1.operationComplete(Connection.java:156) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.driver.core.Connection$1.operationComplete(Connection.java:139) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:268) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:284) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.7.0_80]\nCaused by: java.net.ConnectException: Connection refused: /127.0.0.3:9042\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_80]\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744) ~[na:1.7.0_80]\n\tat com.datastax.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224) ~[cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:281) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\t... 6 common frames omitted\nERROR 15:43:07 Error creating pool to /127.0.0.1:9042\ncom.datastax.driver.core.TransportException: [/127.0.0.1:9042] Cannot connect\n\tat com.datastax.driver.core.Connection$1.operationComplete(Connection.java:156) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.driver.core.Connection$1.operationComplete(Connection.java:139) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:268) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:284) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.7.0_80]\nCaused by: java.net.ConnectException: Connection refused: /127.0.0.1:9042\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_80]\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744) ~[na:1.7.0_80]\n\tat com.datastax.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224) ~[cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:281) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\n\t... 6 common frames omitted\nFailed to connect over JMX; not collecting these stats\n\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-b0pWB9\ndtest: DEBUG: Done setting configuration options:\n{   'num_tokens': None,\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\n--------------------- >> end captured logging << ---------------------\n\n{code}\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/repair_tests/repair_test.py\", line 886, in test_multiple_concurrent_repairs\n    self.assertTrue(len(stderr) == 0, stderr)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 422, in assertTrue\n    raise self.failureException(msg)\n\"ERROR 15:43:07 Error creating pool to /127.0.0.3:9042\\ncom.datastax.driver.core.TransportException: [/127.0.0.3:9042] Cannot connect\\n\\tat com.datastax.driver.core.Connection$1.operationComplete(Connection.java:156) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.driver.core.Connection$1.operationComplete(Connection.java:139) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:268) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:284) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat java.lang.Thread.run(Thread.java:745) [na:1.7.0_80]\\nCaused by: java.net.ConnectException: Connection refused: /127.0.0.3:9042\\n\\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_80]\\n\\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744) ~[na:1.7.0_80]\\n\\tat com.datastax.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224) ~[cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:281) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\t... 6 common frames omitted\\nERROR 15:43:07 Error creating pool to /127.0.0.1:9042\\ncom.datastax.driver.core.TransportException: [/127.0.0.1:9042] Cannot connect\\n\\tat com.datastax.driver.core.Connection$1.operationComplete(Connection.java:156) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.driver.core.Connection$1.operationComplete(Connection.java:139) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:268) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:284) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat java.lang.Thread.run(Thread.java:745) [na:1.7.0_80]\\nCaused by: java.net.ConnectException: Connection refused: /127.0.0.1:9042\\n\\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_80]\\n\\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744) ~[na:1.7.0_80]\\n\\tat com.datastax.shaded.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224) ~[cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\tat com.datastax.shaded.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:281) [cassandra-driver-core-2.2.0-rc2-SNAPSHOT-20150617-shaded.jar:na]\\n\\t... 6 common frames omitted\\nFailed to connect over JMX; not collecting these stats\\n\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-b0pWB9\\ndtest: DEBUG: Done setting configuration options:\\n{   'num_tokens': None,\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\n--------------------- >> end captured logging << ---------------------\"\n\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.repair_test.TestRepair.test_multiple_concurrent_repairs"
   },
   {
      "_id": "12996303",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-08-10 14:51:18",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/787/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_writing_with_token_boundaries\n\nFailed on CassCI build cassandra-3.0_dtest build #787\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 1022, in test_writing_with_token_boundaries\n    self._test_writing_with_token_boundaries(10000, None, 2000000000000000000)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 1059, in _test_writing_with_token_boundaries\n    self.assertItemsEqual(csv_values, result)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 901, in assertItemsEqual\n    self.fail(msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"Element counts were not equal:\\nFirst has 0, Second has 1:  ('130', -4364617663693876050L)\\nFirst has 0, Second has 1:  ('1504', -4313346088993828066L)\\nFirst has 0, Second has 1:  ('1657', -4298243044528711865L)\\nFirst has 0, Second has 1:  ('1908', -4357762565998238890L)\\nFirst has 0, Second has 1:  ('196', -4311842292754600676L)\\nFirst has 0, Second has 1:  ('2069', -4364398944370882217L)\\nFirst has 0, Second has 1:  ('2840', -4341639477649832153L)\\nFirst has 0, Second has 1:  ('2887', -4318016824479819783L)\\nFirst has 0, Second has 1:  ('2899', -4302748366908469185L)\\nFirst has 0, Second has 1:  ('2928', -4320094196758787736L)\\nFirst has 0, Second has 1:  ('2985', -4314356124534988584L)\\nFirst has 0, Second has 1:  ('3684', -4338074463992249966L)\\nFirst has 0, Second has 1:  ('371', -4314424123257001171L)\\nFirst has 0, Second has 1:  ('3726', -4327342039280507889L)\\nFirst has 0, Second has 1:  ('3767', -4314615789624913427L)\\nFirst has 0, Second has 1:  ('3837', -4345782419910891107L)\\nFirst has 0, Second has 1:  ('3917', -4288469607605675346L)\\nFirst has 0, Second has 1:  ('4023', -4327319429102869913L)\\nFirst has 0, Second has 1:  ('4340', -4364719196309290555L)\\nFirst has 0, Second has 1:  ('4775', -4334399295585005795L)\\nFirst has 0, Second has 1:  ('480', -4297721626756162038L)\\nFirst has 0, Second has 1:  ('4927', -4363012199808638126L)\\nFirst has 0, Second has 1:  ('5227', -4322405738833807588L)\\nFirst has 0, Second has 1:  ('564', -4294201317243228473L)\\nFirst has 0, Second has 1:  ('585', -4359001293509999319L)\\nFirst has 0, Second has 1:  ('5869', -4350305245827564608L)\\nFirst has 0, Second has 1:  ('6907', -4350623491924194304L)\\nFirst has 0, Second has 1:  ('709', -4304008865600291097L)\\nFirst has 0, Second has 1:  ('7415', -4315752378065264743L)\\nFirst has 0, Second has 1:  ('7476', -4300546270541034340L)\\nFirst has 0, Second has 1:  ('7805', -4344641724309508742L)\\nFirst has 0, Second has 1:  ('7922', -4363605089028496367L)\\nFirst has 0, Second has 1:  ('8026', -4319008002233878821L)\\nFirst has 0, Second has 1:  ('8180', -4361912691055780971L)\\nFirst has 0, Second has 1:  ('8371', -4309172311179179912L)\\nFirst has 0, Second has 1:  ('8988', -4326093437666683541L)\\nFirst has 0, Second has 1:  ('9492', -4347264403260361686L)\\nFirst has 0, Second has 1:  ('9783', -4329297319597600121L)\\nFirst has 0, Second has 1:  ('9911', -4320490295580904236L)\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-2v8O54\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Exporting to csv file: /tmp/tmpDS47Vq\\ndtest: DEBUG: Exporting to csv file: /tmp/tmpQvnl6e\\ndtest: DEBUG: Exporting to csv file: /tmp/tmpfEEiAz\\ndtest: DEBUG: Exporting to csv file: /tmp/tmpc7T8av\\ndtest: DEBUG: Exporting to csv file: /tmp/tmplxBTNa\\ndtest: DEBUG: Exporting to csv file: /tmp/tmpb5VYGq\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_writing_with_token_boundaries"
   },
   {
      "_id": "12996296",
      "assignee": "krummas",
      "components": [],
      "created": "2016-08-10 14:28:31",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/669/testReport/compaction_test/TestCompaction_with_DateTieredCompactionStrategy/bloomfilter_size_test\n\nFailed on CassCI build cassandra-2.2_dtest build #669\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/compaction_test.py\", line 147, in bloomfilter_size_test\n    self.assertLessEqual(bfSize, size_factor * max_bf_size)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 936, in assertLessEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"125456 not less than or equal to 0\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-XJ96MC\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'start_rpc': 'true'}\\ndtest: DEBUG: bloom filter size is: 125456\\ndtest: DEBUG: size factor = 0\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_DateTieredCompactionStrategy.bloomfilter_size_test"
   },
   {
      "_id": "12996274",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-10 13:38:37",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/669/testReport/consistency_test/TestAvailability/test_network_topology_strategy\n\nFailed on CassCI build cassandra-2.2_dtest build #669\n{code}\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/consistency_test.py\", line 319, in test_network_topology_strategy\n    self._start_cluster()\n  File \"/home/automaton/cassandra-dtest/consistency_test.py\", line 96, in _start_cluster\n    cluster.start(wait_for_binary_proto=True, wait_other_notice=True)\n  File \"/home/automaton/ccm/ccmlib/cluster.py\", line 414, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\n\"Error starting node9.\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-an_vc5\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in consistency_test.TestAvailability.test_network_topology_strategy"
   },
   {
      "_id": "12995962",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-09 14:08:55",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/31/testReport/bootstrap_test/TestBootstrap/local_quorum_bootstrap_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in bootstrap_test.TestBootstrap.local_quorum_bootstrap_test"
   },
   {
      "_id": "12995772",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-08 22:25:16",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/31/testReport/ttl_test/TestDistributedTTL/ttl_is_respected_on_delayed_replication_test\n\n{code}\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/ttl_test.py\", line 439, in ttl_is_respected_on_delayed_replication_test\n    self.assertLessEqual(abs(ttl_session1[0][0] - ttl_session2[0][0]), 1)\n\"unsupported operand type(s) for -: 'NoneType' and 'int'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in ttl_test.TestDistributedTTL.ttl_is_respected_on_delayed_replication_test"
   },
   {
      "_id": "12995764",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2016-08-08 21:37:35",
      "description": "[Link|http://cassci.datastax.com/job/cassandra-3.9_testall/lastCompletedBuild/testReport/org.apache.cassandra.db.compaction/CompactionsCQLTest/testTriggerMinorCompactionDTCS/]\n\nError Message\nNo minor compaction triggered in 5000ms\n\nStacktrace\n{noformat}\njunit.framework.AssertionFailedError: No minor compaction triggered in 5000ms\n\tat org.apache.cassandra.db.compaction.CompactionsCQLTest.waitForMinor(CompactionsCQLTest.java:247)\n\tat org.apache.cassandra.db.compaction.CompactionsCQLTest.testTriggerMinorCompactionDTCS(CompactionsCQLTest.java:72)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "unittest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CompactionsCQLTest.testTriggerMinorCompactionDTCS fails"
   },
   {
      "_id": "12995711",
      "assignee": "cassandra-te",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2016-08-08 17:28:13",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/22/testReport/upgrade_tests.paging_test/TestPagingDataNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/test_paging_using_secondary_indexes\n\n{code}\nERROR [MessagingService-Incoming-/127.0.0.1] 2016-08-06 02:34:06,595 CassandraDaemon.java:201 - Exception in thread Thread[MessagingService-Incoming-/127.0.0.1,5,main]\njava.lang.AssertionError: null\n\tat org.apache.cassandra.db.ReadCommand$LegacyPagedRangeCommandSerializer.deserialize(ReadCommand.java:1042) ~[apache-cassandra-3.0.8.jar:3.0.8]\n\tat org.apache.cassandra.db.ReadCommand$LegacyPagedRangeCommandSerializer.deserialize(ReadCommand.java:964) ~[apache-cassandra-3.0.8.jar:3.0.8]\n\tat org.apache.cassandra.net.MessageIn.read(MessageIn.java:98) ~[apache-cassandra-3.0.8.jar:3.0.8]\n\tat org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:201) ~[apache-cassandra-3.0.8.jar:3.0.8]\n\tat org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:178) ~[apache-cassandra-3.0.8.jar:3.0.8]\n\tat org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:92) ~[apache-cassandra-3.0.8.jar:3.0.8]\n\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.paging_test.TestPagingDataNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x.test_paging_using_secondary_indexes"
   },
   {
      "_id": "12995677",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-08 15:25:09",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_large_dtest/7/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_2_2_x_To_indev_3_x/bootstrap_multidc_test\n\n{code}\nnode5: ERROR [main] 2016-08-06 18:38:38,187 MigrationManager.java:164 - Migration task failed to complete\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.upgrade_through_versions_test.TestUpgrade_current_2_2_x_To_indev_3_x.bootstrap_multidc_test"
   },
   {
      "_id": "12995674",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-08 15:19:07",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_upgrade/11/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_2_2_x/select_with_alias_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_2_2_x.select_with_alias_test"
   },
   {
      "_id": "12995671",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-08 15:11:31",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/6/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_1_x/select_with_alias_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 3187, in select_with_alias_test\n    assert_invalid(cursor, 'SELECT id AS user_id, name AS user_name FROM users WHERE id IN (0) ORDER BY user_name', matching=error_msg)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 92, in assert_invalid\n    assert_exception(session, query, matching=matching, expected=expected)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 65, in assert_exception\n    _assert_exception(session.execute, query, matching=matching, expected=expected)\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 54, in _assert_exception\n    assert_regexp_matches(str(e), matching)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 1002, in assertRegexpMatches\n    raise self.failureException(msg)\n'Regexp didn\\'t match: \"Aliases aren\\'t allowed in the where clause\" not found in \\'Error from server: code=2200 [Invalid query] message=\"Aliases are not allowed in order by clause (\\\\\\'user_name\\\\\\')\"\\'\n{code}\n\nRelated failures:\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/6/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_0_x_To_indev_2_1_x/select_with_alias_test/\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/6/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_0_x_To_indev_2_1_x/select_with_alias_test/\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_upgrade/6/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_2_1_x/select_with_alias_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_1_x.select_with_alias_test"
   },
   {
      "_id": "12995667",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-08-08 14:54:38",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/381/testReport/cql_tracing_test/TestCqlTracing/tracing_simple_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cql_tracing_test.py\", line 102, in tracing_simple_test\n    self.trace(session)\n  File \"/home/automaton/cassandra-dtest/cql_tracing_test.py\", line 74, in trace\n    self.assertIn('/127.0.0.1', out)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 803, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n'\\'/127.0.0.1\\' not found in \"Consistency level set to ALL.\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tracing_test.TestCqlTracing.tracing_simple_test"
   },
   {
      "_id": "12995287",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-05 17:45:56",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1326/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_pep8_compliance\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 290, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_tests.py\", line 69, in test_pep8_compliance\n    self.assertEqual(len(stdout), 0, stdout)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"/home/automaton/cassandra/pylib/cqlshlib/cql3handling.py:796:1: E302 expected 2 blank lines, found 1\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_tests.TestCqlsh.test_pep8_compliance"
   },
   {
      "_id": "12995237",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-08-05 15:15:55",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/666/testReport/bootstrap_test/TestBootstrap/local_quorum_bootstrap_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in bootstrap_test.TestBootstrap.local_quorum_bootstrap_test"
   },
   {
      "_id": "12995234",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-05 15:07:15",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/666/testReport/read_repair_test/TestReadRepair/test_gcable_tombstone_resurrection_on_range_slice_query",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in read_repair_test.TestReadRepair.test_gcable_tombstone_resurrection_on_range_slice_query"
   },
   {
      "_id": "12995126",
      "assignee": "slebresne",
      "components": [],
      "created": "2016-08-05 07:07:45",
      "description": "\"INSERT INTO collection_type(key,normal_column,list_column) VALUES ('k','value',[ '#293847','#323442' ]);\"\n\n\"UPDATE collection_type SET list_column=list_column+'#611987' WHERE key='k`;\"\n\nUsing 2.1.7.1 java driver to run Update query, the output is: '#611987', '#293847','#323442'\n\nUsing DevCenter 1.3.1 to execute Update query, result is in correct order: '#293847','#323442', '#611987'\n\nThe error happened in 3 node cluster. In local, one node is working properly.\n(all Cassandra 2.1.13. )\n\nIs it related to internal message processing?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "remove-reopen"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "List Append order is wrong"
   },
   {
      "_id": "12994919",
      "assignee": "stefania",
      "components": [],
      "created": "2016-08-04 15:03:15",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/783/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_reading_with_multiple_files",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_reading_with_multiple_files"
   },
   {
      "_id": "12994680",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-03 19:43:17",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/276/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV1Upgrade_AllVersions_EndsAt_indev_2_2_x/parallel_upgrade_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.upgrade_through_versions_test.ProtoV1Upgrade_AllVersions_EndsAt_indev_2_2_x.parallel_upgrade_test"
   },
   {
      "_id": "12994675",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-08-03 19:27:21",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_jdk8/291/testReport/read_repair_test/TestReadRepair/test_gcable_tombstone_resurrection_on_range_slice_query",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in read_repair_test.TestReadRepair.test_gcable_tombstone_resurrection_on_range_slice_query"
   },
   {
      "_id": "12994269",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-02 12:20:02",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest_upgrade/5/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_x/list_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/cql_tests.py\", line 1375, in list_test\n    assert_one(cursor, \"SELECT tags FROM user\", [['foo', 'bar', 'foo', 'foobar']])\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 124, in assert_one\n    assert list_res == [expected], \"Expected {} from {}, but got {}\".format([expected], query, list_res)\n\"Expected [[['foo', 'bar', 'foo', 'foobar']]] from SELECT tags FROM user, but got [[[u'foo', u'foo', u'bar', u'foo', u'foobar']]]\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_x.list_test"
   },
   {
      "_id": "12994072",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-01 19:45:06",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_novnode_dtest/24/testReport/materialized_views_test/TestMaterializedViews/add_dc_after_mv_simple_replication_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.add_dc_after_mv_simple_replication_test"
   },
   {
      "_id": "12994067",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-01 19:25:09",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_upgrade/7/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_2_2_x/bug_10652_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_2_2_x.bug_10652_test"
   },
   {
      "_id": "12994004",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-08-01 15:46:29",
      "description": "These are all similar looking test failures, which appear to be timeout issues of some kind.\n{noformat}('Unable to connect to any servers', {'127.0.0.1': OperationTimedOut('errors=Timed out creating connection (10 seconds), last_host=None',)}){noformat}\n\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.storage_engine_upgrade_test/TestLoadLaCompactSStables/sstableloader_compression_snappy_to_snappy_test\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.storage_engine_upgrade_test/TestLoadLaSStables/sstableloader_compression_deflate_to_deflate_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingDataNodes2RF1_Upgrade_current_2_1_x_To_indev_3_0_x/test_paging_across_multi_wide_rows/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingDataNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/test_paging_across_multi_wide_rows/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingSizeNodes2RF1_Upgrade_current_2_1_x_To_indev_3_0_x/test_undefined_page_size_default/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingDatasetChangesNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/test_cell_TTL_expiry_during_paging/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingSizeNodes2RF1_Upgrade_current_2_2_x_To_indev_3_0_x/test_undefined_page_size_default/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingDatasetChangesNodes2RF1_Upgrade_current_3_0_x_To_indev_3_0_x/test_cell_TTL_expiry_during_paging/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingDatasetChangesNodes2RF1_Upgrade_current_2_1_x_To_indev_3_0_x/test_row_TTL_expiry_during_paging/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.storage_engine_upgrade_test/TestBootstrapAfterUpgrade/upgrade_with_unclustered_CQL_table_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/range_tombstones_compaction_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_3_0_x_To_indev_3_0_x/bug_5732_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/collection_flush_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_3_0_x_To_indev_3_0_x/large_count_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/conditional_delete_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_3_0_x/range_tombstones_compaction_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingWithDeletionsNodes2RF1_Upgrade_current_2_2_x_To_indev_3_0_x/test_failure_threshold_deletions/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingWithDeletionsNodes2RF1_Upgrade_current_3_0_x_To_indev_3_0_x/test_ttl_deletions/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/limit_multiget_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/limit_multiget_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingDatasetChangesNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/test_data_change_impacting_later_page/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/expanded_list_item_conditional_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/no_range_ghost_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/limit_compact_table_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/counters_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/bug_6612_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/static_columns_with_2i_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/bug_6115_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/cas_and_ttl_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/order_by_multikey_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingDataNodes2RF1_Upgrade_current_2_2_x_To_indev_3_0_x/test_paging_using_secondary_indexes/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/indexes_composite_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/multi_in_compact_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/more_user_types_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingWithModifiersNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/test_with_order_by_reversed/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.paging_test/TestPagingWithModifiersNodes3RF3_Upgrade_current_3_0_x_To_indev_3_0_x/test_with_order_by/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/key_index_with_reverse_clustering_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/limit_sparse_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/select_distinct_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/dense_cf_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/list_item_conditional_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/bug_5240_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_3_0_x/bug7105_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_upgrade/10/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_2_x_To_indev_3_0_x/composite_index_with_pk_test/\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_upgrade/7/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_1_x_To_indev_2_2_x/batch_test/\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_upgrade/7/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3_Upgrade_current_2_1_x_To_indev_2_2_x/static_with_limit_test/\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_upgrade/7/testReport/upgrade_tests.paging_test/TestPagingWithDeletionsNodes2RF1_Upgrade_current_2_1_x_To_indev_2_2_x/test_multiple_cell_deletions/\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_upgrade/7/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_2_2_x_To_indev_2_2_x/range_query_2ndary_test/\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.storage_engine_upgrade_test.TestLoadLaCompactSStables.sstableloader_compression_snappy_to_snappy_test"
   },
   {
      "_id": "12993560",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-29 15:08:44",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/440/testReport/hintedhandoff_test/TestHintedHandoffConfig/hintedhandoff_enabled_test\n\n{code}\nError Message\n\n29 Jul 2016 00:56:17 [node1] Missing: ['Finished hinted']:\nINFO  [HANDSHAKE-/127.0.0.2] 2016-07-29 00:54:14,4.....\nSee system.log for remainder\n{code}\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/hintedhandoff_test.py\", line 125, in hintedhandoff_enabled_test\n    self._do_hinted_handoff(node1, node2, True)\n  File \"/home/automaton/cassandra-dtest/hintedhandoff_test.py\", line 61, in _do_hinted_handoff\n    node1.watch_log_for([\"Finished hinted\"], from_mark=log_mark, timeout=120)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 449, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"29 Jul 2016 00:56:17 [node1] Missing: ['Finished hinted']:\\nINFO  [HANDSHAKE-/127.0.0.2] 2016-07-29 00:54:14,4.....\\nSee system.log for remainder\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in hintedhandoff_test.TestHintedHandoffConfig.hintedhandoff_enabled_test"
   },
   {
      "_id": "12993539",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-29 13:15:46",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/21/testReport/cql_tracing_test/TestCqlTracing/tracing_unknown_impl_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tracing_test.TestCqlTracing.tracing_unknown_impl_test"
   },
   {
      "_id": "12992973",
      "assignee": "krummas",
      "components": [],
      "created": "2016-07-27 15:52:03",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_novnode_dtest/19/testReport/compaction_test/TestCompaction_with_DateTieredCompactionStrategy/bloomfilter_size_test\n\n500352 not less than or equal to 150000",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_DateTieredCompactionStrategy.bloomfilter_size_test"
   },
   {
      "_id": "12992959",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-27 15:15:41",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_novnode_dtest/16/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_round_trip_random",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_round_trip_random"
   },
   {
      "_id": "12992950",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-07-27 14:57:37",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_cqlsh_tests/17/testReport/nose.failure/Failure/runTest\n\n{code}\nStack Trace\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/usr/local/lib/python2.7/dist-packages/nose/loader.py\", line 418, in loadTestsFromName\n    addr.filename, addr.module)\n  File \"/usr/local/lib/python2.7/dist-packages/nose/importer.py\", line 47, in importFromPath\n    return self.importFromDir(dir_path, fqname)\n  File \"/usr/local/lib/python2.7/dist-packages/nose/importer.py\", line 94, in importFromDir\n    mod = load_module(part_fqname, fh, filename, desc)\n  File \"/home/automaton/cassandra/pylib/cqlshlib/test/__init__.py\", line 17, in <module>\n    from .cassconnect import create_test_db, remove_test_db\n  File \"/home/automaton/cassandra/pylib/cqlshlib/test/cassconnect.py\", line 22, in <module>\n    from .basecase import cql, cqlsh, cqlshlog, TEST_HOST, TEST_PORT, rundir\n  File \"/home/automaton/cassandra/pylib/cqlshlib/test/basecase.py\", line 46, in <module>\n    import cqlsh\n  File \"/home/automaton/cassandra/pylib/cqlshlib/test/cqlsh.py\", line 109, in <module>\n    from cassandra.cluster import Cluster, PagedResult\nImportError: cannot import name PagedResult\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in nose.failure.Failure.runTest"
   },
   {
      "_id": "12992417",
      "assignee": "stefania",
      "components": [],
      "created": "2016-07-25 22:14:54",
      "description": "[History|https://cassci.datastax.com/view/cassandra-3.9/job/cassandra-3.9_testall/lastCompletedBuild/testReport/org.apache.cassandra.cql3.validation.miscellaneous/SSTablesIteratedTest/testDeletionOnOverlappingIndexedSSTable_compression/history/]\n\nError Message\nexpected:<2> but was:<3>\n\nStacktrace\n{noformat}\njunit.framework.AssertionFailedError: expected:<2> but was:<3>\n\tat org.apache.cassandra.cql3.validation.miscellaneous.SSTablesIteratedTest.executeAndCheck(SSTablesIteratedTest.java:45)\n\tat org.apache.cassandra.cql3.validation.miscellaneous.SSTablesIteratedTest.testDeletionOnOverlappingIndexedSSTable(SSTablesIteratedTest.java:435)\n\tat org.apache.cassandra.cql3.validation.miscellaneous.SSTablesIteratedTest.testDeletionOnOverlappingIndexedSSTable(SSTablesIteratedTest.java:361)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "unittest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "SSTablesIteratedTest.testDeletionOnOverlappingIndexedSSTable-compression is flaky"
   },
   {
      "_id": "12992308",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-25 15:15:11",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/354/testReport/json_test/JsonFullRowInsertSelect/pkey_requirement_test\n\n{code}\nError Message\n\nDoctest failed! Captured output:\n**********************************************************************\nLine 25, in pkey_requirement_test\nFailed example:\n    cqlsh_err_print('''INSERT INTO primitive_type_test JSON '{\"col1\": \"bar\"}' ''')\nExpected:\n    <stdin>:2:InvalidRequest: Error from server: code=2200 [Invalid query] message=\"Invalid null value in condition for column key1\"\n    <BLANKLINE>\nGot:\n    <stdin>:2:InvalidRequest: code=2200 [Invalid query] message=\"Invalid null value in condition for column key1\"\n    <BLANKLINE>\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in json_test.JsonFullRowInsertSelect.pkey_requirement_test"
   },
   {
      "_id": "12992306",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-25 15:11:33",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/354/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_describe\n\n{code}\nError Message\n\nLists differ: [\"CREATE KEYSPACE test WITH re... != [\"CREATE KEYSPACE test WITH re...\n\nFirst differing element 9:\nAND cdc = false\n{code}\n\nRelated Failure: \n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/354/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_describe_mv/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_tests.TestCqlsh.test_describe"
   },
   {
      "_id": "12992304",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-25 15:10:41",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_cqlsh_tests/2/testReport/cqlshlib/test/remove_test_db\n\nhttp://cassci.datastax.com/job/cassandra-3.9_cqlsh_tests/3/cython=yes,label=ctool-lab/testReport/cqlshlib.test.test_cqlsh_completion/TestCqlshCompletion/test_complete_in_create_columnfamily/\n\nhttp://cassci.datastax.com/job/cassandra-3.9_cqlsh_tests/3/cython=yes,label=ctool-lab/testReport/cqlshlib.test.test_cqlsh_completion/TestCqlshCompletion/test_complete_in_create_table/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlshlib.test.remove_test_db"
   },
   {
      "_id": "12992303",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2016-07-25 15:02:56",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/347/testReport/secondary_indexes_test/TestSecondaryIndexes/test_query_indexes_with_vnodes\n\n{code}\nStandard Output\n\nUnexpected error in node2 log, error: \nERROR [ReadStage-1] 2016-07-20 04:58:27,391 MessageDeliveryTask.java:74 - The secondary index 'composites_index' is not yet available\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in secondary_indexes_test.TestSecondaryIndexes.test_query_indexes_with_vnodes"
   },
   {
      "_id": "12992275",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-07-25 13:32:50",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/17/testReport/user_functions_test/TestUserFunctions/test_migration",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in user_functions_test.TestUserFunctions.test_migration"
   },
   {
      "_id": "12991974",
      "assignee": "stefania",
      "components": [],
      "created": "2016-07-22 22:47:05",
      "description": "Error Message\nexpected:<3> but was:<4>\n\nStacktrace\njunit.framework.AssertionFailedError: expected:<3> but was:<4>\n\tat org.apache.cassandra.cql3.validation.miscellaneous.SSTablesIteratedTest.executeAndCheck(SSTablesIteratedTest.java:45)\n\tat org.apache.cassandra.cql3.validation.miscellaneous.SSTablesIteratedTest.testDeletionOnIndexedSSTableASC(SSTablesIteratedTest.java:348)\n\tat org.apache.cassandra.cql3.validation.miscellaneous.SSTablesIteratedTest.testDeletionOnIndexedSSTableASC(SSTablesIteratedTest.java:312)\n\n[Failure|http://cassci.datastax.com/job/cassandra-3.9_testall/lastCompletedBuild/testReport/org.apache.cassandra.cql3.validation.miscellaneous/SSTablesIteratedTest/testDeletionOnIndexedSSTableASC_compression/]\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "unittest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "SSTablesIteratedTest.testDeletionOnIndexedSSTableASC-compression failure"
   },
   {
      "_id": "12991836",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-22 14:43:58",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/271/testReport/offline_tools_test/TestOfflineTools/sstableofflinerelevel_test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in offline_tools_test.TestOfflineTools.sstableofflinerelevel_test"
   },
   {
      "_id": "12991526",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-21 16:33:10",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/432/testReport/materialized_views_test/TestMaterializedViews/add_dc_after_mv_simple_replication_test\n\n{code}\nStandard Output\n\nUnexpected error in node4 log, error: \nERROR [main] 2016-07-21 01:57:17,951 MigrationManager.java:164 - Migration task failed to complete\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.add_dc_after_mv_simple_replication_test"
   },
   {
      "_id": "12991524",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-21 16:30:58",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/431/testReport/bootstrap_test/TestBootstrap/consistent_range_movement_false_with_two_replicas_down_should_fail_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/bootstrap_test.py\", line 180, in consistent_range_movement_false_with_two_replicas_down_should_fail_test\n    self._bootstrap_test_with_replica_down(False, stop_two_replicas=True)\n  File \"/home/automaton/cassandra-dtest/bootstrap_test.py\", line 233, in _bootstrap_test_with_replica_down\n    node4.watch_log_for(\"Unable to find sufficient sources for streaming range\")\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 449, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"20 Jul 2016 00:58:03 [node4] Missing: ['Unable to find sufficient sources for streaming range']:\\nINFO  [main] 2016-07-20 00:48:02,304 YamlConfigura.....\\nSee system.log for remainder\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in bootstrap_test.TestBootstrap.consistent_range_movement_false_with_two_replicas_down_should_fail_test"
   },
   {
      "_id": "12991522",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-07-21 16:27:22",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1311/testReport/user_functions_test/TestUserFunctions/test_migration\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/user_functions_test.py\", line 92, in test_migration\n    [2, 2.0, math.sin(2.0), math.cos(2.0), math.tan(2.0)])\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 122, in assert_one\n    res = session.execute(simple_query)\n  File \"cassandra/cluster.py\", line 1941, in cassandra.cluster.Session.execute (cassandra/cluster.c:33653)\n    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile).result()\n  File \"cassandra/cluster.py\", line 3629, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:69380)\n    raise self._final_exception\n'Error from server: code=2200 [Invalid query] message=\"Unknown function \\'x_tan\\'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in user_functions_test.TestUserFunctions.test_migration"
   },
   {
      "_id": "12991519",
      "assignee": "krummas",
      "components": [],
      "created": "2016-07-21 16:21:53",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/15/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_marking_test\n\n{code}\nError Message\n\n'Repaired at: 0' unexpectedly found in 'SSTable: \n{code}\n\nRelated failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1315/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_marking_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.incremental_repair_test.TestIncRepair.sstable_marking_test"
   },
   {
      "_id": "12991488",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2016-07-21 14:31:19",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_novnode_dtest/14/testReport/write_failures_test/TestWriteFailures/test_thrift\n\nFailure is\n{code}\nUnexpected error in node3 log, error: \nERROR [NonPeriodicTasks:1] 2016-07-20 07:09:52,127 LogTransaction.java:205 - Unable to delete /tmp/dtest-CSPEFG/test/node3/data2/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/mb-2-big-Data.db as it does not exist\nUnexpected error in node3 log, error: \nERROR [NonPeriodicTasks:1] 2016-07-20 07:09:52,334 LogTransaction.java:205 - Unable to delete /tmp/dtest-CSPEFG/test/node3/data2/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/mb-15-big-Data.db as it does not exist\nUnexpected error in node3 log, error: \nERROR [NonPeriodicTasks:1] 2016-07-20 07:09:52,337 LogTransaction.java:205 - Unable to delete /tmp/dtest-CSPEFG/test/node3/data2/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/mb-31-big-Data.db as it does not exist\nUnexpected error in node3 log, error: \nERROR [NonPeriodicTasks:1] 2016-07-20 07:09:52,339 LogTransaction.java:205 - Unable to delete /tmp/dtest-CSPEFG/test/node3/data2/system_schema/tables-afddfb9dbc1e30688056eed6c302ba09/mb-18-big-Data.db as it does not exist\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in write_failures_test.TestWriteFailures.test_thrift"
   },
   {
      "_id": "12989873",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2016-07-15 17:51:50",
      "description": "[~Stefania]  \nhttp://cassci.datastax.com/job/cassandra-3.9_cqlsh_tests/lastCompletedBuild/testReport/\n\nHello, these three tests are failing:\ncqlshlib.test.remove_test_db\ncqlshlib.test.test_cqlsh_completion.TestCqlshCompletion.test_complete_in_create_columnfamily\ncqlshlib.test.test_cqlsh_completion.TestCqlshCompletion.test_complete_in_create_table\n\nCan you look at them, please?  Thank you!",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlshlib test failure: cqlshlib.test.remove_test_db"
   },
   {
      "_id": "12989861",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328216",
            "id": "12328216",
            "name": "Legacy/Distributed Metadata",
            "description": "Gossip, Schema, Auth"
         }
      ],
      "created": "2016-07-15 17:20:27",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/10/testReport/write_failures_test/TestWriteFailures/test_paxos_any\n\nand:\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/10/testReport/write_failures_test/TestWriteFailures/test_mutation_v3/\n\nFailed on CassCI build cassandra-3.9_dtest #10\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in write_failures_test.TestWriteFailures.test_paxos_any"
   },
   {
      "_id": "12989184",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-07-13 17:11:30",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/upgrade_tests-all/59/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_2_1_x_To_indev_3_x/bootstrap_test\n\nFailed on CassCI build upgrade_tests-all #59\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 707, in bootstrap_test\n    self.upgrade_scenario(after_upgrade_call=(self._bootstrap_new_node,))\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 383, in upgrade_scenario\n    call()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 688, in _bootstrap_new_node\n    nnode.start(use_jna=True, wait_other_notice=True, wait_for_binary_proto=True)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 634, in start\n    node.watch_log_for_alive(self, from_mark=mark)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 481, in watch_log_for_alive\n    self.watch_log_for(tofind, from_mark=from_mark, timeout=timeout, filename=filename)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 449, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"13 Jul 2016 02:23:05 [node2] Missing: ['127.0.0.4.* now UP']:\\nINFO  [HANDSHAKE-/127.0.0.4] 2016-07-13 02:21:00,2.....\\nSee system.log for remainder\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.upgrade_through_versions_test.TestUpgrade_current_2_1_x_To_indev_3_x.bootstrap_test"
   },
   {
      "_id": "12989179",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-13 17:04:27",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/upgrade_tests-all/59/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_2_2_x_To_indev_3_0_x/rolling_upgrade_with_internode_ssl_test\n\nFailed on CassCI build upgrade_tests-all #59\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 295, in rolling_upgrade_with_internode_ssl_test\n    self.upgrade_scenario(rolling=True, internode_ssl=True)\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 352, in upgrade_scenario\n    self._check_on_subprocs(self.subprocs)\n  File \"/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py\", line 409, in _check_on_subprocs\n    raise RuntimeError(message)\n\"A subprocess has terminated early. Subprocess statuses: Process-13 (is_alive: False), Process-14 (is_alive: True), Process-15 (is_alive: True), Process-16 (is_alive: True), attempting to terminate remaining subprocesses now.\n{code}\n\nnode2_debug.log is too large to attach.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.upgrade_through_versions_test.TestUpgrade_current_2_2_x_To_indev_3_0_x.rolling_upgrade_with_internode_ssl_test"
   },
   {
      "_id": "12988256",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-11 12:08:06",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/309/testReport/materialized_views_test/TestMaterializedViews/add_dc_after_mv_network_replication_test\n\nFailed on CassCI build trunk_offheap_dtest #309\n\n{code}\nStandard Output\n\nUnexpected error in node4 log, error: \nERROR [main] 2016-07-06 19:21:26,631 MigrationManager.java:164 - Migration task failed to complete\n{code}\n\nRelated failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/423/testReport/materialized_views_test/TestMaterializedViews/add_node_after_mv_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.add_dc_after_mv_network_replication_test"
   },
   {
      "_id": "12988243",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-11 11:31:05",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/493/testReport/cql_tracing_test/TestCqlTracing/tracing_simple_test\n\nFailed on CassCI build cassandra-2.1_dtest #493\n\nSeems related to CASSANDRA-12007.\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cql_tracing_test.py\", line 102, in tracing_simple_test\n    self.trace(session)\n  File \"/home/automaton/cassandra-dtest/cql_tracing_test.py\", line 73, in trace\n    self.assertIn('/127.0.0.1', out)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 803, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n'\\'/127.0.0.1\\' not found in \"Consistency level set to ALL....\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tracing_test.TestCqlTracing.tracing_simple_test"
   },
   {
      "_id": "12988240",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-07-11 11:22:24",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/492/testReport/thrift_tests/TestMutations/test_describe_keyspace\n\nFailed on CassCI build cassandra-2.1_dtest #492\n\n{code}\nStacktrace\n\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/thrift_tests.py\", line 1507, in test_describe_keyspace\n    assert len(kspaces) == 4, [x.name for x in kspaces]  # ['Keyspace2', 'Keyspace1', 'system', 'system_traces']\nAssertionError: ['Keyspace2', 'system', 'Keyspace1', 'ValidKsForUpdate', 'system_traces']\n{code}\n\nRelated failures:\nhttp://cassci.datastax.com/job/cassandra-2.2_novnode_dtest/304/testReport/thrift_tests/TestMutations/test_describe_keyspace/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/767/testReport/thrift_tests/TestMutations/test_describe_keyspace/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/264/testReport/thrift_tests/TestMutations/test_describe_keyspace/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1301/testReport/thrift_tests/TestMutations/test_describe_keyspace/\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/421/testReport/thrift_tests/TestMutations/test_describe_keyspace/\n\nhttp://cassci.datastax.com/job/cassandra-3.9_dtest/6/testReport/thrift_tests/TestMutations/test_describe_keyspace/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in thrift_tests.TestMutations.test_describe_keyspace"
   },
   {
      "_id": "12987565",
      "assignee": "joshuamckenzie",
      "components": [],
      "created": "2016-07-07 18:21:03",
      "description": "The latency with which CDC data becomes available has a known limitation due to our reliance on CommitLogSegments being discarded to have the data available in cdc_raw: if a slowly written table co-habitates a CommitLogSegment with CDC data, the CommitLogSegment won't be flushed until we hit either memory pressure on memtables or CommitLog limit pressure. Ultimately, this leaves a non-deterministic element to when data becomes available for CDC consumption unless a consumer parses live CommitLogSegments.\n\nTo work around this limitation and make semi-realtime CDC consumption more friendly to end-users, I propose we extend CDC as follows:\nh6. High level:\n* Consumers parse hard links of active CommitLogSegments in cdc_raw instead of waiting for flush/discard and file move\n* C* stores an offset of the highest seen CDC mutation in a separate idx file per commit log segment in cdc_raw. Clients tail this index file, delta their local last parsed offset on change, and parse the corresponding commit log segment using their last parsed offset as min\n* C* flags that index file with an offset and DONE when the file is flushed so clients know when they can clean up\n\nh6. Details:\n* On creation of a CommitLogSegment, also hard-link the file in cdc_raw\n* On first write of a CDC-enabled mutation to a segment, we:\n** Flag it as {{CDCState.CONTAINS}}\n** Set a long tracking the {{CommitLogPosition}} of the 1st CDC-enabled mutation in the log\n** Set a long in the CommitLogSegment tracking the offset of the end of the last written CDC mutation in the segment if higher than the previously known highest CDC offset\n* On subsequent writes to the segment, we update the offset of the highest known CDC data\n* On CommitLogSegment fsync, we write a file in cdc_raw as <segment_name>_cdc.idx containing the min offset and end offset fsynced to disk per file\n* On segment discard, if CDCState == {{CDCState.PERMITTED}}, delete both the segment in commitlog and in cdc_raw\n* On segment discard, if CDCState == {{CDCState.CONTAINS}}, delete the segment in commitlog and update the <segment_name>_cdc.idx file w/end offset and a DONE marker\n* On segment replay, store the highest end offset of seen CDC-enabled mutations from a segment and write that to <segment_name>_cdc.idx on completion of segment replay. This should bridge the potential correctness gap of a node writing to a segment and then dying before it can write the <segment_name>_cdc.idx file.\n\nThis should allow clients to skip the beginning of a file to the 1st CDC mutation, track an offset of how far they've parsed, delta against the _cdc.idx file end offset, and use that as a determinant on when to parse new CDC data. Any existing clients written to the initial implementation of CDC need only add the <segment_name>_cdc.idx logic and checking for DONE marker to their code, so the burden on users to update to support this should be quite small for the benefit of having data available as soon as it's fsynced instead of at a non-deterministic time when potentially unrelated tables are flushed.\n\nFinally, we should look into extending the interface on CommitLogReader to be more friendly for realtime parsing, perhaps supporting taking a CommitLogDescriptor and RandomAccessReader and resuming readSection calls, assuming the reader is at the start of a SyncSegment. Would probably also need to rewind to the start of the segment before returning so subsequent calls would respect this contract. This would skip needing to deserialize the descriptor and all completed SyncSegments to get to the root of the desired segment for parsing.\n\nOne alternative we discussed offline - instead of just storing the highest seen CDC offset, we could instead store an offset per CDC mutation (potentially delta encoded) in the idx file to allow clients to seek and only parse the mutations with CDC enabled. My hunch is that the performance delta from doing so wouldn't justify the complexity given the SyncSegment deserialization and seeking restrictions in the compressed and encrypted cases as mentioned above.\n\nThe only complication I can think of with the above design is uncompressed mmapped CommitLogSegments on Windows being undeletable, but it'd be pretty simple to disallow configuration of CDC w/uncompressed CommitLog on that environment.\n\nAnd as a final note: while the above might sound involved, it really shouldn't be a big change from where we are with v1 of CDC from a C* complexity nor code perspective, or from a client implementation perspective.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "native_protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve determinism of CDC data availability"
   },
   {
      "_id": "12986893",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-07-05 18:01:09",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/409/testReport/snapshot_test/TestArchiveCommitlog/dont_test_archive_commitlog\n\nFailed on CassCI build trunk_novnode_dtest #409\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/snapshot_test.py\", line 168, in dont_test_archive_commitlog\n    self.run_archive_commitlog(restore_point_in_time=False, restore_archived_commitlog=False)\n  File \"/home/automaton/cassandra-dtest/snapshot_test.py\", line 279, in run_archive_commitlog\n    set())\n  File \"/usr/lib/python2.7/unittest/case.py\", line 522, in assertNotEqual\n    raise self.failureException(msg)\n\"set([]) == set([])\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in snapshot_test.TestArchiveCommitlog.dont_test_archive_commitlog"
   },
   {
      "_id": "12986878",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-05 16:48:55",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/764/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_round_trip_random\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 928, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2334, in test_round_trip_random\n    self._test_round_trip(nodes=3, partitioner=\"random\")\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2296, in _test_round_trip\n    self.prepare(nodes=nodes, partitioner=partitioner)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 109, in prepare\n    self.cluster.populate(nodes, tokens=tokens).start(wait_for_binary_proto=True)\n  File \"/home/automaton/ccm/ccmlib/cluster.py\", line 412, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\n\"Error starting node1.\n{code}\n\nFailed on CassCI build cassandra-3.0_dtest #764",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_round_trip_random"
   },
   {
      "_id": "12986872",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-05 16:29:05",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_jdk8/240/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_marking_test\n\nFailed on CassCI build cassandra-2.1_dtest_jdk8 #240\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/repair_tests/incremental_repair_test.py\", line 42, in sstable_marking_test\n    node3.stop(gently=True)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 701, in stop\n    raise NodeError(\"Problem stopping node %s\" % self.name)\n\"Problem stopping node node3\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.incremental_repair_test.TestIncRepair.sstable_marking_test"
   },
   {
      "_id": "12986866",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-07-05 16:18:04",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/488/testReport/repair_tests.repair_test/TestRepair/dc_repair_test\n\nFailed on CassCI build cassandra-2.1_dtest #488\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/repair_tests/repair_test.py\", line 441, in dc_repair_test\n    cluster = self._setup_multi_dc()\n  File \"/home/automaton/cassandra-dtest/repair_tests/repair_test.py\", line 540, in _setup_multi_dc\n    self.check_rows_on_node(node2, 2000, missings=[1000])\n  File \"/home/automaton/cassandra-dtest/repair_tests/repair_test.py\", line 70, in check_rows_on_node\n    self.assertEqual(len(result), rows)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"2001 != 2000\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.repair_test.TestRepair.dc_repair_test"
   },
   {
      "_id": "12986267",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2016-07-01 17:46:09",
      "description": "While looking at the CAS code in Cassandra, I found a potential issue with CAS Reads. Here is how it can happen with RF=3\n\n1) You issue a CAS Write and it fails in the propose phase. A machine replies true to a propose and saves the commit in accepted filed. The other two machines B and C does not get to the accept phase. \n\nCurrent state is that machine A has this commit in paxos table as accepted but not committed and B and C does not. \n\n2) Issue a CAS Read and it goes to only B and C. You wont be able to read the value written in step 1. This step is as if nothing is inflight. \n\n3) Issue another CAS Read and it goes to A and B. Now we will discover that there is something inflight from A and will propose and commit it with the current ballot. Now we can read the value written in step 1 as part of this CAS read.\n\nIf we skip step 3 and instead run step 4, we will never learn about value written in step 1. \n\n4. Issue a CAS Write and it involves only B and C. This will succeed and commit a different value than step 1. Step 1 value will never be seen again and was never seen before. \n\n\n\nIf you read the Lamport \u201cpaxos made simple\u201d paper and read section 2.3. It talks about this issue which is how learners can find out if majority of the acceptors have accepted the proposal. \n\nIn step 3, it is correct that we propose the value again since we dont know if it was accepted by majority of acceptors. When we ask majority of acceptors, and more than one acceptors but not majority has something in flight, we have no way of knowing if it is accepted by majority of acceptors. So this behavior is correct. \n\nHowever we need to fix step 2, since it caused reads to not be linearizable with respect to writes and other reads. In this case, we know that majority of acceptors have no inflight commit which means we have majority that nothing was accepted by majority. I think we should run a propose step here with empty commit and that will cause write written in step 1 to not be visible ever after. \n\nWith this fix, we will either see data written in step 1 on next serial read or will never see it which is what we want. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT",
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CAS Reads Inconsistencies "
   },
   {
      "_id": "12985848",
      "assignee": "slebresne",
      "components": [],
      "created": "2016-06-30 19:02:30",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/upgrade_tests-all-custom_branch_runs/37/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_next_2_1_x_To_head_trunk/select_with_alias_test\n\nFailed on CassCI build upgrade_tests-all-custom_branch_runs #37\n\nThis is just a problem with different error messages across C* versions. Someone needs to do the legwork of figuring out what is required where, and filtering. The query is failing correctly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_next_2_1_x_To_head_trunk.select_with_alias_test"
   },
   {
      "_id": "12985826",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-06-30 17:12:19",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1292/testReport/read_repair_test/TestReadRepair/alter_rf_and_run_read_repair_test/\n\nFailed on CassCI build trunk_dtest #1292",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "read_repair_test.TestReadRepair.alter_rf_and_run_read_repair_test"
   },
   {
      "_id": "12985806",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-30 15:24:03",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/compaction_test/TestCompaction_with_SizeTieredCompactionStrategy/compaction_throughput_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/compaction_test.py\", line 251, in compaction_throughput_test\n    avgthroughput = re.match(throughput_pattern, stringline).group(1).strip()\n\"'NoneType' object has no attribute 'group'\n{code}\n\nRelated failures:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/compaction_test/TestCompaction_with_LeveledCompactionStrategy/compaction_throughput_test/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/compaction_test/TestCompaction_with_SizeTieredCompactionStrategy/compaction_throughput_test/\n\nFailed on CassCI build trunk_dtest #1290",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_SizeTieredCompactionStrategy.compaction_throughput_test"
   },
   {
      "_id": "12985805",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-06-30 15:22:46",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/compaction_test/TestCompaction_with_DateTieredCompactionStrategy/large_compaction_warning_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/compaction_test.py\", line 330, in large_compaction_warning_test\n    node.watch_log_for('{} large partition ks/large:user \\({}\\)'.format(verb, sizematcher), from_mark=mark, timeout=180)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 448, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"28 Jun 2016 15:16:51 [node1] Missing: ['Writing large partition ks/large:user \\\\\\\\(\\\\\\\\d+ bytes\\\\\\\\)']:\\nINFO  [Native-Transport-Requests-5] 2016-06-28 15:.....\\nSee system.log for remainder\n{code}\n\nRelated failures:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/compaction_test/TestCompaction_with_LeveledCompactionStrategy/large_compaction_warning_test/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/compaction_test/TestCompaction_with_SizeTieredCompactionStrategy/large_compaction_warning_test/\n\nFailed on CassCI build trunk_dtest #1290",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_DateTieredCompactionStrategy.large_compaction_warning_test"
   },
   {
      "_id": "12985802",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-30 15:20:41",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_past_and_future_dates\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 288, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_tests.py\", line 149, in test_past_and_future_dates\n    self.assertIn(\"2143-04-19 11:21:01+0000\", output)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 803, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"'2143-04-19 11:21:01+0000' not found in '\\\\n id | value\\\\n----+---------------------------------\\\\n  1 | 2143-04-19 11:21:01.000000+0000\\\\n  2 | 1943-04-19 11:21:01.000000+0000\\\\n\\\\n(2 rows)\\\\n'\n{code}\n\nFailed on CassCI build trunk_dtest #1290",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_tests.TestCqlsh.test_past_and_future_dates"
   },
   {
      "_id": "12985798",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-30 15:11:36",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/jmx_test/TestJMX/table_metric_mbeans_test\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/jmx_test.py\", line 77, in table_metric_mbeans_test\n    with JolokiaAgent(node1) as jmx:\n  File \"/home/automaton/cassandra-dtest/jmxutils.py\", line 231, in __enter__\n    self.start()\n  File \"/home/automaton/cassandra-dtest/jmxutils.py\", line 122, in start\n    subprocess.check_output(args, stderr=subprocess.STDOUT)\n  File \"/usr/lib/python2.7/subprocess.py\", line 573, in check_output\n    raise CalledProcessError(retcode, cmd, output=output)\n\"Command '('/usr/lib/jvm/jdk1.8.0_45/bin/java', '-cp', '/usr/lib/jvm/jdk1.8.0_45/lib/tools.jar:lib/jolokia-jvm-1.2.3-agent.jar', 'org.jolokia.jvmagent.client.AgentLauncher', '--host', '127.0.0.1', 'start', '32367')' returned non-zero exit status 1\n{code}\n\nOther related failures:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/configuration_test/TestConfiguration/change_durable_writes_test/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/repair_tests.deprecated_repair_test/TestDeprecatedRepairAPI/force_repair_async_1_test/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/disk_balance_test/TestDiskBalance/blacklisted_directory_test/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/repair_tests.deprecated_repair_test/TestDeprecatedRepairAPI/force_repair_async_2_test/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/thrift_hsha_test/ThriftHSHATest/test_closing_connections/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/jmx_test/TestJMX/test_compactionstats/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1290/testReport/repair_tests.deprecated_repair_test/TestDeprecatedRepairAPI/force_repair_range_async_1_test/\n\n\n\nFailed on CassCI build trunk_dtest #1290",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in jmx_test.TestJMX.table_metric_mbeans_test"
   },
   {
      "_id": "12985792",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-30 14:49:14",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/260/testReport/snapshot_test/TestSnapshot/test_basic_snapshot_and_restore\n\nFailed on CassCI build cassandra-2.1_novnode_dtest #260\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/snapshot_test.py\", line 96, in test_basic_snapshot_and_restore\n    self.restore_snapshot(snapshot_dir, node1, 'ks', 'cf')\n  File \"/home/automaton/cassandra-dtest/snapshot_test.py\", line 68, in restore_snapshot\n    (\" \".join(args), exit_status, stdout, stderr))\n'sstableloader command \\'/home/automaton/cassandra/bin/sstableloader -d 127.0.0.1 /tmp/tmpGgR_dT/0/ks/cf\\' failed; exit status: 1\\'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in snapshot_test.TestSnapshot.test_basic_snapshot_and_restore"
   },
   {
      "_id": "12985134",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-06-29 18:33:02",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/647/testReport/rebuild_test/TestRebuild/rebuild_ranges_test\n\nFailed on CassCI build cassandra-2.2_dtest #647",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in rebuild_test.TestRebuild.rebuild_ranges_test"
   },
   {
      "_id": "12984398",
      "assignee": "stefania",
      "components": [],
      "created": "2016-06-28 14:44:20",
      "description": "Create a custom index with a case-sensitive name.\nThe result of the DESCRIBE INDEX command does not have quotes around the index name. As a result, the index cannot be recreated with this output.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "DESCRIBE INDEX: missing quotes for case-sensitive index name"
   },
   {
      "_id": "12983836",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-27 16:05:00",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/274/testReport/snitch_test/TestGossipingPropertyFileSnitch/test_prefer_local_reconnect_on_listen_address\n\nFailed on CassCI build trunk_offheap_dtest #274\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 358, in run\n    self.tearDown()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 761, in tearDown\n    ['\\n'.join(msg) for msg in node.grep_log_for_errors()]))\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 357, in grep_log_for_errors\n    return self.grep_log_for_errors_from(seek_start=getattr(self, 'error_mark', 0))\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 360, in grep_log_for_errors_from\n    with open(os.path.join(self.get_path(), 'logs', filename)) as f:\n\"[Errno 2] No such file or directory: '/mnt/tmp/dtest-Pa4WH7/test/node2/logs/system.log'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in snitch_test.TestGossipingPropertyFileSnitch.test_prefer_local_reconnect_on_listen_address"
   },
   {
      "_id": "12983820",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-06-27 15:25:46",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/407/testReport/consistency_test/TestAccuracy/test_simple_strategy_each_quorum_users\n\nFailed on CassCI build trunk_novnode_dtest #407\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 288, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/consistency_test.py\", line 591, in test_simple_strategy_each_quorum_users\n    self._run_test_function_in_parallel(TestAccuracy.Validation.validate_users, [self.nodes], [self.rf], combinations)\n  File \"/home/automaton/cassandra-dtest/consistency_test.py\", line 543, in _run_test_function_in_parallel\n    assert False, err.message\n'Error from server: code=2200 [Invalid query] message=\"unconfigured table users\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in consistency_test.TestAccuracy.test_simple_strategy_each_quorum_users"
   },
   {
      "_id": "12983808",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-06-27 14:50:25",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/484/testReport/consistency_test/TestAccuracy/test_simple_strategy_counters\n\nFailed on CassCI build cassandra-2.1_dtest #484\n\n{code}\nStandard Error\n\nTraceback (most recent call last):\n  File \"/home/automaton/cassandra-dtest/consistency_test.py\", line 514, in run\n    valid_fcn(v)\n  File \"/home/automaton/cassandra-dtest/consistency_test.py\", line 497, in validate_counters\n    check_all_sessions(s, n, c)\n  File \"/home/automaton/cassandra-dtest/consistency_test.py\", line 490, in check_all_sessions\n    \"value of %s at key %d, instead got these values: %s\" % (write_nodes, val, n, results)\nAssertionError: Failed to read value from sufficient number of nodes, required 2 nodes to have a counter value of 1 at key 200, instead got these values: [0, 0, 1]\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in consistency_test.TestAccuracy.test_simple_strategy_counters"
   },
   {
      "_id": "12983804",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-27 14:40:24",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/483/testReport/pushed_notifications_test/TestPushedNotifications/add_and_remove_node_test\n\nFailed on CassCI build cassandra-2.1_dtest #483\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/pushed_notifications_test.py\", line 242, in add_and_remove_node_test\n    self.assertEquals(2, len(notifications), notifications)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"[{'change_type': u'NEW_NODE', 'address': ('127.0.0.2', 9042)}]\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in pushed_notifications_test.TestPushedNotifications.add_and_remove_node_test"
   },
   {
      "_id": "12982723",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-24 15:28:03",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/260/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_writing_with_max_output_size\n\nFailed on CassCI build cassandra-3.0_dtest_win32 #260",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_writing_with_max_output_size"
   },
   {
      "_id": "12982046",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-22 18:40:23",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/262/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_copy_options_from_config_file\n\nFailed on CassCI build trunk_offheap_dtest #262\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2203, in test_copy_options_from_config_file\n    [('header', 'True'), ('maxattempts', '9')])\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2194, in do_test\n    check_options(out, expected_options)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2176, in check_options\n    d = json.loads(opts)\n  File \"/usr/lib/python2.7/json/__init__.py\", line 338, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python2.7/json/decoder.py\", line 366, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/usr/lib/python2.7/json/decoder.py\", line 384, in raw_decode\n    raise ValueError(\"No JSON object could be decoded\")\n'No JSON object could be decoded\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_copy_options_from_config_file"
   },
   {
      "_id": "12982042",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-06-22 18:21:53",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/261/testReport/paging_test/TestPagingData/static_columns_paging_test\n\nFailed on CassCI build trunk_offheap_dtest #261\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 288, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/paging_test.py\", line 715, in static_columns_paging_test\n    self.assertEqual(16, len(results))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"16 != 6\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in paging_test.TestPagingData.static_columns_paging_test"
   },
   {
      "_id": "12982031",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-22 18:04:22",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/405/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_round_trip_with_different_number_precision\n\nFailed on CassCI build trunk_novnode_dtest #405\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 288, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2049, in test_round_trip_with_different_number_precision\n    do_test(0, 0)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2044, in do_test\n    self.assertItemsEqual(sorted(list(csv_rows(tempfile1.name))), sorted(list(csv_rows(tempfile2.name))))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 901, in assertItemsEqual\n    self.fail(msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"Element counts were not equal:\\nFirst has 1, Second has 0:  ['1', '1', '1']\n{code}\n\nLogs are attached.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_round_trip_with_different_number_precision"
   },
   {
      "_id": "12981983",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-22 17:23:46",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/259/testReport/repair_tests.repair_test/TestRepair/repair_after_upgrade_test\n\nFailed on CassCI build cassandra-3.0_dtest_win32 #259",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.repair_test.TestRepair.repair_after_upgrade_test"
   },
   {
      "_id": "12981945",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-22 16:08:07",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1284/testReport/auth_test/TestAuth/login_test\n\nFailed on CassCI build trunk_dtest #1284\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/auth_test.py\", line 82, in login_test\n    assert isinstance(e.errors.values()[0], AuthenticationFailed)\n{code}\n\nLogs are attached.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in auth_test.TestAuth.login_test"
   },
   {
      "_id": "12981910",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-22 15:04:49",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/482/testReport/pushed_notifications_test/TestPushedNotifications/add_and_remove_node_test\n\nFailed on CassCI build cassandra-2.1_dtest #482\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/pushed_notifications_test.py\", line 242, in add_and_remove_node_test\n    self.assertEquals(2, len(notifications), notifications)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"[{'change_type': u'NEW_NODE', 'address': ('127.0.0.2', 9042)}]\n{code}\n\nLogs are attached.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in pushed_notifications_test.TestPushedNotifications.add_and_remove_node_test"
   },
   {
      "_id": "12981429",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-21 17:42:52",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/252/testReport/batch_test/TestBatch/logged_batch_compatibility_3_test\n\nFailed on CassCI build cassandra-3.0_novnode_dtest #252",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in batch_test.TestBatch.logged_batch_compatibility_3_test"
   },
   {
      "_id": "12981178",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2016-06-21 03:04:33",
      "description": "We update the most recent commit on requiredParticipant replicas if out of sync during the prepare round in beginAndRepairPaxos method. We keep doing this in a loop till the requiredParticipant replicas have the same most recent commit or we hit timeout. \n\nSay we have 3 machines A,B and C and gc grace on the table is 10 days. We do a CAS write at time 0 and it went to A and B but not to C.  C will get the hint later but will not update the most recent commit in paxos table. This is how CAS hints work. \nIn the paxos table whose gc_grace=0, most_recent_commit in A and B will be inserted with timestamp 0 and with a TTL of 10 days. After 10 days, this insert will become a tombstone at time 0 till it is compacted away since gc_grace=0.\n\nDo a CAS read after say 1 day on the same CQL partition and this time prepare phase involved A and C. most_recent_commit on C for this CQL partition is empty. A sends the most_recent_commit to C with a timestamp of 0 and with a TTL of 10 days. This most_recent_commit on C will expire on 11th day since it is inserted after 1 day. \n\nmost_recent_commit are now in sync on A,B and C, however A and B most_recent_commit will expire on 10th day whereas for C it will expire on 11th day since it was inserted one day later. \n\nDo another CAS read after 10days when most_recent_commit on A and B have expired and is treated as tombstones till compacted. In this CAS read, say A and C are involved in prepare phase. most_recent_commit will not match between them since it is expired in A and is still there on C. This will cause most_recent_commit to be applied to A with a timestamp of 0 and TTL of 10 days. If A has not compacted away the original most_recent_commit which has expired, this new write to most_recent_commit wont be visible on reads since there is a tombstone with same timestamp(Delete wins over data with same timestamp). \n\nAnother round of prepare will follow and again A would say it does not know about most_recent_write(covered by original write which is not a tombstone) and C will again try to send the write to A. This can keep going on till the request timeouts or only A and B are involved in the prepare phase. \n\nWhen A\u2019s original most_recent_commit which is now a tombstone is compacted, all the inserts which it was covering will come live. This will in turn again get played to another replica. This ping pong can keep going on for a long time. \n\nThe issue is that most_recent_commit is expiring at different times across replicas. When they get replayed to a replica to make it in sync, we again set the TTL from that point.  \nDuring the CAS read which timed out, most_recent_commit was being sent to another replica in a loop. Even in successful requests, it will try to loop for a couple of times if involving A and C and then when the replicas which respond are A and B, it will succeed. So this will have impact on latencies as well. \n\nThese timeouts gets worse when a machine is down as no progress can be made as the machine with unexpired commit is always involved in the CAS prepare round. Also with range movements, the new machine gaining range has empty most recent commit and gets the commit at a later time causing same issue. \n\nRepro steps:\n1. Paxos TTL is max(3 hours, gc_grace) as defined in SystemKeyspace.paxosTtl(). Change this method to not put a minimum TTL of 3 hours. \nMethod  SystemKeyspace.paxosTtl() will look like return metadata.getGcGraceSeconds();   instead of return Math.max(3 * 3600, metadata.getGcGraceSeconds());\nWe are doing this so that we dont need to wait for 3 hours. \n\nCreate a 3 node cluster with the code change suggested above with machines A,B and C\nCREATE KEYSPACE  test WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 };\nuse test;\nCREATE TABLE users (a int PRIMARY KEY,b int);\nalter table users WITH gc_grace_seconds=120;\nconsistency QUORUM;\nbring down machine C\nINSERT INTO users (user_name, password ) VALUES ( 1,1) IF NOT EXISTS;\nNodetool flush on machine A and B\nBring up the down machine B \nconsistency SERIAL;\ntracing on;\nwait 80 seconds\nBring up machine C\nselect * from users where user_name = 1;\nWait 40 seconds \nselect * from users where user_name = 1;  //All queries from this point forward will timeout. \n\nOne of the potential fixes could be to set the TTL based on the remaining time left on another replicas. This will be TTL-timestamp of write. This timestamp is calculated from ballot which uses server time.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Syncing most recent commit in CAS across replicas can cause all CAS queries in the CQL partition to fail"
   },
   {
      "_id": "12980886",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-20 15:08:10",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/252/testReport/batch_test/TestBatch/logged_batch_compatibility_3_test\n\nFailed on CassCI build cassandra-3.0_novnode_dtest #252",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in batch_test.TestBatch.logged_batch_compatibility_3_test"
   },
   {
      "_id": "12980883",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-20 14:59:23",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/257/testReport/repair_tests.repair_test/TestRepair/repair_after_upgrade_test\n\nFailed on CassCI build cassandra-3.0_dtest_win32 #257",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.repair_test.TestRepair.repair_after_upgrade_test"
   },
   {
      "_id": "12980230",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-06-17 15:57:10",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/360/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_copy_to_with_child_process_crashing\n\nFailed on CassCI build cassandra-2.1_offheap_dtest #360\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 889, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2701, in test_copy_to_with_child_process_crashing\n    self.assertIn('some records might be missing', err)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 803, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\nError Message\n\n'some records might be missing' not found in ''\n{code}\n\nLogs are attached.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_copy_to_with_child_process_crashing"
   },
   {
      "_id": "12978834",
      "assignee": "krummas",
      "components": [],
      "created": "2016-06-14 15:35:56",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_jdk8/229/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_repairedset_test\n\nFailed on CassCI build cassandra-2.1_dtest_jdk8 #229\n\nLogs are attached.\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/repair_tests/incremental_repair_test.py\", line 226, in sstable_repairedset_test\n    self.assertNotIn('Repaired at: 0', finaloutput)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 810, in assertNotIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"'Repaired at: 0' unexpectedly found in 'No such file: /mnt/tmp/dtest-DoN5MO/test/node1/data0/keyspace1/standard1-0d92e6402f7c11e6bac8356bf83fc3ce/keyspace1-standard1-ka-81-Data.db\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.incremental_repair_test.TestIncRepair.sstable_repairedset_test"
   },
   {
      "_id": "12978198",
      "assignee": "stefania",
      "components": [],
      "created": "2016-06-13 15:45:43",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/745/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_refresh_schema_on_timeout_error\n\nFailed on CassCI build cassandra-3.0_dtest #745",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_tests.TestCqlsh.test_refresh_schema_on_timeout_error"
   },
   {
      "_id": "12977666",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2016-06-10 16:17:15",
      "description": "W made a mistake in CASSANDRA-9649 so that a temporal clock skew on one node can \"corrupt\" other node clocks through Paxos. That wasn't intended and we should fix that. I'll attach a patch later.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "On clock skew, paxos may \"corrupt\" the node clock"
   },
   {
      "_id": "12976900",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-06-08 15:24:20",
      "description": "pylib.copyutil presently accesses cluster metadata using {{shell.hostname}} which could be an unresolved hostname.\nhttps://github.com/apache/cassandra/blob/58d3b9a90461806d44dd85bf4aa928e575d5fb6c/pylib/cqlshlib/copyutil.py#L207\n\nCluster metadata normally refers to hosts in terms of numeric host address, not hostname. This works in the current integration because the driver allows hosts with unresolved names into metadata during the initial control connection. In a future version of the driver, that anomaly is removed, and no duplicate hosts-by-name are present in the metadata.\n\nWe will need to update copyutil to refer to hosts by address when accessing metadata. This can be accomplished by one of two methods presently:\n\n# shell.conn.control_connection.host (gives the current connected host address)\n# scan metadata.all_hosts() for the one that {{is_up}} and use host.address/host.datacenter",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh copyutil should get host metadata by connected address"
   },
   {
      "_id": "12976694",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-06-08 03:10:18",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/252/testReport/json_tools_test/TestJson/json_tools_test\n\nFailed on CassCI build cassandra-2.2_dtest_win32 #252",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in json_tools_test.TestJson.json_tools_test"
   },
   {
      "_id": "12975533",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-06-03 16:35:33",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/234/testReport/user_functions_test/TestUserFunctions/test_migration\n\nFailed on CassCI build trunk_offheap_dtest #234\n\nLogs are attached.\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/user_functions_test.py\", line 50, in test_migration\n    session2.execute(\"use ks\")\n  File \"cassandra/cluster.py\", line 1706, in cassandra.cluster.Session.execute (cassandra/cluster.c:28532)\n    return self.execute_async(query, parameters, trace, custom_payload, timeout).result()\n  File \"cassandra/cluster.py\", line 3339, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:62978)\n    raise self._final_exception\n'Error from server: code=2200 [Invalid query] message=\"Keyspace \\'ks\\' does not exist\"\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-1nvamN\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   \\'enable_scripted_user_defined_functions\\': \\'true\\',\\n    \\'enable_user_defined_functions\\': \\'true\\',\\n    \\'initial_token\\': None,\\n    \\'memtable_allocation_type\\': \\'offheap_objects\\',\\n    \\'num_tokens\\': \\'32\\',\\n    \\'phi_convict_threshold\\': 5}\\n--------------------- >> end captured logging << ---------------------'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in user_functions_test.TestUserFunctions.test_migration"
   },
   {
      "_id": "12975530",
      "assignee": "stefania",
      "components": [],
      "created": "2016-06-03 16:13:30",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_large_dtest/10/testReport/consistency_test/TestAvailability/test_network_topology_strategy_each_quorum\n\nFailed on CassCI build trunk_large_dtest #10\n\nLogs are attached.\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 358, in run\n    self.tearDown()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 719, in tearDown\n    raise AssertionError('Unexpected error in log, see stdout')\n\nStandard Output\n\nUnexpected error in node3 log, error: \nERROR [SharedPool-Worker-1] 2016-06-03 14:25:27,460 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-2] 2016-06-03 14:25:27,460 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-3] 2016-06-03 14:25:27,462 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-2] 2016-06-03 14:25:27,464 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-3] 2016-06-03 14:25:27,464 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-1] 2016-06-03 14:25:27,465 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-4] 2016-06-03 14:25:27,465 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-5] 2016-06-03 14:25:27,465 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-7] 2016-06-03 14:25:27,465 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\nERROR [SharedPool-Worker-6] 2016-06-03 14:25:27,465 Keyspace.java:504 - Attempting to mutate non-existant table 03b14ad0-2997-11e6-b8c7-01c3aea11be7 (mytestks.users)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in consistency_test.TestAvailability.test_network_topology_strategy_each_quorum"
   },
   {
      "_id": "12974235",
      "assignee": "cassandra-te",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2016-05-31 14:29:53",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1245/testReport/secondary_indexes_test/TestSecondaryIndexes/test_manual_rebuild_index\n\nFailed on CassCI build trunk_dtest #1245\n\nLogs are attached.\n\n{code}\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 288, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/secondary_indexes_test.py\", line 305, in test_manual_rebuild_index\n    self.assertEqual(1, len(list(session.execute(stmt, [lookup_value]))))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"1 != 0\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-HSQXU3\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in secondary_indexes_test.TestSecondaryIndexes.test_manual_rebuild_index"
   },
   {
      "_id": "12973436",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-05-27 15:21:37",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1243/testReport/cql_tests/AbortedQueriesTester/remote_query_test\n\nFailed on CassCI build trunk_dtest #1243\n\n{code}\nERROR [SharedPool-Worker-1] 2016-05-27 10:08:49,471 Keyspace.java:504 - Attempting to mutate non-existant table 01855840-23f3-11e6-912e-c5dc3b68cc6d (ks.test2)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tests.AbortedQueriesTester.remote_query_test"
   },
   {
      "_id": "12973105",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-05-26 15:42:50",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1236/testReport/cql_tests/AbortedQueriesTester/materialized_view_test\n\nFailed on CassCI build trunk_dtest #1236",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tests.AbortedQueriesTester.materialized_view_test"
   },
   {
      "_id": "12973085",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-05-26 14:40:14",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/243/testReport/sstable_generation_loading_test/TestSSTableGenerationAndLoading/sstableloader_compression_snappy_to_none_test\n\nFailed on CassCI build cassandra-3.0_dtest_win32 #243\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/243/testReport/sstable_generation_loading_test/TestSSTableGenerationAndLoading/sstableloader_compression_none_to_deflate_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/243/testReport/sstable_generation_loading_test/TestSSTableGenerationAndLoading/sstableloader_compression_none_to_deflate_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/243/testReport/sstable_generation_loading_test/TestSSTableGenerationAndLoading/sstableloader_compression_none_to_none_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/243/testReport/sstable_generation_loading_test/TestSSTableGenerationAndLoading/sstableloader_compression_snappy_to_deflate_test/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/243/testReport/sstable_generation_loading_test/TestSSTableGenerationAndLoading/sstableloader_compression_snappy_to_deflate_test/\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in sstable_generation_loading_test.TestSSTableGenerationAndLoading.sstableloader_compression_snappy_to_none_test"
   },
   {
      "_id": "12972422",
      "assignee": "krummas",
      "components": [],
      "created": "2016-05-24 15:48:03",
      "description": "Once validation compaction has been finished, all mismatching sstable sections for a token range will be used for streaming as return by {{StreamSession.getSSTableSectionsForRanges}}. Currently 2.1 will try to restrict the sstable candidates by checking if they can be found in {{CANONICAL_SSTABLES}} and will ignore them otherwise. At the same time {{IntervalTree}} in the {{DataTracker}} will be build based on replaced non-canonical sstables as well. In case of early opened sstables this becomes a problem, as the tree will be update with {{OpenReason.EARLY}} replacements that cannot be found in canonical. But whenever {{getSSTableSectionsForRanges}} will get a early instance from the view, it will fail to retrieve the corresponding canonical version from the map, as the different generation will cause a hashcode mismatch. Please find a test attached.\n\nAs a consequence not all sections for a range are streamed. In our case this has caused deleted data to reappear, as sections holding tombstones were left out due to this behavior.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "correctness",
         "repair",
         "streaming"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Streaming will miss sections for early opened sstables during compaction"
   },
   {
      "_id": "12972142",
      "assignee": "krummas",
      "components": [],
      "created": "2016-05-23 18:24:33",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/upgrade_tests-all/47/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_Upgrade_current_3_x_To_indev_3_x/select_key_in_test\n\nFailed on CassCI build upgrade_tests-all #47\n\nAttached logs for test failure.\n\n{code}\nERROR [CompactionExecutor:2] 2016-05-21 23:10:35,678 CassandraDaemon.java:195 - Exception in thread Thread[CompactionExecutor:2,1,main]\njava.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down\n\tat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:61) ~[apache-cassandra-3.5.jar:3.5]\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1364) ~[na:1.8.0_51]\n\tat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:165) ~[apache-cassandra-3.5.jar:3.5]\n\tat java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:112) ~[na:1.8.0_51]\n\tat org.apache.cassandra.db.compaction.CompactionManager.submitBackground(CompactionManager.java:184) ~[apache-cassandra-3.5.jar:3.5]\n\tat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:270) ~[apache-cassandra-3.5.jar:3.5]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_51]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_Upgrade_current_3_x_To_indev_3_x.select_key_in_test"
   },
   {
      "_id": "12971376",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-05-20 02:03:27",
      "description": "OS: Debian GNU/Linux stretch/sid \nKernel: 4.5.0-2-amd64 #1 SMP Debian 4.5.4-1 (2016-05-16) x86_64 GNU/Linux\nPython version: 2.7.11+ (default, May  9 2016, 15:54:33)\n[GCC 5.3.1 20160429]\n\ncqlsh --version: cqlsh 5.0.1\ncassandra -v: 3.5 (also occurs with 3.0.6)\n\nIssue:\nwhen running cqlsh, it returns the following error:\n\ncqlsh -u dbarpt_usr01\nPassword: *****\n\nConnection error: ('Unable to connect to any servers', {'odbasandbox1': TypeError('ref() does not take keyword arguments',)})\n\nI cleared PYTHONPATH:\n\npython -c \"import json; print dir(json); print json.__version__\"\n['JSONDecoder', 'JSONEncoder', '__all__', '__author__', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', '__version__', '_default_decoder', '_default_encoder', 'decoder', 'dump', 'dumps', 'encoder', 'load', 'loads', 'scanner']\n2.0.9\n\nJava based clients can connect to Cassandra with no issue. Just CQLSH and Python clients cannot.\n\nnodetool status also works.\n\nThank you for your help.\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cannot use cql since upgrading python to 2.7.11+"
   },
   {
      "_id": "12970865",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-05-18 18:10:51",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1223/testReport/topology_test/TestTopology/simple_decommission_test\n\nFailed on CassCI build trunk_dtest #1223\n\nThe problem is that node3 detected node2 as down before the stop call was made, so the wait_other_notice check fails. The fix here is almost certainly as simple as just changing that line to {{node2.stop()}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in topology_test.TestTopology.simple_decommission_test"
   },
   {
      "_id": "12970593",
      "assignee": "krummas",
      "components": [],
      "created": "2016-05-18 01:13:55",
      "description": "I have a test that disables gossip and runs repair at the same time. \n\n{quote}\nWARN  [RMI TCP Connection(15)-54.67.121.105] 2016-05-17 16:57:21,775 StorageService.java:384 - Stopping gossip by operator request\nINFO  [RMI TCP Connection(15)-54.67.121.105] 2016-05-17 16:57:21,775 Gossiper.java:1463 - Announcing shutdown\nINFO  [RMI TCP Connection(15)-54.67.121.105] 2016-05-17 16:57:21,776 StorageService.java:1999 - Node /172.31.31.1 state jump to shutdown\nINFO  [HANDSHAKE-/172.31.17.32] 2016-05-17 16:57:21,895 OutboundTcpConnection.java:514 - Handshaking version with /172.31.17.32\nINFO  [HANDSHAKE-/172.31.24.76] 2016-05-17 16:57:21,895 OutboundTcpConnection.java:514 - Handshaking version with /172.31.24.76\nINFO  [Thread-25] 2016-05-17 16:57:21,925 RepairRunnable.java:125 - Starting repair command #1, repairing keyspace keyspace1 with repair options (parallelism: parallel, primary range: false, incremental: true, job threads: 1, ColumnFamilies: [], dataCenters: [], hosts: [], # of ranges: 3)\nINFO  [Thread-26] 2016-05-17 16:57:21,953 RepairRunnable.java:125 - Starting repair command #2, repairing keyspace stresscql with repair options (parallelism: parallel, primary range: false, incremental: true, job threads: 1, ColumnFamilies: [], dataCenters: [], hosts: [], # of ranges: 3)\nINFO  [Thread-27] 2016-05-17 16:57:21,967 RepairRunnable.java:125 - Starting repair command #3, repairing keyspace system_traces with repair options (parallelism: parallel, primary range: false, incremental: true, job threads: 1, ColumnFamilies: [], dataCenters: [], hosts: [], # of ranges: 2)\n{quote}\n\nThis ends up failing:\n\n{quote}\n16:54:44.844 INFO  serverGroup-node-1-574 - STDOUT: [2016-05-17 16:57:21,933] Starting repair command #1, repairing keyspace keyspace1 with repair options (parallelism: parallel, primary range: false, incremental: true, job threads: 1, ColumnFamilies: [], dataCenters: [], hosts: [], # of ranges: 3)\n[2016-05-17 16:57:21,943] Did not get positive replies from all endpoints. List of failed endpoint(s): [172.31.24.76, 172.31.17.32]\n[2016-05-17 16:57:21,945] null\n{quote}\n\nSubsequent calls to repair with all nodes up still fails:\n\n{quote}\nERROR [ValidationExecutor:3] 2016-05-17 18:58:53,460 CompactionManager.java:1193 - Cannot start multiple repair sessions over the same sstables\nERROR [ValidationExecutor:3] 2016-05-17 18:58:53,460 Validator.java:261 - Failed creating a merkle tree for [repair #66425f10-1c61-11e6-83b2-0b1fff7a067d on keyspace1/standard1, \n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "fallout"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "If repair fails no way to run repair again"
   },
   {
      "_id": "12970447",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-05-17 17:36:58",
      "description": "Test is failing on trunk. Example failure is here:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/378/testReport/replication_test/SnitchConfigurationUpdateTest/test_rf_expand_gossiping_property_file_snitch_multi_dc/\n\nIt appears to be running out of memory to allocate, inside the dtest python code, when starting nodetool. This may need moved to large test, but it's odd that it just started happening\n\n{code}\n[node3 ERROR] Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f25b9fd0000, 65536, 1) failed; error='Cannot allocate memory' (errno=12)\n[node2 ERROR] Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f591e0c0000, 65536, 1) failed; error='Cannot allocate memory' (errno=12)\n[node5 ERROR] Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00007fabca130000, 65536, 1) failed; error='Cannot allocate memory' (errno=12)\n[node6 ERROR] Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00007fd0b2080000, 65536, 1) failed; error='Cannot allocate memory' (errno=12)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in replication_test.SnitchConfigurationUpdateTest.test_rf_expand_gossiping_property_file_snitch_multi_dc"
   },
   {
      "_id": "12969234",
      "assignee": "stefania",
      "components": [],
      "created": "2016-05-12 17:17:50",
      "description": "No cassci link, as jenkins is failing to show failures for this test, but I'm seeing detected leaks.\n\nRelevant log section:\n{code}\nERROR [Reference-Reaper:1] 2016-05-11 16:17:47,616 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@41f74411) to class org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Cleanup@1328587359:/mnt/tmp/dtest-X5kTWw/test/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/la-12-big-Data.db was not released before the reference was garbage collected\nDEBUG [Reference-Reaper:1] 2016-05-11 16:17:47,617 FileCacheService.java:177 - Invalidating cache for /mnt/tmp/dtest-X5kTWw/test/node1/data2/system/local-7ad54392bcdd35a684174e047860b377/tmplink-la-13-big-Data.db\nERROR [Reference-Reaper:1] 2016-05-11 16:17:47,617 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@4b0f2f61) to class org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Cleanup@235776100:/mnt/tmp/dtest-X5kTWw/test/node1/data2/system/local-7ad54392bcdd35a684174e047860b377/tmplink-la-13-big-Data.db was not released before the reference was garbage collected\nERROR [Reference-Reaper:1] 2016-05-11 16:17:47,617 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@75a1b278) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@1061799113:[Memory@[0..8), Memory@[0..50)] was not released before the reference was garbage collected\nERROR [Reference-Reaper:1] 2016-05-11 16:17:47,617 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@d0f8066) to class org.apache.cassandra.io.util.MmappedSegmentedFile$Cleanup@1847744299:/mnt/tmp/dtest-X5kTWw/test/node1/data2/system/local-7ad54392bcdd35a684174e047860b377/tmplink-la-13-big-Index.db was not released before the reference was garbage collected\nERROR [Reference-Reaper:1] 2016-05-11 16:17:47,617 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@16680ae5) to class org.apache.cassandra.io.util.MmappedSegmentedFile$Cleanup@1744239469:/mnt/tmp/dtest-X5kTWw/test/node1/data0/system/local-7ad54392bcdd35a684174e047860b377/la-12-big-Index.db was not released before the reference was garbage collected\nERROR [Reference-Reaper:1] 2016-05-11 16:17:47,618 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@160b4b45) to class org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$1@1785515424:[[OffHeapBitSet]] was not released before the reference was garbage collected\n{code}\n\nLogs are attached. node1 is the one experiencing the issue.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.upgrade_through_versions_test.ProtoV3Upgrade_AllVersions_EndsAt_Trunk_HEAD.rolling_upgrade_test"
   },
   {
      "_id": "12968662",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2016-05-12 15:07:43",
      "description": "Example failure:\n\nhttp://cassci.datastax.com/view/Parameterized/job/upgrade_tests-all-custom_branch_runs/12/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_Skips_3_0_x_EndsAt_Trunk_HEAD/rolling_upgrade_test_2/\n\nThe test is seeing a corrupt hint sstable after upgrade from 2.2.5 to 3.6. Relevant stack trace is\n\n{code}\nERROR [main] 2016-05-11 16:22:25,180 CassandraDaemon.java:727 - Exception encountered during startup\njava.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /mnt/tmp/dtest-X7IReF/test/node1/data2/system/hints-2666e20573ef38b390fefecf96e8f0c7/la-3-big-Data.db\n\tat org.apache.cassandra.hints.LegacyHintsMigrator.forceCompaction(LegacyHintsMigrator.java:119) ~[main/:na]\n\tat org.apache.cassandra.hints.LegacyHintsMigrator.compactLegacyHints(LegacyHintsMigrator.java:108) ~[main/:na]\n\tat org.apache.cassandra.hints.LegacyHintsMigrator.migrate(LegacyHintsMigrator.java:92) ~[main/:na]\n\tat org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:321) [main/:na]\n\tat org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:581) [main/:na]\n\tat org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:710) [main/:na]\nCaused by: java.util.concurrent.ExecutionException: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /mnt/tmp/dtest-X7IReF/test/node1/data2/system/hints-2666e20573ef38b390fefecf96e8f0c7/la-3-big-Data.db\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_51]\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_51]\n\tat org.apache.cassandra.hints.LegacyHintsMigrator.forceCompaction(LegacyHintsMigrator.java:115) ~[main/:na]\n\t... 5 common frames omitted\nCaused by: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /mnt/tmp/dtest-X7IReF/test/node1/data2/system/hints-2666e20573ef38b390fefecf96e8f0c7/la-3-big-Data.db\n\tat org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator.computeNext(BigTableScanner.java:351) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator.computeNext(BigTableScanner.java:265) ~[main/:na]\n\tat org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.big.BigTableScanner.hasNext(BigTableScanner.java:245) ~[main/:na]\n\tat org.apache.cassandra.utils.MergeIterator$OneToOne.computeNext(MergeIterator.java:463) ~[main/:na]\n\tat org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[main/:na]\n\tat org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$2.hasNext(UnfilteredPartitionIterators.java:150) ~[main/:na]\n\tat org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:72) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionIterator.hasNext(CompactionIterator.java:226) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:182) ~[main/:na]\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:82) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:60) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionManager$10.runMayThrow(CompactionManager.java:805) ~[main/:na]\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_51]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_51]\n\tat java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_51]\nCaused by: java.io.EOFException: null\n\tat org.apache.cassandra.io.util.RebufferingInputStream.readFully(RebufferingInputStream.java:68) ~[main/:na]\n\tat org.apache.cassandra.io.util.RebufferingInputStream.readFully(RebufferingInputStream.java:60) ~[main/:na]\n\tat org.apache.cassandra.io.util.TrackedDataInputPlus.readFully(TrackedDataInputPlus.java:93) ~[main/:na]\n\tat org.apache.cassandra.utils.ByteBufferUtil.read(ByteBufferUtil.java:400) ~[main/:na]\n\tat org.apache.cassandra.utils.ByteBufferUtil.readWithShortLength(ByteBufferUtil.java:375) ~[main/:na]\n\tat org.apache.cassandra.db.Serializers$1.deserialize(Serializers.java:109) ~[main/:na]\n\tat org.apache.cassandra.db.Serializers$1.deserialize(Serializers.java:89) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.IndexInfo$Serializer.deserialize(IndexInfo.java:135) ~[main/:na]\n\tat org.apache.cassandra.db.RowIndexEntry$IndexedEntry.<init>(RowIndexEntry.java:651) ~[main/:na]\n\tat org.apache.cassandra.db.RowIndexEntry$IndexedEntry.<init>(RowIndexEntry.java:577) ~[main/:na]\n\tat org.apache.cassandra.db.RowIndexEntry$LegacyShallowIndexedEntry.deserialize(RowIndexEntry.java:508) ~[main/:na]\n\tat org.apache.cassandra.db.RowIndexEntry$Serializer.deserialize(RowIndexEntry.java:321) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator.computeNext(BigTableScanner.java:310) ~[main/:na]\n\t... 19 common frames omitted\nERROR [CompactionExecutor:2] 2016-05-11 16:22:25,183 CassandraDaemon.java:213 - Exception in thread Thread[CompactionExecutor:2,1,main]\norg.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /mnt/tmp/dtest-X7IReF/test/node1/data2/system/hints-2666e20573ef38b390fefecf96e8f0c7/la-3-big-Data.db\n\tat org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator.computeNext(BigTableScanner.java:351) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator.computeNext(BigTableScanner.java:265) ~[main/:na]\n\tat org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.big.BigTableScanner.hasNext(BigTableScanner.java:245) ~[main/:na]\n\tat org.apache.cassandra.utils.MergeIterator$OneToOne.computeNext(MergeIterator.java:463) ~[main/:na]\n\tat org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[main/:na]\n\tat org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$2.hasNext(UnfilteredPartitionIterators.java:150) ~[main/:na]\n\tat org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:72) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionIterator.hasNext(CompactionIterator.java:226) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:182) ~[main/:na]\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:82) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:60) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionManager$10.runMayThrow(CompactionManager.java:805) ~[main/:na]\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_51]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]\nCaused by: java.io.EOFException: null\n\tat org.apache.cassandra.io.util.RebufferingInputStream.readFully(RebufferingInputStream.java:68) ~[main/:na]\n\tat org.apache.cassandra.io.util.RebufferingInputStream.readFully(RebufferingInputStream.java:60) ~[main/:na]\n\tat org.apache.cassandra.io.util.TrackedDataInputPlus.readFully(TrackedDataInputPlus.java:93) ~[main/:na]\n\tat org.apache.cassandra.utils.ByteBufferUtil.read(ByteBufferUtil.java:400) ~[main/:na]\n\tat org.apache.cassandra.utils.ByteBufferUtil.readWithShortLength(ByteBufferUtil.java:375) ~[main/:na]\n\tat org.apache.cassandra.db.Serializers$1.deserialize(Serializers.java:109) ~[main/:na]\n\tat org.apache.cassandra.db.Serializers$1.deserialize(Serializers.java:89) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.IndexInfo$Serializer.deserialize(IndexInfo.java:135) ~[main/:na]\n\tat org.apache.cassandra.db.RowIndexEntry$IndexedEntry.<init>(RowIndexEntry.java:651) ~[main/:na]\n\tat org.apache.cassandra.db.RowIndexEntry$IndexedEntry.<init>(RowIndexEntry.java:577) ~[main/:na]\n\tat org.apache.cassandra.db.RowIndexEntry$LegacyShallowIndexedEntry.deserialize(RowIndexEntry.java:508) ~[main/:na]\n\tat org.apache.cassandra.db.RowIndexEntry$Serializer.deserialize(RowIndexEntry.java:321) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator.computeNext(BigTableScanner.java:310) ~[main/:na]\n\t... 19 common frames omitted\n{code}\n\nLogs are attached",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.upgrade_through_versions_test.ProtoV3Upgrade_AllVersions_Skips_3_0_x_EndsAt_Trunk_HEAD.rolling_upgrade_test"
   },
   {
      "_id": "12967925",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328222",
            "id": "12328222",
            "name": "Legacy/Observability",
            "description": "JMX, Metrics, Tracing, Logging"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-05-11 20:28:55",
      "description": "Output from show session in cqlsh:\n{quote}\nSubmit hint for /10.255.227.20 [EXPIRING-MAP-REAPER:1] | 2016-05-11 15:57:53.730000 | 10.255.226.163 |         283246\n{quote}\nOutput from select * from trace_events where session_id=(same as above):\n{quote}\n 1bbce5c0-1791-11e6-9598-3b9ec975a2e6 | 1ee37a20-1791-11e6-9598-3b9ec975a2e6 |                         Submit hint for /10.255.227.20 | 10.255.226.163 |        5283246 |                     EXPIRING-MAP-REAPER:1\n{quote}\nNotice that the 5 (seconds) part is being truncated in the output.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh show sessions truncates time_elapsed values > 999999"
   },
   {
      "_id": "12965767",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-05-06 23:01:26",
      "description": "one recent failure (no vnode job)\n\n{noformat}\n'MOVED_NODE' != u'NEW_NODE'\n{noformat}\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/366/testReport/pushed_notifications_test/TestPushedNotifications/move_single_node_test\n\nFailed on CassCI build trunk_novnode_dtest #366",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in pushed_notifications_test.TestPushedNotifications.move_single_node_test"
   },
   {
      "_id": "12965715",
      "assignee": "krummas",
      "components": [],
      "created": "2016-05-06 20:20:03",
      "description": "Produced on 2.1.12\n\nWe are seeing incremental repair fail with an error regarding creating multiple repair sessions on overlapping sstables. This is happening in the following setup\n\n* 6 nodes\n* 2 Datacenters\n* Vnodes enabled\n* Leveled compaction on the relevant tables\n\nWhen STCS is used instead, we don't hit an issue. This is slightly related to https://issues.apache.org/jira/browse/CASSANDRA-11461, except in this case OpsCenter repair service is running all repairs sequentially. Let me know what other information we can provide. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Incremental repair fails with vnodes+lcs+multi-dc"
   },
   {
      "_id": "12964485",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-05-02 23:52:08",
      "description": "from offheap test job, failure. looks like it could be a routine timeout, but I think I saw the exact same timeout for this test on another job.\n\n{noformat}\n('Unable to connect to any servers', {})\n{noformat}\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/178/testReport/pushed_notifications_test/TestPushedNotifications/restart_node_localhost_test\n\nFailed on CassCI build trunk_offheap_dtest #178",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in pushed_notifications_test.TestPushedNotifications.restart_node_localhost_test"
   },
   {
      "_id": "12964484",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-05-02 23:47:00",
      "description": "looks to be an assertion problem, so could be test or cassandra related:\n\ne.g.:\n{noformat}\n10000 != 331\n{noformat}\n\nhttp://cassci.datastax.com/job/trunk_dtest_win32/404/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_reading_with_skip_and_max_rows\n\nFailed on CassCI build trunk_dtest_win32 #404",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "[windows] dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_reading_with_skip_and_max_rows"
   },
   {
      "_id": "12964481",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-05-02 23:39:41",
      "description": "single failure, unsure if test or cassandra issue:\n{noformat}\nERROR [BatchlogTasks:1] 2016-05-02 20:23:08,488 CassandraDaemon.java:195 - Exception in thread Thread[BatchlogTasks:1,5,main]\njava.lang.NoClassDefFoundError: org/apache/cassandra/utils/JVMStabilityInspector\n\tat org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run(DebuggableScheduledThreadPoolExecutor.java:122) ~[main/:na]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_45]\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_45]\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_45]\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_45]\nCaused by: java.lang.ClassNotFoundException: org.apache.cassandra.utils.JVMStabilityInspector\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_45]\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_45]\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_45]\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_45]\n\t... 8 common frames omitted\nERROR [BatchlogTasks:1] 2016-05-02 20:23:08,490 CassandraDaemon.java:195 - Exception in thread Thread[BatchlogTasks:1,5,main]\njava.lang.NoClassDefFoundError: org/apache/cassandra/utils/JVMStabilityInspector\n\tat org.apache.cassandra.service.CassandraDaemon$2.uncaughtException(CassandraDaemon.java:199) ~[main/:na]\n\tat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.handleOrLog(DebuggableThreadPoolExecutor.java:244) ~[main/:na]\n\tat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.logExceptionsAfterExecute(DebuggableThreadPoolExecutor.java:227) ~[main/:na]\n\tat org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor.afterExecute(DebuggableScheduledThreadPoolExecutor.java:89) ~[main/:na]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1150) ~[na:1.8.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_45]\n\tat java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_45]\nCaused by: java.lang.ClassNotFoundException: org.apache.cassandra.utils.JVMStabilityInspector\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_45]\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_45]\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_45]\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_45]\n\t... 7 common frames omitted\nERROR [OptionalTasks:1] 2016-05-02 20:23:08,577 CassandraDaemon.java:195 - Exception in thread Thread[OptionalTasks:1,5,main]\njava.lang.NoClassDefFoundError: org/apache/cassandra/utils/JVMStabilityInspector\n\tat org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run(DebuggableScheduledThreadPoolExecutor.java:122) ~[main/:na]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_45]\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) ~[na:1.8.0_45]\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) ~[na:1.8.0_45]\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) ~[na:1.8.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_45]\nERROR [OptionalTasks:1] 2016-05-02 20:23:08,588 CassandraDaemon.java:195 - Exception in thread Thread[OptionalTasks:1,5,main]\njava.lang.NoClassDefFoundError: org/apache/cassandra/utils/JVMStabilityInspector\n\tat org.apache.cassandra.service.CassandraDaemon$2.uncaughtException(CassandraDaemon.java:199) ~[main/:na]\n\tat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.handleOrLog(DebuggableThreadPoolExecutor.java:244) ~[main/:na]\n\tat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.logExceptionsAfterExecute(DebuggableThreadPoolExecutor.java:227) ~[main/:na]\n\tat org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor.afterExecute(DebuggableScheduledThreadPoolExecutor.java:89) ~[main/:na]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1150) ~[na:1.8.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_45]\n\tat java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_45]\nWARN  [OptionalTasks:2] 2016-05-02 20:23:08,588 CassandraRoleManager.java:344 - CassandraRoleManager skipped default role setup: some nodes were not ready\n{noformat}\nhttp://cassci.datastax.com/job/trunk_dtest/1190/testReport/upgrade_crc_check_chance_test/TestCrcCheckChanceUpgrade/crc_check_chance_upgrade_test\n\nFailed on CassCI build trunk_dtest #1190",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_crc_check_chance_test.TestCrcCheckChanceUpgrade.crc_check_chance_upgrade_test"
   },
   {
      "_id": "12963999",
      "assignee": "stefania",
      "components": [],
      "created": "2016-04-29 22:21:55",
      "description": "example failure:\n\n{noformat}\nLists differ: ['/mnt/tmp/dtest-hXZ_VA/test/n... != ['/mnt/tmp/dtest-hXZ_VA/test/n...\n\nFirst differing element 16:\n/mnt/tmp/dtest-hXZ_VA/test/node1/data2/keyspace1/standard1-483ee2700d5911e6b19a879d803a6aae/ma-3-big-CRC.db\n/mnt/tmp/dtest-hXZ_VA/test/node1/data2/keyspace1/standard1-483ee2700d5911e6b19a879d803a6aae/ma-5-big-CRC.db\n\nDiff is 5376 characters long. Set self.maxDiff to None to see it.\n{noformat}\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/360/testReport/sstableutil_test/SSTableUtilTest/abortedcompaction_test\n\nFailed on CassCI build trunk_novnode_dtest #360",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in sstableutil_test.SSTableUtilTest.abortedcompaction_test"
   },
   {
      "_id": "12963264",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-04-27 18:57:45",
      "description": "these appear to be related, all failed on the same build (but appear to be passing now).\n\nhttp://cassci.datastax.com/job/trunk_dtest/1165/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_copy_from_with_brackets_in_UDT/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1165/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_undefined_as_null_indicator/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1165/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_round_trip_with_sub_second_precision/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1165/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_null_as_null_indicator/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1165/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_default_null_indicator/\n\nhttp://cassci.datastax.com/job/trunk_dtest/1165/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_all_datatypes_write/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "multiple dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest"
   },
   {
      "_id": "12963234",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-27 18:23:14",
      "description": "single failure, but might be worth looking into to see if it repros at all.\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/669/testReport/materialized_views_test/TestMaterializedViews/clustering_column_test\n\nFailed on CassCI build cassandra-3.0_dtest #669",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.clustering_column_test"
   },
   {
      "_id": "12963227",
      "assignee": "krummas",
      "components": [],
      "created": "2016-04-27 18:01:15",
      "description": "This test was originally waiting on CASSANDRA-11179, which I recently removed the 'require' annotation from (since 11179 is committed). Not sure why failing on 2.1 now, perhaps didn't get committed.\n\nhttp://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/339/testReport/bootstrap_test/TestBootstrap/test_cleanup\n\nFailed on CassCI build cassandra-2.1_offheap_dtest #339",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "(2.1) dtest failure in bootstrap_test.TestBootstrap.test_cleanup"
   },
   {
      "_id": "12962805",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-26 23:13:30",
      "description": "single test flap, so could be a fluke. happened on the trunk no-vnode test:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/354/testReport/pushed_notifications_test/TestPushedNotifications/move_single_node_test\n\nFailed on CassCI build trunk_novnode_dtest #354",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in pushed_notifications_test.TestPushedNotifications.move_single_node_test"
   },
   {
      "_id": "12962790",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-04-26 22:44:00",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/353/testReport/topology_test/TestTopology/movement_test\n\nFailed on CassCI build trunk_novnode_dtest #353",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in topology_test.TestTopology.movement_test"
   },
   {
      "_id": "12962775",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-26 22:31:48",
      "description": "intermittent failure, example failure:\n\nfailed on trunk no-vnodes job\n\n\"True is not false\"\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/351/testReport/topology_test/TestTopology/decommissioned_node_cant_rejoin_test\n\nFailed on CassCI build trunk_novnode_dtest #351",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in topology_test.TestTopology.decommissioned_node_cant_rejoin_test"
   },
   {
      "_id": "12962510",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2016-04-26 07:38:22",
      "description": "Seems CASSANDRA-10099 broke LongLeveledCompactionStrategyTest",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "LongLeveledCompactionStrategyTest broken since CASSANDRA-10099"
   },
   {
      "_id": "12962423",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-25 23:30:26",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/660/testReport/sstableutil_test/SSTableUtilTest/abortedcompaction_test\n\nFailed on CassCI build cassandra-3.0_dtest #660\n\nLooks likely to be a test problem, with error message \"0 not greater than 0\"",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in sstableutil_test.SSTableUtilTest.abortedcompaction_test"
   },
   {
      "_id": "12962387",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-04-25 20:38:56",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/585/testReport/json_test/ToJsonSelectTests/basic_data_types_test\n\nFailed on CassCI build cassandra-2.2_dtest #585",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in json_test.ToJsonSelectTests.basic_data_types_test"
   },
   {
      "_id": "12962386",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-04-25 20:38:48",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/585/testReport/json_test/ToJsonSelectTests/complex_data_types_test\n\nFailed on CassCI build cassandra-2.2_dtest #585",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in json_test.ToJsonSelectTests.complex_data_types_test"
   },
   {
      "_id": "12962385",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-04-25 20:38:42",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/585/testReport/json_test/JsonFullRowInsertSelect/simple_schema_test\n\nFailed on CassCI build cassandra-2.2_dtest #585",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in json_test.JsonFullRowInsertSelect.simple_schema_test"
   },
   {
      "_id": "12962384",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-04-25 20:38:35",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/585/testReport/json_test/FromJsonInsertTests/basic_data_types_test\n\nFailed on CassCI build cassandra-2.2_dtest #585",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in json_test.FromJsonInsertTests.basic_data_types_test"
   },
   {
      "_id": "12961585",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-04-22 09:27:40",
      "description": "cqlsh's {{COPY FROM ... WITH PREPAREDSTATEMENTS = False}} fails if the row contains null values. Reason is that the {{','.join(r)}} in {{make_non_prepared_batch_statement}} doesn't seem to handle {{None}}, which results in this error message.\n{code}\nFailed to import 1 rows: TypeError - sequence item 2: expected string, NoneType found,  given up without retries\n{code}\n\nAttached patch should fix the problem.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh COPY FROM fails for null values with non-prepared statements"
   },
   {
      "_id": "12960321",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2016-04-20 12:35:36",
      "description": "2.2.6 has no this bug.\nI've tried 3.0 alpha 1, 3.0 beta 1, 3.0 beta 2, 3.0.0, 3.0.6, 3.5, datastax-ddc 3.5.0 (from repo), and trunk (3.6) - all of them have this bug. \nI've found that the error is thrown since d12d2d496540c698f30e9b528b66e8f6636842d3, which is included in 3.0 beta 1 (but *not* in the alpha 1).\nCassandra 3.0 alpha 1 does not throw the error, but forgets about the changes after shutting down.\n\n\nOnly after rm ./data/commitlog/* , Cassandra starts fine.\nBy the way, map<int, boolean> works fine.\n\nSteps to reproduce:\n{code}\n$ ant build\n$ ./bin/cassandra\n$ ./bin/cqlsh\n{code}\n{code:sql}\nCREATE KEYSPACE bugs\n    WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}\n    AND durable_writes = true;\n\nCREATE TABLE bugs.bug1 (\n    id int,\n    m  map<int, tinyint or smallint>, -- key can be any type\n    PRIMARY KEY (id)\n);\n\nINSERT INTO bugs.bug1 (id, m) VALUES (1, {0: 4, 4: 3});\n\nUPDATE bugs.bug1 SET m[0]=NULL WHERE id=1;\n-- and/or UPDATE bugs.bug1 SET m[1]=NULL WHERE id=1;\n\nSELECT * FROM bugs.bug1;\n{code}\n{code}\n id | m\n----+--------\n  1 | {4: 3}\n\n(1 rows)\n{code}\n{code}\n$ ./bin/nodetool stopdaemon\n$ ./bin/cassandra\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "commitlog",
         "regression",
         "serializers"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Removing an element from map<any type, tinyint/smallint> corrupts commitlog"
   },
   {
      "_id": "12960065",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-19 17:38:22",
      "description": "This looks like a timeout kind of flap. It's flapped once. Example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_offheap_dtest/344/testReport/replace_address_test/TestReplaceAddress/replace_first_boot_test\n\nFailed on CassCI build cassandra-2.2_offheap_dtest #344 - 2.2.6-tentative\n\n{code}\nError Message\n\n15 Apr 2016 16:23:41 [node3] Missing: ['127.0.0.4.* now UP']:\nINFO  [main] 2016-04-15 16:21:32,345 Config.java:4.....\nSee system.log for remainder\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-4i5qkE\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'memtable_allocation_type': 'offheap_objects',\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'start_rpc': 'true'}\ndtest: DEBUG: Starting cluster with 3 nodes.\ndtest: DEBUG: 32\ndtest: DEBUG: Inserting Data...\ndtest: DEBUG: Stopping node 3.\ndtest: DEBUG: Testing node stoppage (query should fail).\ndtest: DEBUG: Retrying read after timeout. Attempt #0\ndtest: DEBUG: Retrying read after timeout. Attempt #1\ndtest: DEBUG: Retrying request after UE. Attempt #2\ndtest: DEBUG: Retrying request after UE. Attempt #3\ndtest: DEBUG: Retrying request after UE. Attempt #4\ndtest: DEBUG: Starting node 4 to replace node 3\ndtest: DEBUG: Verifying querying works again.\ndtest: DEBUG: Verifying tokens migrated sucessfully\ndtest: DEBUG: ('WARN  [main] 2016-04-15 16:21:21,068 TokenMetadata.java:196 - Token -3855903180169109916 changing ownership from /127.0.0.3 to /127.0.0.4\\n', <_sre.SRE_Match object at 0x7fd21c0e2370>)\ndtest: DEBUG: Try to restart node 3 (should fail)\ndtest: DEBUG: [('WARN  [GossipStage:1] 2016-04-15 16:21:22,942 StorageService.java:1962 - Host ID collision for 75916cc0-86ec-4136-b336-862a49953616 between /127.0.0.3 and /127.0.0.4; /127.0.0.4 is the new owner\\n', <_sre.SRE_Match object at 0x7fd1f83555e0>)]\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/replace_address_test.py\", line 212, in replace_first_boot_test\n    node4.start(wait_for_binary_proto=True)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 610, in start\n    node.watch_log_for_alive(self, from_mark=mark)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 457, in watch_log_for_alive\n    self.watch_log_for(tofind, from_mark=from_mark, timeout=timeout, filename=filename)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 425, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"15 Apr 2016 16:23:41 [node3] Missing: ['127.0.0.4.* now UP']:\\nINFO  [main] 2016-04-15 16:21:32,345 Config.java:4.....\\nSee system.log for remainder\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-4i5qkE\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'memtable_allocation_type': 'offheap_objects',\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'start_rpc': 'true'}\\ndtest: DEBUG: Starting cluster with 3 nodes.\\ndtest: DEBUG: 32\\ndtest: DEBUG: Inserting Data...\\ndtest: DEBUG: Stopping node 3.\\ndtest: DEBUG: Testing node stoppage (query should fail).\\ndtest: DEBUG: Retrying read after timeout. Attempt #0\\ndtest: DEBUG: Retrying read after timeout. Attempt #1\\ndtest: DEBUG: Retrying request after UE. Attempt #2\\ndtest: DEBUG: Retrying request after UE. Attempt #3\\ndtest: DEBUG: Retrying request after UE. Attempt #4\\ndtest: DEBUG: Starting node 4 to replace node 3\\ndtest: DEBUG: Verifying querying works again.\\ndtest: DEBUG: Verifying tokens migrated sucessfully\\ndtest: DEBUG: ('WARN  [main] 2016-04-15 16:21:21,068 TokenMetadata.java:196 - Token -3855903180169109916 changing ownership from /127.0.0.3 to /127.0.0.4\\\\n', <_sre.SRE_Match object at 0x7fd21c0e2370>)\\ndtest: DEBUG: Try to restart node 3 (should fail)\\ndtest: DEBUG: [('WARN  [GossipStage:1] 2016-04-15 16:21:22,942 StorageService.java:1962 - Host ID collision for 75916cc0-86ec-4136-b336-862a49953616 between /127.0.0.3 and /127.0.0.4; /127.0.0.4 is the new owner\\\\n', <_sre.SRE_Match object at 0x7fd1f83555e0>)]\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in replace_address_test.TestReplaceAddress.replace_first_boot_test"
   },
   {
      "_id": "12960056",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-19 17:10:30",
      "description": "This is a single flap:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/217/testReport/user_types_test/TestUserTypes/test_nested_user_types\n\nFailed on CassCI build cassandra-2.2_dtest_win32 #217\n\n{code}\nError Message\n\nLists differ: [None] != [[u'test', u'test2']]\n\nFirst differing element 0:\nNone\n[u'test', u'test2']\n\n- [None]\n+ [[u'test', u'test2']]\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: d:\\temp\\dtest-vgkgwi\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 329, in run\n    testMethod()\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\user_types_test.py\", line 289, in test_nested_user_types\n    self.assertEqual(listify(primary_item), [[u'test', u'test2']])\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 742, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 724, in assertSequenceEqual\n    self.fail(msg)\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"Lists differ: [None] != [[u'test', u'test2']]\\n\\nFirst differing element 0:\\nNone\\n[u'test', u'test2']\\n\\n- [None]\\n+ [[u'test', u'test2']]\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\dtest-vgkgwi\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\n--------------------- >> end captured logging << ---------------------\"\nStandard Error\n\nStarted: node1 with pid: 4328\nStarted: node3 with pid: 7568\nStarted: node2 with pid: 7504\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in user_types_test.TestUserTypes.test_nested_user_types"
   },
   {
      "_id": "12958863",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-04-14 14:34:10",
      "description": "Any COPY FROM command in cqlsh is throwing the following error:\n\n\"get_num_processes() takes no keyword arguments\"\n\nExample command: \n\nCOPY inboxdata (to_user_id,to_user_network,created_time,attachments,from_user_id,from_user_name,from_user_network,id,message,to_user_name,updated_time) FROM 'inbox.csv';\n\nSimilar commands worked parfectly in the previous versions such as 3.0.4",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "clqsh: COPY FROM throws TypeError with Cython extensions enabled"
   },
   {
      "_id": "12958509",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-13 15:44:51",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/329/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_bulk_round_trip_non_prepared_statements\n\nFailed on CassCI build cassandra-2.1_offheap_dtest #329\n\n{noformat}\nError Message\n\n'int' object has no attribute 'on_read_timeout'\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-LNfFyy\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'memtable_allocation_type': 'offheap_objects',\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Running stress without any user profile\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2325, in test_bulk_round_trip_non_prepared_statements\n    copy_from_options={'PREPAREDSTATEMENTS': False})\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2283, in _test_bulk_round_trip\n    num_records = create_records()\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2258, in create_records\n    ret = rows_to_list(self.session.execute(count_statement))[0][0]\n  File \"cassandra/cluster.py\", line 1581, in cassandra.cluster.Session.execute (cassandra/cluster.c:27046)\n    return self.execute_async(query, parameters, trace, custom_payload, timeout).result()\n  File \"cassandra/cluster.py\", line 3145, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:59905)\n    raise self._final_exception\n\"'int' object has no attribute 'on_read_timeout'\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-LNfFyy\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'memtable_allocation_type': 'offheap_objects',\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Running stress without any user profile\\n--------------------- >> end captured logging << ---------------------\"\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_bulk_round_trip_non_prepared_statements"
   },
   {
      "_id": "12958506",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2016-04-13 15:35:27",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/344/testReport/secondary_indexes_test/TestSecondaryIndexes/test_query_indexes_with_vnodes\n\nFailed on CassCI build trunk_novnode_dtest #344\n\nTest does not appear to configure single-token cluster correctly:\n{noformat}\nError Message\n\nError starting node1.\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-4pEIhy\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'num_tokens': None,\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/secondary_indexes_test.py\", line 436, in test_query_indexes_with_vnodes\n    cluster.populate(2, use_vnodes=True).start()\n  File \"/home/automaton/ccm/ccmlib/cluster.py\", line 360, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\n\"Error starting node1.\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-4pEIhy\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'num_tokens': None,\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\n--------------------- >> end captured logging << ---------------------\"\nStandard Output\n\n[node1 ERROR] Invalid yaml. Those properties [num_tokens] are not valid\n[node2 ERROR] Invalid yaml. Those properties [num_tokens] are not valid\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in secondary_indexes_test.TestSecondaryIndexes.test_query_indexes_with_vnodes"
   },
   {
      "_id": "12958505",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-13 15:33:49",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_novnode_dtest/344/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_marking_test_not_intersecting_all_ranges\n\nFailed on CassCI build trunk_novnode_dtest #344\n\nTest does not appear to deal with single-token cluster testing correctly:\n{noformat}\nError Message\n\nError starting node1.\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-I164Fa\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'num_tokens': None, 'phi_convict_threshold': 5, 'start_rpc': 'true'}\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/repair_tests/incremental_repair_test.py\", line 369, in sstable_marking_test_not_intersecting_all_ranges\n    cluster.populate(4, use_vnodes=True).start()\n  File \"/home/automaton/ccm/ccmlib/cluster.py\", line 360, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\n\"Error starting node1.\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-I164Fa\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'num_tokens': None, 'phi_convict_threshold': 5, 'start_rpc': 'true'}\\n--------------------- >> end captured logging << ---------------------\"\nStandard Output\n\n[node1 ERROR] Invalid yaml. Those properties [num_tokens] are not valid\n[node3 ERROR] Invalid yaml. Those properties [num_tokens] are not valid\n[node2 ERROR] Invalid yaml. Those properties [num_tokens] are not valid\n[node4 ERROR] Invalid yaml. Those properties [num_tokens] are not valid\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.incremental_repair_test.TestIncRepair.sstable_marking_test_not_intersecting_all_ranges"
   },
   {
      "_id": "12957218",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-04-08 14:09:24",
      "description": "Given is a simple table. Selecting the columns without an alias works fine. However, if the map is selected using an alias, cqlsh fails to format the value.\n\n{code}\ncreate keyspace foo WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};\nCREATE TABLE foo.foo (id int primary key, m map<int, text>);\ninsert into foo.foo (id, m) VALUES ( 1, {1: 'one', 2: 'two', 3:'three'});\ninsert into foo.foo (id, m) VALUES ( 2, {1: '1one', 2: '2two', 3:'3three'});\n\ncqlsh> select id, m from foo.foo;\n\n id | m\n----+-------------------------------------\n  1 |    {1: 'one', 2: 'two', 3: 'three'}\n  2 | {1: '1one', 2: '2two', 3: '3three'}\n\n(2 rows)\ncqlsh> select id, m as \"weofjkewopf\" from foo.foo;\n\n id | weofjkewopf\n----+-----------------------------------------------------------------------\n  1 |    OrderedMapSerializedKey([(1, u'one'), (2, u'two'), (3, u'three')])\n  2 | OrderedMapSerializedKey([(1, u'1one'), (2, u'2two'), (3, u'3three')])\n\n(2 rows)\nFailed to format value OrderedMapSerializedKey([(1, u'one'), (2, u'two'), (3, u'three')]) : 'NoneType' object has no attribute 'sub_types'\nFailed to format value OrderedMapSerializedKey([(1, u'1one'), (2, u'2two'), (3, u'3three')]) : 'NoneType' object has no attribute 'sub_types'\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh fails to format collections when using aliases"
   },
   {
      "_id": "12956737",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2016-04-07 03:14:19",
      "description": "Allow clients to stream data from a C* host, bypassing the coordination layer and eliminating the need to query individual pages one by one.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "protocolv5"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Implement streaming for bulk read requests"
   },
   {
      "_id": "12956586",
      "assignee": "joshuamckenzie",
      "components": [],
      "created": "2016-04-06 18:16:40",
      "description": "In a directory named 'test space', I see the following on launch:\n\n{noformat}\nError: Could not find or load main class space\\cassandra.logs.gc.log\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "C* won't launch with whitespace in path on Windows"
   },
   {
      "_id": "12956245",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-04-05 19:04:45",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/197/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_reading_max_parse_errors\n\nFailed on CassCI build cassandra-3.0_novnode_dtest #197\n\n{noformat}\nError Message\n\nFalse is not true\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-c2AJlu\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'num_tokens': None,\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Importing csv file /mnt/tmp/tmp2O43PH with 10 max parse errors\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 943, in test_reading_max_parse_errors\n    self.assertTrue(num_rows_imported < (num_rows / 2))  # less than the maximum number of valid rows in the csv\n  File \"/usr/lib/python2.7/unittest/case.py\", line 422, in assertTrue\n    raise self.failureException(msg)\n\"False is not true\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-c2AJlu\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'num_tokens': None,\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Importing csv file /mnt/tmp/tmp2O43PH with 10 max parse errors\\n--------------------- >> end captured logging << ---------------------\"\nStandard Output\n\n(EE)  Using CQL driver: <module 'cassandra' from '/home/automaton/cassandra/bin/../lib/cassandra-driver-internal-only-3.0.0-6af642d.zip/cassandra-driver-3.0.0-6af642d/cassandra/__init__.py'>(EE)  Using connect timeout: 5 seconds(EE)  Using 'utf-8' encoding(EE)  <stdin>:2:Failed to import 2500 rows: ParseError - could not convert string to float: abc,  given up without retries(EE)  <stdin>:2:Exceeded maximum number of parse errors 10(EE)  <stdin>:2:Failed to process 2500 rows; failed rows written to import_ks_testmaxparseerrors.err(EE)  <stdin>:2:Exceeded maximum number of parse errors 10(EE)  \n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_reading_max_parse_errors"
   },
   {
      "_id": "12955973",
      "assignee": "stefania",
      "components": [],
      "created": "2016-04-04 23:07:58",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/637/testReport/sstableutil_test/SSTableUtilTest/abortedcompaction_test\n\nFailed on CassCI build cassandra-3.0_dtest #637\n\nNext run passed, so this could be a flaky test.\n\n{noformat}\nError Message\n\n0 not greater than 0\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-gbo1Uc\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'start_rpc': 'true'}\ndtest: DEBUG: About to invoke sstableutil...\ndtest: DEBUG: Listing files...\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-TOC.txt\n\ndtest: DEBUG: Got 40 files\ndtest: DEBUG: About to invoke sstableutil...\ndtest: DEBUG: Listing files...\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-TOC.txt\n\ndtest: DEBUG: Got 40 files\ndtest: DEBUG: About to invoke sstableutil...\ndtest: DEBUG: Listing files...\n\ndtest: DEBUG: Got 0 files\ndtest: DEBUG: About to invoke sstableutil...\ndtest: DEBUG: Listing files...\n\ndtest: DEBUG: Got 0 files\ndtest: DEBUG: Comparing all files...\ndtest: DEBUG: Comparing final files...\ndtest: DEBUG: Comparing tmp files...\ndtest: DEBUG: Comparing op logs...\ndtest: DEBUG: About to invoke sstableutil...\ndtest: DEBUG: Listing files...\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-TOC.txt\n\ndtest: DEBUG: Got 40 files\ndtest: DEBUG: About to invoke sstableutil...\ndtest: DEBUG: Listing files...\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-TOC.txt\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-CRC.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Data.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Digest.crc32\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Filter.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Index.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Statistics.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Summary.db\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-TOC.txt\n\ndtest: DEBUG: Got 40 files\ndtest: DEBUG: About to invoke sstableutil...\ndtest: DEBUG: Listing files...\n\ndtest: DEBUG: Got 0 files\ndtest: DEBUG: About to invoke sstableutil...\ndtest: DEBUG: Listing files...\n\ndtest: DEBUG: Got 0 files\ndtest: DEBUG: Comparing all files...\ndtest: DEBUG: Comparing final files...\ndtest: DEBUG: Comparing tmp files...\ndtest: DEBUG: Comparing op logs...\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/sstableutil_test.py\", line 79, in abortedcompaction_test\n    self.assertGreater(len(tmpfiles), 0)\n  File \"/usr/lib/python2.7/unittest/case.py\", line 942, in assertGreater\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/usr/lib/python2.7/unittest/case.py\", line 410, in fail\n    raise self.failureException(msg)\n\"0 not greater than 0\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-gbo1Uc\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'start_rpc': 'true'}\\ndtest: DEBUG: About to invoke sstableutil...\\ndtest: DEBUG: Listing files...\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-TOC.txt\\n\\ndtest: DEBUG: Got 40 files\\ndtest: DEBUG: About to invoke sstableutil...\\ndtest: DEBUG: Listing files...\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-TOC.txt\\n\\ndtest: DEBUG: Got 40 files\\ndtest: DEBUG: About to invoke sstableutil...\\ndtest: DEBUG: Listing files...\\n\\ndtest: DEBUG: Got 0 files\\ndtest: DEBUG: About to invoke sstableutil...\\ndtest: DEBUG: Listing files...\\n\\ndtest: DEBUG: Got 0 files\\ndtest: DEBUG: Comparing all files...\\ndtest: DEBUG: Comparing final files...\\ndtest: DEBUG: Comparing tmp files...\\ndtest: DEBUG: Comparing op logs...\\ndtest: DEBUG: About to invoke sstableutil...\\ndtest: DEBUG: Listing files...\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-TOC.txt\\n\\ndtest: DEBUG: Got 40 files\\ndtest: DEBUG: About to invoke sstableutil...\\ndtest: DEBUG: Listing files...\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data0/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-4-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data1/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-1-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-2-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-3-big-TOC.txt\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-CRC.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Data.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Digest.crc32\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Filter.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Index.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Statistics.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-Summary.db\\n/mnt/tmp/dtest-gbo1Uc/test/node1/data2/keyspace1/standard1-688fdfd0f83611e5ad7e97459da1b606/ma-5-big-TOC.txt\\n\\ndtest: DEBUG: Got 40 files\\ndtest: DEBUG: About to invoke sstableutil...\\ndtest: DEBUG: Listing files...\\n\\ndtest: DEBUG: Got 0 files\\ndtest: DEBUG: About to invoke sstableutil...\\ndtest: DEBUG: Listing files...\\n\\ndtest: DEBUG: Got 0 files\\ndtest: DEBUG: Comparing all files...\\ndtest: DEBUG: Comparing final files...\\ndtest: DEBUG: Comparing tmp files...\\ndtest: DEBUG: Comparing op logs...\\n--------------------- >> end captured logging << ---------------------\"\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in sstableutil_test.SSTableUtilTest.abortedcompaction_test"
   },
   {
      "_id": "12955942",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-04 21:53:46",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/327/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_bulk_round_trip_default\n\nFailed on CassCI build cassandra-2.1_offheap_dtest #327\n\nLooks like a test error in dtest.py FlakyRetryPolicy() getting in an odd state. This test runs OK for me locally.\n\n{noformat}\nError Message\n\n'int' object has no attribute 'on_read_timeout'\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-SrTCbF\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'memtable_allocation_type': 'offheap_objects',\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: removing ccm cluster test at: /mnt/tmp/dtest-SrTCbF\ndtest: DEBUG: clearing ssl stores from [/mnt/tmp/dtest-SrTCbF] directory\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-smdNhH\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'memtable_allocation_type': 'offheap_objects',\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Running stress without any user profile\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/dtest.py\", line 829, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2306, in test_bulk_round_trip_default\n    self._test_bulk_round_trip(nodes=3, partitioner=\"murmur3\", num_operations=100000)\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2277, in _test_bulk_round_trip\n    num_records = create_records()\n  File \"/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 2252, in create_records\n    ret = rows_to_list(self.session.execute(count_statement))[0][0]\n  File \"cassandra/cluster.py\", line 1581, in cassandra.cluster.Session.execute (cassandra/cluster.c:27107)\n    return self.execute_async(query, parameters, trace, custom_payload, timeout).result()\n  File \"cassandra/cluster.py\", line 3145, in cassandra.cluster.ResponseFuture.result (cassandra/cluster.c:60227)\n    raise self._final_exception\n\"'int' object has no attribute 'on_read_timeout'\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-SrTCbF\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'memtable_allocation_type': 'offheap_objects',\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: removing ccm cluster test at: /mnt/tmp/dtest-SrTCbF\\ndtest: DEBUG: clearing ssl stores from [/mnt/tmp/dtest-SrTCbF] directory\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-smdNhH\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'memtable_allocation_type': 'offheap_objects',\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Running stress without any user profile\\n--------------------- >> end captured logging << ---------------------\"\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_bulk_round_trip_default"
   },
   {
      "_id": "12955927",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-04-04 21:13:13",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/326/testReport/consistency_test/TestAccuracy/test_simple_strategy_users\n\nFailed on CassCI build cassandra-2.1_offheap_dtest #326",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in consistency_test.TestAccuracy.test_simple_strategy_users"
   },
   {
      "_id": "12955796",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2016-04-04 15:29:39",
      "description": "As [~Stefania] explains [in this JIRA comment|https://issues.apache.org/jira/browse/CASSANDRA-11225?focusedCommentId=15221059&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15221059], {{SimpleSnitch}} does not implement {{IEndpointSnitch.sortByProximity(localhost, liveendpoints)}}, so a query for data on the coordinator may query other nodes. That seems like unnecessary work to me, and on that note, Stefania woonders [in this JIRA comment|https://issues.apache.org/jira/browse/CASSANDRA-11225?focusedCommentId=15223598&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15223598] - should this be considered a bug?\n\nStefania, I'm assigning you here -- could you find the right people to involve in this discussion?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Bug or not?: coordinator using SimpleSnitch may query other nodes for copies of local data "
   },
   {
      "_id": "12955322",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-04-01 15:08:23",
      "description": "The test was unable to find the tombstone failure threshold error in the logs\n\nexample failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/635/testReport/pushed_notifications_test/TestVariousNotifications/tombstone_failure_threshold_message_test\n\nFailed on CassCI build cassandra-3.0_dtest #635",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in pushed_notifications_test.TestVariousNotifications.tombstone_failure_threshold_message_test"
   },
   {
      "_id": "12955158",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-04-01 00:38:12",
      "description": "I haven't reproduced it with a test yet but, from code inspection, if CQL rows are larger than {{batch_size_fail_threshold_in_kb}} and this parameter cannot be changed, then data import will fail.\n\nUsers can control the batch size by setting MAXBATCHSIZE.\n\nIf a batch contains a single statement, there is no need to use a batch and we should use normal inserts instead or, alternatively, we should skip the batch size check for unlogged batches with only one statement.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh: COPY FROM should use regular inserts for single statement batches"
   },
   {
      "_id": "12955019",
      "assignee": "stefania",
      "components": [],
      "created": "2016-03-31 16:59:54",
      "description": "base_replica_repair_test has failed on trunk with the following exception in the log of node2:\n\n{code}\nERROR [main] 2016-03-31 08:48:46,949 CassandraDaemon.java:708 - Exception encountered during startup\njava.lang.RuntimeException: Failed to list files in /mnt/tmp/dtest-du964e/test/node2/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985\n        at org.apache.cassandra.db.lifecycle.LogAwareFileLister.list(LogAwareFileLister.java:53) ~[main/:na]\n        at org.apache.cassandra.db.lifecycle.LifecycleTransaction.getFiles(LifecycleTransaction.java:547) ~[main/:na]\n        at org.apache.cassandra.db.Directories$SSTableLister.filter(Directories.java:725) ~[main/:na]\n        at org.apache.cassandra.db.Directories$SSTableLister.list(Directories.java:690) ~[main/:na]\n        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:567) ~[main/:na]\n        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:555) ~[main/:na]\n        at org.apache.cassandra.db.Keyspace.initCf(Keyspace.java:383) ~[main/:na]\n        at org.apache.cassandra.db.Keyspace.<init>(Keyspace.java:320) ~[main/:na]\n        at org.apache.cassandra.db.Keyspace.open(Keyspace.java:130) ~[main/:na]\n        at org.apache.cassandra.db.Keyspace.open(Keyspace.java:107) ~[main/:na]\n        at org.apache.cassandra.cql3.restrictions.StatementRestrictions.<init>(StatementRestrictions.java:139) ~[main/:na]\n        at org.apache.cassandra.cql3.statements.SelectStatement$RawStatement.prepareRestrictions(SelectStatement.java:864) ~[main/:na]\n        at org.apache.cassandra.cql3.statements.SelectStatement$RawStatement.prepare(SelectStatement.java:811) ~[main/:na]\n        at org.apache.cassandra.cql3.statements.SelectStatement$RawStatement.prepare(SelectStatement.java:799) ~[main/:na]\n        at org.apache.cassandra.cql3.QueryProcessor.getStatement(QueryProcessor.java:505) ~[main/:na]\n        at org.apache.cassandra.cql3.QueryProcessor.parseStatement(QueryProcessor.java:242) ~[main/:na]\n        at org.apache.cassandra.cql3.QueryProcessor.prepareInternal(QueryProcessor.java:286) ~[main/:na]\n        at org.apache.cassandra.cql3.QueryProcessor.executeInternal(QueryProcessor.java:294) ~[main/:na]\n        at org.apache.cassandra.schema.SchemaKeyspace.query(SchemaKeyspace.java:1246) ~[main/:na]\n        at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesWithout(SchemaKeyspace.java:875) ~[main/:na]\n        at org.apache.cassandra.schema.SchemaKeyspace.fetchNonSystemKeyspaces(SchemaKeyspace.java:867) ~[main/:na]\n        at org.apache.cassandra.config.Schema.loadFromDisk(Schema.java:134) ~[main/:na]\n        at org.apache.cassandra.config.Schema.loadFromDisk(Schema.java:124) ~[main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:229) [main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:562) [main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:691) [main/:na]\nCaused by: java.lang.RuntimeException: Failed to list directory files in /mnt/tmp/dtest-du964e/test/node2/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985, inconsistent disk state for transaction [ma_txn_flush_58db56b0-f71d-11e5-bf68-03a01adb9f11.log in /mnt/tmp/dtest-du964e/test/node2/data0/system_schema/views-9786ac1cdd583201a7cdad556410c985]\n        at org.apache.cassandra.db.lifecycle.LogAwareFileLister.classifyFiles(LogAwareFileLister.java:149) ~[main/:na]\n        at org.apache.cassandra.db.lifecycle.LogAwareFileLister.classifyFiles(LogAwareFileLister.java:103) ~[main/:na]\n        at org.apache.cassandra.db.lifecycle.LogAwareFileLister$$Lambda$48/35984028.accept(Unknown Source) ~[na:na]\n        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ~[na:1.8.0_45]\n        at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ~[na:1.8.0_45]\n        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ~[na:1.8.0_45]\n        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512) ~[na:1.8.0_45]\n        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502) ~[na:1.8.0_45]\n        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) ~[na:1.8.0_45]\n        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) ~[na:1.8.0_45]\n        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[na:1.8.0_45]\n        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) ~[na:1.8.0_45]\n        at org.apache.cassandra.db.lifecycle.LogAwareFileLister.innerList(LogAwareFileLister.java:71) ~[main/:na]\n        at org.apache.cassandra.db.lifecycle.LogAwareFileLister.list(LogAwareFileLister.java:49) ~[main/:na]\n        ... 25 common frames omitted\n{code}\n\nexample failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1092/testReport/materialized_views_test/TestMaterializedViews/base_replica_repair_test\n\nFailed on CassCI build trunk_dtest #1092\n\nI've attached the logs from the failure in build 1092.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.base_replica_repair_test"
   },
   {
      "_id": "12954731",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328222",
            "id": "12328222",
            "name": "Legacy/Observability",
            "description": "JMX, Metrics, Tracing, Logging"
         }
      ],
      "created": "2016-03-30 19:46:38",
      "description": "Failing on the following assert, on trunk only: {{self.assertEqual(len(errs[0]), 1)}}\n\nIs not failing consistently.\n\nexample failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1087/testReport/cql_tracing_test/TestCqlTracing/tracing_unknown_impl_test\n\nFailed on CassCI build trunk_dtest #1087",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tracing_test.TestCqlTracing.tracing_unknown_impl_test"
   },
   {
      "_id": "12954704",
      "assignee": "krummas",
      "components": [],
      "created": "2016-03-30 18:23:30",
      "description": "The final assertion {{self.assertGreaterEqual(bfSize, min_bf_size)}} is failing with {{44728 not greater than or equal to 50000}} on 2.1, pretty consistently.\n\nexample failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/439/testReport/compaction_test/TestCompaction_with_LeveledCompactionStrategy/bloomfilter_size_test\n\nFailed on CassCI build cassandra-2.1_dtest #439",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_LeveledCompactionStrategy.bloomfilter_size_test"
   },
   {
      "_id": "12953974",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-28 15:04:53",
      "description": "{{Invalid yaml. Please remove properties [require_endpoint_verification] from your cassandra.yaml}}\n\nexample failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/556/testReport/sslnodetonode_test/TestNodeToNodeSSLEncryption/ssl_wrong_hostname_no_validation_test\n\nFailed on CassCI build cassandra-2.2_dtest #556\n\nAll of the sslnodetonodetests are failing on 2.2 and 3.0. I assume a ticket was committed that broke these tests by changing the appropriate yaml key?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in sslnodetonode_test.TestNodeToNodeSSLEncryption"
   },
   {
      "_id": "12953635",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-25 18:13:10",
      "description": "This test and consistency_test.TestAvailability.test_network_topology_strategy have begun failing now that we dropped the instance size we run CI with. The tests should be altered to reflect the constrained resources. They are ambitious for dtests, regardless.\n\nexample failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/221/testReport/consistency_test/TestAccuracy/test_network_topology_strategy_users\n\nFailed on CassCI build cassandra-2.1_novnode_dtest #221",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in consistency_test.TestAccuracy.test_network_topology_strategy_users"
   },
   {
      "_id": "12953620",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2016-03-25 16:47:49",
      "description": "As per this conversation with [~Stefania]:\n\nhttps://github.com/riptano/cassandra-dtest/pull/869#issuecomment-200597829\n\nwe don't currently have a way to verify that the test environment variable {{CQLSH_COPY_TEST_NUM_CORES}} actually affects the behavior of {{COPY}} in the intended way. If this were added, we could make our tests of the one-core edge case a little stricter.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Make number of cores used by cqlsh COPY visible to testing code"
   },
   {
      "_id": "12953601",
      "assignee": "krummas",
      "components": [],
      "created": "2016-03-25 15:44:30",
      "description": "sstable_repairedset_test is failing on 2.1 and 2.2, but not on trunk.\n\nIn the final assertion, after running sstablemetadata on both nodes, we see unrepaired sstables, when we expect all sstables to be repaired.\n\nexample failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/220/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_repairedset_test\n\nFailed on CassCI build cassandra-2.1_novnode_dtest #220",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.incremental_repair_test.TestIncRepair.sstable_repairedset_test"
   },
   {
      "_id": "12952901",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2016-03-23 16:54:46",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1076/testReport/cql_tests/AbortedQueriesTester/remote_query_test\n\nFailed on CassCI build trunk_dtest #1076\n\nAlso breaking:\ncql_tests.AbortedQueriesTester.materialized_view_test\ntopology_test.TestTopology.do_not_join_ring_test\n\nBroken by https://github.com/pcmanus/ccm/pull/479",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in cql_tests.AbortedQueriesTester.remote_query_test"
   },
   {
      "_id": "12951608",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-18 20:05:21",
      "description": "We've got a single flap on the 3.0 novnode job:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/189/testReport/materialized_views_test/TestMaterializedViews/complex_mv_select_statements_test\n\n{code}\n\nError Message\n\nExpected [[1, 0, 1, 0], [1, 1, 1, 0], [1, 2, 1, 0]] from SELECT a, b, c, d FROM mv, but got [[1, 0, 1, 0], [1, 1, 1, 0]]\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-d0ZZ9_\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'num_tokens': None,\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Creating keyspace\ndtest: DEBUG: Testing MV primary key: ((a, b), c)\ndtest: DEBUG: Testing MV primary key: ((b, a), c)\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/materialized_views_test.py\", line 1193, in complex_mv_select_statements_test\n    cl=ConsistencyLevel.QUORUM\n  File \"/home/automaton/cassandra-dtest/assertions.py\", line 67, in assert_all\n    assert list_res == expected, \"Expected %s from %s, but got %s\" % (expected, query, list_res)\n\"Expected [[1, 0, 1, 0], [1, 1, 1, 0], [1, 2, 1, 0]] from SELECT a, b, c, d FROM mv, but got [[1, 0, 1, 0], [1, 1, 1, 0]]\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-d0ZZ9_\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'num_tokens': None,\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Creating keyspace\\ndtest: DEBUG: Testing MV primary key: ((a, b), c)\\ndtest: DEBUG: Testing MV primary key: ((b, a), c)\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.complex_mv_select_statements_test"
   },
   {
      "_id": "12951341",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-17 21:17:08",
      "description": "This fails hard on 3.0:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/186/testReport/topology_test/TestTopology/decommissioned_node_cant_rejoin_test\n\nHere's the changeset from the first failure on that job:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/186/changes\n\n(just this commit: https://github.com/apache/cassandra/commit/719caa67649bf6f27cdd99dd7d6055d2aa8546ae)\n\nIt has failed on trunk as well:\n\nhttp://cassci.datastax.com/view/trunk/job/trunk_novnode_dtest/lastCompletedBuild/testReport/topology_test/TestTopology/decommissioned_node_cant_rejoin_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in topology_test.TestTopology.decommissioned_node_cant_rejoin_test"
   },
   {
      "_id": "12951333",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-17 20:46:56",
      "description": "This has flapped once on 3.0:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/614/testReport/topology_test/TestTopology/crash_during_decommission_test\n\nand more frequently on trunk:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1057/testReport/junit/topology_test/TestTopology/crash_during_decommission_test/\n\nMessage and trace:\n\n{code}\nError Message\n\n15 Mar 2016 10:48:55 [node1] Missing: ['127.0.0.2.* now UP']:\n.....\nSee system.log for remainder\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-EJfTo3\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: Status as reported by node 127.0.0.2\ndtest: DEBUG: Datacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  127.0.0.1  112.85 KB  32           64.1%             d7d836bd-a0ff-474c-b04c-2c00bd2fc636  rack1\nUN  127.0.0.2  127.25 KB  32           61.7%             68c5a8c4-8986-40df-afb2-ee0849814618  rack1\nUN  127.0.0.3  112.68 KB  32           74.2%             6dd52315-53f4-444d-bace-a8a0d7c2b34e  rack1\n\n\ndtest: DEBUG: Restarting node2\ndtest: DEBUG: \ndtest: DEBUG: \n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 253, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/topology_test.py\", line 230, in crash_during_decommission_test\n    node2.start(wait_for_binary_proto=True)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 597, in start\n    node.watch_log_for_alive(self, from_mark=mark)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 449, in watch_log_for_alive\n    self.watch_log_for(tofind, from_mark=from_mark, timeout=timeout, filename=filename)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 417, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"15 Mar 2016 10:48:55 [node1] Missing: ['127.0.0.2.* now UP']:\\n.....\\nSee system.log for remainder\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-EJfTo3\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'range_request_timeout_in_ms': 10000,\\n    'read_request_timeout_in_ms': 10000,\\n    'request_timeout_in_ms': 10000,\\n    'truncate_request_timeout_in_ms': 10000,\\n    'write_request_timeout_in_ms': 10000}\\ndtest: DEBUG: Status as reported by node 127.0.0.2\\ndtest: DEBUG: Datacenter: datacenter1\\n=======================\\nStatus=Up/Down\\n|/ State=Normal/Leaving/Joining/Moving\\n--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack\\nUN  127.0.0.1  112.85 KB  32           64.1%             d7d836bd-a0ff-474c-b04c-2c00bd2fc636  rack1\\nUN  127.0.0.2  127.25 KB  32           61.7%             68c5a8c4-8986-40df-afb2-ee0849814618  rack1\\nUN  127.0.0.3  112.68 KB  32           74.2%             6dd52315-53f4-444d-bace-a8a0d7c2b34e  rack1\\n\\n\\ndtest: DEBUG: Restarting node2\\ndtest: DEBUG: \\ndtest: DEBUG: \\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in topology_test.TestTopology.crash_during_decommission_test"
   },
   {
      "_id": "12951315",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-17 20:00:49",
      "description": "example failures:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/lastCompletedBuild/testReport/replace_address_test/TestReplaceAddress/resumable_replace_test/history/\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/612/testReport/replace_address_test/TestReplaceAddress/resumable_replace_test/\n\nSeems to fail hard with the following error:\n\n{code}\n16 Mar 2016 18:42:00 [node1] Missing: ['127.0.0.4.* now UP']:\nINFO  [HANDSHAKE-/127.0.0.4] 2016-03-16 18:40:03,1.....\nSee system.log for remainder\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-JdjudW\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'start_rpc': 'true'}\ndtest: DEBUG: Starting node 4 to replace node 3\n--------------------- >> end captured logging << ---------------------\nStacktrace\n\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\n    testMethod()\n  File \"/home/automaton/cassandra-dtest/tools.py\", line 253, in wrapped\n    f(obj)\n  File \"/home/automaton/cassandra-dtest/replace_address_test.py\", line 253, in resumable_replace_test\n    node4.start(jvm_args=[\"-Dcassandra.replace_address_first_boot=127.0.0.3\"])\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 597, in start\n    node.watch_log_for_alive(self, from_mark=mark)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 449, in watch_log_for_alive\n    self.watch_log_for(tofind, from_mark=from_mark, timeout=timeout, filename=filename)\n  File \"/home/automaton/ccm/ccmlib/node.py\", line 417, in watch_log_for\n    raise TimeoutError(time.strftime(\"%d %b %Y %H:%M:%S\", time.gmtime()) + \" [\" + self.name + \"] Missing: \" + str([e.pattern for e in tofind]) + \":\\n\" + reads[:50] + \".....\\nSee {} for remainder\".format(filename))\n\"16 Mar 2016 18:42:00 [node1] Missing: ['127.0.0.4.* now UP']:\\nINFO  [HANDSHAKE-/127.0.0.4] 2016-03-16 18:40:03,1.....\\nSee system.log for remainder\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: /mnt/tmp/dtest-JdjudW\\ndtest: DEBUG: Custom init_config not found. Setting defaults.\\ndtest: DEBUG: Done setting configuration options:\\n{   'initial_token': None,\\n    'num_tokens': '32',\\n    'phi_convict_threshold': 5,\\n    'start_rpc': 'true'}\\ndtest: DEBUG: Starting node 4 to replace node 3\\n--------------------- >> end captured logging << ---------------------\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in replace_address_test.TestReplaceAddress.resumable_replace_test"
   },
   {
      "_id": "12951245",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2016-03-17 15:36:09",
      "description": "Our test is basically running *nodetool repair* on specific keyspaces (such as keyspace1) and the test is also triggering *nodetool compact keyspace1 standard1* in the background. \nAnd so it looks like running major compactions & repairs lead to that issue when using *LCS*.\n\n\nBelow is an excerpt from the *thread dump* (the rest is attached)\n{code}\n\"CompactionExecutor:2\" #33 daemon prio=1 os_prio=4 tid=0x00007f5363e64f10 nid=0x3c4e waiting for monitor entry [0x00007f53340d8000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat org.apache.cassandra.db.compaction.CompactionStrategyManager.handleNotification(CompactionStrategyManager.java:252)\n\t- waiting to lock <0x00000006c9362c80> (a org.apache.cassandra.db.compaction.CompactionStrategyManager)\n\tat org.apache.cassandra.db.lifecycle.Tracker.notifySSTableRepairedStatusChanged(Tracker.java:434)\n\tat org.apache.cassandra.db.compaction.CompactionManager.performAnticompaction(CompactionManager.java:550)\n\tat org.apache.cassandra.db.compaction.CompactionManager$7.runMayThrow(CompactionManager.java:465)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n   Locked ownable synchronizers:\n\t- <0x00000006c9362ca8> (a java.util.concurrent.ThreadPoolExecutor$Worker)\n\n\"CompactionExecutor:1\" #32 daemon prio=1 os_prio=4 tid=0x00007f5363e618b0 nid=0x3c4d runnable [0x00007f5334119000]\n   java.lang.Thread.State: RUNNABLE\n\tat com.google.common.collect.Iterators$7.computeNext(Iterators.java:650)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n\tat com.google.common.collect.Iterators.addAll(Iterators.java:361)\n\tat com.google.common.collect.Iterables.addAll(Iterables.java:354)\n\tat org.apache.cassandra.db.compaction.LeveledManifest.getCandidatesFor(LeveledManifest.java:589)\n\tat org.apache.cassandra.db.compaction.LeveledManifest.getCompactionCandidates(LeveledManifest.java:349)\n\t- locked <0x00000006d0f7a6a8> (a org.apache.cassandra.db.compaction.LeveledManifest)\n\tat org.apache.cassandra.db.compaction.LeveledCompactionStrategy.getNextBackgroundTask(LeveledCompactionStrategy.java:98)\n\t- locked <0x00000006d0f7a568> (a org.apache.cassandra.db.compaction.LeveledCompactionStrategy)\n\tat org.apache.cassandra.db.compaction.CompactionStrategyManager.getNextBackgroundTask(CompactionStrategyManager.java:95)\n\t- locked <0x00000006c9362c80> (a org.apache.cassandra.db.compaction.CompactionStrategyManager)\n\tat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:257)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}\n\n*CPU usage is at 100%*\n{code}\ntop -p 15386\ntop - 12:12:40 up  1:28,  1 user,  load average: 1.08, 1.11, 1.16\nTasks:   1 total,   0 running,   1 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  0.3 us,  0.0 sy, 12.4 ni, 87.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem:  16433792 total,  8947336 used,  7486456 free,    89552 buffers\nKiB Swap:        0 total,        0 used,        0 free.  3326796 cached Mem\n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n15386 automat+  20   0 7891448 5.004g 290184 S 102.9 31.9  80:07.06 java\n\n{code}\n\n*ttop shows that the compaction thread consumes all the CPU*\n{code}\n$ java -jar sjk.jar ttop -p 15386\nMonitoring threads ...\n\n2016-03-17T12:17:13.514+0000 Process summary\n  process cpu=126.34%\n  application cpu=102.81% (user=102.46% sys=0.35%)\n  other: cpu=23.53%\n  heap allocation rate 375mb/s\n[000002] user= 0.00% sys= 0.00% alloc=     0b/s - Reference Handler\n[000003] user= 0.00% sys= 0.00% alloc=     0b/s - Finalizer\n[000005] user= 0.00% sys= 0.00% alloc=     0b/s - Signal Dispatcher\n[000012] user= 0.00% sys= 0.00% alloc=     0b/s - RMI TCP Accept-7199\n[000013] user= 0.00% sys= 0.00% alloc=     0b/s - RMI TCP Accept-0\n[000015] user= 0.00% sys= 0.00% alloc=   476b/s - AsyncAppender-Worker-ASYNCDEBUGLOG\n[000016] user= 0.00% sys= 0.05% alloc=  1070b/s - ScheduledTasks:1\n[000017] user= 0.00% sys= 0.00% alloc=    33b/s - EXPIRING-MAP-REAPER:1\n[000018] user= 0.00% sys= 0.02% alloc=  1932b/s - Background_Reporter:1\n[000022] user= 0.00% sys= 0.00% alloc=     0b/s - MemtablePostFlush:1\n[000023] user= 0.00% sys= 0.00% alloc=     0b/s - MemtableReclaimMemory:1\n[000026] user= 0.00% sys= 0.00% alloc=     0b/s - SlabPoolCleaner\n[000027] user= 0.00% sys= 0.00% alloc=     0b/s - PERIODIC-COMMIT-LOG-SYNCER\n[000028] user= 0.00% sys= 0.00% alloc=     0b/s - COMMIT-LOG-ALLOCATOR\n[000029] user= 0.00% sys= 0.01% alloc=  7086b/s - OptionalTasks:1\n[000030] user= 0.00% sys= 0.00% alloc=     0b/s - Reference-Reaper:1\n[000031] user= 0.00% sys= 0.00% alloc=     0b/s - Strong-Reference-Leak-Detector:1\n[000032] user=99.45% sys= 0.07% alloc=  374mb/s - CompactionExecutor:1\n[000033] user= 0.00% sys= 0.00% alloc=     0b/s - CompactionExecutor:2\n[000036] user= 0.00% sys= 0.00% alloc=     0b/s - NonPeriodicTasks:1\n[000037] user= 0.00% sys= 0.00% alloc=     0b/s - LocalPool-Cleaner:1\n[000041] user= 0.00% sys= 0.00% alloc=     0b/s - IndexSummaryManager:1\n[000043] user= 0.00% sys= 0.01% alloc=  2705b/s - GossipTasks:1\n[000044] user= 0.00% sys= 0.00% alloc=     0b/s - ACCEPT-/10.200.182.146\n[000045] user= 0.00% sys= 0.01% alloc=  2283b/s - BatchlogTasks:1\n[000055] user= 0.00% sys= 0.02% alloc=  9494b/s - GossipStage:1\n[000056] user= 0.00% sys= 0.00% alloc=     0b/s - AntiEntropyStage:1\n[000057] user= 0.00% sys= 0.00% alloc=     0b/s - MigrationStage:1\n[000058] user= 0.00% sys= 0.00% alloc=     0b/s - MiscStage:1\n[000067] user= 0.00% sys= 0.02% alloc=  2445b/s - MessagingService-Incoming-/10.200.182.144\n[000068] user= 0.00% sys= 0.01% alloc=   968b/s - MessagingService-Outgoing-/10.200.182.144\n[000069] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Outgoing-/10.200.182.144\n[000070] user= 0.00% sys= 0.02% alloc=   512b/s - MessagingService-Outgoing-/10.200.182.144\n[000072] user= 0.00% sys= 0.00% alloc=     0b/s - NanoTimeToCurrentTimeMillis updater\n[000073] user= 0.00% sys= 0.02% alloc=  3113b/s - MessagingService-Incoming-/10.200.182.144\n[000074] user= 0.00% sys= 0.00% alloc=     0b/s - PendingRangeCalculator:1\n[000075] user= 0.00% sys= 0.41% alloc=   66kb/s - SharedPool-Worker-1\n[000076] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-2\n[000077] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-3\n[000078] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-4\n[000079] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-5\n[000080] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-6\n[000081] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-7\n[000082] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-8\n[000084] user= 0.00% sys= 0.00% alloc=     0b/s - Thread-2\n[000085] user= 0.00% sys= 0.00% alloc=   181b/s - HintsWriteExecutor:1\n[000091] user= 0.00% sys= 0.00% alloc=     0b/s - PO-thread-0\n[000092] user= 0.00% sys= 0.00% alloc=     0b/s - NodeHealthPlugin-Scheduler-thread-0\n[000093] user= 0.00% sys= 0.00% alloc=     0b/s - pool-10-thread-1\n[000094] user= 0.00% sys= 0.00% alloc=     0b/s - pool-10-thread-2\n[000097] user= 0.00% sys= 0.00% alloc=     0b/s - Lease RemoteMessageServer acceptor-2-1\n[000104] user= 0.00% sys= 0.00% alloc=     0b/s - RemoteMessageClient worker-4-1\n[000120] user= 0.00% sys= 0.00% alloc=     0b/s - RemoteMessageClient connection limiter - 0\n[000121] user= 0.00% sys= 0.00% alloc=     0b/s - threadDeathWatcher-5-1\n[000122] user= 0.00% sys= 0.00% alloc=     0b/s - PO-thread scheduler\n[000123] user= 0.00% sys= 0.00% alloc=     0b/s - JOB-TRACKER\n[000124] user= 0.00% sys= 0.01% alloc=  1276b/s - TASK-TRACKER\n[000127] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-1\n[000128] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-2\n[000129] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-3\n[000130] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-4\n[000131] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-5\n[000132] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-6\n[000133] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-7\n[000134] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-8\n[000135] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-9\n[000136] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-10\n[000137] user= 0.19% sys=-0.18% alloc=     0b/s - epollEventLoopGroup-6-11\n[000138] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-12\n[000139] user= 0.19% sys=-0.19% alloc=     0b/s - epollEventLoopGroup-6-13\n[000140] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-14\n[000141] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-15\n[000142] user= 0.00% sys= 0.00% alloc=     0b/s - epollEventLoopGroup-6-16\n[000143] user= 0.19% sys=-0.04% alloc=   13kb/s - Thread-7\n[000144] user= 0.00% sys= 0.00% alloc=     0b/s - taskCleanup\n[000145] user= 0.00% sys= 0.00% alloc=     0b/s - DseGossipStateUpdater\n[000146] user= 0.00% sys= 0.00% alloc=     0b/s - DestroyJavaVM\n[000149] user= 0.00% sys= 0.00% alloc=     0b/s - Thread-10\n[000150] user= 0.00% sys= 0.00% alloc=     0b/s - Thread-11\n[000151] user= 0.00% sys= 0.00% alloc=     0b/s - Directory/File cleanup thread\n[000153] user= 0.00% sys= 0.00% alloc=     0b/s - pool-15-thread-1\n[000190] user= 0.00% sys= 0.00% alloc=     0b/s - pool-18-thread-1\n[000215] user= 0.00% sys= 0.00% alloc=     0b/s - pool-10-thread-3\n[000217] user= 0.00% sys= 0.00% alloc=     0b/s - RMI Scheduler(0)\n[000220] user= 0.00% sys= 0.00% alloc=     0b/s - RMI TCP Connection(335)-10.200.182.146\n[000222] user= 0.00% sys= 0.00% alloc=     0b/s - pool-10-thread-4\n[000223] user= 0.00% sys= 0.00% alloc=     0b/s - taskCleanup\n[000224] user= 0.00% sys= 0.00% alloc=     0b/s - Thread-69\n[000225] user= 0.00% sys= 0.00% alloc=     0b/s - Thread-70\n[000227] user= 0.00% sys= 0.00% alloc=     0b/s - pool-19-thread-1\n[000254] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-9\n[000255] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-11\n[000256] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-10\n[000269] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-13\n[000270] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-12\n[000272] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-14\n[000273] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-15\n[000274] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-18\n[000275] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-19\n[000276] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-20\n[000277] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-17\n[000278] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-16\n[000279] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-22\n[000280] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-21\n[000281] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-23\n[000282] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-24\n[000283] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-25\n[000284] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-26\n[000285] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-27\n[000286] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-28\n[000287] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-29\n[000288] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-30\n[000289] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-31\n[000290] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-32\n[000296] user= 0.00% sys= 0.00% alloc=  1970b/s - pool-2-thread-1\n[000297] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-33\n[000298] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-34\n[000302] user= 0.00% sys= 0.01% alloc=  1576b/s - MessagingService-Incoming-/10.200.182.145\n[000303] user= 0.00% sys= 0.00% alloc=   451b/s - MessagingService-Outgoing-/10.200.182.145\n[000304] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Outgoing-/10.200.182.145\n[000305] user= 0.00% sys= 0.01% alloc=   206b/s - MessagingService-Outgoing-/10.200.182.145\n[000308] user= 0.00% sys= 0.00% alloc=   424b/s - MessagingService-Incoming-/10.200.182.145\n[000314] user= 0.00% sys= 0.00% alloc=     0b/s - StreamingTransferTaskTimeouts:1\n[000324] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Outgoing-/10.200.182.146\n[000325] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Outgoing-/10.200.182.146\n[000326] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Outgoing-/10.200.182.146\n[000328] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Incoming-/10.200.182.146\n[000329] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-35\n[000330] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-37\n[000331] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-36\n[000332] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-39\n[000333] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-38\n[000334] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-42\n[000335] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-41\n[000336] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-40\n[000337] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-46\n[000338] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-44\n[000339] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-45\n[000340] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-43\n[000341] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-47\n[000342] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-48\n[000343] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-50\n[000344] user= 0.00% sys= 0.00% alloc=     0b/s - SharedPool-Worker-49\n[000375] user= 0.00% sys= 0.00% alloc=     0b/s - StreamConnectionEstablisher:1\n[000376] user= 0.00% sys= 0.00% alloc=     0b/s - StreamConnectionEstablisher:2\n[000406] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Incoming-/10.200.182.145\n[000408] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Incoming-/10.200.182.146\n[000409] user= 0.00% sys= 0.00% alloc=     0b/s - MessagingService-Incoming-/10.200.182.144\n[000415] user= 0.00% sys= 0.00% alloc=     0b/s - StreamConnectionEstablisher:3\n[000418] user= 0.00% sys= 0.00% alloc=     0b/s - StreamConnectionEstablisher:4\n[000435] user= 0.00% sys= 0.00% alloc=     0b/s - StreamConnectionEstablisher:5\n[000438] user= 0.00% sys= 0.00% alloc=     0b/s - StreamConnectionEstablisher:6\n[000439] user= 0.00% sys= 0.00% alloc=     0b/s - StreamConnectionEstablisher:7\n[000444] user= 0.00% sys= 0.00% alloc=     0b/s - StreamConnectionEstablisher:8\n[000687] user= 0.00% sys= 0.00% alloc=     0b/s - JMX server connection timeout 687\n[000688] user= 2.44% sys= 0.16% alloc= 1380kb/s - RMI TCP Connection(401)-10.200.182.146\n[000694] user= 0.00% sys= 0.00% alloc=     0b/s - Attach Listener\n[000726] user= 0.00% sys= 0.00% alloc=     0b/s - RMI TCP Connection(400)-10.200.182.146\n[000743] user=-0.00% sys=-0.16% alloc=-109800b/s - MemtableFlushWriter:112\n[000745] user= 0.00% sys= 0.00% alloc=     0b/s - MemtableFlushWriter:113\n[000746] user= 0.00% sys= 0.03% alloc=  4295b/s - JMX server connection timeout 746\n{code}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Cancelled compaction leading to infinite loop in compaction strategy getNextBackgroundTask"
   },
   {
      "_id": "12950910",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-16 17:31:44",
      "description": "This is a weird one:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/540/testReport/snitch_test/TestGossipingPropertyFileSnitch/test_prefer_local_reconnect_on_listen_address\n\nNot sure why the keyspace isn't getting created. At first I thought it was expecting {{keyspace1}} but finding {{Keyspace1}}, but then the test would just never pass.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in snitch_test.TestGossipingPropertyFileSnitch.test_prefer_local_reconnect_on_listen_address"
   },
   {
      "_id": "12950855",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-16 14:39:57",
      "description": "This new(ish) test failed on the 2.1 novnodes job. I don't know if it's a flap, or if it never would have passed; the test is relatively new, and I think this may be one of the first commits to 2.1 since it was committed. Here's the failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/216/testReport/repair_tests.repair_test/TestRepair/partitioner_range_repair_test\n\nFailed on CassCI build cassandra-2.1_novnode_dtest #216. Assigning [~philipthompson] for initial triaging, since he wrote this test.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_tests.repair_test.TestRepair.partitioner_range_repair_test"
   },
   {
      "_id": "12950195",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2016-03-15 06:17:21",
      "description": "Hey. Please help me with a problem. Recently I updated to 3.3.0 and this problem appeared in the logs.\n\nERROR [CompactionExecutor:2458] 2016-03-10 12:41:15,127 CassandraDaemon.java:195 - Exception in thread Thread[CompactionExecutor:2458,1,main]\njava.lang.AssertionError: null\nat org.apache.cassandra.db.rows.BufferCell.<init>(BufferCell.java:49) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.BufferCell.tombstone(BufferCell.java:88) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.BufferCell.tombstone(BufferCell.java:83) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.BufferCell.purge(BufferCell.java:175) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.ComplexColumnData.lambda$purge$107(ComplexColumnData.java:165) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.ComplexColumnData$$Lambda$68/1224572667.apply(Unknown Source) ~[na:na]\nat org.apache.cassandra.utils.btree.BTree$FiltrationTracker.apply(BTree.java:650) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.utils.btree.BTree.transformAndFilter(BTree.java:693) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.utils.btree.BTree.transformAndFilter(BTree.java:668) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.ComplexColumnData.transformAndFilter(ComplexColumnData.java:170) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.ComplexColumnData.purge(ComplexColumnData.java:165) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.ComplexColumnData.purge(ComplexColumnData.java:43) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.BTreeRow.lambda$purge$102(BTreeRow.java:333) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.BTreeRow$$Lambda$67/1968133513.apply(Unknown Source) ~[na:na]\nat org.apache.cassandra.utils.btree.BTree$FiltrationTracker.apply(BTree.java:650) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.utils.btree.BTree.transformAndFilter(BTree.java:693) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.utils.btree.BTree.transformAndFilter(BTree.java:668) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.BTreeRow.transformAndFilter(BTreeRow.java:338) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.rows.BTreeRow.purge(BTreeRow.java:333) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.partitions.PurgeFunction.applyToRow(PurgeFunction.java:88) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:116) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.transform.UnfilteredRows.isEmpty(UnfilteredRows.java:38) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:64) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:24) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:76) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.compaction.CompactionIterator.hasNext(CompactionIterator.java:226) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:177) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:78) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:60) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:264) ~[apache-cassandra-3.3.0.jar:3.3.0]\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_51]\nat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_51]\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_51]\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]\nat java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "error"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "ERROR [CompactionExecutor] CassandraDaemon.java Exception in thread"
   },
   {
      "_id": "12949031",
      "assignee": "krummas",
      "components": [],
      "created": "2016-03-11 09:18:17",
      "description": "Since CASSANDRA-7272 we most often over allocate the bloom filter size with LCS",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix bloom filter sizing with LCS"
   },
   {
      "_id": "12948874",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-10 18:51:56",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_offheap_dtest/68/testReport/consistency_test/TestConsistency/quorum_available_during_failure_test\n\nFailed on CassCI build trunk_offheap_dtest #68\n\nThis seems to be failing after merging this CCM PR:\n\nhttps://github.com/pcmanus/ccm/pull/461\n\nI'm not sure why it would fail with that error-checking code but not without it. On this test run, it ran after these two tests:\n\n{code}\ntest_simple_strategy_each_quorum (consistency_test.TestAvailability) ... ok\ntest_simple_strategy_each_quorum_counters (consistency_test.TestAccuracy) ... ok\n{code}\n\nso, maybe processes are hanging around after one of those tests. [~philipthompson] can you have a first look here?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in consistency_test.TestConsistency.quorum_available_during_failure_test"
   },
   {
      "_id": "12948625",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-03-10 01:44:40",
      "description": "If an invalid column is specified in the COPY FROM command, then it fails without an appropriate error notification.\n\nFor example using this schema:\n\n{code}\nCREATE TABLE bulk_read.value500k_cluster1 (\n    pk int,\n    c1 int,\n    v1 text,\n    v2 text,\n    PRIMARY KEY (pk, c1)\n);\n{code}\n\nand this COPY FROM command (note the third column name is wrong:\n\n{code}\nCOPY bulk_read.value500k_cluster1 (pk, c1, vv, v2) FROM 'test.csv';\n{code}\n\nwe get the following error:\n\n{code}\nStarting copy of bulk_read.value500k_cluster1 with columns ['pk', 'c1', 'vv', 'v2'].\n1 child process(es) died unexpectedly, aborting\nProcessed: 0 rows; Rate:       0 rows/s; Avg. rate:       0 rows/s\n0 rows imported from 0 files in 0.109 seconds (0 skipped).\n{code}\n\nRunning cqlsh with {{--debug}} reveals where the problem is:\n\n{code}\nStarting copy of bulk_read.value500k_cluster1 with columns ['pk', 'c1', 'vv', 'v2'].\nTraceback (most recent call last):\n  File \"/home/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py\", line 2005, in run\n    self.inner_run(*self.make_params())\n  File \"/home/automaton/cassandra-src/bin/../pylib/cqlshlib/copyutil.py\", line 2027, in make_params\n    is_counter = (\"counter\" in [table_meta.columns[name].cql_type for name in self.valid_columns])\n{code}\n\nThe parent process should check that all column names are valid and output an appropriate error message rather than letting worker processes crash.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh: COPY FROM should check that explicit column names are valid"
   },
   {
      "_id": "12948481",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-03-09 18:30:57",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1043/testReport/ttl_test/TestTTL/remove_column_ttl_with_default_ttl_test\n\nThis test started failing on build #1041, when a change to TTL behavior was introduced:\n\nhttps://github.com/apache/cassandra/commit/e017f9494844234fa73848890347f59c622cea40\n\n[~blerer] Looks like I failed to review this properly, sorry. Could you have a look at this, please?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in ttl_test.TestTTL.remove_column_ttl_with_default_ttl_test"
   },
   {
      "_id": "12948418",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-09 15:02:12",
      "description": "This dtest has failed once:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/597/testReport/compaction_test/TestCompaction_with_LeveledCompactionStrategy/data_size_test\n\nHere's the history for this test:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/597/testReport/compaction_test/TestCompaction_with_LeveledCompactionStrategy/data_size_test/history/\n\nIt failed at this line:\n\nhttps://github.com/riptano/cassandra-dtest/blob/88a74d7/compaction_test.py#L86\n\nBasically, it ran compaction over the default stress tables, but timed out waiting to see the line {{Compacted }} in the log.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in compaction_test.TestCompaction_with_LeveledCompactionStrategy.data_size_test"
   },
   {
      "_id": "12948253",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-03-09 02:39:22",
      "description": "Currently we have an exponential back-off policy in COPY FROM that kicks in when timeouts are received. However there are two limitations:\n\n* it does not cover new requests and therefore we may not back-off sufficiently to give time to an overloaded server to recover\n* the pause is performed in the receiving thread and therefore we may not process server messages quickly enough\n\nThere is a static throttling mechanism in rows per second from feeder to worker processes (the INGESTRATE) but the feeder has no idea of the load of each worker process. However it's easy to keep track of how many chunks a worker process has yet to read by introducing a bounded semaphore.\n\nThe idea is to move the back-off pauses to the worker processes main thread so as to include all messages, new and retries, not just the retries that timed out. The worker process will not read new chunks during the back-off pauses, and the feeder process can then look at the number of pending chunks before sending new chunks to a worker process.\n\n[~aholmber], [~aweisberg] what do you think?  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve backoff policy for cqlsh COPY FROM"
   },
   {
      "_id": "12948166",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-08 21:29:55",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/592/testReport/replication_test/SnitchConfigurationUpdateTest/test_rf_collapse_property_file_snitch\n\nFailed on CassCI build cassandra-3.0_dtest #592\n\nThe test failed on this line:\n\nhttps://github.com/riptano/cassandra-dtest/blob/7a331cda807c96ae107b58017854f0e57996d8c3/replication_test.py#L567\n\nSo, a node's expected move from one rack to another doesn't happen in the allotted timeout time. This is the only flap I've seen. Maybe the thing to do here is increase the timeout and keep an eye on it?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in replication_test.SnitchConfigurationUpdateTest.test_rf_collapse_property_file_snitch"
   },
   {
      "_id": "12945984",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-03-01 23:32:31",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.regression_test/TestForRegressions/test_10822\n\nFailed on CassCI build upgrade_tests-all #2\n\nlooks like it fails every time, likely to be a test code problem:\n{noformat}\n'NoneType' object has no attribute 'starting_version'\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.regression_test.TestForRegressions.test_10822"
   },
   {
      "_id": "12945655",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-02-29 22:54:51",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest_win32/337/testReport/compaction_test/TestCompaction_with_LeveledCompactionStrategy/compaction_strategy_switching_test\n\nFailed on CassCI build trunk_dtest_win32 #337\n\nFailing pretty regularly:\n{noformat}\n[Error 5] Access is denied: u'\\\\\\\\?\\\\d:\\\\temp\\\\dtest-wigqqn\\\\test\\\\node1\\\\data0\\\\ks\\\\cf-293dd6c0c58c11e58fa05d04d8558111\\\\ma-1-big-Data.db'\n{noformat}\n\nError looks very similar to that seen on CASSANDRA-11281, so perhaps the same root cause.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "(windows) dtest failure in compaction_test.TestCompaction_with_LeveledCompactionStrategy.compaction_strategy_switching_test"
   },
   {
      "_id": "12945653",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-02-29 22:53:41",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest_win32/337/testReport/compaction_test/TestCompaction_with_DateTieredCompactionStrategy/compaction_strategy_switching_test\n\nFailed on CassCI build trunk_dtest_win32 #337\n\nthis test appears to be flaky:\n{noformat}\n[Error 5] Access is denied: u'\\\\\\\\?\\\\d:\\\\temp\\\\dtest-ha5dpw\\\\test\\\\node1\\\\data0\\\\ks\\\\cf-ef8f1030c58911e5a56c87d8e427fe34\\\\ma-7-big-Data.db'\n{noformat}\n\nError looks very similar to that seen on CASSANDRA-11281, so perhaps the same root cause.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "(windows) dtest failure in compaction_test.TestCompaction_with_DateTieredCompactionStrategy.compaction_strategy_switching_test"
   },
   {
      "_id": "12945616",
      "assignee": "krummas",
      "components": [],
      "created": "2016-02-29 21:15:45",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/trunk_dtest/1011/testReport/disk_balance_test/TestDiskBalance/disk_balance_bootstrap_test\n\nFailed on CassCI build trunk_dtest #1011\n\nThis looks likely to be a test issue, perhaps we need to relax the assertion here a bit:\n{noformat}\nvalues not within 20.00% of the max: (474650, 382235, 513385) (node1)\n{noformat}\n\nThis is flaky with several flaps in the last few weeks.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in disk_balance_test.TestDiskBalance.disk_balance_bootstrap_test"
   },
   {
      "_id": "12945545",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-29 18:10:43",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/155/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1/select_distinct_with_deletions_test\n\nFailed on CassCI build cassandra-3.0_novnode_dtest #155\n\nlooks to be an assertion error, so could be test code or possibly cassandra:\n{noformat}\n9 != 8\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1.select_distinct_with_deletions_test"
   },
   {
      "_id": "12945088",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-02-26 22:28:20",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/167/testReport/upgrade_internal_auth_test/TestAuthUpgrade/upgrade_to_30_test\n\nFailed on CassCI build cassandra-3.0_dtest_win32 #167\n\nthis test is flapping pretty frequently. not certain yet on failure cause, might vary across builds.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "(windows) dtest failure in upgrade_internal_auth_test.TestAuthUpgrade.upgrade_to_30_test"
   },
   {
      "_id": "12945014",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-26 19:31:24",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/564/testReport/materialized_views_test/TestMaterializedViews/view_tombstone_test\n\nFailed on CassCI build cassandra-3.0_dtest #564\n\nintermittent failure, error:\n{noformat}\nExpected [[1, 1, 'b', 3.0]] from SELECT * FROM t_by_v WHERE v = 1, but got []\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in materialized_views_test.TestMaterializedViews.view_tombstone_test"
   },
   {
      "_id": "12944756",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-02-26 03:22:49",
      "description": "At the moment COPY TO uses the same float precision as cqlsh, which by default is 5 but it can be changed in cqlshrc. However, typically people want to preserve precision when exporting data and so this default is too low for COPY TO.\n\nI suggest adding a new COPY FROM option to specify floating point precision with a much higher default value, for example 12.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting",
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "COPY TO should have higher double precision"
   },
   {
      "_id": "12944729",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-26 00:55:43",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/194/testReport/auth_test/TestAuth/restart_node_doesnt_lose_auth_data_test\n\nFailed on CassCI build cassandra-2.2_dtest_win32 #194\n\nlooks like a problem with dtest code:\n{noformat}\ncode=2200 [Invalid query] message=\"Keyspace ks does not exist\"\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "(windows) dtest failure in auth_test.TestAuth.restart_node_doesnt_lose_auth_data_test"
   },
   {
      "_id": "12944689",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2016-02-25 22:41:53",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/174/testReport/upgrade_internal_auth_test/TestAuthUpgrade/upgrade_to_22_test\n\nFailed on CassCI build cassandra-2.2_dtest_win32 #174\n\nlooks like there could be multiple causes for this intermittent failure.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "(windows) dtest failure in upgrade_internal_auth_test.TestAuthUpgrade.upgrade_to_22_test"
   },
   {
      "_id": "12944664",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-25 21:02:26",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/165/testReport/replace_address_test/TestReplaceAddress/replace_with_reset_resume_state_test\n\nFailed on CassCI build cassandra-2.2_dtest_win32 #165\n\n2 flaps of this test in recent history, looks like a possible test issue, perhaps with invalid yaml at startup (somehow).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "(windows) dtest failure in replace_address_test.TestReplaceAddress.replace_with_reset_resume_state_test"
   },
   {
      "_id": "12944657",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2016-02-25 20:38:37",
      "description": "It would be nice if options to trigger a repair (-pr, -local, -parallelism, incremental, etc) are also included in the {{system_distributed.parent_repair_history}} and {{system_distributed.repair_history}} tables. \n\nThe simplest way would be to add it as a map to allow for new options in the future.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add repair options to repair_history table"
   },
   {
      "_id": "12944327",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-25 00:07:02",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/526/testReport/bootstrap_test/TestBootstrap/simple_bootstrap_test_nodata\n\nFailed on CassCI build cassandra-2.2_dtest #526",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in bootstrap_test.TestBootstrap.simple_bootstrap_test_nodata"
   },
   {
      "_id": "12944325",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-24 23:47:55",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest/519/testReport/repair_test/TestRepair/local_dc_repair_test\n\nFailed on CassCI build cassandra-2.2_dtest #519\n\nAppears to be flapping occasionally, most recent error:\n{noformat}\n[Unavailable exception] message=\"Cannot achieve consistency level ALL\" info={'required_replicas': 4, 'alive_replicas': 3, 'consistency': 'ALL'\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in repair_test.TestRepair.local_dc_repair_test"
   },
   {
      "_id": "12944001",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-24 22:42:14",
      "description": "example failure:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/301/testReport/replication_test/SnitchConfigurationUpdateTest/test_failed_snitch_update_property_file_snitch\n\nFailed on CassCI build cassandra-2.1_offheap_dtest #301\nFailed on CassCI build cassandra-2.1_offheap_dtest #286\n\nLooks to be a timeout issue on both historical failures:\n{noformat}\nRan out of time waiting for topology to change on node 0\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest failure in replication_test.SnitchConfigurationUpdateTest.test_failed_snitch_update_property_file_snitch"
   },
   {
      "_id": "12943092",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334946",
            "id": "12334946",
            "name": "Tool/nodetool"
         }
      ],
      "created": "2016-02-24 21:59:52",
      "description": "In the nodetool tablestats output (formerly cfstats), we display \"keyspace\" level metrics before the table-level metrics:\n\n{noformat}\nKeyspace: testks\n        Read Count: 14772528\n        Read Latency: 0.14456651623879135 ms.\n        Write Count: 4761283\n        Write Latency: 0.062120404521218336 ms.\n        Pending Flushes: 0\n                Table: processes\n                SSTable count: 7\n                Space used (live): 496.76 MB\n                Space used (total): 496.76 MB\n                Space used by snapshots (total): 0 bytes\n                Off heap memory used (total): 285.76 KB\n                SSTable Compression Ratio: 0.2318241570710227\n                Number of keys (estimate): 3027\n                Memtable cell count: 2140\n                Memtable data size: 1.66 MB\n                Memtable off heap memory used: 0 bytes\n                Memtable switch count: 967\n                Local read count: 14772528\n                Local read latency: 0.159 ms\n                Local write count: 4761283\n                Local write latency: 0.068 ms\n{noformat}\n\nHowever, the keyspace-level metrics are misleading, at best.  They are aggregate metrics for every table in the keyspace _that is included in the command line filters_.  So, if you run {{tablestats}} for a single table, the keyspace-level stats will only reflect that table's stats.\n\nI see two possible fixes:\n# If the command line options don't include the entire keyspace, skip the keyspace-level stats\n# Ignore the command line options, and always make the keyspace-level stats an aggregate of all tables in the keyspace\n\nMy only concern with option 2 is that performance may suffer a bit on keyspaces with many tables.  However, this is a command line tool, so as long as the response time is reasonable, I don't think it's a big deal.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "nodetool tablestats' keyspace-level metrics are wrong/misleading"
   },
   {
      "_id": "12941589",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-24 00:29:06",
      "description": "Test intermittently failing with set comparison errors that differ from one failure to the next. Looks a bit more stable recently since #203 failed, but probably worth keeping an eye on, and check if there's a problem with the test code.\n\nmost recent failure:\nhttp://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/203/testReport/replication_test/ReplicationTest/network_topology_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "replication_test.ReplicationTest.network_topology_test flaps"
   },
   {
      "_id": "12941537",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-23 20:52:24",
      "description": "recent occurence:\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/427/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_repairedset_test/\n\nlast 2 runs failed:\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/427/testReport/repair_tests.incremental_repair_test/TestIncRepair/sstable_repairedset_test/history/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "repair_tests.incremental_repair_test.TestIncRepair.sstable_repairedset_test failing"
   },
   {
      "_id": "12940642",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-02-19 20:51:27",
      "description": "I've seen these tests flap:\n\n{code}\nupgrade_tests/upgrade_through_versions_test.py:ProtoV4Upgrade_3_1_UpTo_3_2_HEAD.bootstrap_test\nupgrade_tests/upgrade_through_versions_test.py:ProtoV4Upgrade_3_3_UpTo_Trunk_HEAD.bootstrap_test\n\nupgrade_tests/upgrade_through_versions_test.py:ProtoV3Upgrade_3_0_UpTo_3_1_HEAD.bootstrap_multidc_test\nupgrade_tests/upgrade_through_versions_test.py:ProtoV3Upgrade_3_2_UpTo_3_3_HEAD.bootstrap_multidc_test\nupgrade_tests/upgrade_through_versions_test.py:ProtoV3Upgrade_3_3_UpTo_Trunk_HEAD.bootstrap_multidc_test\nupgrade_tests/upgrade_through_versions_test.py:ProtoV4Upgrade_3_3_UpTo_Trunk_HEAD.bootstrap_multidc_test\n{code}\n\nThere may be more upgrade paths that flap, I'm not sure. All the failures I've seen look like this:\n\n{code}\nUnexpected error in node5 node log: ['ERROR [main] 2016-02-18 20:05:13,012 MigrationManager.java:164 - Migration task failed to complete\\nERROR [main] 2016-02-18 20:05:14,012 MigrationManager.java:164 - Migration task failed to complete']\n{code}\n\n[~rhatch] Do these look familiar at all?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "upgrade bootstrap tests flap when migration tasks fail"
   },
   {
      "_id": "12939988",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2016-02-17 23:24:04",
      "description": "In CASSANDRA-5547, we made cleanup (among other things) run in parallel across multiple sstables.  There have been reports on IRC of this leading to disk space exhaustion, because multiple sstables are (almost entirely) rewritten at the same time.  This seems particularly problematic because cleanup is frequently run after a cluster is expanded due to low disk space.\n\nI'm not really familiar with how we perform free disk space checks now, but it sounds like we can make some improvements here.  It would be good to reduce the concurrency of cleanup operations if there isn't enough free disk space to support this.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Parallel cleanup can lead to disk space exhaustion"
   },
   {
      "_id": "12939330",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2016-02-15 17:43:47",
      "description": "Observed that after a large repair on LCS that sometimes the system will enter an infinite loop with vast amounts of logs lines recording, \"Adding high-level (L${LEVEL}) SSTableReader(path='${TABLE}') to candidates\"\n\nThis results in an outage of the node and eventual crashing. The log spam quickly rotates out possibly useful earlier debugging.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Infinite loop bug adding high-level SSTableReader in compaction"
   },
   {
      "_id": "12938255",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-02-10 17:44:33",
      "description": "a difference in behaviour between SOURCE command in CQLSH 3.1 and 3.2. \nIn CQLSH 3.1 SOURCE will NOT require \"use keyspace\" in the cql file that you execute: the \"keyspace\" directive in the qlshrc file will work and the cql file will be executed.\n\nIn CQLSH 3.2.1, SOURCE command requires that \"use keyspace\" is in the cql file that you are sourcing, otherwise it throws this error:\n\"No keyspace has been specified. USE a keyspace, or explicitly specify keyspace.tablename\". \nThe \"keyspace\" directive in cqlshrc is overridden by source command.\n\nsteps to reproduce:\ncreate a file called select.cql in your home directory:\n{noformat}\necho \"CONSISTENCY ONE;\" > select.cql\necho \"select * from tab;\" >> select.cql\n{noformat}\n\nin cqlsh:\n{noformat}\ncreate KEYSPACE kspace WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};\ncreate TABLE tab ( id int primary key);\ninsert into tab (id) VALUES ( 1);\n{noformat}\n\nAdd this to cqlsgrc:\n{noformat}\n[authentication]\nkeyspace = kspace\n{noformat}\n\nThen exit cqlsh and rerun cqlsh using the cqlshrc just modified.\nNote that you are in keyspace \"kspace\".\nexecute:\n{noformat}\nsource 'select.cql' \n{noformat}\n\nthis will have different behaviour in CQLSH 3.2 and 3.1",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "SOURCE command in CQLSH 3.2 requires that \"use keyspace\" is in the cql file that you are sourcing"
   },
   {
      "_id": "12937142",
      "assignee": "slebresne",
      "components": [],
      "created": "2016-02-05 20:29:13",
      "description": "Looks like this was fixed in CASSANDRA-10762, but not for non-vnode environments:\n\n{code}\n$ DISABLE_VNODES=yes KEEP_TEST_DIR=yes CASSANDRA_VERSION=git:cassandra-3.0 PRINT_DEBUG=true nosetests -s -v upgrade_tests/cql_tests.py:TestCQLNodes2RF1.select_distinct_with_deletions_test\nselect_distinct_with_deletions_test (upgrade_tests.cql_tests.TestCQLNodes2RF1) ... cluster ccm directory: /tmp/dtest-UXb0un\nhttp://git-wip-us.apache.org/repos/asf/cassandra.git git:cassandra-3.0\nCustom init_config not found. Setting defaults.\nDone setting configuration options:\n{   'num_tokens': None,\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ngetting default job version for 3.0.3\nUpgradePath(starting_version='binary:2.2.3', upgrade_version=None)\nstarting from 2.2.3\nupgrading to {'install_dir': '/home/ryan/.ccm/repository/gitCOLONcassandra-3.0'}\nQuerying upgraded node\nFAIL\n\n======================================================================\nFAIL: select_distinct_with_deletions_test (upgrade_tests.cql_tests.TestCQLNodes2RF1)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/ryan/git/datastax/cassandra-dtest/upgrade_tests/cql_tests.py\", line 3360, in select_distinct_with_deletions_test\n    self.assertEqual(9, len(rows))\nAssertionError: 9 != 8\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-UXb0un\ndtest: DEBUG: Custom init_config not found. Setting defaults.\ndtest: DEBUG: Done setting configuration options:\n{   'num_tokens': None,\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: getting default job version for 3.0.3\ndtest: DEBUG: UpgradePath(starting_version='binary:2.2.3', upgrade_version=None)\ndtest: DEBUG: starting from 2.2.3\ndtest: DEBUG: upgrading to {'install_dir': '/home/ryan/.ccm/repository/gitCOLONcassandra-3.0'}\ndtest: DEBUG: Querying upgraded node\n--------------------- >> end captured logging << ---------------------\n\n----------------------------------------------------------------------\nRan 1 test in 56.022s\n\nFAILED (failures=1)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "select_distinct_with_deletions_test failing on non-vnode environments"
   },
   {
      "_id": "12936865",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-02-04 21:32:46",
      "description": "See [here|http://cassci.datastax.com/job/cassandra-2.1_dtest/415/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_datetimeformat_round_trip/] for a failure of {{cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_datetimeformat_round_trip}} on 2.1 against the SHA 165f586e6f5e7.\n\nThe test is seeing different timestamps than expected.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh_copy_test failing on 2.1"
   },
   {
      "_id": "12934503",
      "assignee": "philipthompson",
      "components": [],
      "created": "2016-01-27 15:57:59",
      "description": "This tests in this module fail [here|https://github.com/riptano/cassandra-dtest/blob/18647a3e167f127795e2fe63d73305dddf103716/upgrade_supercolumns_test.py#L213] and [here|https://github.com/riptano/cassandra-dtest/blob/529cd71ad5ac4c2f28ccb5560ddc068f604c7b28/upgrade_supercolumns_test.py#L106] when a call to {{start}} with {{wait_other_notice=True}} times out. It happens consistently on the upgrade path from cassandra-2.1 to 2.2. I haven't seen clear evidence as to whether this is a test failure or a C* bug, so I'll mark it as a test error for the TE team to debug.\n\nI don't have a CassCI link for this failure - the changes to the tests haven't been merged yet.\n\nEDIT: changing the title of this ticket since there are multiple similar failures. The failing tests are\n\n{code}\nupgrade_supercolumns_test.py:TestSCUpgrade.upgrade_with_counters_test failing\nupgrade_supercolumns_test.py:TestSCUpgrade.upgrade_with_index_creation_test\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "upgrade_supercolumns_test dtests failing on 2.1"
   },
   {
      "_id": "12933106",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2016-01-21 16:15:52",
      "description": "This is absolutely a test issue. {{largecolumn_test.TestLargeColumn.cleanup_test}} fails on a few versions, as seen [here|http://cassci.datastax.com/job/cassandra-2.2_dtest/488/testReport/largecolumn_test/TestLargeColumn/cleanup_test/]. The nominal complaint is \n{{Expected numeric from fields from nodetool gcstats}}\nexcept as we can see from the new debug output I added, gcstats is printing out numeric fields. So the regex is wrong somehow.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "largecolumn_test.TestLargeColumn.cleanup_test is failing"
   },
   {
      "_id": "12933073",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-01-21 13:56:49",
      "description": "C* 2.1 cqlsh DESCRIBE KEYSPACE ( or TABLE ) returns:\n\n{code}\n 'NoneType' object has no attribute 'replace' \n{code}\n\nfor thrift CF's originally created in C* 1.2.\n\nRepro:\n\n1. Create cf in cassandra-cli on C* 1.2.x  (1.2.9 was used here)\n\n{code}\n[default@ks1] CREATE COLUMN FAMILY t1\n...\tWITH column_type='Standard'\n...\tAND comparator='CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type)'\n...\tAND default_validation_class='UTF8Type'\n...\tAND key_validation_class='UTF8Type'\n...\tAND read_repair_chance=0.1\n...\tAND dclocal_read_repair_chance=0.0\n...\tAND gc_grace=864000\n...\tAND min_compaction_threshold=4\n...\tAND max_compaction_threshold=32\n...\tAND replicate_on_write=true\n...\tAND compaction_strategy='LeveledCompactionStrategy' AND compaction_strategy_options={sstable_size_in_mb: 32}\n...\tAND caching='KEYS_ONLY'\n...\tAND compression_options={sstable_compression:SnappyCompressor, chunk_length_kb:64};\n\nqlsh> describe keyspace ks1;\n\nCREATE KEYSPACE ks1 WITH replication = {\n  'class': 'NetworkTopologyStrategy',\n  'datacenter1': '1'\n};\n\nUSE ks1;\n\nCREATE TABLE t1 (\n  key text,\n  column1 text,\n  column2 text,\n  value text,\n  PRIMARY KEY (key, column1, column2)\n) WITH COMPACT STORAGE AND\n  bloom_filter_fp_chance=0.100000 AND\n  caching='KEYS_ONLY' AND\n  comment='' AND\n  dclocal_read_repair_chance=0.000000 AND\n  gc_grace_seconds=864000 AND\n  read_repair_chance=0.100000 AND\n  replicate_on_write='true' AND\n  populate_io_cache_on_flush='false' AND\n  compaction={'sstable_size_in_mb': '32', 'class': 'LeveledCompactionStrategy'} AND\n  compression={'chunk_length_kb': '64', 'sstable_compression': 'SnappyCompressor'};\n\n\ncqlsh> select keyspace_name, columnfamily_name,column_aliases,key_aliases from system.schema_columnfamilies where keyspace_name= 'ks1';\n\n keyspace_name | columnfamily_name | column_aliases | key_aliases\n---------------+-------------------+----------------+-------------\n           ks1 |                t1 |             [] |          []\n\n\n2/ Upgrade -> C* 2.0.9 -> nodetool upgradesstables -a\n\nAt this stage , DESCRIBE in cqlsh is working\n\n3/ Upgrade -> C* 2.1.12 -> nodetool upgradesstables -a\n\nDESCRIBE now fails:\n\ncqlsh> describe table ks1.t1;\n'NoneType' object has no attribute 'replace'\n\ncqlsh> describe keyspace ks1;\n'NoneType' object has no attribute 'replace'\n{code}\n\nYou can workaround by manually updating {{system.schema_columnfamilies}}\n\n{code}\n UPDATE system.schema_columnfamilies SET column_aliases ='[\"column1\",\"column2\"]' WHERE keyspace_name = 'ks1' AND columnfamily_name = 't1';\n{code}\n\nOnce you exit and restart cqlsh, {{DESCRIBE}} is not working as per C* 1.2\n\n{code}\ncqlsh> describe keyspace ks1;\n\nCREATE KEYSPACE ks1 WITH replication = {'class': 'NetworkTopologyStrategy', 'datacenter1': '1'}  AND durable_writes = true;\n\nCREATE TABLE ks1.t1 (\n    key text,\n    column1 text,\n    column2 text,\n    value text,\n    PRIMARY KEY (key, column1, column2)\n) WITH COMPACT STORAGE\n    AND CLUSTERING ORDER BY (column1 ASC, column2 ASC)\n    AND caching = '{\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"}'\n    AND comment = ''\n    AND compaction = {'sstable_size_in_mb': '32', 'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy'}\n    AND compression = {'chunk_length_kb': '64', 'sstable_compression': 'org.apache.cassandra.io.compress.SnappyCompressor'}\n    AND dclocal_read_repair_chance = 0.0\n    AND default_time_to_live = 0\n    AND gc_grace_seconds = 864000\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 128\n    AND read_repair_chance = 0.1\n    AND speculative_retry = '99.0PERCENTILE';\n{code}\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "C*2.1 cqlsh DESCRIBE KEYSPACE ( or TABLE ) returns 'NoneType' object has no attribute 'replace'"
   },
   {
      "_id": "12932942",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-01-21 01:56:27",
      "description": "h5. Description\n\nRunning COPY from on a large dataset (20G divided in 20M records) revealed two issues:\n\n* The progress report is incorrect, it is very slow until almost the end of the test at which point it catches up extremely quickly.\n\n* The performance in rows per second is similar to running smaller tests with a smaller cluster locally (approx 35,000 rows per second). As a comparison, cassandra-stress manages 50,000 rows per second under the same set-up, therefore resulting 1.5 times faster. \n\nSee attached file _copy_from_large_benchmark.txt_ for the benchmark details.\n\nh5. Doc-impacting changes to COPY FROM options\n\n* A new option was added: PREPAREDSTATEMENTS - it indicates if prepared statements should be used; it defaults to true.\n* The default value of CHUNKSIZE changed from 1000 to 5000.\n* The default value of MINBATCHSIZE changed from 2 to 10.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "COPY FROM on large datasets: fix progress report and optimize performance part 4"
   },
   {
      "_id": "12932643",
      "assignee": "krummas",
      "components": [],
      "created": "2016-01-20 07:42:19",
      "description": "We have had a few cases lately where users misunderstand what timestamp_resolution does, we should;\n\n* make the option not autocomplete in cqlsh\n* update documentation\n* log a warning",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Make it clear what timestamp_resolution is used for with DTCS"
   },
   {
      "_id": "12932522",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2016-01-19 20:52:18",
      "description": "The novnode dtest {{consistent_bootstrap_test.TestBootstrapConsistency.consistent_reads_after_move_test}} is failing on trunk. See an example failure [here|http://cassci.datastax.com/job/trunk_novnode_dtest/274/testReport/consistent_bootstrap_test/TestBootstrapConsistency/consistent_reads_after_move_test/].\n\nOn trunk I am getting an OOM of one of my C* nodes [node3], which is what causes the nodetool move to fail. Logs are attached.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "consistent_reads_after_move_test is failing on trunk"
   },
   {
      "_id": "12930060",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2016-01-14 06:58:34",
      "description": "The following CF is never compacting from day one\n\nCREATE TABLE globaldb.\"DynamicParameter\" (\n    dp_id bigint PRIMARY KEY,\n    dp_advertiser_id int,\n    dp_application_id int,\n    dp_application_user_id bigint,\n    dp_banner_id int,\n    dp_campaign_id int,\n    dp_click_timestamp timestamp,\n    dp_country text,\n    dp_custom_parameters text,\n    dp_flags bigint,\n    dp_ip int,\n    dp_machine_id text,\n    dp_string text\n) WITH bloom_filter_fp_chance = 0.01\n    AND caching = '{\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"}'\n    AND comment = ''\n    AND compaction = {'max_sstable_age_days': '30', 'base_time_seconds': '3600', 'timestamp_resolution': 'MILLISECONDS', 'enabled': 'true', 'min_threshold': '2', 'class': 'org.apache.cassandra.db.compaction.DateTieredCompactionStrategy'}\n    AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n    AND dclocal_read_repair_chance = 0.2\n    AND default_time_to_live = 10713600\n    AND gc_grace_seconds = 1209600\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 128\n    AND read_repair_chance = 0.0\n    AND speculative_retry = '99.0PERCENTILE';\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "DateTieredCompactionStrategy not compacting  sstables in 2.1.12"
   },
   {
      "_id": "12929250",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-01-11 18:27:06",
      "description": "Check out [an example cassci failure|http://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/186/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_list_data/] as well as the [full novnode report page|http://cassci.datastax.com/userContent/cstar_report/index.html?jobs=cassandra-2.1_novnode_dtest,cassandra-3.0_novnode_dtest,cassandra-2.2_novnode_dtest&show_known=true].\n\nMany COPY TO tests are failing when the cluster only has one token. The message {{Found no ranges to query, check begin and end tokens: None - None}} is printed, and it appears to be coming from cqlsh, specfically in pylib/cqlshlib/copyutil.py",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh_copy_tests failing en mass when vnodes are disabled"
   },
   {
      "_id": "12928084",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-01-06 18:07:31",
      "description": "http://cassci.datastax.com/job/trunk_dtest/891/testReport/junit/disk_balance_test/TestDiskBalance/disk_balance_bootstrap_test/\n\n{code}\n======================================================================\nFAIL: disk_balance_bootstrap_test (disk_balance_test.TestDiskBalance)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/aboudreault/git/cstar/cassandra-dtest/disk_balance_test.py\", line 51, in disk_balance_bootstrap_test\n    self.assert_balanced(node)\n  File \"/home/aboudreault/git/cstar/cassandra-dtest/disk_balance_test.py\", line 127, in assert_balanced\n    assert_almost_equal(*sums, error=0.2, error_message=node.name)\n  File \"/home/aboudreault/git/cstar/cassandra-dtest/assertions.py\", line 65, in assert_almost_equal\n    assert vmin > vmax * (1.0 - error) or vmin == vmax, \"values not within %.2f%% of the max: %s (%s)\" % (error * 100, args, kwargs['error_message'])\nAssertionError: values not within 20.00% of the max: (529955, 386060, 473640) (node4)\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-nNoQzp\n--------------------- >> end captured logging << ---------------------\n\n----------------------------------------------------------------------\nRan 1 test in 114.862s\n\nFAILED (failures=1)\n\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "disk_balance_bootstrap_test is failing on trunk"
   },
   {
      "_id": "12928082",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2016-01-06 18:04:44",
      "description": "http://cassci.datastax.com/job/trunk_dtest/891/testReport/junit/disk_balance_test/TestDiskBalance/disk_balance_decommission_test/\n\n{code}\n======================================================================\nFAIL: disk_balance_decommission_test (disk_balance_test.TestDiskBalance)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/aboudreault/git/cstar/cassandra-dtest/disk_balance_test.py\", line 74, in disk_balance_decommission_test\n    self.assert_balanced(node)\n  File \"/home/aboudreault/git/cstar/cassandra-dtest/disk_balance_test.py\", line 127, in assert_balanced\n    assert_almost_equal(*sums, error=0.2, error_message=node.name)\n  File \"/home/aboudreault/git/cstar/cassandra-dtest/assertions.py\", line 65, in assert_almost_equal\n    assert vmin > vmax * (1.0 - error) or vmin == vmax, \"values not within %.2f%% of the max: %s (%s)\" % (error * 100, args, kwargs['error_message'])\nAssertionError: values not within 20.00% of the max: (482095, 477840, 612940) (node2)\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-SLbi3e\n--------------------- >> end captured logging << ---------------------\n\n----------------------------------------------------------------------\nRan 1 test in 121.295s\n\nFAILED (failures=1)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "disk_balance_decommission_test is failing on trunk"
   },
   {
      "_id": "12924894",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-12-30 14:14:33",
      "description": "Steps to reproduce:\n\n{code:sql}\nCREATE TABLE simple(\n  id int PRIMARY KEY,\n  int_list list<int>\n);\n\nINSERT INTO simple(id, int_list) VALUES(10, [1,2,3]);\nSELECT * FROM simple;\n\n id | int_list\n----+-----------\n 10 | [1, 2, 3]\n\nUPDATE simple SET int_list[0]=null WHERE id=10;\nServerError: <ErrorMessage code=0000 [Server error] message=\"java.lang.AssertionError\">\n{code}\n\n Per CQL semantics, setting a column to NULL == deleting it.\n\n When using debugger, below is the Java stack trace on server side:\n\n{noformat}\n ERROR o.apache.cassandra.transport.Message - Unexpected exception during request; channel = [id: 0x6dbc33bd, /192.168.51.1:57723 => /192.168.51.1:9473]\njava.lang.AssertionError: null\n\tat org.apache.cassandra.db.rows.BufferCell.<init>(BufferCell.java:49) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.db.rows.BufferCell.tombstone(BufferCell.java:88) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.UpdateParameters.addTombstone(UpdateParameters.java:141) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.UpdateParameters.addTombstone(UpdateParameters.java:136) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.Lists$SetterByIndex.execute(Lists.java:362) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.statements.UpdateStatement.addUpdateForKey(UpdateStatement.java:94) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.statements.ModificationStatement.addUpdates(ModificationStatement.java:666) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.statements.ModificationStatement.getMutations(ModificationStatement.java:606) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.statements.ModificationStatement.executeWithoutCondition(ModificationStatement.java:413) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.statements.ModificationStatement.execute(ModificationStatement.java:401) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:206) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:472) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:449) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.transport.messages.ExecuteMessage.execute(ExecuteMessage.java:130) ~[cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:507) [cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:401) [cassandra-all-3.1.1.jar:3.1.1]\n\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.23.Final.jar:4.0.23.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333) [netty-all-4.0.23.Final.jar:4.0.23.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.access$700(AbstractChannelHandlerContext.java:32) [netty-all-4.0.23.Final.jar:4.0.23.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext$8.run(AbstractChannelHandlerContext.java:324) [netty-all-4.0.23.Final.jar:4.0.23.Final]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60-ea]\n\tat org.apache.cassandra.concurrent.AbstractTracingAwareExecutorService$FutureTask.run(AbstractTracingAwareExecutorService.java:164) [cassandra-all-3.1.1.jar:3.1.1]\n\tat org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [cassandra-all-3.1.1.jar:3.1.1]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_60-ea]\n{noformat}\n\nThe root cause seems to be located at *org.apache.cassandra.cql3.Lists:362* :\n\n{code:java}\n            CellPath elementPath = existingRow.getComplexColumnData(column).getCellByIndex(idx).path();\n            if (value == null)\n            {\n                params.addTombstone(column);\n            }\n            else if (value != ByteBufferUtil.UNSET_BYTE_BUFFER)\n            {\n                params.addCell(column, elementPath, value);\n            }\n{code}\n\n In the if block, it seems we do not pass the CellPath as it should be and it makes the asertion _assert column.isComplex() == (path != null);_ fails at \n*org.apache.cassandra.db.rows:49*\n\n{code:java}\n    public BufferCell(ColumnDefinition column, long timestamp, int ttl, int localDeletionTime, ByteBuffer value, CellPath path)\n    {\n        super(column);\n        assert column.isComplex() == (path != null);\n        ....\n   }\n{code}\n\n Another remark about the code block in *org.apache.cassandra.cql3.Lists:362*, there is an *if/else if* but there is no final *else* block to catch all other alternatives, is it *intended* or just an oversight ?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "regression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "[Regression] Error when removing list element with UPDATE statement"
   },
   {
      "_id": "12924450",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-12-28 05:54:33",
      "description": "Hey. Please help me with a problem. Recently I updated to 3.0.1 and this problem appeared in the logs.\n\nERROR [CompactionExecutor:2596] 2015-12-28 08:30:27,733 CassandraDaemon.java:195 - Exception in thread Thread[CompactionExecutor:2596,1,main]\njava.lang.AssertionError: null\n\tat org.apache.cassandra.db.rows.BufferCell.<init>(BufferCell.java:49) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.BufferCell.tombstone(BufferCell.java:88) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.BufferCell.tombstone(BufferCell.java:83) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.BufferCell.purge(BufferCell.java:175) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.ComplexColumnData.lambda$purge$100(ComplexColumnData.java:165) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.ComplexColumnData$$Lambda$53/1339741213.apply(Unknown Source) ~[na:na]\n\tat org.apache.cassandra.utils.btree.BTree$FiltrationTracker.apply(BTree.java:614) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.utils.btree.BTree.transformAndFilter(BTree.java:657) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.utils.btree.BTree.transformAndFilter(BTree.java:632) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.ComplexColumnData.transformAndFilter(ComplexColumnData.java:170) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.ComplexColumnData.purge(ComplexColumnData.java:165) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.ComplexColumnData.purge(ComplexColumnData.java:43) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.BTreeRow.lambda$purge$95(BTreeRow.java:333) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.BTreeRow$$Lambda$52/1236900032.apply(Unknown Source) ~[na:na]\n\tat org.apache.cassandra.utils.btree.BTree$FiltrationTracker.apply(BTree.java:614) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.utils.btree.BTree.transformAndFilter(BTree.java:657) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.utils.btree.BTree.transformAndFilter(BTree.java:632) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.BTreeRow.transformAndFilter(BTreeRow.java:338) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.rows.BTreeRow.purge(BTreeRow.java:333) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.partitions.PurgeFunction.applyToRow(PurgeFunction.java:88) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:116) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.transform.UnfilteredRows.isEmpty(UnfilteredRows.java:38) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:64) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:24) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:76) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.compaction.CompactionIterator.hasNext(CompactionIterator.java:226) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:177) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:78) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:60) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:253) ~[apache-cassandra-3.0.1.jar:3.0.1]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_51]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_51]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_51]\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "error"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "ERROR [CompactionExecutor] CassandraDaemon.java  Exception in thread"
   },
   {
      "_id": "12923645",
      "assignee": "krummas",
      "components": [],
      "created": "2015-12-22 02:41:51",
      "description": "{{sstableutil_test.py:SSTableUtilTest.abortedcompaction_test}} flaps on 3.0:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest/438/testReport/junit/sstableutil_test/SSTableUtilTest/abortedcompaction_test/\n\nIt also flaps on the CassCI job running without vnodes:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/110/testReport/junit/sstableutil_test/SSTableUtilTest/abortedcompaction_test/history/\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "sstableutil_test.py:SSTableUtilTest.abortedcompaction_test flapping on 3.0"
   },
   {
      "_id": "12923606",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2015-12-21 23:51:13",
      "description": "jmx_test.py:TestJMX.netstats_test started failing hard on Windows about a month ago:\n\nhttp://cassci.datastax.com/job/cassandra-3.0_dtest_win32/140/testReport/junit/jmx_test/TestJMX/netstats_test/history/?start=25\n\nhttp://cassci.datastax.com/job/cassandra-2.2_dtest_win32/156/testReport/jmx_test/TestJMX/netstats_test/history/\n\nIt fails when it is unable to connect to a node via JMX. I don't know if this problem has any relationship to CASSANDRA-10913.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtest",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "netstats_test dtest fails on Windows, flaps on Linux"
   },
   {
      "_id": "12922766",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2015-12-17 16:16:18",
      "description": "This will be a general ticket for upgrade dtests that fail because of bad logic surrounding skipping tests. We need a better system in place for skipping tests that are not intended to work on certain versions of Cassandra; at present, we run the upgrade tests with {{SKIP=false}} because, again, the built-in skipping logic is bad.\n\nOne such test is test_v2_protocol_IN_with_tuples:\n\nhttp://cassci.datastax.com/job/storage_engine_upgrade_dtest-22_tarball-311/lastCompletedBuild/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3/test_v2_protocol_IN_with_tuples/\n\nThis shouldn't be run on clusters that include nodes running 3.0.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix skipping logic on upgrade tests in dtest"
   },
   {
      "_id": "12922490",
      "assignee": "cassandra-te",
      "components": [],
      "created": "2015-12-16 20:33:31",
      "description": "These tests create keyspaces and tables through cqlsh, then runs {{DESCRIBE}} to confirm they were successfully created. These tests flap under the novnode dtest runs:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/lastCompletedBuild/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_refresh_schema_on_timeout_error/history/\nhttp://cassci.datastax.com/job/cassandra-2.2_novnode_dtest/lastCompletedBuild/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_refresh_schema_on_timeout_error/history/\n\nI have not reproduced this locally on Linux.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "test_refresh_schema_on_timeout_error dtest flapping on CassCI"
   },
   {
      "_id": "12922479",
      "assignee": "philipthompson",
      "components": [],
      "created": "2015-12-16 20:04:28",
      "description": "It looks like CASSANDRA-8158 may not have been properly resolved:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/176/testReport/replication_test/ReplicationTest/network_topology_test/history/\nhttp://cassci.datastax.com/job/cassandra-2.2_novnode_dtest/lastCompletedBuild/testReport/replication_test/ReplicationTest/network_topology_test/history/\nhttp://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/lastCompletedBuild/testReport/replication_test/ReplicationTest/network_topology_test/history/\n\n[~philipthompson] Can you have a look?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "network_topology_test dtest still failing"
   },
   {
      "_id": "12922252",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-12-16 05:31:46",
      "description": "In an attempt to give operator insight into potentially harmful batch usage, Jiras were created to log WARN or fail on certain batch sizes. This ignores the single partition batch, which doesn't create the same issues as a multi-partition batch. \n\nThe proposal is to ignore size on single partition batch statements. \n\nReference:\n[CASSANDRA-6487|https://issues.apache.org/jira/browse/CASSANDRA-6487]\n[CASSANDRA-8011|https://issues.apache.org/jira/browse/CASSANDRA-8011]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Alter behavior of batch WARN and fail on single partition batches"
   },
   {
      "_id": "12921817",
      "assignee": "philipthompson",
      "components": [],
      "created": "2015-12-14 23:17:35",
      "description": "This test flaps on CassCI on 2.1. [~aboudreault] Do I remember correctly that you did some work on these tests in the past few months? If so, could you have a look and see if there's some assumption the test makes that don't hold for 2.1?\n\nOddly, it fails frequently under JDK8:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest_jdk8/lastCompletedBuild/testReport/pushed_notifications_test/TestPushedNotifications/restart_node_test/history/\n\nbut less frequently on JDK7:\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/lastCompletedBuild/testReport/pushed_notifications_test/TestPushedNotifications/restart_node_test/history/\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "pushed_notifications_test.py:TestPushedNotifications.restart_node_test flapping on C* 2.1"
   },
   {
      "_id": "12921799",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-12-14 22:33:30",
      "description": "http://cassci.datastax.com/job/cassandra-2.1_dtest/376/testReport/thrift_tests/TestCQLAccesses/test_range_tombstone_and_static/history/\n\nI haven't had enough experience with thrift or the thrift tests to debug this. It passes on 2.2+. I've reproduced this failure locally.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "thrift_tests.py:TestCQLAccesses.test_range_tombstone_and_static failing on C* 2.1"
   },
   {
      "_id": "12921122",
      "assignee": "cassandra-te",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-12-11 17:56:44",
      "description": "This test is failing on 2.1-head. There appear to be structural issues with the test, and no C* bug to be fixed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtest"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "jmxmetrics_test.TestJMXMetrics.begin_test is failing"
   },
   {
      "_id": "12920407",
      "assignee": "krummas",
      "components": [],
      "created": "2015-12-09 12:34:27",
      "description": "We have a bug when we replace sstables after anticompaction, we keep adding duplicates which causes leveled compaction to fail after. Reason being that LCS does not keep its sstables in a {{Set}}, so after first compaction, we will keep around removed sstables in the leveled manifest and that will put LCS in an infinite loop as it tries to mark non-existing sstables as compacting\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix the way we replace sstables after anticompaction"
   },
   {
      "_id": "12916743",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2015-11-28 16:49:38",
      "description": "I have defined the following UDF\n\n{code:sql}\nCREATE OR REPLACE FUNCTION  maxOf(current int, testValue int) RETURNS NULL ON NULL INPUT \nRETURNS int \nLANGUAGE java \nAS  'return Math.max(current,testValue);'\n\nCREATE TABLE maxValue(id int primary key, val int);\nINSERT INTO maxValue(id, val) VALUES(1, 100);\n\nSELECT maxOf(val, 101) FROM maxValue WHERE id=1;\n{code}\n\nI got the following error message:\n\n{code}\nSyntaxException: <ErrorMessage code=2000 [Syntax error in CQL query] message=\"line 1:19 no viable alternative at input '101' (SELECT maxOf(val1, [101]...)\">\n{code}\n\n It would be nice to allow literal value as parameter of UDF and UDA too.\n\n I was thinking about an use-case for an UDA groupBy() function where the end user can *inject* at runtime a literal value to select which aggregation he want to display, something similar to GROUP BY ... HAVING <filter clause>",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "CQL3",
         "UDF",
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow literal value as parameter of UDF & UDA"
   },
   {
      "_id": "12912405",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-11-12 07:11:38",
      "description": "Seems we blow away the level info when doing upgradesstables. Introduced in  CASSANDRA-8004",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't remove level info when doing upgradesstables"
   },
   {
      "_id": "12905520",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-10-16 13:09:17",
      "description": "cqlsh tests break if the runner has an authentication section in their ~/.cassandra/cqlshrc, because cqlsh changes the prompt and the tests scan output for a prompt. It manifests as read timeouts while waiting for a prompt in test/run_cqlsh.py.\n[This pattern|https://github.com/mambocab/cassandra/blob/1c27f9be1ba8ea10dbe843d513e23de6238dede8/pylib/cqlshlib/test/run_cqlsh.py#L30] could be generalized to match the \"<username>@cqlsh...\" prompt that arises with this config.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Make cqlsh tests work when authentication is configured"
   },
   {
      "_id": "12905450",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-10-16 09:05:54",
      "description": "Broken out from CASSANDRA-6696, we should split sstables based on ranges during compaction.\r\n\r\nRequirements;\r\n* dont create tiny sstables - keep them bunched together until a single vnode is big enough (configurable how big that is)\r\n* make it possible to run existing compaction strategies on the per-range sstables\r\n\r\nWe should probably add a global compaction strategy parameter that states whether this should be enabled or not.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "lcs",
         "vnodes"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "RangeAwareCompaction"
   },
   {
      "_id": "12904919",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2015-10-14 16:25:01",
      "description": "C* sockets are often staying TIME_WAIT for up to 120 seconds (2x max segment lifetime) for me in my dev environment on Windows. This is rather obnoxious since it means I can't launch C* for up to 2 minutes after stopping it.\n\nAttaching a patch that adds a simple -a for aggressive startup to the launch scripts to ignore duplicate port check from netstat if it's TIME_WAIT. Also snuck in some more liberal interpretation of help strings in the .ps1.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add ability to skip TIME_WAIT sockets on port check on Windows startup"
   },
   {
      "_id": "12903904",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-10-09 21:28:26",
      "description": "We have seen an issue intermittently but repeatedly over the last few months where, after exiting the Cassandra process, it fails to start with an FSReadError (stack trace below). The FSReadError refers to a 'statistics' file for a  that doesn't exist, though a corresponding temporary file does exist (eg. there is no /media/data/cassandraDB/data/clusteradmin/singleton_token-01a92ed069b511e59b2c53679a538c14/clusteradmin-singleton_token-ka-9-Statistics.db file, but there is a /media/data/cassandraDB/data/clusteradmin/singleton_token-01a92ed069b511e59b2c53679a538c14/clusteradmin-singleton_token-tmp-ka-9-Statistics.db file.)\n\nWe tracked down the issue to the fact that the process exited with leftover compactions and some of the 'tmp' files for the SSTable had been renamed to final files, but not all of them - the issue happens if the 'Statistics' file is not renamed but others are. The scenario we've seen on the last two occurrences involves the 'CompressionInfo' file being a final file while all other files for the SSTable generation were left with 'tmp' names.\n\nWhen this occurs, Cassandra cannot start until the file issue is resolved; we've worked around it by deleting the SSTable files from the same generation, both final and tmp, which at least allows Cassandra to start. Renaming all files to either tmp or final names would also work.\n\nWe've done some debugging in Cassandra and have been unable to cause the issue without renaming the files manually. The rename code at SSTableWriter.rename() looks like it could result in this if the process exits in the middle of the rename, but in every occurrence we've debugged through, the Set of components is ordered and Statistics is the first file renamed.\n\nHowever the comments in SSTableWriter.rename() suggest that the 'Data' file is meant to be used as meaning the files were completely renamed. The method ColumnFamilyStore. removeUnfinishedCompactionLeftovers(), however, will proceed assuming the compaction is complete if any of the component files has a final name, and will skip temporary files when reading the list. If the 'Statistics' file is temporary then it won't be read, and the defaults does not include a list of ancestors, leading to the NullPointerException.\n\nIt appears that ColumnFamilyStore. removeUnfinishedCompactionLeftovers() should perhaps either ensure that all 'tmp' files are properly renamed before it uses them, or skip SSTable files that don't have either the 'Data' or 'Statistics' file in final form.\n\nStack trace: \n{code}\nFSReadError in Failed to remove unfinished compaction leftovers (file: /media/data/cassandraDB/data/clusteradmin/singleton_token-01a92ed069b511e59b2c53679a538c14/clusteradmin-singleton_token-ka-9-Statistics.db).  See log for details.\n        at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:617)\n        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:302)\n        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:536)\n        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:625)\nCaused by: java.lang.NullPointerException\n        at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:609)\n        ... 3 more\nException encountered during startup: java.lang.NullPointerException\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "triage"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Failure to start up Cassandra when temporary compaction files are not all renamed after kill/crash (FSReadError)"
   },
   {
      "_id": "12902842",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-10-06 22:34:27",
      "description": "The dtest for sstableverify is failing:\n\nhttp://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest/lastCompletedBuild/testReport/offline_tools_test/TestOfflineTools/sstableverify_test/\n\nIt fails in the same way when I run it on OpenStack, so I don't think it's just a CassCI problem.\n\n[~slebresne] Looks like you made changes to this test recently:\n\nhttps://github.com/riptano/cassandra-dtest/commit/51ab085f21e01cc8e5ad88a277cb4a43abd3f880\n\nCould you have a look at the failure? I'm assigning you for triage, but feel free to reassign.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix sstableverify_test dtest"
   },
   {
      "_id": "12902784",
      "assignee": "philipthompson",
      "components": [],
      "created": "2015-10-06 19:09:33",
      "description": "cqlsh has fallen out of pep8 compliance:\n\nhttp://cassci.datastax.com/view/trunk/job/cassandra-3.0_dtest/lastCompletedBuild/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_pep8_compliance/\n\n[~philipthompson] has said off-JIRA that he'll fix it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix pep8 compliance in cqlsh.py"
   },
   {
      "_id": "12902141",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-10-02 15:34:51",
      "description": "We need to send a meaningful error message if user try to use {{offheap_objects}} in 3.0 since it's not supported currently (pending CASSANDRA-9472). And document the current removal in the NEWS file.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Remove offheap_objects option until 9472 re-introduces them"
   },
   {
      "_id": "12901713",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-09-30 21:58:53",
      "description": "Query with >= timestamp works. But the exact timestamp value is not working.\n\n{noformat}\nNCHAN-M-D0LZ:bin nchan$ ./cqlsh\nConnected to CCC Multi-Region Cassandra Cluster at <host>:<port>.\n[cqlsh 5.0.1 | Cassandra 2.1.7 | CQL spec 3.2.0 | Native protocol v3]\nUse HELP for help.\ncqlsh>\n{noformat}\n\n{panel:title=Schema|borderStyle=dashed|borderColor=#ccc|titleBGColor=#F7D6C1|bgColor=#FFFFCE}\ncqlsh:ccc> desc COLUMNFAMILY ez_task_result ;\n\nCREATE TABLE ccc.ez_task_result (\n    submissionid text,\n    ezid text,\n    name text,\n    time timestamp,\n    analyzed_index_root text,\n    ...\n    ...\n    PRIMARY KEY (submissionid, ezid, name, time)\n{panel}\n\n{panel:title=Working|borderStyle=dashed|borderColor=#ccc|titleBGColor=#F7D6C1|bgColor=#FFFFCE}\ncqlsh:ccc> select submissionid, ezid, name, time, state, status, translated_criteria_status from ez_task_result where submissionid='760dd154670811e58c04005056bb6ff0' and ezid='760dd6de670811e594fc005056bb6ff0' and name='run-sanities' and time>='2015-09-29 20:54:23-0700';\n\n submissionid                     | ezid                             | name         | time                     | state     | status      | translated_criteria_status\n----------------------------------+----------------------------------+--------------+--------------------------+-----------+-------------+----------------------------\n 760dd154670811e58c04005056bb6ff0 | 760dd6de670811e594fc005056bb6ff0 | run-sanities | 2015-09-29 20:54:23-0700 | EXECUTING | IN_PROGRESS |       run-sanities started\n\n(1 rows)\ncqlsh:ccc>\n{panel}\n{panel:title=Not working|borderStyle=dashed|borderColor=#ccc|titleBGColor=#F7D6C1|bgColor=#FFFFCE}\ncqlsh:ccc> select submissionid, ezid, name, time, state, status, translated_criteria_status from ez_task_result where submissionid='760dd154670811e58c04005056bb6ff0' and ezid='760dd6de670811e594fc005056bb6ff0' and name='run-sanities' and time='2015-09-29 20:54:23-0700';\n\n submissionid | ezid | name | time | analyzed_index_root | analyzed_log_path | clientid | end_time | jenkins_path | log_file_path | path_available | path_to_task | required_for_overall_status | start_time | state | status | translated_criteria_status | type\n--------------+------+------+------+---------------------+-------------------+----------+----------+--------------+---------------+----------------+--------------+-----------------------------+------------+-------+--------+----------------------------+------\n\n(0 rows)\ncqlsh:ccc>\n{panel}\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh: Include sub-second precision in timestamps by default"
   },
   {
      "_id": "12901458",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-09-29 23:15:59",
      "description": "[cqlsh_tests.cqlsh_tests.TestCqlsh.test_clear|http://cassci.datastax.com/view/win32/job/cassandra-3.0_dtest_win32/72/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_clear/] and [cqlsh_tests.cqlsh_tests.TestCqlsh.test_cls|http://cassci.datastax.com/view/win32/job/cassandra-3.0_dtest_win32/72/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_cls/] both fail when the regex looking for a screen-clearing character fails. This is probably a Linux-only test at this point.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows",
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: cqlsh CLEAR/CLS tests fail"
   },
   {
      "_id": "12901440",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-09-29 21:49:17",
      "description": "This is followup to CASSANDRA-10289\n\nThe tests currently failing should be:\n\n* {{cqlshlib.test.test_cqlsh_completion.TestCqlshCompletion.test_complete_in_create_columnfamily}}\n** uses {{create_columnfamily_table_template}}. Stefania says \"the {{(}} after {{CREATE ... IF}} does not look valid to me.\"\n* {{cqlshlib.test.test_cqlsh_completion.TestCqlshCompletion.test_complete_in_create_table}}\n** uses {{create_columnfamily_table_template}}, see above.\n* {{cqlshlib.test.test_cqlsh_completion.TestCqlshCompletion.test_complete_in_delete}}\n** Stefania says: \"I don't think keyspaces are a valid completion after {{DELETE a [}} and after {{DELETE FROM twenty_rows_composite_table USING TIMESTAMP 0 WHERE TOKEN(a) >=}}. From a quick analysis of {{cqlhandling.py}} I think it comes from {{<term>}}, which picks up {{<functionName>}}, which was changed to include {{ks.}} by CASSANDRA-7556.\n* {{cqlshlib.test.test_cqlsh_completion.TestCqlshCompletion.test_complete_in_drop_keyspace}}\n** Stefania says: \"the {{;}} after {{DROP KEYSPACE IF}} is not valid.\n* {{cqlshlib.test.test_cqlsh_output.TestCqlshOutput.test_timestamp_output}}\n** already documented with CASSANDRA-10313 and CASSANDRA-10397\n\nI'm happy to break these out into separate tickets if necessary. \n\nTo run the tests locally, I cd to {{cassandra/pylib/cqlshlib}} and run the following:\n\n{code}\nccm create -n 1 --install-dir=../.. test\nccm start --wait-for-binary-proto\nnosetests test 2>&1\nccm remove\n{code}\n\nThis requires nose and ccm. Until CASSANDRA-10289 is resolved, you'll have to use my branch here: https://github.com/mambocab/cassandra/tree/fix-cqlsh-tests\n\nTests for this branch are run (non-continuously) here:\n\nhttp://cassci.datastax.com/job/scratch_mambocab-fix_cqlsh/\n\nAssigning [~Stefania] for now, since she's already looked at 10289, but feel free to reassign.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix cqlsh bugs"
   },
   {
      "_id": "12901266",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-09-29 09:36:22",
      "description": "Sorry for the somewhat vague summary, but while doing some quick profiling on the plane, I noticed 3 places which could be slightly and trivially improved (I don't mean by that that they are the only 3 places that can be improved, I just semi-randomly looked at those), so I've pushed 3 commits for those [here|https://github.com/pcmanus/cassandra/commits/minor_optims]. There is no particular link between the 3 commits but they are trivial enough that I don't have the courage to open 3 tickets. Each commit description should provide enough informations on what each commit is about so I won't repeat it here.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Minor random optimizations"
   },
   {
      "_id": "12901262",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-09-29 09:12:07",
      "description": "{{MultiCBuilder}} is used to build the {{Clustering}} and {{Slice.Bound}} used by  queries. As the name implies, it's able to build multiple {{Clustering}}/{{Slice.Bound}} for when we have {{IN}}, but most queries don't use {{IN}} and in this (frequent) case, {{MultiCBuilder}} creates quite a bit more objects that would be necessary (it creates 2 lists for its {{elementsList}}, then a {{CBuilder}} and a {{BTreeSet.Builder}} (even though we know the resulting set will have only one element in this case)). Without being huge, this does show up as non entirely negligible when profiling some simple stress.\n\nWe can easily know if the query has a {{IN}} and so we can know when only a single {{Clustering}}/{{Slice.Bound}} is built, and we can specialize the implementation in that case to be less wasteful.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Specialize MultiCBuilder when building a single clustering"
   },
   {
      "_id": "12895551",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-09-22 19:01:41",
      "description": "Looks like there's a regex failure taking place: [link|https://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest_win32/69/testReport/junit/replication_test/SnitchConfigurationUpdateTest/test_rf_collapse_gossiping_property_file_snitch_multi_dc/]\n\nRack changes appear to be working but not being picked up by test checking.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: replication_test fails on Windows"
   },
   {
      "_id": "12864258",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-09-15 13:21:58",
      "description": "Currently, stress always exits with sucess status, even if after a failure. In order to be able to rely on stress exit status during dtests it would be nice if it exited with a non-zero status after failures.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf",
         "stress"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Stress should exit with non-zero status after failure"
   },
   {
      "_id": "12863719",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-09-13 23:53:07",
      "description": "I get this failure on my box with TZ at GMT+08:\n{code}\n======================================================================\nFAIL: test_all_datatypes_read (cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/stefi/git/cstar/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 674, in test_all_datatypes_read\n    self.assertCsvResultEqual(self.tempfile.name, results)\n  File \"/home/stefi/git/cstar/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py\", line 137, in assertCsvResultEqual\n    raise e\nAssertionError: Element counts were not equal:\nFirst has 1, Second has 0:  ['ascii', '1099511627776', '0xbeef', 'True', '3.140000000000000124344978758017532527446746826171875', '2.444', '1.1', '127.0.0.1', '25', '\\xe3\\x83\\xbd(\\xc2\\xb4\\xe3\\x83\\xbc\\xef\\xbd\\x80)\\xe3\\x83\\x8e', '2005-07-14 12:30:00', '30757c2c-584a-11e5-b2d0-9cebe804ecbe', '2471e7de-41e4-478f-a402-e99ed779be76', 'asdf', '36893488147419103232']\nFirst has 0, Second has 1:  ['ascii', '1099511627776', '0xbeef', 'True', '3.140000000000000124344978758017532527446746826171875', '2.444', '1.1', '127.0.0.1', '25', '\\xe3\\x83\\xbd(\\xc2\\xb4\\xe3\\x83\\xbc\\xef\\xbd\\x80)\\xe3\\x83\\x8e', '2005-07-14 04:30:00', '30757c2c-584a-11e5-b2d0-9cebe804ecbe', '2471e7de-41e4-478f-a402-e99ed779be76', 'asdf', '36893488147419103232']\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-8VAvBl\ndtest: DEBUG: Importing from csv file: /tmp/tmpGwW8yB\ndtest: WARNING: Mismatch at index: 10\ndtest: WARNING: Value in csv: 2005-07-14 12:30:00\ndtest: WARNING: Value in result: 2005-07-14 04:30:00\n--------------------- >> end captured logging << ---------------------\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_all_datatypes_read fails locally"
   },
   {
      "_id": "12862261",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-09-07 16:19:41",
      "description": "Operational tasks become incredibly expensive if you keep around a long timespan of data with DTCS - with default settings and 1 year of data, the oldest window covers about 180 days. Bootstrapping a node with vnodes with this data layout will force cassandra to compact very many sstables in this window.\n\nWe should probably put a cap on how big the biggest windows can get. We could probably default this to something sane based on max_sstable_age (ie, say we can reasonably handle 1000 sstables per node, then we can calculate how big the windows should be to allow that)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Make DTCS work well with old data"
   },
   {
      "_id": "12862172",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-09-07 08:46:52",
      "description": "To avoid constant recompaction of files in big ( > max threshold) DTCS windows, we should do STCS of those files.\n\nPatch here: https://github.com/krummas/cassandra/commits/marcuse/dtcs_stcs",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Do STCS in DTCS-windows"
   },
   {
      "_id": "12862005",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-09-05 06:03:48",
      "description": "BEGIN BATCH .... APPLY BATCH is not parsed correctly.\n\nSteps:\n{code}\nCREATE KEYSPACE Excelsior  WITH REPLICATION={'class':'SimpleStrategy','replication_factor':1};\nCREATE TABLE excelsior.data (id int primary key);\nBEGIN BATCH INSERT INTO excelsior.data (id) VALUES (0); APPLY BATCH ;\n{code}\nError\n{code}\nSyntaxException: <ErrorMessage code=2000 [Syntax error in CQL query] message=\"line 0:-1 mismatched input '<EOF>' expecting K_APPLY\">\nSyntaxException: <ErrorMessage code=2000 [Syntax error in CQL query] message=\"line 1:0 no viable alternative at input 'APPLY' ([APPLY]...)\">\n{code}\nWhile \n{code}\nBEGIN BATCH INSERT INTO excelsior.data (id) VALUES (0)  APPLY BATCH ;\n{code}\nwithout *;* after insert works.\n\nConsequently neither\n{code}\nBEGIN BATCH INSERT INTO excelsior.data (id) VALUES (0);INSERT INTO excelsior.data (id) VALUES (0); APPLY BATCH ;\n{code}\nError:\n{code}\nSyntaxException: <ErrorMessage code=2000 [Syntax error in CQL query] message=\"line 0:-1 mismatched input '<EOF>' expecting K_APPLY\">\nSyntaxException: <ErrorMessage code=2000 [Syntax error in CQL query] message=\"line 1:0 no viable alternative at input 'APPLY' ([APPLY]...)\">\n{code}\nnor\n{code}\nBEGIN BATCH INSERT INTO excelsior.data (id) VALUES (0);INSERT INTO excelsior.data (id) VALUES (0) APPLY BATCH ;\n{code}\nError\n{code}\nSyntaxException: <ErrorMessage code=2000 [Syntax error in CQL query] message=\"line 0:-1 mismatched input '<EOF>' expecting K_APPLY\">\nSyntaxException: <ErrorMessage code=2000 [Syntax error in CQL query] message=\"line 1:43 missing EOF at 'APPLY' (...(id) VALUES (0) [APPLY] BATCH...)\">\n{code}\nworks.\n\nIt was OK in 2.2.0 and 3.0 beta 1.\n3.0-beta2-tentative also affected.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "BATCH statement is broken in cqlsh"
   },
   {
      "_id": "12861398",
      "assignee": "krummas",
      "components": [],
      "created": "2015-09-02 21:16:31",
      "description": "HI,\nwe are ingesting data 6 million records every 15 mins into one DTCS table and relaying on Cassandra for purging the data.Table Schema given below, Issue 1: we are expecting to see table sstable created on day d1 will not be compacted after d1 how we are not seeing this, how ever i see some data being purged at random intervals\nIssue 2: when we run incremental repair using \"nodetool repair keyspace table -inc -pr\" each sstable is splitting up to multiple smaller SStables and increasing the total storage.This behavior is same running repairs on any node and any number of times\nThere are mutation drop's in the cluster\n\nTable:\n{code}\nCREATE TABLE TableA (\n    F1 text,\n    F2 int,\n    createts bigint,\n    stats blob,\n    PRIMARY KEY ((F1,F2), createts)\n) WITH CLUSTERING ORDER BY (createts DESC)\n    AND bloom_filter_fp_chance = 0.01\n    AND caching = '{\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"}'\n    AND comment = ''\n    AND compaction = {'min_threshold': '12', 'max_sstable_age_days': '1', 'base_time_seconds': '50', 'class': 'org.apache.cassandra.db.compaction.DateTieredCompactionStrategy'}\n    AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n    AND dclocal_read_repair_chance = 0.0\n    AND default_time_to_live = 93600\n    AND gc_grace_seconds = 3600\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 128\n    AND read_repair_chance = 0.0\n    AND speculative_retry = '99.0PERCENTILE';\n{code}\n\nThanks",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Incremental repairs not working as expected with DTCS"
   },
   {
      "_id": "12860295",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-08-28 15:24:34",
      "description": "The changes in CASSANDRA-9658 leave us in a position where a node on Windows will have to be restarted to clear out snapshots that cannot be deleted at request time due to sstables still being mapped, thus preventing deletions of hard links. A simple periodic task to categorize failed snapshot deletions and retry them would help prevent node disk utilization from growing unbounded by snapshots as compaction will eventually make these snapshot files deletable.\n\nGiven that hard links to files in NTFS don't take up any extra space on disk so long as the original file still exists, the only limitation for users from this approach will be the inability to 'move' a snapshot file to another drive share. They will be copyable, however, so it's a minor platform difference.\n\nThis goes directly against the goals of CASSANDRA-8271 and will likely be built on top of that code. Until such time as we get buffered performance in-line with memory-mapped, this is an interim necessity for production roll-outs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Periodically attempt to delete failed snapshot deletions on Windows"
   },
   {
      "_id": "12859554",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12337007",
            "id": "12337007",
            "name": "CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328216",
            "id": "12328216",
            "name": "Legacy/Distributed Metadata",
            "description": "Gossip, Schema, Auth"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-08-27 09:28:38",
      "description": "This test passes locally but reliably fails on Jenkins. It seems after we restart node4, it is unable to Gossip with other nodes:\n\n{code}\nINFO  [HANDSHAKE-/127.0.0.2] 2015-08-27 06:50:42,778 OutboundTcpConnection.java:494 - Handshaking version with /127.0.0.2\nINFO  [HANDSHAKE-/127.0.0.1] 2015-08-27 06:50:42,778 OutboundTcpConnection.java:494 - Handshaking version with /127.0.0.1\nINFO  [HANDSHAKE-/127.0.0.3] 2015-08-27 06:50:42,778 OutboundTcpConnection.java:494 - Handshaking version with /127.0.0.3\nERROR [main] 2015-08-27 06:51:13,785 CassandraDaemon.java:635 - Exception encountered during startup\njava.lang.RuntimeException: Unable to gossip with any seeds\n        at org.apache.cassandra.gms.Gossiper.doShadowRound(Gossiper.java:1342) ~[main/:na]\n        at org.apache.cassandra.service.StorageService.checkForEndpointCollision(StorageService.java:518) ~[main/:na]\n        at org.apache.cassandra.service.StorageService.prepareToJoin(StorageService.java:763) ~[main/:na]\n        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:687) ~[main/:na]\n        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:570) ~[main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:320) [main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:516) [main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:622) [main/:na]\nWARN  [StorageServiceShutdownHook] 2015-08-27 06:51:13,799 Gossiper.java:1453 - No local state or state is in silent shutdown, not announcing shutdown\n{code}\n\nIt seems both the addresses and port number of the seeds are correct so I don't think the problem is the Amazon private addresses but I might be wrong. \n\nIt's also worth noting that the first time the node starts up without problems. The problem only occurs during a restart.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "decommissioned_wiped_node_can_join_test fails on Jenkins"
   },
   {
      "_id": "12858744",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-25 20:30:48",
      "description": "Lists differ error. Looks to be \\r vs. \\r\\n related.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: cqlsh_tests\\cqlsh_tests.py:TestCqlsh.test_describe fails"
   },
   {
      "_id": "12858740",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-25 20:20:23",
      "description": "CI error:\n{noformat}\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 329, in run\n    testMethod()\n  File \"D:\\jenkins\\workspace\\cassandra-3.0_dtest_win32\\cassandra-dtest\\tools.py\", line 252, in wrapped\n    f(obj)\n  File \"D:\\jenkins\\workspace\\cassandra-3.0_dtest_win32\\cassandra-dtest\\offline_tools_test.py\", line 75, in sstablelevelreset_test\n    self.assertTrue(max(final_levels) == 0)\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 422, in assertTrue\n    raise self.failureException(msg)\n'False is not true\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\dtest-epkti6\\ndtest: DEBUG: \\ndtest: DEBUG: [1, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1]\\ndtest: DEBUG: [1, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1]\\n--------------------- >> end captured logging << ---------------------'\n{noformat}\n\nLocal failure:\n{noformat}\nFAIL: sstablelevelreset_test (offline_tools_test.TestOfflineTools)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"c:\\src\\cassandra-dtest\\tools.py\", line 252, in wrapped\n    f(obj)\n  File \"c:\\src\\cassandra-dtest\\offline_tools_test.py\", line 32, in sstablelevelreset_test\n    self.assertIn(\"ColumnFamily not found: keyspace1/standard1\", error)\nAssertionError: 'ColumnFamily not found: keyspace1/standard1' not found in 'Exception in thread \"main\" java.lang.NoClassDefFoundError: Could not initialize class org.apache.cassandra.config.DatabaseDescriptor\\r\\n\\tat org.apache.cassandra.utils.JVMStabilityInspector.inspectThrowable(JVMStabilityInspector.java:57)\\r\\n\\tat org.apache.cassandra.tools.SSTableLevelResetter.main(SSTableLevelResetter.java:104)\\r\\n'\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: c:\\temp\\dtest-3kgttu\n{noformat}\n\nFailure is consistent.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: offline_tools_test.py:TestOfflineTools.sstablelevelreset_test fails"
   },
   {
      "_id": "12857231",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332464",
            "id": "12332464",
            "name": "Feature/Materialized Views"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-19 14:56:43",
      "description": "Test times out and also throws errors, ending in:\n{noformat}\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"C:\\Python27\\lib\\multiprocessing\\forking.py\", line 380, in main\nOn 0; match: 0; extra: 0; missing: 0    prepare(preparation_data)\n  File \"C:\\Python27\\lib\\multiprocessing\\forking.py\", line 488, in prepare\n    assert main_name not in sys.modules, main_name\nAssertionError: __main__\n{noformat}\n\nReproducible locally, happening on CI as well",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: consistent_reads_after_write_test (materialized_views_test.TestMaterializedViewsConsistency) timing out"
   },
   {
      "_id": "12856956",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-08-18 16:48:45",
      "description": "{noformat}\njunit.framework.AssertionFailedError\n\tat org.apache.cassandra.db.compaction.LeveledCompactionStrategyTest.testGrouperLevels(LeveledCompactionStrategyTest.java:131)\n{noformat}\n\n[Test is flaky on Windows|http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_utest_win32/lastCompletedBuild/testReport/org.apache.cassandra.db.compaction/LeveledCompactionStrategyTest/testGrouperLevels/history/]\n\n[Test is consistent on linux|http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_utest/lastCompletedBuild/testReport/org.apache.cassandra.db.compaction/LeveledCompactionStrategyTest/testGrouperLevels/history/]\n\nDoesn't repro locally.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows utest 2.2: LeveledCompactionStrategyTest.testGrouperLevels flaky"
   },
   {
      "_id": "12856787",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-08-18 00:42:20",
      "description": "Transaction logs were introduced by CASSANDRA-7066 and are read during start-up. In case of file system errors, such as disk corruption, we currently log a panic error and leave the sstable files and transaction logs as they are; this is to avoid rolling back a transaction (i.e. deleting files) by mistake.\n\nWe should instead look at the {{disk_failure_policy}} and refuse to start unless the failure policy is {{ignore}}. \n\nWe should also consider stashing files that cannot be read during startup, either transaction logs or sstables, by moving them to a dedicated sub-folder. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Refuse to start and print txn log information in case of disk corruption"
   },
   {
      "_id": "12856742",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-08-17 20:59:01",
      "description": "ttl_test.py:TestTTL.update_column_ttl_with_default_ttl_test2\nttl_test.py:TestTTL.update_multiple_columns_ttl_test\nttl_test.py:TestTTL.update_single_column_ttl_test\n\nErrors locally are different than CI from yesterday. Yesterday on CI we have timeouts and general node hangs. Today on all 3 tests when run locally I see:\n{noformat}\nTraceback (most recent call last):\n  File \"c:\\src\\cassandra-dtest\\dtest.py\", line 532, in tearDown\n    raise AssertionError('Unexpected error in %s node log: %s' % (node.name, errors))\nAssertionError: Unexpected error in node1 node log: ['ERROR [main] 2015-08-17 16:53:43,120 NoSpamLogger.java:97 - This platform does not support atomic directory streams (SecureDirectoryStream); race conditions when loading sstable files could occurr']\n{noformat}\n\nThis traces back to the commit for CASSANDRA-7066 today by [~Stefania] and [~benedict].  Stefania - care to take this ticket and also look further into whether or not we're going to have issues with 7066 on Windows? That error message certainly *sounds* like it's not a good thing.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: ttl_test.py failures"
   },
   {
      "_id": "12856736",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-08-17 20:45:05",
      "description": "scrub_test.py:TestScrub.test_standalone_scrub\nscrub_test.py:TestScrub.test_standalone_scrub_essential_files_only\nscrub_test.py:TestScrubIndexes.test_standalone_scrub\n\nSomewhat different messages between CI and local, but consistent on env. Locally, I see:\n{noformat}\ndtest: DEBUG: ERROR 20:41:20 This platform does not support atomic directory streams (SecureDirectoryStream); race conditions when loading sstable files could occurr\n{noformat}\n\nConsistently fails, both on CI and locally.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: TestScrub and TestScrubIndexes failures"
   },
   {
      "_id": "12856729",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-17 20:21:35",
      "description": "repair_test.py:TestRepair.dc_repair_test\nrepair_test.py:TestRepair.local_dc_repair_test\nrepair_test.py:TestRepair.simple_parallel_repair_test\nrepair_test.py:TestRepair.simple_sequential_repair_test\n\nAll failing w/the following error:\n{noformat}\nFile \"D:\\Python27\\lib\\unittest\\case.py\", line 358, in run\n    self.tearDown()\n  File \"D:\\jenkins\\workspace\\cassandra-3.0_dtest_win32\\cassandra-dtest\\dtest.py\", line 532, in tearDown\n    raise AssertionError('Unexpected error in %s node log: %s' % (node.name, errors))\n\"Unexpected error in node3 node log: ['ERROR [STREAM-IN-/127.0.0.1] 2015-08-17 00:41:09,426 StreamSession.java:520 - [Stream #a69fc140-4478-11e5-a8ae-4f8718583077] Streaming error occurred java.io.IOException: An existing connection was forcibly closed by the remote host \\\\tat sun.nio.ch.SocketDispatcher.read0(Native Method) ~[na:1.8.0_45] \\\\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[na:1.8.0_45] \\\\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223) ~[na:1.8.0_45] \\\\tat sun.nio.ch.IOUtil.read(IOUtil.java:197) ~[na:1.8.0_45] \\\\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380) ~[na:1.8.0_45] \\\\tat org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:53) ~[main/:na] \\\\tat org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:261) ~[main/:na] \\\\tat java.lang.Thread.run(Thread.java:745) [na:1.8.0_45]']\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\dtest-3kmbjb\\ndtest: DEBUG: Starting cluster..\\ndtest: DEBUG: Inserting data...\\ndtest: DEBUG: Checking data on node3...\\ndtest: DEBUG: Checking data on node1...\\ndtest: DEBUG: Checking data on node2...\\ndtest: DEBUG: starting repair...\\ndtest: DEBUG: Repair time: 5.37800002098\\ndtest: DEBUG: removing ccm cluster test at: d:\\\\temp\\\\dtest-3kmbjb\\ndtest: DEBUG: clearing ssl stores from [d:\\\\temp\\\\dtest-3kmbjb] directory\\n--------------------- >> end captured logging << ---------------------\"\n{noformat}\n\nFailure history: [consistent|http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest_win32/17/testReport/repair_test/TestRepair/dc_repair_test/history/]\n\nEnv: ci and local",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: TestRepair multiple failures"
   },
   {
      "_id": "12856716",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-08-17 19:56:50",
      "description": "offline_tools_test.py:TestOfflineTools.sstablelevelreset_test\noffline_tools_test.py:TestOfflineTools.sstableofflinerelevel_test\n\nBoth tests fail with the following:\n{noformat}\nTraceback (most recent call last):\n  File \"c:\\src\\cassandra-dtest\\dtest.py\", line 532, in tearDown\n    raise AssertionError('Unexpected error in %s node log: %s' % (node.name, errors))\nAssertionError: Unexpected error in node1 node log: ['ERROR [main] 2015-08-17 15:55:05,060 NoSpamLogger.java:97 - This platform does not support atomic directory streams (SecureDirectoryStream); race conditions when loading sstable files could occurr']\n{noformat}\n\nFailure history: [consistent|http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest_win32/17/testReport/junit/jmx_test/TestJMX/netstats_test/history/]\n\nEnv: ci and local",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: TestOfflineTools failures"
   },
   {
      "_id": "12856697",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328217",
            "id": "12328217",
            "name": "Legacy/Streaming and Messaging",
            "description": "MessagingService, Bootstrap, Repair, Bulk Loading"
         }
      ],
      "created": "2015-08-17 18:42:09",
      "description": "{noformat}\nFile \"D:\\Python27\\lib\\unittest\\case.py\", line 329, in run\n    testMethod()\n  File \"D:\\jenkins\\workspace\\cassandra-3.0_dtest_win32\\cassandra-dtest\\incremental_repair_test.py\", line 165, in sstable_repairedset_test\n    self.assertGreaterEqual(len(uniquematches), 2)\n  File \"D:\\Python27\\lib\\unittest\\case.py\", line 948, in assertGreaterEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"D:\\Python27\\lib\\unittest\\case.py\", line 410, in fail\n    raise self.failureException(msg)\n'0 not greater than or equal to 2\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\dtest-pq7lpx\\ndtest: DEBUG: []\\n--------------------- >> end captured logging << ---------------------'\n{noformat}\n\nFailure history: [consistent|http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest_win32/17/testReport/junit/hintedhandoff_test/TestHintedHandoffConfig/hintedhandoff_dc_disabled_test/history/]\n\nEnv: both CI and local",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: incremental_repair_test.py:TestIncRepair.sstable_repairedset_test fails"
   },
   {
      "_id": "12856691",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-17 18:25:31",
      "description": "hintedhandoff_test.py:TestHintedHandoffConfig.hintedhandoff_dc_disabled_test\nhintedhandoff_test.py:TestHintedHandoffConfig.hintedhandoff_dc_reenabled_test\nhintedhandoff_test.py:TestHintedHandoffConfig.hintedhandoff_disabled_test\nhintedhandoff_test.py:TestHintedHandoffConfig.hintedhandoff_enabled_test\nhintedhandoff_test.py:TestHintedHandoffConfig.nodetool_test\n\nAll are failing with some variant of the following:\n{noformat}\nFile \"D:\\Python27\\lib\\unittest\\case.py\", line 329, in run\n    testMethod()\n  File \"D:\\jenkins\\workspace\\cassandra-3.0_dtest_win32\\cassandra-dtest\\hintedhandoff_test.py\", line 130, in hintedhandoff_dc_disabled_test\n    self.assertEqual('Hinted handoff is running\\nData center dc1 is disabled', res.rstrip())\n  File \"D:\\Python27\\lib\\unittest\\case.py\", line 513, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"D:\\Python27\\lib\\unittest\\case.py\", line 506, in _baseAssertEqual\n    raise self.failureException(msg)\n\"'Hinted handoff is running\\\\nData center dc1 is disabled' != 'Starting NodeTool\\\\r\\\\nHinted handoff is running\\\\r\\\\nData center dc1 is disabled'\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\dtest-pddrcf\\n--------------------- >> end captured logging << ---------------------\"\n{noformat}\n\nFailure history: consistent for all jobs\n\nEnv: Both ci and local",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 3.0: HintedHandoff tests failing"
   },
   {
      "_id": "12856683",
      "assignee": "krummas",
      "components": [],
      "created": "2015-08-17 18:06:51",
      "description": "Continue discussion from CASSANDRA-9882.\n\nCompactionStrategyManager(WrappingCompactionStrategy for <3.0) tracks SSTable changes mainly for separating repaired / unrepaired SSTables (+ LCS manages level).\n\nThis is blocking operation, and can lead to block of flush etc. when determining next background task takes longer.\n\nExplore the way to mitigate this concurrency issue.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve concurrency in CompactionStrategyManager"
   },
   {
      "_id": "12856659",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-17 17:08:39",
      "description": "Parent ticket to track subtasks for dtest failures on Windows on the 3.0 branch",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix dtests on 3.0 branch on Windows"
   },
   {
      "_id": "12856209",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-14 16:34:53",
      "description": "Error text:\n{noformat}\nconcurrent rebuild should not be allowed\nFile \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 329, in run\n    testMethod()\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\rebuild_test.py\", line 87, in simple_rebuild_test\n    self.fail(\"concurrent rebuild should not be allowed\")\n  File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 410, in fail\n    raise self.failureException(msg)\n'concurrent rebuild should not be allowed\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\dtest-rltloj\\n--------------------- >> end captured logging << ---------------------'\n{noformat}\n\n[Failure history|http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/61/testReport/rebuild_test/TestRebuild/simple_rebuild_test/history/] (Consistent)\n\nEnv: Both CI and local",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 2.2: rebuild_test.py:TestRebuild.simple_rebuild_test"
   },
   {
      "_id": "12856207",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-14 16:31:59",
      "description": "Error text: \n{noformat}\nDoctest failed! Captured output:\n**********************************************************************\nLine 25, in pkey_requirement_test\nFailed example:\n    cqlsh_err_print('''INSERT INTO primitive_type_test JSON '{\"col1\": \"bar\"}' ''')\nExpected:\n    <stdin>:2:InvalidRequest: code=2200 [Invalid query] message=\"Invalid null value in condition for column key1\"\n    <BLANKLINE>\nGot:\n    <stdin>:2:InvalidRequest: code=2200 [Invalid query] message=\"Invalid null value in condition for column key1\"\n    <BLANKLINE>\n\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: d:\\temp\\dtest-fgbxha\n--------------------- >> end captured logging << ---------------------\n{noformat}\nand:\n{noformat}\nFile \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 329, in run\n    testMethod()\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\json_test.py\", line 1252, in pkey_requirement_test\n    run_func_docstring(tester=self, test_func=self.pkey_requirement_test)\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\json_test.py\", line 181, in run_func_docstring\n    raise RuntimeError(\"Doctest failed! Captured output:\\n{}\".format(test_output_capturer.content))\n'Doctest failed! Captured output:\\n**********************************************************************\\nLine 25, in pkey_requirement_test\\nFailed example:\\n    cqlsh_err_print(\\'\\'\\'INSERT INTO primitive_type_test JSON \\'{\"col1\": \"bar\"}\\' \\'\\'\\')\\nExpected:\\n    <stdin>:2:InvalidRequest: code=2200 [Invalid query] message=\"Invalid null value in condition for column key1\"\\n    <BLANKLINE>\\nGot:\\n    <stdin>:2:InvalidRequest: code=2200 [Invalid query] message=\"Invalid null value in condition for column key1\"\\r\\n    <BLANKLINE>\\n\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\dtest-fgbxha\\n--------------------- >> end captured logging << ---------------------'\n{noformat}\n\n[Failure history|http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/61/testReport/json_test/JsonFullRowInsertSelect/pkey_requirement_test/history/] (Consistent, introduced in build 58)\n\nEnv: Both CI and Local.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 2.2: json_test.py:JsonFullRowInsertSelect.pkey_requirement_test"
   },
   {
      "_id": "12856203",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-08-14 16:25:04",
      "description": "Error text:\n{noformat}\n File \"C:\\tools\\python2\\lib\\unittest\\case.py\", line 358, in run\n    self.tearDown()\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\dtest.py\", line 513, in tearDown\n    self._cleanup_cluster()\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\dtest.py\", line 212, in _cleanup_cluster\n    self.cluster.remove()\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\ccm\\ccmlib\\cluster.py\", line 223, in remove\n    common.rmdirs(self.get_path())\n  File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\ccm\\ccmlib\\common.py\", line 156, in rmdirs\n    shutil.rmtree(u\"\\\\\\\\?\\\\\" + path)\n  File \"C:\\tools\\python2\\lib\\shutil.py\", line 247, in rmtree\n    rmtree(fullname, ignore_errors, onerror)\n  File \"C:\\tools\\python2\\lib\\shutil.py\", line 247, in rmtree\n    rmtree(fullname, ignore_errors, onerror)\n  File \"C:\\tools\\python2\\lib\\shutil.py\", line 252, in rmtree\n    onerror(os.remove, fullname, sys.exc_info())\n  File \"C:\\tools\\python2\\lib\\shutil.py\", line 250, in rmtree\n    os.remove(fullname)\n\"[Error 5] Access is denied: u'\\\\\\\\\\\\\\\\?\\\\\\\\d:\\\\\\\\temp\\\\\\\\dtest-zsl_4c\\\\\\\\test\\\\\\\\node1\\\\\\\\commitlogs\\\\\\\\CommitLog-5-1439489973883.log'\\n-------------------- >> begin captured logging << --------------------\\ndtest: DEBUG: cluster ccm directory: d:\\\\temp\\\\dtest-zsl_4c\\ndtest: DEBUG: Run stress to insert data\\ndtest: DEBUG: Compact sstables.\\ndtest: DEBUG: Number of sstables after compaction: 1\\ndtest: DEBUG: Run sstablesplit\\ndtest: DEBUG: Original sstable and sizes before split: [('d:\\\\\\\\temp\\\\\\\\dtest-zsl_4c\\\\\\\\test\\\\\\\\node1\\\\\\\\data\\\\\\\\keyspace1\\\\\\\\standard1-e596155041e611e5b337390aedd65e00\\\\\\\\la-25-big-Data.db', 281000000L)]\\ndtest: DEBUG: Number of sstables after split: 27. expected 26.0\\ndtest: DEBUG: Compact sstables.\\ndtest: DEBUG: Number of sstables after compaction: 1\\ndtest: DEBUG: Run sstablesplit\\ndtest: DEBUG: Original sstable and sizes before split: [('d:\\\\\\\\temp\\\\\\\\dtest-zsl_4c\\\\\\\\test\\\\\\\\node1\\\\\\\\data\\\\\\\\keyspace1\\\\\\\\standard1-e596155041e611e5b337390aedd65e00\\\\\\\\la-54-big-Data.db', 281000000L)]\\ndtest: DEBUG: Number of sstables after split: 27. expected 26.0\\ndtest: DEBUG: Run stress to ensure data is readable\\ndtest: DEBUG: removing ccm cluster test at: d:\\\\temp\\\\dtest-zsl_4c\\n--------------------- >> end captured logging << -----\n{noformat}\n\n[Failure History|http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/61/testReport/sstablesplit_test/TestSSTableSplit/split_test/history/]\n\nEnv: CI only. Passes locally.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest 2.2: sstablesplit_test.py:TestSSTableSplit.split_test"
   },
   {
      "_id": "12856188",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-08-14 15:29:04",
      "description": "Within cqlsh, the HELP SELECT_EXPR states that COUNT is the only function supported by CQL.\n\nIt is missing a description of the SUM, AVG, MIN, and MAX built in functions.\n\nIt should probably also mention that user defined functions can be invoked via SELECT.\n\nThe outdated text is in pylib/cqlshlib/helptopics.py under def help_select_expr",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh HELP SELECT_EXPR gives outdated incorrect information"
   },
   {
      "_id": "12855904",
      "assignee": "philipthompson",
      "components": [],
      "created": "2015-08-13 16:31:34",
      "description": "In order for us to begin running flake8 against cqlsh.py in CI, it would be helpful if it were already PEP8 complaint, with the exception of using 120 character lines.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Bring cqlsh into PEP8 compliance"
   },
   {
      "_id": "12853943",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-08-10 19:30:49",
      "description": "If a table with the name 'map' is created, the describe command will return \"Improper describe command\", indicating a parse error.\n\nI believe this is because 'map' is a keyword when referring to a type, but cqlshlib's parser identifies it as a keyword in the context of a describe command, even though it is not. This same mismatch likely applies to other CQL keywords as well.\n\nThe cqlshlib and C* CQL parsers should treat keywords the same where possible.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Parse Error on CQLSH describe when describing a table with a non-reserved keyword name"
   },
   {
      "_id": "12853915",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-08-10 18:17:06",
      "description": "{noformat}\n    [junit] Testcase: testScrubDataDirectories(org.apache.cassandra.db.ColumnFamilyStoreTest):  Caused an ERROR\n    [junit] java.nio.file.AccessDeniedException: build\\test\\cassandra\\data;0\\ColumnFamilyStoreTest1\\Standard1-a0d5fa503f8b11e58dec831ef068609c\\ma-7-big-Index.db\n    [junit] FSWriteError in build\\test\\cassandra\\data;0\\ColumnFamilyStoreTest1\\Standard1-a0d5fa503f8b11e58dec831ef068609c\\ma-7-big-Index.db\n    [junit]     at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:135)\n    [junit]     at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:152)\n    [junit]     at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:147)\n    [junit]     at org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:556)\n    [junit]     at org.apache.cassandra.db.ColumnFamilyStoreTest.testScrubDataDirectories(ColumnFamilyStoreTest.java:533)\n    [junit] Caused by: java.nio.file.AccessDeniedException: build\\test\\cassandra\\data;0\\ColumnFamilyStoreTest1\\Standard1-a0d5fa503f8b11e58dec831ef068609c\\ma-7-big-Index.db\n    [junit]     at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)\n    [junit]     at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)\n    [junit]     at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)\n    [junit]     at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)\n    [junit]     at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)\n    [junit]     at java.nio.file.Files.delete(Files.java:1126)\n    [junit]     at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:129)\n{noformat}\n\nTest has never passed on Windows ([history|http://cassci.datastax.com/view/trunk/job/trunk_utest_win32/lastCompletedBuild/testReport/org.apache.cassandra.db/ColumnFamilyStoreTest/testScrubDataDirectories/history/]).\n\n[~stefania_alborghetti]: Looks like this is your test. Care to take this?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows utest 3.0: ColumnFamilyStoreTest.testScrubDataDirectories failing"
   },
   {
      "_id": "12853912",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-08-10 18:04:37",
      "description": "{noformat}\n    [junit] Testcase: testUntrack(org.apache.cassandra.db.lifecycle.TransactionLogsTest):       FAILED\n    [junit] build\\test\\cassandra\\data;0\\TransactionLogsTest\\mockcf4-6742d2103f8911e58737831ef068609c\\ma-1-big-Data.db\n    [junit] junit.framework.AssertionFailedError: build\\test\\cassandra\\data;0\\TransactionLogsTest\\mockcf4-6742d2103f8911e58737831ef068609c\\ma-1-big-Data.db\n    [junit]     at org.apache.cassandra.db.lifecycle.TransactionLogsTest.assertFiles(TransactionLogsTest.java:575)\n    [junit]     at org.apache.cassandra.db.lifecycle.TransactionLogsTest.testUntrack(TransactionLogsTest.java:215)\n    [junit]\n    [junit]\n    [junit] Testcase: testAbortOnlyNew(org.apache.cassandra.db.lifecycle.TransactionLogsTest):  FAILED\n    [junit] build\\test\\cassandra\\data;0\\TransactionLogsTest\\mockcf5-67456a203f8911e58737831ef068609c\\ma-0-big-Data.db\n    [junit] junit.framework.AssertionFailedError: build\\test\\cassandra\\data;0\\TransactionLogsTest\\mockcf5-67456a203f8911e58737831ef068609c\\ma-0-big-Data.db\n    [junit]     at org.apache.cassandra.db.lifecycle.TransactionLogsTest.assertFiles(TransactionLogsTest.java:575)\n    [junit]     at org.apache.cassandra.db.lifecycle.TransactionLogsTest.testAbortOnlyNew(TransactionLogsTest.java:312)\n    [junit]\n    [junit]\n    [junit] Testcase: testNoPrepare(org.apache.cassandra.db.lifecycle.TransactionLogsTest):     FAILED\n    [junit] build\\test\\cassandra\\data;0\\TransactionLogsTest\\mockcf13-675681203f8911e58737831ef068609c\\ma-1-big-Data.db\n    [junit] junit.framework.AssertionFailedError: build\\test\\cassandra\\data;0\\TransactionLogsTest\\mockcf13-675681203f8911e58737831ef068609c\\ma-1-big-Data.db\n    [junit]     at org.apache.cassandra.db.lifecycle.TransactionLogsTest.assertFiles(TransactionLogsTest.java:575)\n    [junit]     at org.apache.cassandra.db.lifecycle.TransactionLogsTest.access$200(TransactionLogsTest.java:56)\n    [junit]     at org.apache.cassandra.db.lifecycle.TransactionLogsTest$TxnTest$Transaction.assertAborted(TransactionLogsTest.java:143)\n    [junit]     at org.apache.cassandra.db.lifecycle.TransactionLogsTest$TxnTest.assertAborted(TransactionLogsTest.java:191)\n    [junit]     at org.apache.cassandra.utils.concurrent.AbstractTransactionalTest.testNoPrepare(AbstractTransactionalTest.java:40)\n{noformat}\n\ntaking the testPrepare case as an example: looks like it never passed on Windows ([history|http://cassci.datastax.com/view/trunk/job/trunk_utest_win32/lastCompletedBuild/testReport/org.apache.cassandra.db.lifecycle/TransactionLogsTest/testPrepare/history/])\n\n[~stefania_alborghetti]: annotate points to you on these tests. Care to take a look at this?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows utest 3.0: TransactionLogsTest failure"
   },
   {
      "_id": "12853898",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-08-10 17:27:28",
      "description": "21 failures on Windows, 10 on linux as of 2015-08-10. Ticket to track subtasks.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows 3.0 utest parity"
   },
   {
      "_id": "12851491",
      "assignee": "philipthompson",
      "components": [],
      "created": "2015-08-04 20:14:06",
      "description": "After fixing the jolokia agent problem, we can now see that these tests are genuinely failing. Every test follows the same basic pattern:\n\n{code}\n\n    def force_repair_async_1_test(self, ):\n        \"\"\"\n        test forceRepairAsync(String keyspace, boolean isSequential,\n                              Collection<String> dataCenters,\n                              Collection<String> hosts,\n                              boolean primaryRange, boolean fullRepair, String... columnFamilies)\n        \"\"\"\n        opt = self._deprecated_repair_jmx(\"forceRepairAsync(java.lang.String,boolean,java.util.Collection,java.util.Collection,boolean,boolean,[Ljava.lang.String;)\",\n                                          ['ks', True, [], [], False, False, [\"cf\"]])\n        self.assertEqual(opt[\"parallelism\"], \"sequential\", opt)\n        self.assertEqual(opt[\"primary_range\"], \"false\", opt)\n        self.assertEqual(opt[\"incremental\"], \"true\", opt)\n        self.assertEqual(opt[\"job_threads\"], \"1\", opt)\n        self.assertEqual(opt[\"data_centers\"], \"[]\", opt)\n        self.assertEqual(opt[\"hosts\"], \"[]\", opt)\n        self.assertEqual(opt[\"column_families\"], \"[cf]\", opt)\n{code}\nIn each test, the response for {{opt[\"parallelism\"]}} is incorrect. [~yukim] wrote these tests, and may be able to shed light on what's going on.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Deprecated Repair tests fail on windows"
   },
   {
      "_id": "12851126",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332464",
            "id": "12332464",
            "name": "Feature/Materialized Views"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-08-03 15:22:22",
      "description": "cqlsh doesn't currently produce describe output that can be used to recreate a MV. Needs to add a new {{DESCRIBE MATERIALIZED VIEW}} command, and also add to {{DESCRIBE KEYSPACE}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting",
         "materializedviews"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh should have DESCRIBE MATERIALIZED VIEW"
   },
   {
      "_id": "12849577",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-07-28 10:31:43",
      "description": "There seems to be a potential race in the cleanup of transaction log files, introduced in CASSANDRA-7066\nIt's pretty hard to trigger on trunk, but it's possible to hit it via {{o.a.c.db.SecondaryIndexTest#testCreateIndex}} \n\nThat test creates an index, then removes it to check that the removal is correctly recorded, then adds the index again to assert that it gets rebuilt from the existing data. \nThe removal causes the SSTables of the index CFS to be dropped, which is a transactional operation and so writes a transaction log. When the drop is completed and the last reference to an SSTable is released, the cleanup of the transaction log is scheduled on the periodic tasks executor. The issue is that re-creating the index re-creates the index CFS. When this happens, it's possible for the cleanup of the txn log to have not yet happened. If so, the initialization of the CFS attempts to read the log to identify any orphaned temporary files. The cleanup can happen between the finding the log file and reading it's contents, which results in a {{NoSuchFileException}}\n\n{noformat}\n[junit] java.nio.file.NoSuchFileException: build/test/cassandra/data:1/SecondaryIndexTest1/CompositeIndexToBeAdded-d0885f60323211e5a5e8ad83a3dc3e9c/.birthdate_index/transactions/unknowncompactiontype_d4b69fc0-3232-11e5-a5e8-ad83a3dc3e9c_old.log\n[junit] java.lang.RuntimeException: java.nio.file.NoSuchFileException: build/test/cassandra/data:1/SecondaryIndexTest1/CompositeIndexToBeAdded-d0885f60323211e5a5e8ad83a3dc3e9c/.birthdate_index/transactions/unknowncompactiontype_d4b69fc0-3232-11e5-a5e8-ad83a3dc3e9c_old.log\n[junit]     at org.apache.cassandra.io.util.FileUtils.readLines(FileUtils.java:620)\n[junit]     at org.apache.cassandra.db.lifecycle.TransactionLogs$TransactionFile.getTrackedFiles(TransactionLogs.java:190)\n[junit]     at org.apache.cassandra.db.lifecycle.TransactionLogs$TransactionData.getTemporaryFiles(TransactionLogs.java:338)\n[junit]     at org.apache.cassandra.db.lifecycle.TransactionLogs.getTemporaryFiles(TransactionLogs.java:739)\n[junit]     at org.apache.cassandra.db.lifecycle.LifecycleTransaction.getTemporaryFiles(LifecycleTransaction.java:541)\n[junit]     at org.apache.cassandra.db.Directories$SSTableLister.getFilter(Directories.java:652)\n[junit]     at org.apache.cassandra.db.Directories$SSTableLister.filter(Directories.java:641)\n[junit]     at org.apache.cassandra.db.Directories$SSTableLister.list(Directories.java:606)\n[junit]     at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:351)\n[junit]     at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:313)\n[junit]     at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:511)\n[junit]     at org.apache.cassandra.index.internal.CassandraIndexer.addIndexedColumn(CassandraIndexer.java:115)\n[junit]     at org.apache.cassandra.index.SecondaryIndexManager.addIndexedColumn(SecondaryIndexManager.java:265)\n[junit]     at org.apache.cassandra.db.SecondaryIndexTest.testIndexCreate(SecondaryIndexTest.java:467)\n[junit] Caused by: java.nio.file.NoSuchFileException: build/test/cassandra/data:1/SecondaryIndexTest1/CompositeIndexToBeAdded-d0885f60323211e5a5e8ad83a3dc3e9c/.birthdate_index/transactions/unknowncompactiontype_d4b69fc0-3232-11e5-a5e8-ad83a3dc3e9c_old.log\n[junit]     at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n[junit]     at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n[junit]     at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n[junit]     at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n[junit]     at java.nio.file.Files.newByteChannel(Files.java:361)\n[junit]     at java.nio.file.Files.newByteChannel(Files.java:407)\n[junit]     at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)\n[junit]     at java.nio.file.Files.newInputStream(Files.java:152)\n[junit]     at java.nio.file.Files.newBufferedReader(Files.java:2784)\n[junit]     at java.nio.file.Files.readAllLines(Files.java:3202)\n[junit]     at org.apache.cassandra.io.util.FileUtils.readLines(FileUtils.java:616)\n[junit] \n[junit] \n[junit] Test org.apache.cassandra.db.SecondaryIndexTest FAILED\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "benedict-to-commit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Potential race caused by async cleanup of transaction log files"
   },
   {
      "_id": "12849406",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-07-27 19:31:08",
      "description": "Last run shows failure on all the cqlsh copy dtests with messages similar to the following:\n{noformat}\n05:39:07 ======================================================================\n05:39:07 ERROR: test_source_copy_round_trip (cqlsh_copy_tests.CqlshCopyTest)\n05:39:07 ----------------------------------------------------------------------\n05:39:07 Traceback (most recent call last):\n05:39:07   File \"D:\\jenkins\\workspace\\cassandra-2.2_dtest_win32\\cassandra-dtest\\cqlsh_tests\\cqlsh_copy_tests.py\", line 789, in test_source_copy_round_trip\n05:39:07     with open(commandfile.name, 'w') as commands:\n05:39:07 IOError: [Errno 13] Permission denied: 'd:\\\\temp\\\\tmpawtlxf'\n05:39:07 -------------------- >> begin captured logging << --------------------\n05:39:07 dtest: DEBUG: removing ccm cluster test at: d:\\temp\\dtest-9dklfv\n05:39:07 dtest: DEBUG: cluster ccm directory: d:\\temp\\dtest-98gttb\n05:39:07 dtest: DEBUG: Exporting to csv file: d:\\temp\\tmppok0qa\n05:39:07 --------------------- >> end captured logging << ---------------------\n{noformat}\n\nJake did quite a bit of work around this on CASSANDRA-9795 but I'm not certain this is a related issue so opening as a new ticket and linking.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest: cqlsh_tests\\cqlsh_copy_tests.py failing with Permission denied"
   },
   {
      "_id": "12849073",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-07-25 07:15:54",
      "description": "since CASSANDRA-6851 we group sstables before running anticompaction on them to avoid increasing sstable count.\n\nWe should not do this for DTCS as it can mix new and old data.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Anticompaction can mix old and new data with DTCS in 2.2+"
   },
   {
      "_id": "12848945",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-07-24 17:28:52",
      "description": "System call is linux-specific:\n\n{noformat}\nERROR [CommitLogArchiver:1] 2015-07-24 13:26:39,622 CassandraDaemon.java:181 - Exception in thread Thread[CommitLogArchiver:1,5,main]\njava.lang.RuntimeException: java.io.IOException: Exception while executing the command: cp c:\\temp\\dtest-phi4wd\\test\\node1\\commitlogs\\CommitLog-5-1437758795056.log c:  emp     mpkzsvkb/CommitLog-5-1437758795056.log, command error Code: 1, command output: cp: accessing `c:\\temp\\tmpkzsvkb/CommitLog-5-1437758795056.log': Invalid argument\n\n        at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) ~[main/:na]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_45]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_45]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45]\n        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45]\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest: snapshot_test.py failures"
   },
   {
      "_id": "12848660",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-07-23 19:03:44",
      "description": "MemtableFlushWriter tasks can get blocked by Compaction getNextBackgroundTask.  This is in a wonky cluster with 200k sstables in the CF, but seems bad for flushing to be blocked by getNextBackgroundTask when we are trying to make these new \"smart\" strategies that may take some time to calculate what to do.\n\n{noformat}\n\"MemtableFlushWriter:21\" daemon prio=10 tid=0x00007ff7ad965000 nid=0x6693 waiting for monitor entry [0x00007ff78a667000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat org.apache.cassandra.db.compaction.WrappingCompactionStrategy.handleNotification(WrappingCompactionStrategy.java:237)\n\t- waiting to lock <0x00000006fcdbbf60> (a org.apache.cassandra.db.compaction.WrappingCompactionStrategy)\n\tat org.apache.cassandra.db.DataTracker.notifyAdded(DataTracker.java:518)\n\tat org.apache.cassandra.db.DataTracker.replaceFlushed(DataTracker.java:178)\n\tat org.apache.cassandra.db.compaction.AbstractCompactionStrategy.replaceFlushed(AbstractCompactionStrategy.java:234)\n\tat org.apache.cassandra.db.ColumnFamilyStore.replaceFlushed(ColumnFamilyStore.java:1475)\n\tat org.apache.cassandra.db.Memtable$FlushRunnable.runMayThrow(Memtable.java:336)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n\tat com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)\n\tat org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1127)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\n   Locked ownable synchronizers:\n\t- <0x0000000743b3ac38> (a java.util.concurrent.ThreadPoolExecutor$Worker)\n\n\"MemtableFlushWriter:19\" daemon prio=10 tid=0x00007ff7ac57a000 nid=0x649b waiting for monitor entry [0x00007ff78b8ee000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat org.apache.cassandra.db.compaction.WrappingCompactionStrategy.handleNotification(WrappingCompactionStrategy.java:237)\n\t- waiting to lock <0x00000006fcdbbf60> (a org.apache.cassandra.db.compaction.WrappingCompactionStrategy)\n\tat org.apache.cassandra.db.DataTracker.notifyAdded(DataTracker.java:518)\n\tat org.apache.cassandra.db.DataTracker.replaceFlushed(DataTracker.java:178)\n\tat org.apache.cassandra.db.compaction.AbstractCompactionStrategy.replaceFlushed(AbstractCompactionStrategy.java:234)\n\tat org.apache.cassandra.db.ColumnFamilyStore.replaceFlushed(ColumnFamilyStore.java:1475)\n\tat org.apache.cassandra.db.Memtable$FlushRunnable.runMayThrow(Memtable.java:336)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n\tat com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)\n\tat org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1127)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\"CompactionExecutor:14\" daemon prio=10 tid=0x00007ff7ad359800 nid=0x4d59 runnable [0x00007fecce3ea000]\n   java.lang.Thread.State: RUNNABLE\n\tat org.apache.cassandra.io.sstable.SSTableReader.equals(SSTableReader.java:628)\n\tat com.google.common.collect.ImmutableSet.construct(ImmutableSet.java:206)\n\tat com.google.common.collect.ImmutableSet.construct(ImmutableSet.java:220)\n\tat com.google.common.collect.ImmutableSet.access$000(ImmutableSet.java:74)\n\tat com.google.common.collect.ImmutableSet$Builder.build(ImmutableSet.java:531)\n\tat com.google.common.collect.Sets$1.immutableCopy(Sets.java:606)\n\tat org.apache.cassandra.db.ColumnFamilyStore.getOverlappingSSTables(ColumnFamilyStore.java:1352)\n\tat org.apache.cassandra.db.compaction.DateTieredCompactionStrategy.getNextBackgroundSSTables(DateTieredCompactionStrategy.java:88)\n\tat org.apache.cassandra.db.compaction.DateTieredCompactionStrategy.getNextBackgroundTask(DateTieredCompactionStrategy.java:65)\n\t- locked <0x00000006fcdbbf00> (a org.apache.cassandra.db.compaction.DateTieredCompactionStrategy)\n\tat org.apache.cassandra.db.compaction.WrappingCompactionStrategy.getNextBackgroundTask(WrappingCompactionStrategy.java:72)\n\t- locked <0x00000006fcdbbf60> (a org.apache.cassandra.db.compaction.WrappingCompactionStrategy)\n\tat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:238)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "DTCS (maybe other strategies) can block flushing when there are lots of sstables"
   },
   {
      "_id": "12848381",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-07-22 21:08:19",
      "description": "{noformat}\n======================================================================\nFAIL: ignore_failure_policy_test (commitlog_test.TestCommitLog)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"C:\\src\\cassandra-dtest\\commitlog_test.py\", line 251, in ignore_failure_policy_test\n    \"\"\")\nAssertionError: (<class 'cassandra.OperationTimedOut'>, <class 'cassandra.WriteTimeout'>) not raised\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: c:\\temp\\dtest-fzrrz1\n--------------------- >> end captured logging << ---------------------\n\n----------------------------------------------------------------------\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest: fix commitlog_test errors"
   },
   {
      "_id": "12846950",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-07-22 17:24:53",
      "description": "Did some juggling to get the state cleared/prepped when I wrote the test but apparently it's intermittently failing with the following:\n\n{noformat}\njunit.framework.AssertionFailedError\n\tat org.apache.cassandra.db.WindowsFailedSnapshotTracker.handleFailedSnapshot(WindowsFailedSnapshotTracker.java:104)\n\tat org.apache.cassandra.db.Directories.clearSnapshot(Directories.java:741)\n\tat org.apache.cassandra.db.ColumnFamilyStore.clearEphemeralSnapshots(ColumnFamilyStore.java:2343)\n\tat org.apache.cassandra.db.ColumnFamilyStoreTest.testClearEphemeralSnapshots(ColumnFamilyStoreTest.java:1555)\n{noformat}\n\nI assume it's something trivial (having not yet looked into it at all).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "windows - failed testClearEphemeralSnapshots"
   },
   {
      "_id": "12846943",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2015-07-22 16:45:28",
      "description": "Looks like there's a failure during the abort path on SSTableWriter w/access violation. This didn't show up in CI since there was apparently a missing library on there and auth_test.py was being skipped entirely.\n\n{noformat}\nINFO  [MigrationStage:1] 2015-07-22 12:33:33,728 ColumnFamilyStore.java:328 - Initializing system_auth.permissions\nERROR [CompactionExecutor:2] 2015-07-22 12:33:33,745 SSTable.java:261 - Missing component: c:\\temp\\dtest-n95zao\\test\\node1\\data\\system\\schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697\\system-schema_columnfamilies-tmp-ka-5-Digest.sha1\nERROR [CompactionExecutor:2] 2015-07-22 12:33:33,745 SSTable.java:261 - Missing component: c:\\temp\\dtest-n95zao\\test\\node1\\data\\system\\schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697\\system-schema_columnfamilies-tmp-ka-5-CompressionInfo.dbERROR [CompactionExecutor:2] 2015-07-22 12:33:33,745 SSTable.java:261 - Missing component: c:\\temp\\dtest-n95zao\\test\\node1\\data\\system\\schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697\\system-schema_columnfamilies-tmp-ka-5-Summary.db\nERROR [CompactionExecutor:2] 2015-07-22 12:33:33,756 SSTableWriter.java:367 - Failed deleting temp components for c:\\temp\\dtest-n95zao\\test\\node1\\data\\system\\schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697\\system-schema_columnfamilies-tmp-ka-5\norg.apache.cassandra.io.FSWriteError: java.nio.file.FileSystemException: c:\\temp\\dtest-n95zao\\test\\node1\\data\\system\\schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697\\system-schema_columnfamilies-tmp-ka-5-Data.db: The process cannot access the file because it is being used by another process.\n\n        at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:135) ~[main/:na]\n        at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:121) ~[main/:na]\n        at org.apache.cassandra.io.sstable.SSTable.delete(SSTable.java:108) ~[main/:na]\n        at org.apache.cassandra.io.sstable.SSTableWriter.abort(SSTableWriter.java:363) ~[main/:na]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.abort(SSTableRewriter.java:236) [main/:na]\n        at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:220) [main/:na]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [main/:na]\n        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:73) [main/:na]\n        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59) [main/:na]\n        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:236) [main/:na]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_45]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_45]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_45]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45]\n        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45]\nCaused by: java.nio.file.FileSystemException: c:\\temp\\dtest-n95zao\\test\\node1\\data\\system\\schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697\\system-schema_columnfamilies-tmp-ka-5-Data.db: The process cannot access the file because it is being used by another process.\n\n        at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86) ~[na:1.8.0_45]\n        at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97) ~[na:1.8.0_45]\n        at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102) ~[na:1.8.0_45]\n        at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269) ~[na:1.8.0_45]\n        at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103) ~[na:1.8.0_45]\n        at java.nio.file.Files.delete(Files.java:1126) ~[na:1.8.0_45]\n        at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:131) ~[main/:na]\n        ... 14 common frames omitted\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows dtest: auth_test failure"
   },
   {
      "_id": "12846047",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-07-18 02:11:07",
      "description": "{noformat}\npig-test:\n    [mkdir] Created dir: /var/lib/jenkins/jobs/trunk_pigtest/workspace/build/test/cassandra\n    [mkdir] Created dir: /var/lib/jenkins/jobs/trunk_pigtest/workspace/build/test/output\n    [junit] WARNING: multiple versions of ant detected in path for junit \n    [junit]          jar:file:/usr/share/ant/lib/ant.jar!/org/apache/tools/ant/Project.class\n    [junit]      and jar:file:/var/lib/jenkins/jobs/trunk_pigtest/workspace/build/lib/jars/ant-1.8.3.jar!/org/apache/tools/ant/Project.class\n    [junit] Testsuite: org.apache.cassandra.pig.CqlRecordReaderTest\n    [junit] Testsuite: org.apache.cassandra.pig.CqlRecordReaderTest Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.799 sec\n    [junit] \n    [junit] Testsuite: org.apache.cassandra.pig.CqlTableDataTypeTest\n    [junit] Testsuite: org.apache.cassandra.pig.CqlTableDataTypeTest Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.627 sec\n    [junit] \n    [junit] Testsuite: org.apache.cassandra.pig.CqlTableTest\n    [junit] \n    [junit] Exception: java.lang.IllegalStateException thrown from the UncaughtExceptionHandler in thread \"cluster15357-connection-reaper-0\"\n    [junit] Testsuite: org.apache.cassandra.pig.CqlTableTest\n    [junit] Testsuite: org.apache.cassandra.pig.CqlTableTest Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 sec\n    [junit] \n    [junit] Testcase: org.apache.cassandra.pig.CqlTableTest:testCqlNativeStorageSingleKeyTable:\tCaused an ERROR\n    [junit] Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.\n    [junit] junit.framework.AssertionFailedError: Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.\n    [junit] \n    [junit] \n    [junit] Test org.apache.cassandra.pig.CqlTableTest FAILED (crashed)\n    [junit] Testsuite: org.apache.cassandra.pig.ThriftColumnFamilyDataTypeTest\n    [junit] Testsuite: org.apache.cassandra.pig.ThriftColumnFamilyDataTypeTest Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 19.889 sec\n    [junit] \n    [junit] Testcase: testCassandraStorageDataType(org.apache.cassandra.pig.ThriftColumnFamilyDataTypeTest):\tCaused an ERROR\n    [junit] Unable to open iterator for alias rows\n    [junit] org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1066: Unable to open iterator for alias rows\n    [junit] \tat org.apache.pig.PigServer.openIterator(PigServer.java:882)\n    [junit] \tat org.apache.cassandra.pig.ThriftColumnFamilyDataTypeTest.testCassandraStorageDataType(ThriftColumnFamilyDataTypeTest.java:81)\n    [junit] Caused by: java.io.IOException: Job terminated with anomalous status FAILED\n    [junit] \tat org.apache.pig.PigServer.openIterator(PigServer.java:874)\n    [junit] \n    [junit] \n    [junit] Test org.apache.cassandra.pig.ThriftColumnFamilyDataTypeTest FAILED\n    [junit] Testsuite: org.apache.cassandra.pig.ThriftColumnFamilyTest\n    [junit] Testsuite: org.apache.cassandra.pig.ThriftColumnFamilyTest\n    [junit] Testsuite: org.apache.cassandra.pig.ThriftColumnFamilyTest Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 sec\n    [junit] \n    [junit] Testcase: org.apache.cassandra.pig.ThriftColumnFamilyTest:testCqlNativeStorageCompositeKeyCF:\tCaused an ERROR\n    [junit] Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.\n    [junit] junit.framework.AssertionFailedError: Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.\n    [junit] \n    [junit] \n    [junit] Test org.apache.cassandra.pig.ThriftColumnFamilyTest FAILED (crashed)\n[junitreport] Processing /var/lib/jenkins/jobs/trunk_pigtest/workspace/build/test/TESTS-TestSuites.xml to /tmp/null1591595172\n[junitreport] Loading stylesheet jar:file:/usr/share/ant/lib/ant-junit.jar!/org/apache/tools/ant/taskdefs/optional/junit/xsl/junit-frames.xsl\n[junitreport] Transform time: 1048ms\n[junitreport] Deleting: /tmp/null1591595172\n\nBUILD FAILED\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "trunk pig-test fails"
   },
   {
      "_id": "12844931",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-07-14 11:31:01",
      "description": "I've seen random failures with {{RangeTombstoneList.addAllRandomTest}}. The problem is 2 inequalities in {{RangeTombstoneList.insertFrom}} that should be inclusive rather than strict when we deal with boundaries between range. In practice, that makes us consider range like {{[3, 3)}} during addition, which is non-sensical.\n\nAttaching patch as well as a test that reproduce (extracted from {{addAllRandomTest}} with a failing seed).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "RangeTombstonListTest sometimes fails on trunk"
   },
   {
      "_id": "12844908",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-07-14 08:56:15",
      "description": "While profiling a simple stress write run ({{cassandra-stress write n=2000000 -rate threads=50}} to be precise) with Mission Control, I noticed that a non trivial amount of heap pressure was due to the {{ByteBuffer.wrap()}} call in {{SequentialWriter.write(byte[])}}. Basically, when writing a byte array, we wrap it in a ByteBuffer to reuse the {{SequentialWriter.write(ByteBuffer)}} method. One could have hoped this wrapping would be stack allocated, but if Mission Control isn't lying (and I was told it's fairly honest on that front), it's not. And we do use that {{write(byte[])}} method quite a bit, especially with the new vint encodings since they use a {{byte[]}} thread local buffer and call that method.\n\nAnyway, it sounds very simple to me to have a more direct {{write(byte[])}} method, so attaching a patch to do that. A very quick local benchmark seems to show a little bit less allocation and a slight edge for the branch with this patch (on top of CASSANDRA-9705 I must add), but that local bench was far from scientific so happy if someone that knows how to use our perf service want to give that patch a shot.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't wrap byte arrays in SequentialWriter"
   },
   {
      "_id": "12844763",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-07-13 19:42:06",
      "description": "This test failure started with the 8099 commit.\n{noformat}\nError Message\n\nexpected:<10> but was:<0>\n\nStacktrace\n\njunit.framework.AssertionFailedError: expected:<10> but was:<0>\n\tat org.apache.cassandra.db.RangeTombstoneTest.runCompactionWithRangeTombstoneAndCheckSecondaryIndex(RangeTombstoneTest.java:579)\n\tat org.apache.cassandra.db.RangeTombstoneTest.testRowWithRangeTombstonesUpdatesSecondaryIndex(RangeTombstoneTest.java:455)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "RangeTombstoneTest.testRowWithRangeTombstonesUpdatesSecondaryIndex failure"
   },
   {
      "_id": "12841220",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332464",
            "id": "12332464",
            "name": "Feature/Materialized Views"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2015-06-29 01:15:39",
      "description": "Currently we allocate an on-heap {{ByteBuffer}} to serialize the batched mutations into, before sending it to a distant node, generating unnecessary garbage (potentially a lot of it).\n\nWith materialized views using the batchlog, it would be nice to optimise the write path:\n- introduce a new verb ({{Batch}})\n- introduce a new message ({{BatchMessage}}) that would encapsulate the mutations, expiration, and creation time (similar to {{HintMessage}} in CASSANDRA-6230)\n- have MS serialize it directly instead of relying on an intermediate buffer\n\nTo avoid merely shifting the temp buffer to the receiving side(s) we should change the structure of the batchlog table to use a list or a map of individual mutations.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve batchlog write path"
   },
   {
      "_id": "12840877",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-06-26 15:07:10",
      "description": "It appears that the impact of buffered vs. memory-mapped index file reads has changed dramatically since last I tested. [Here's some results on various platforms we pulled together yesterday w/2.2-HEAD|https://docs.google.com/spreadsheets/d/1JaO2x7NsK4SSg_ZBqlfH0AwspGgIgFZ9wZ12fC4VZb0/edit#gid=0].\n\nTL;DR: On linux we see a 40% hit in performance from 108k ops/sec on reads to 64.8k ops/sec. While surprising in itself, the really unexpected result (to me) is on Windows - with standard access we're getting 16.8k ops/second on our bare-metal perf boxes vs. 184.7k ops/sec with memory-mapped index files, an over 10-fold increase in throughput. While testing w/standard access, CPU's on the stress machine and C* node are both sitting < 4%, network doesn't appear bottlenecked, resource monitor doesn't show anything interesting, and performance counters in the kernel show very little. Changes in thread count simply serve to increase median latency w/out impacting any other visible metric that we're measuring, so I'm at a loss as to why the disparity is so huge on the platform.\n\nThe combination of my changes to get the 2.1 branch to behave on Windows along with [~benedict] and [~Stefania]'s changes in lifecycle and cleanup patterns on 2.2 should hopefully have us in a state where transitioning back to using memory-mapped I/O on Windows will only cause trouble on snapshot deletion. Fairly simple runs of stress w/compaction aren't popping up any obvious errors on file access or renaming - I'm going to do some much heavier testing (ccm multi-node clusters, long stress w/repair and compaction, etc) and see if there's any outstanding issues that need to be stamped out to call mmap'ed index files on Windows safe. The one thing we'll never be able to support is deletion of snapshots while a node is running and sstables are mapped, but for a > 10x throughput increase I think users would be willing to make that sacrifice.\n\nThe combination of the powercfg profile change, the kernel timer resolution, and memory-mapped index files are giving some pretty interesting performance numbers on EC2.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Re-enable memory-mapped index file reads on Windows"
   },
   {
      "_id": "12840391",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2015-06-25 01:09:12",
      "description": "This code in {{StorageProxy.beginAndRepairPaxos()}} takes a timestamp in microseconds but divides it by 1000 before adding one. So if the summary is null, ballotMillis would be the same for up to 1000 possible state timestamp values:\n\n{code}\n    long currentTime = (state.getTimestamp() / 1000) + 1;\n    long ballotMillis = summary == null\n                                 ? currentTime\n                                 : Math.max(currentTime, 1 +    UUIDGen.unixTimestamp(summary.mostRecentInProgressCommit.ballot));\n    UUID ballot = UUIDGen.getTimeUUID(ballotMillis);\n{code}\n\n{{state.getTimestamp()}} returns the time in micro seconds and it ensures to add one microsecond to any previously used timestamp if the client sends the same or an older timestamp. \n\nInitially I used this code in {{ModificationStatement.casInternal()}}, introduced by CASSANDRA-9160 to support cas unit tests, but occasionally these tests were failing. It was only when I ensured uniqueness of the ballot that the tests started to pass reliably.\n\nI wonder if we could ever have the same issue in StorageProxy?\n\ncc [~jbellis] and [~slebresne] for CASSANDRA-7801",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Paxos ballot in StorageProxy could clash"
   },
   {
      "_id": "12840351",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2015-06-24 21:53:50",
      "description": "Windows' power profiles have a pretty marked impact on application performance and the CPU frequency throttling is fairly aggressive even in balanced mode. As we have a large number of threads with varying work rather than a single busy thread-per-core, the scheduler on Windows sees enough downtime to constantly struggle w/our user-space operations and the frequency on the system will jump up and down even when fully saturated from a stress.\n\nI've done some benchmarking of the \"Balanced\" vs. \"High Performance\" power profiles - [link to performance numbers|https://docs.google.com/spreadsheets/d/1YS8VtdZAgyec-mcnSgtNhQH9LiHstOaiMtlppvEIIM8/edit#gid=0]. Note: reads are not saturating the box (or even impacting resources at all really) as the CPU's on both stress and node are sitting around 4% usage. Still have something to figure out there on 2.2.\n\nWe have a few ways we can approach this - for the 1st (warn), here's a branch with warning during startup if non-High Performance power profile detected: [here|https://github.com/apache/cassandra/compare/trunk...josh-mckenzie:check_power_plan].\n\nAlternatively we could get more aggressive and actually attempt a powercfg /s to the GUID of the High Performance power profile or refuse to start Cassandra if we're not in the performance profile. I also briefly pursued using Sigar to query this information however the documentation for the library is no longer available (or at least I couldn't find it).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Performance",
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Warn if power profile is not High Performance on Windows"
   },
   {
      "_id": "12840061",
      "assignee": "krummas",
      "components": [],
      "created": "2015-06-24 07:50:12",
      "description": "This is a document bringing up some issues when DTCS is used to compact time series data in a three node cluster. The DTCS is currently configured with a few parameters that are making the configuration fairly simple, but might cause problems in certain special cases like recovering from the flood of small SSTables due to repair operation. We are suggesting some ideas that might be a starting point for further discussions. Following sections are containing:\n\n- Description of the cassandra setup\n- Feeding process of the data\n- Failure testing\n- Issues caused by the repair operations for the DTCS\n- Proposal for the DTCS configuration parameters\n\nAttachments are included to support the discussion and there is a separate section giving explanation for those.\n\nCassandra setup and data model\n\n- Cluster is composed from three nodes running Cassandra 2.1.2. Replication factor is two and read and write consistency levels are ONE.\n- Data is time series data. Data is saved so that one row contains a certain time span of data for a given metric ( 20 days in this case). The row key contains information about the start time of the time span and metrix name. Column name gives the offset from the beginning of time span. Column time stamp is set to correspond time stamp when adding together the timestamp from the row key and the offset (the actual time stamp of data point). Data model is analog to KairosDB implementation.\n- Average sampling rate is 10 seconds varying significantly from metric to metric.\n- 100 000 metrics are fed to the Cassandra.\n- max_sstable_age_days is set to 5 days (objective is to keep SStable files in manageable size, around 50 GB)\n- TTL is not in use in the test.\n\nProcedure for the failure test.\n\n- Data is first dumped to Cassandra for 11 days and the data dumping is stopped so that DTCS will have a change to finish all compactions. Data is dumped with \"fake timestamps\" so that column time stamp is set when data is written to Cassandra.\n- One of the nodes is taken down and new data is dumped on top of the earlier data covering couple of hours worth of data (faked time stamps).\n- Dumping is stopped and the node is kept down for few hours.\n- Node is taken up and the \"nodetool repair\" is applied on the node that was down.\n\nConsequences\n\n- Repair operation will lead to massive amount of new SStables far back in the history. New SStables are covering similar time spans than the files that were created by DTCS before the shutdown of one of the nodes.\n- To be able to compact the small files the max_sstable_age_days should be increased to allow compaction to handle the files. However, the in a practical case the time window will increase so large that generated files will be huge that is not desirable. The compaction also combines together one very large file with a bunch of small files in several phases that is not effective. Generating really large files may also lead to out of disc space problems.\n- See the list of time graphs later in the document.\n\nImprovement proposals for the DTCS configuration\n\nBelow is a list of desired properties for the configuration. Current parameters are mentioned if available.\n\n- Initial window size (currently:base_time_seconds)\n- The amount of similar size windows for the bucketing (currently: min_threshold)\n- The multiplier for the window size when increased (currently: min_threshold). This we would like to be independent from the min_threshold parameter so that you could actually control the rate how fast the window size is increased.\n- Maximum length of the time window inside which the files are assigned for a certain bucket (not currently defined). This means that expansion of time window length is restricted. When the limit is reached the window size will be same all the way back in the history (e.g. one week)\n- The maximum horizon in which SStables are candidates for buckets (currently: max_sstable_age_days)\n- Maximum file size of SStable allowed to be in a set of files to be compacted (not possible currently). Preventing out of disk space situations.\n- Optional strategies to select the most interesting bucket:\n    - Minimum amount of SStables in the time window before it is a candidate for the most interesting bucket (currently: min_threshold for the most recent window, otherwise two). Being able set this value independently would allow to put most of the efforts on those areas where a large amount of small files should be compacted together instead of few new files.\n    - Optionally, the criteria for the most interesting bucket could be set: e.g. select the window with most files to be compacted.\n    - Inside the bucket when the amount of files is limited by max_threshold, the compaction would select first small files instead of one huge file and a bunch of small files.\n\nThe above set of parameters allows to recover from repair operations producing large amount of small SStables.\n\n- Maximum length of the time window for compactions would keep the compacted SStable size in reasonable range and would allow to extend the horizon far back in the history\n- Combining small files together instead of combining one huge file with e.g. 31 small files again and again is more disk efficient\n\nIn addition to the previous advantages the above parameters would also allow:\n\n- Dumping of more data in the history (e.g. new metrics) by assigning the correct timestamp for the column (fake time stamp) and proper compaction of new and existing SStables.\n- Expiring reasonable size SStable with TTL even if the compactions would be intermittently executed far back in the history. In this case the new data has to fed with TTL calculated dynamically.\n- Note: Being able to give the absolute time stamp for the column expiry time would be beneficial when data is dumped back in the history. This is the case when you move data from some legacy system to Cassandra with faked time stamps and would like to keep the data only a certain time period.  Currently the absolute time stamp is calculated by Cassandra from the system time and given TTL. TTL has to be calculated dynamically based on the current time and desired expiry moment making things more complex.\n\nOne interesting question is that why those duplicate SStable files are created? The duplication problem could not be produced when the data was dumped with following spec:\n\n- 100 metrics\n- 20 days of data in one row\n- one year of data\n- max_sstable_age_days = 15\n - memtable_offheap_space_in_mb was decreased so that small SStables were created (to create something to be compacted)\n - One node was taken down and one more day of data was dumped on top of the earlier data\n- \"nodetool repair -pr\" was executed on each node => duplicates were checked in each step => no duplicates\n- \"nodetool repair\" was executed on a node that was down => no duplicates were generated\n\n\n--------------------------------------------------------------------------------------------------------------------\n\nATTACHMENTS\n\n\nTime graphs of content of SSTables from different phases of the test run:\n\n*************************************************************\n\nFields in the below time graphs are following:\n\n- Order number from the  SSTable file name\n- Minimum column timestamp in the SSTable file\n- Timespan representation graphically\n- Maximum column time stamp in SStable\n- The size of the SStable in megabytes\n\nTime graphs after dumping the 11 days of data and letting all compactions to run through\n\nnode0_20150621_1646_time_graph.txt\nnode1_20150621_1646_time_graph.txt\nnode2_20150621_1646_time_graph.txt (error: same as for node1, but the behavior is same)\n\nTime graphs after taking one node down (node2) and dumping couple of hours of mode data\n\nnode0_20150621_2320_time_graph.txt\nnode1_20150621_2320_time_graph.txt\nnode2_20150621_2320_time_graph.txt \n\nTime graphs when the repair operation has finished and compactions are done. Compactions will naturally handle only the files inside the max_sstable_age_days range.\n\n==> Now there is a large amount of small files covering pretty much same areas as the original SStables\n\nnode0_20150623_1526_time_graph.txt\nnode1_20150623_1526_time_graph.txt\nnode2_20150623_1526_time_graph.txt\n\n-----------\nTrend from the SStable count as a function of time on each node.\nsstable_counts.jpg\n\nVertical lines:\n\n1) Clearing the database and dumping the 11 days worth of data\n2) Stopping the dumping and letting compactions run\n3) Taking one node down (top bottom one in figure) and dumping few hours of new data on top of earlier data\n4) Starting the repair operation\n5) Repair operation finished\n\n\n--------\nNodetool status prints before and after repair operation\nnodetool status infos.txt\n\n--------------\nTracing compactions\n\nLog files were parsed to demonstrate the creation of new small SStables and the combination of one large file with a bunch of small ones. This is done from the time range where the max_sstable_age_days is able to reach (in this case 5 days). The hierarchy of the files is shown in the file \"sstable_compaction_trace.txt\". The first flushed file can be found from the line 10.\n\nEach line represents either a flushed SStable or the SStable created by DTCS. For flushed files the timestamp indicates the time period the file represents. For compacted files (marked with C) the first timestamp represents the moment when the compaction was done (wall clock). Time stamps are faked when written to the database. The size of the file is the last field. The first field with number in parenthesis shows the level of the file. Top level files marked with (0) are those that don't have any predecessors and should be found from the disk also.\n\nSStables that are created by the repair operation are not mentioned in the log files so they are handled as phantom files. The existence of file can be concluded from the predecessor list of compacted SStable. Those are marked with None,None in timestamps.\n\nIn the file \"sstable_compaction_trace_snipped.txt\" is one portion that shows the compaction hierarchy for the small files originating from the repair operation. max_threshold is in the default value of 32. In each step 31 tiny files are compacted together with 46 GB file.\n\n\nsstable_compaction_trace.txt\nsstable_compaction_trace_snipped.txt",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "DTCS configuration proposals for handling consequences of repairs"
   },
   {
      "_id": "12839585",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328322",
            "id": "12328322",
            "name": "Local/Startup and Shutdown",
            "description": "Startup and Shutdown"
         }
      ],
      "created": "2015-06-22 16:06:43",
      "description": "In Windows 7/Server 2008 and to a similar extent Windows 8/Server 2012, the kernel's internal time is set to an interval of 15.6ms. (Use [clockres|https://technet.microsoft.com/en-us/sysinternals/bb897568.aspx] to confirm current 'tick rate' on Windows). Win8/Server2012 have a tickless kernel w/timer coalescing ([info here|http://arstechnica.com/information-technology/2012/10/better-on-the-inside-under-the-hood-of-windows-8/2/]) and the platform shows similar performance characteristics with C* to Windows 7 with a slight edge in performance to win8/server 2012 in my testing (the testing and results of which are outside the scope of this ticket).\n\nSome arguments against lowering the system's internal timer to 1ms are [here|https://randomascii.wordpress.com/2013/07/08/windows-timer-resolution-megawatts-wasted/]. These seem largely constrained to \"it'll drain your battery\" and \"it'll prevent your processor from being as effective in sleep states\". The 2nd is somewhat of a concern as we don't want Windows users to all of a sudden have increased CPU-usage bills from virtualized environments. In the comments, one individual mentions a VirtualBox VM spinning at 10-20% cpu just from changing that flag alone which seems mathematically unlikely, but is worth keeping an eye on and testing.\n\nA Microsoft publication that largely reinforces the cautionary tale on power consumption can be found [here|http://download.microsoft.com/download/3/0/2/3027D574-C433-412A-A8B6-5E0A75D5B237/Timer-Resolution.docx].\n\nWith the cautionary tales on our radar, the impact on throughput and latency on the 2.2 branch on Windows is [fairly dramatic|https://docs.google.com/spreadsheets/d/1nqPhNwOVt0SU7b9lt9o4Tyl0Z1yDrV2oo7LbBPaFa6A/edit#gid=0]. A couple of caveats on these #'s: I'm not completely saturating the system as the thread count is relatively low (keeping it consistent with other testing where it *was* saturating), and the read #'s from our 2012 test environment are not affected by this timer change while I see it on 3 other bare-metal installations. The testing environment is new and we haven't worked out the kinks yet, however the write / mixed illustrate the throughput and latency #'s I've mentioned above; for reads the cpu's are sitting idle at 1-5% used by stress and C* so something else clearly needs to be addressed there; I included them for completeness sake.\n\nSome preliminary testing on OpenStack indicates kernel-space syscall saturation w/this patch that actually *degrades* performance, however the unpatched performance numbers in our OpenStack environment are low enough that I question their validity.\n\nOpening this ticket w/attached branch to get it on the radar / conversation going, and I'm going to update this from being hard-coded to being a tunable in the .yaml.\n\nInitial patch [available here|https://github.com/apache/cassandra/compare/trunk...josh-mckenzie:2.2_WinTimer].",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Set kernel timer resolution on Windows"
   },
   {
      "_id": "12838588",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2015-06-17 21:04:54",
      "description": "Currently the async callback to start C* on Windows from within ccm is taking upwards of 1.5 to 2 seconds per node due to a variety of somewhat expensive process launches we're doing in there (java version check, async port open checking). Contrast this with a crisp 0-1 ms on linux...\n\nSome of that stuff can be cleaned up and sped up which should help both speed up our testing environment and iron out an error that pops up on the port check w/IPv6 (note: node still starts, just complains).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Speed up Windows launch scripts"
   },
   {
      "_id": "12838097",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-06-16 08:46:53",
      "description": "[PYTHON-206|https://datastax-oss.atlassian.net/browse/PYTHON-206] introduced the ability to change the initial connection timeout on connections from the default of 5s.\n\nThis change was introduced because some auth providers (kerberos) can take longer than 5s to complete a first time negotiation for a connection. \n\ncqlsh should allow this setting to be changed. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow an initial connection timeout to be set in cqlsh"
   },
   {
      "_id": "12837353",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-06-12 09:04:47",
      "description": "The current version of sstableofflinerelevel prints the new level hierarchy. While \"nodetool cfstats ...\" will tell the current hierarchy it would be nice to have \"sstableofflinerelevel\" output the current level histograms for easy comparison of what changes will be made. Especially since sstableofflinerelevel needs to run when node isn't running and \"nodetool cfstats ...\" doesn't work because of that.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs",
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Make sstableofflinerelevel print stats before relevel"
   },
   {
      "_id": "12836815",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-06-10 12:01:40",
      "description": "DateTieredCompaction works correctly when data is dumped for a certain time period in short SSTables in time manner and then compacted together. However, if TTL is applied to the data columns the DTCS fails to compact files correctly in timely manner. In our opinion the problem is caused by two issues:\n\nA) During the DateTieredCompaction process the getFullyExpiredSStables is called twice. First from the DateTieredCompactionStrategy class and second time from the CompactionTask class. On the first time the target is to find out fully expired SStables that are not overlapping with any non-fully expired SSTables. That works correctly. When the getFullyExpiredSSTables is called second time from CompactionTask class the selection of fully expired SSTables is modified compared to the first selection.\n\nB) The minimum timestamp of the new SSTables created by combining together fully expired SSTable and files from the most interesting bucket is not correct.\n\nThese two issues together cause problems for the DTCS process when it combines together SSTables having overlap in time and TTL for the column. This is demonstrated by generating test data first without compactions and showing the timely distribution of files. When the compaction is enabled the DCTS combines files together, but the end result is not something to be expected. This is demonstrated in the file motivation_jira.txt\n\nAttachments contain following material:\n\n- Motivation_jira.txt: Practical examples how the DTCS behaves with TTL\n- Explanation_jira.txt: gives more details, explains test cases and demonstrates the problems in the compaction process\n- Logfile file for the compactions in the first test case (compaction_stage_test01_jira.log)\n- Logfile file for the compactions in the seconnd test case (compaction_stage_test02_jira.log)\n- source code zip file for version 2.1.5 with additional comment statements (src_2.1.5_with_debug.zip)\n- Python script to generate test data (datagen.py)\n- Python script to read metadata from SStables (cassandra_sstable_metadata_reader.py)\n- Python script to generate timeline representation of SSTables (cassandra_sstable_timespan_graph.py)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "DateTieredCompactionStrategy fails to combine SSTables correctly when TTL is used."
   },
   {
      "_id": "12835710",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-06-05 13:07:07",
      "description": "CASSANDRA-8099, in {{UnfilteredRowIterators.digest()}}:\n\n{code}\n        // TODO: we're not computing digest the same way that old nodes. This\n        // means we'll have digest mismatches during upgrade. We should pass the messaging version of\n        // the node this is for (which might mean computing the digest last, and won't work\n        // for schema (where we announce the version through gossip to everyone))\n{code}\n\nIn a mixed 2.1(2.2) - 3.0 clusters, we need to calculate both digest at the same time and keep both results, and send the appropriate one, depending on receiving nodes' messaging versions. Do that until {{MessagingService.allNodesAtLeast30()}} is true (this is not unprecedented).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "upgrade"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Avoid digest mismatch storm on upgrade to 3.0"
   },
   {
      "_id": "12834943",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-06-03 06:32:55",
      "description": "It's extremely hard to reproduce but occasionally some Jenkins tests fail as follows:\n\nhttp://cassci.datastax.com/job/trunk_utest/229/testReport/org.apache.cassandra.db.lifecycle/TrackerTest/testAddInitialSSTables/\n\n{code}\njunit.framework.AssertionFailedError\n\tat org.apache.cassandra.utils.concurrent.Ref$State.assertNotReleased(Ref.java:157)\n\tat org.apache.cassandra.utils.concurrent.Ref.ref(Ref.java:113)\n\tat org.apache.cassandra.io.sstable.format.SSTableReader$GlobalTidy.get(SSTableReader.java:2111)\n\tat org.apache.cassandra.io.sstable.format.SSTableReader$DescriptorTypeTidy.<init>(SSTableReader.java:1980)\n\tat org.apache.cassandra.io.sstable.format.SSTableReader$DescriptorTypeTidy.get(SSTableReader.java:2017)\n\tat org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier.setup(SSTableReader.java:1897)\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.setup(SSTableReader.java:1842)\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.internalOpen(SSTableReader.java:530)\n\tat org.apache.cassandra.MockSchema.sstable(MockSchema.java:128)\n\tat org.apache.cassandra.MockSchema.sstable(MockSchema.java:92)\n\tat org.apache.cassandra.MockSchema.sstable(MockSchema.java:87)\n\tat org.apache.cassandra.db.lifecycle.TrackerTest.testAddInitialSSTables(TrackerTest.java:146)\n{code}\n\nI propose not to reuse cfname in MockSchema.sstable() and in fact to get rid of the shared MockSchema.cfs which has caused other test problems, see CASSANDRA-9514.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Sstables created with MockSchema occasionally triggers assertions"
   },
   {
      "_id": "12833870",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-05-29 19:44:25",
      "description": "Error:\n{{0(true) 1(false) expected:<1> but was:<2>}}\n\nhttp://cassci.datastax.com/job/trunk_testall/125/testReport/org.apache.cassandra.db.lifecycle/ViewTest/testSSTablesInBounds/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "ViewTest.testSSTablesInBounds fails in trunk"
   },
   {
      "_id": "12833868",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-05-29 19:41:10",
      "description": "Error:\n{{expected:<1> but was:<2>}}\n\nhttp://cassci.datastax.com/job/cassandra-2.2_testall/33/testReport/org.apache.cassandra.db.lifecycle/TrackerTest/testTryModify/\nhttp://cassci.datastax.com/job/trunk_testall/125/testReport/org.apache.cassandra.db.lifecycle/TrackerTest/testDropSSTables/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "TrackerTest.testAddSSTables fails in 2.2 and trunk"
   },
   {
      "_id": "12833492",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-05-28 16:53:39",
      "description": "{noformat}\n    [junit] Testcase: testSliceByNamesCommandOldMetadata(org.apache.cassandra.db.ColumnFamilyStoreTest):        FAILED\n    [junit] null\n    [junit] junit.framework.AssertionFailedError\n    [junit]     at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:171)\n    [junit]     at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:166)\n    [junit]     at org.apache.cassandra.io.sstable.format.SSTableWriter.rename(SSTableWriter.java:266)\n    [junit]     at org.apache.cassandra.db.ColumnFamilyStore.loadNewSSTables(ColumnFamilyStore.java:766)\n    [junit]     at org.apache.cassandra.db.ColumnFamilyStoreTest.testSliceByNamesCommandOldMetadata(ColumnFamilyStoreTest.java:1125)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "ColumnFamilyStoreTest.testSliceByNamesCommandOldMetadata failing"
   },
   {
      "_id": "12833127",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2015-05-27 18:12:26",
      "description": "I can import a chunk of data into Cassandra table with COPY command like:\n\nCOPY my_table (name, address) FROM my_file.csv WITH option='value' ... ;\n\nBut I am not able to specify a finite TTL in COPY command with \"USING TTL 3600\", for example. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Need to set TTL with COPY command"
   },
   {
      "_id": "12832787",
      "assignee": "krummas",
      "components": [],
      "created": "2015-05-26 17:28:33",
      "description": "I have a dtest that fails intermittently because of SSTable leaks. The test logic leading to the error is:\n\n- create a 5-node cluster\n- insert 5000 records with {{stress}}, RF=3 at CL=ONE\n- run {{flush}} on all nodes \n- run {{repair}} on a single node.\n\nThe leak is detected on a different node than {{repair}} was run on.\n\nThe failing test is [here|https://github.com/mambocab/cassandra-dtest/blob/CASSANDRA-5839-squash/repair_test.py#L317]. The relevant error his [here|https://gist.github.com/mambocab/8aab7b03496e0b279bd3#file-node2-log-L256], along with the errors from the entire 5-node cluster. In these logs, the {{repair}} was run on {{node1}} and the leak was found on {{node2}}.\n\nI can bisect, but I thought I'd get the ball rolling in case someone knows where to look.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "stress"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "SSTable leak after stress and repair"
   },
   {
      "_id": "12831664",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-05-21 09:13:15",
      "description": "There are a number of exposed metrics that currently are named using the old nomenclature of columnfamily and rows (meaning partitions).\nIt would be good to audit all metrics and update any names to match what they actually represent; we should probably do that in a single sweep to avoid a confusing mixture of old and new terminology. \n\nAs we'd need to do this in a major release, I've initially set the fixver for 3.0 beta1.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "jmx"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Metrics should use up to date nomenclature"
   },
   {
      "_id": "12830767",
      "assignee": "philipthompson",
      "components": [],
      "created": "2015-05-18 18:23:02",
      "description": "When I was looking at CASSANDRA-9408, I noticed that {{conf/cassandra-env.sh}} and {{conf/cassandra-env.ps1}} do JVM version checking and should get updated for 3.x to refuse to start with JVM_VERSION < 1.8.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "3.x should refuse to start on JVM_VERSION < 1.8"
   },
   {
      "_id": "12830731",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-05-18 16:21:49",
      "description": "Failure is intermittent enough that bisect is proving to be more hassle than it's worth. Seems pretty consistent in CI.\n\n{noformat}\n    [junit] Testcase: testDeleteIfNotDirty(org.apache.cassandra.db.CommitLogTest):      Caused an ERROR\n    [junit] java.nio.file.AccessDeniedException: build\\test\\cassandra\\commitlog;0\\CommitLog-5-1431965988394.log\n    [junit] FSWriteError in build\\test\\cassandra\\commitlog;0\\CommitLog-5-1431965988394.log\n    [junit]     at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:131)\n    [junit]     at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:148)\n    [junit]     at org.apache.cassandra.db.commitlog.CommitLogSegmentManager.recycleSegment(CommitLogSegmentManager.java:360)\n    [junit]     at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:166)\n    [junit]     at org.apache.cassandra.db.commitlog.CommitLog.startUnsafe(CommitLog.java:416)\n    [junit]     at org.apache.cassandra.db.commitlog.CommitLog.resetUnsafe(CommitLog.java:389)\n    [junit]     at org.apache.cassandra.db.CommitLogTest.testDeleteIfNotDirty(CommitLogTest.java:178)\n    [junit] Caused by: java.nio.file.AccessDeniedException: build\\test\\cassandra\\commitlog;0\\CommitLog-5-1431965988394.log\n    [junit]     at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)\n    [junit]     at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)\n    [junit]     at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)\n    [junit]     at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)\n    [junit]     at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)\n    [junit]     at java.nio.file.Files.delete(Files.java:1126)\n    [junit]     at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:125)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows: deleteWithConfirm errors on various unit tests"
   },
   {
      "_id": "12830209",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-05-15 16:07:23",
      "description": "cqlsh/python-driver need to add support for all the new 2.2 CQL features:\n- {{date}} and {{time}} types - CASSANDRA-7523 - not in cqlsh yet\n- {{smallint}} and {{tinyint}} types - CASSANDRA-8951 - not in the driver yet\n- client warnings - CASSANDRA-8930\n- tracing improvements - CASSANDRA-7807",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh support for native protocol v4 features"
   },
   {
      "_id": "12828427",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2015-05-08 17:28:19",
      "description": "-    $env:JVM_OPTS=\"$env:JVM_OPTS $JVM_EXTRA_OPTS\"\n+    $env:JVM_OPTS=\"$env:JVM_OPTS $env:JVM_EXTRA_OPTS\"\n\nMissing env: on front of JVM_EXTRA_OPTS in conf\\cassandra-env.ps1\n\nAttaching trivial patch to fix this.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "JVM_EXTRA_OPTS not getting picked up by windows startup environment"
   },
   {
      "_id": "12827998",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-05-07 11:54:31",
      "description": "since CASSANDRA-7414 we are including high-level sstables in lower level compactions if we have not run compactions in the high level for a while.\n\nIf the compaction candidates only contain a single partition this can cause overlap since first token in sstables == last token in sstables which we interpret as being \"entire ring\".\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Possible overlap with LCS and including non-compacting sstables"
   },
   {
      "_id": "12827319",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-05-05 15:12:54",
      "description": "COPY FROM has gotten a lot of love.  COPY TO not so much.  One obvious improvement could be to parallelize reading and writing (write one page of data while fetching the next).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "COPY TO improvements"
   },
   {
      "_id": "12827313",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-05-05 15:05:40",
      "description": "https://github.com/brianmhess/cassandra-loader added a bunch of options to handle real world requirements, we should match those.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Match cassandra-loader options in COPY FROM"
   },
   {
      "_id": "12824437",
      "assignee": "krummas",
      "components": [],
      "created": "2015-04-27 22:15:02",
      "description": "I was trying to set 'timestamp_resolution' to MINUTES/HOURS/DAYS. it turned out maxSSTableAge was set as wrong value. In the code,\n{code}\n    public DateTieredCompactionStrategyOptions(Map<String, String> options)\n    {\n        String optionValue = options.get(TIMESTAMP_RESOLUTION_KEY);\n        TimeUnit timestampResolution = optionValue == null ? DEFAULT_TIMESTAMP_RESOLUTION : TimeUnit.valueOf(optionValue);\n        optionValue = options.get(MAX_SSTABLE_AGE_KEY);\n        double fractionalDays = optionValue == null ? DEFAULT_MAX_SSTABLE_AGE_DAYS : Double.parseDouble(optionValue);\n        maxSSTableAge = Math.round(fractionalDays * timestampResolution.convert(1, TimeUnit.DAYS));\n ...   }{code}\n\nmaxSSTableAge will be set as the value in \"timestamp_resolution\" unit, such as , with the following settings,\n        'timestamp_resolution':'HOURS',\n        'max_sstable_age_days':'7',\n        'base_time_seconds':'3600'\nand I get: \nmaxSSTableAge=168,  baseTime=1\n\nwhile in the following routine, it expect maxSSTableAge as milliseconds\n    static Iterable<SSTableReader> filterOldSSTables(List<SSTableReader> sstables, long maxSSTableAge, long now)\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "for DateTieredCompactionStrategy, TIMESTAMP_RESOLUTION_KEY sets wrong msxSSTableAge value if RESOLUTION is other than MILLISECONDS"
   },
   {
      "_id": "12823744",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-04-24 13:24:11",
      "description": "nodetool compactionstats\npending tasks: -222222228\n\nI can see negative numbers in 'pending tasks' on all 8 nodes\nit looks like -222222228 + real number of pending tasks\nfor example -222222128 for 100 real pending tasks\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Max sstable size in leveled manifest is an int, creating large sstables overflows this and breaks LCS"
   },
   {
      "_id": "12823670",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-04-24 06:59:35",
      "description": "We should probably disable tombstone compactions by default for DTCS for these reasons:\n\n# users should not do deletes with DTCS\n# the only way we should get rid of data is by TTL - and then we don't want to trigger a single sstable compaction whenever an sstable is 20%+ expired, we want to drop the whole thing when it is fully expired",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Disable single-sstable tombstone compactions for DTCS"
   },
   {
      "_id": "12823511",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-04-23 18:40:18",
      "description": "cqlsh seems to treat \"timestamp\" as a reserved keyword when used as an identifier:\n\n{code}\ncqlsh:ks1> create table t1 (int int primary key, ascii ascii, bigint bigint, blob blob, boolean boolean, date date, decimal decimal, double double, float float, inet inet, text text, time time, timestamp timestamp, timeuuid timeuuid, uuid uuid, varchar varchar, varint varint);\n{code}\n\nLeads to the following completion when building an {{INSERT}} statement:\n\n{code}\ncqlsh:ks1> insert into t1 (int, \n\"timestamp\" ascii       bigint      blob        boolean     date        decimal     double      float       inet        text        time        timeuuid    uuid        varchar     varint\n{code}\n\n\"timestamp\" is a keyword but not a reserved one and should therefore not be proposed as a quoted string. It looks like this error happens only for timestamp. Not a big deal of course, but it might be worth reviewing the keywords treated as reserved in cqlsh, especially with the many changes introduced in 3.0.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "\"timestamp\" is considered as a reserved keyword in cqlsh completion"
   },
   {
      "_id": "12822794",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-04-21 20:56:26",
      "description": "We currently use a {{DEFAULT_FLOAT_PRECISION}} of 5 in cqlsh with formatting {{'%.*g' % (float_precision, val)}}.  In practice, this is way too low.  For example, 12345.5 will show up as 123456.  Since the float precision is used for cqlsh's COPY TO, it's particularly important that we maintain as much precision as is practical by default.\n\nThere are some other tricky considerations, though.  If the precision is too high, python will do something like this:\n\n{noformat}\n> '%.25g' % (12345.5555555555555555,)\n'12345.55555555555474711582'\n{noformat}\n\nThat's not terrible, but it would be nice to avoid if we can.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Figure out a better default float precision rule for cqlsh"
   },
   {
      "_id": "12787788",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-04-02 19:29:07",
      "description": "Variety of different test failures have cropped up over the past 2-3 weeks:\n\nh6. -org.apache.cassandra.cql3.UFTest FAILED (timeout)- // No longer failing / timing out\nh6. testLoadNewSSTablesAvoidsOverwrites(org.apache.cassandra.db.ColumnFamilyStoreTest):       FAILED\n{noformat}\n   12 SSTables unexpectedly exist\n   junit.framework.AssertionFailedError: 12 SSTables unexpectedly exist\n   at org.apache.cassandra.db.ColumnFamilyStoreTest.testLoadNewSSTablesAvoidsOverwrites(ColumnFamilyStoreTest.java:1896)\n{noformat}\n\nh6. org.apache.cassandra.db.KeyCacheTest FAILED\n{noformat}\n   expected:<4> but was:<2>\n   junit.framework.AssertionFailedError: expected:<4> but was:<2>\n   at org.apache.cassandra.db.KeyCacheTest.assertKeyCacheSize(KeyCacheTest.java:221)\n   at org.apache.cassandra.db.KeyCacheTest.testKeyCache(KeyCacheTest.java:181)\n{noformat}\n\nh6. RecoveryManagerTest:\n{noformat}\n   org.apache.cassandra.db.RecoveryManagerTest FAILED\n   org.apache.cassandra.db.RecoveryManager2Test FAILED\n   org.apache.cassandra.db.RecoveryManager3Test FAILED\n   org.apache.cassandra.db.RecoveryManagerTruncateTest FAILED\n   All are the following:\n      java.nio.file.AccessDeniedException: build\\test\\cassandra\\commitlog;0\\CommitLog-5-1427995105229.log\n      FSWriteError in build\\test\\cassandra\\commitlog;0\\CommitLog-5-1427995105229.log\n         at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:128)\n         at org.apache.cassandra.db.commitlog.CommitLogSegmentManager.recycleSegment(CommitLogSegmentManager.java:360)\n         at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:156)\n         at org.apache.cassandra.db.RecoveryManagerTest.testNothingToRecover(RecoveryManagerTest.java:75)\n      Caused by: java.nio.file.AccessDeniedException: build\\test\\cassandra\\commitlog;0\\CommitLog-5-1427995105229.log\n         at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)\n         at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)\n         at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)\n         at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)\n         at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)\n         at java.nio.file.Files.delete(Files.java:1079)\n         at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:124)\n{noformat}\n\nh6. testScrubCorruptedCounterRow(org.apache.cassandra.db.ScrubTest):  FAILED\n{noformat}\nExpecting new size of 1, got 2 while replacing [BigTableReader(path='C:\\src\\refCassandra\\build\\test\\cassandra\\data;0\\Keyspace1\\Counter1-deab62b2d95c11e489c6e117fe147c1d\\la-1-big-Data.db')] by [BigTableReader(path='C:\\src\\refCassandra\\build\\test\\cassandra\\data;0\\Keyspace1\\Counter1-deab62b2d95c11e489c6e117fe147c1d\\la-1-big-Data.db')] in View(pending_count=0, sstables=[BigTableReader(path='C:\\src\\refCassandra\\build\\test\\cassandra\\data;0\\Keyspace1\\Counter1-deab62b2d95c11e489c6e117fe147c1d\\la-3-big-Data.db')], compacting=[])\njunit.framework.AssertionFailedError: Expecting new size of 1, got 2 while replacing [BigTableReader(path='C:\\src\\refCassandra\\build\\test\\cassandra\\data;0\\Keyspace1\\Counter1-deab62b2d95c11e489c6e117fe147c1d\\la-1-big-Data.db')] by [BigTableReader(path='C:\\src\\refCassandra\\build\\test\\cassandra\\data;0\\Keyspace1\\Counter1-deab62b2d95c11e489c6e117fe147c1d\\la-1-big-Data.db')] in View(pending_count=0, sstables=[BigTableReader(path='C:\\src\\refCassandra\\build\\test\\cassandra\\data;0\\Keyspace1\\Counter1-deab62b2d95c11e489c6e117fe147c1d\\la-3-big-Data.db')], compacting=[])\n   at org.apache.cassandra.db.DataTracker$View.replace(DataTracker.java:767)\n   at org.apache.cassandra.db.DataTracker.replaceReaders(DataTracker.java:408)\n   at org.apache.cassandra.db.DataTracker.replaceWithNewInstances(DataTracker.java:312)\n   at org.apache.cassandra.io.sstable.SSTableRewriter.moveStarts(SSTableRewriter.java:341)\n   at org.apache.cassandra.io.sstable.SSTableRewriter.abort(SSTableRewriter.java:202)\n   at org.apache.cassandra.db.compaction.Scrubber.scrub(Scrubber.java:277)\n   at org.apache.cassandra.db.ScrubTest.testScrubCorruptedCounterRow(ScrubTest.java:152)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Unit test failures, trunk + Windows"
   },
   {
      "_id": "12786278",
      "assignee": "krummas",
      "components": [],
      "created": "2015-03-27 18:12:10",
      "description": "When using DTCS, tombstoned sstables past max_sstable_age_days are not removed by minor compactions. I was able to reproduce this manually and also wrote a dtest (currently failing) which reproduces this issue: [dtcs_deletion_test|https://github.com/riptano/cassandra-dtest/blob/master/compaction_test.py#L115] in compaction_test.py. I tried applying the patch in CASSANDRA-8359 but found that the test still fails with the same issue.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "dtcs",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Tombstoned SSTables are not removed past max_sstable_age_days when using DTCS"
   },
   {
      "_id": "12785472",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320019",
            "id": "12320019",
            "name": "Local/Config",
            "description": "Configuration and environment"
         }
      ],
      "created": "2015-03-25 10:24:47",
      "description": "As discussed in CASSANDRA-6157, at the moment we have a single parameter {{hinted_handoff_enabled}} that can be either a boolean or a csv list of enabled data centers.\n\nWe should have a boolean global {{hinted_handoff_enabled}} param plus a separate yaml list for the HH DC blacklist - {{hinted_handoff_disabled_datacenters}} to be checked when the global flag is on.\n\nBackward compatibility with the existing approach should be kept.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix hinted_handoff_enabled yaml setting"
   },
   {
      "_id": "12783395",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2015-03-19 21:50:19",
      "description": "Stress has some very basic validation functionality when used without workload profiles. It found a bug on trunk when I first ran it so it has value even though the validation is basic.\n\nAs a beachhead for the kind of blackbox validation that we are missing we can start by running stress nightly or 24/7 in some rotation.\n\nThere should be two jobs. One job has inverted success criteria (C* should lose some data) and the job should only \"pass\" if the failure is detected. This is just to prove that the harness reports failure if failure occurs.\n\nAnother would be the real job that runs stress, parses and parses the output for reports of missing data.\n\nThis job is the first pass and basis of what we can point to when a developer makes a change, implements a feature, or fixes a bug, and say \"go add validation to this job.\"\n\nFollow on tickets to link to this\n* Test multiple configurations\n* Get stress to validate more query functionality and APIs (counters, LWT, batches)\n* Parse logs and fail tests on error level logs (great way to improve log messages over time)\n* ?\n\nI am going to hold off on creating a ton of issues until we have a basic version of the job running.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "LWT",
         "monthly-release"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Run stress nightly against trunk in a way that validates"
   },
   {
      "_id": "12781556",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-03-12 17:08:03",
      "description": "Platform specific failures:\norg.apache.cassandra.io.sstable.SSTableRewriterTest.testNumberOfFiles_truncate\norg.apache.cassandra.io.sstable.SSTableRewriterTest.testSmallFiles\norg.apache.cassandra.io.sstable.SSTableRewriterTest.testNumberOfFiles_dont_clean_readers\norg.apache.cassandra.io.sstable.SSTableRewriterTest.testNumberOfFiles_finish_empty_new_writer\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix SSTableRewriterTest on Windows"
   },
   {
      "_id": "12781378",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-03-12 01:15:25",
      "description": "Once the python driver supports it, https://datastax-oss.atlassian.net/browse/PYTHON-235, add the client to cqlsh {{SHOW_SESSION}} as done in this commit:\n\nhttps://github.com/apache/cassandra/commit/249f79d3718fa05347d60e09f9d3fa15059bd3d3\n\nAlso, update the bundled python driver.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add client to cqlsh SHOW_SESSION"
   },
   {
      "_id": "12781304",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-03-11 19:55:52",
      "description": "There are a few places within the code base where we use a RandomAccessFile transiently to either grab fd's or channels for other operations. This is prone to access violations on Windows (see CASSANDRA-4050 and CASSANDRA-8709) - while these usages don't appear to be causing issues at this time there's no reason to keep them. The less RandomAccessFile usage in the code-base the more stable we'll be on Windows.\n\n[SSTableReader.dropPageCache|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/io/sstable/format/SSTableReader.java#L2021]\n* Used to getFD, have FileChannel version\n\n[FileUtils.truncate|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/io/util/FileUtils.java#L188]\n* Used to get file channel for channel truncate call. Only use is in index file close so channel truncation down-only is acceptable.\n\n[MMappedSegmentedFile.createSegments|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/io/util/MmappedSegmentedFile.java#L196]\n* Used to get file channel for mapping.\n\nKeeping these in a single ticket as all three should be fairly trivial refactors.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Remove transient RandomAccessFile usage"
   },
   {
      "_id": "12780574",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-03-09 18:44:46",
      "description": "In using the COPY command as follows:\n{{cqlsh -e \"COPY test.test1mb(pkey, ccol, data) FROM 'in/data1MB/data1MB_9.csv'\"}}\nthe following error is thrown:\n{{<stdin>:1:field larger than field limit (131072)}}\n\nThe data file contains a field that is greater than 128KB (it's more like almost 1MB).\n\nA work-around (thanks to [~jjordan] and [~thobbs] is to modify the cqlsh script and add the line\n{{csv.field_size_limit(1000000000)}}\nanywhere after the line\n{{import csv}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "COPY command has inherent 128KB field size limit"
   },
   {
      "_id": "12779756",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-03-05 10:03:14",
      "description": "Currently we look up the maxPurgeableTimestamp in LazilyCompactedRow constructor, we should only do that if we have to (ie, if we know there is a tombstone to possibly drop)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't lookup maxPurgeableTimestamp unless we need to"
   },
   {
      "_id": "12779092",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-03-03 15:00:53",
      "description": "A large contributor to slower buffered reads than mmapped is likely that we read a full 64Kb at once, when average record sizes may be as low as 140 bytes on our stress tests. The TLB has only 128 entries on a modern core, and each read will touch 32 of these, meaning we are unlikely to almost ever be hitting the TLB, and will be incurring at least 30 unnecessary misses each time (as well as the other costs of larger than necessary accesses). When working with an SSD there is little to no benefit reading more than 4Kb at once, and in either case reading more data than we need is wasteful. So, I propose selecting a buffer size that is the next larger power of 2 than our average record size (with a minimum of 4Kb), so that we expect to read in one operation. I also propose that we create a pool of these buffers up-front, and that we ensure they are all exactly aligned to a virtual page, so that the source and target operations each touch exactly one virtual page per 4Kb of expected record size.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "benedict-to-commit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Our default buffer size for (uncompressed) buffered reads should be smaller, and based on the expected record size"
   },
   {
      "_id": "12779090",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-03-03 14:54:02",
      "description": "There's no good reason to open a FileChannel for each \\(Compressed\\)\\?RandomAccessReader, and this would simplify RandomAccessReader to just a thin wrapper.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "RandomAccessReader should share its FileChannel with all instances (via SegmentedFile)"
   },
   {
      "_id": "12776445",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-02-20 13:49:13",
      "description": "In CASSANDRA-8623, we fix an issue about getting \"Data component is missing\" errors when splitting multiple sstable one at the time. I wrote a dtest for that, which work properly to test that error. However, it seems that the CompactionExecutor is failing. It's not the same error, but looks related.  \n\nTest: https://github.com/riptano/cassandra-dtest/blob/master/sstablesplit_test.py#L68\n\nOutput: http://cassci.datastax.com/job/cassandra-2.1_dtest/726/testReport/junit/sstablesplit_test/TestSSTableSplit/single_file_split_test/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "single_file_split_test fails on 2.1"
   },
   {
      "_id": "12775794",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-02-18 02:05:37",
      "description": "We have two DC3, each with 7 nodes.\nHere is the keyspace setup:\n\n create keyspace test\n with placement_strategy = 'NetworkTopologyStrategy'\n and strategy_options = {DC2 : 3, DC1 : 3}\n and durable_writes = true;\n\nWe brought down two nodes in DC2 for maintenance. We only write to DC1 using local_quroum (using datastax JavaClient)\nBut we see this errors in the log:\nCassandra timeout during write query at consistency LOCAL_QUORUM (4 replica were required but only 3 acknowledged the write\nwhy does it say 4 replica were required? and Why would it give error back to client since local_quorum should succeed.\n\nHere are the output from nodetool status\n\nNote: Ownership information does not include topology; for complete information, specify a keyspace\nDatacenter: DC2\n===============\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address      Load       Tokens  Owns   Host ID                               Rack\nUN  10.2.0.1  10.92 GB   256     7.9%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC206\nUN  10.2.0.2   6.17 GB    256     8.0%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC106\nUN  10.2.0.3  6.63 GB    256     7.3%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC107\nDL  10.2.0.4  1.54 GB    256     7.7%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX RAC107\nUN  10.2.0.5  6.02 GB    256     6.6%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC106\nUJ  10.2.0.6   3.68 GB    256     ?      XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC205\nUN  10.2.0.7  7.22 GB    256     7.7%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX RAC205\nDatacenter: DC1\n===============\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address      Load       Tokens  Owns   Host ID                               Rack\nUN  10.1.0.1   6.04 GB    256     8.6%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX RAC10\nUN  10.1.0.2   7.55 GB    256     7.4%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC8\nUN  10.1.0.3   5.83 GB    256     7.0%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC9\nUN  10.1.0.4    7.34 GB    256     7.9%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC6\nUN  10.1.0.5   7.57 GB    256     8.0%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX RAC7\nUN  10.1.0.6   5.31 GB    256     7.3%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX  RAC10\nUN  10.1.0.7   5.47 GB    256     8.6%   XXXXXXXXXXXXXXXXXXXXXXXXXXXX RAC9\n\nI did a cql trace on the query and here is the trace, and it does say \n   Write timeout; received 3 of 4 required replies | 17:27:52,831 |  10.1.0.1 |        2002873\n\nat the end. I guess that is where the client gets the error from. But the rows was inserted to Cassandra correctly. And I traced read with local_quorum and it behaves correctly and the reads don't go to DC2. The problem is only with writes on local_quorum.\n{code}\nTracing session: 5a789fb0-b70d-11e4-8fca-99bff9c19890\n\n activity                                                                                                                                    | timestamp    | source      | source_elapsed\n---------------------------------------------------------------------------------------------------------------------------------------------+--------------+-------------+----------------\n                                                                                                                          execute_cql3_query | 17:27:50,828 |  10.1.0.1 |              0\n Parsing insert into test (user_id, created, event_data, event_id)values ( 123456789 , 9eab8950-b70c-11e4-8fca-99bff9c19891, 'test', '16'); | 17:27:50,828 |  10.1.0.1 |             39\n                                                                                                                         Preparing statement | 17:27:50,828 |  10.1.0.1 |            135\n                                                                                                           Message received from /10.1.0.1 | 17:27:50,829 |  10.1.0.5 |             25\n                                                                                                              Sending message to /10.1.0.5 | 17:27:50,829 |  10.1.0.1 |            421\n                                                                                                   Executing single-partition query on users | 17:27:50,829 |  10.1.0.5 |            177\n                                                                                                                Acquiring sstable references | 17:27:50,829 |  10.1.0.5 |            191\n                                                                                                                 Merging memtable tombstones | 17:27:50,830 |  10.1.0.5 |            208\n                                                                                                           Message received from /10.1.0.5 | 17:27:50,830 |  10.1.0.1 |           1461\n                                                                                                           Message received from /10.1.0.1 | 17:27:50,830 |  10.1.0.2 |             14\n                                                                                                                 Key cache hit for sstable 1 | 17:27:50,830 |  10.1.0.5 |            254\n                                                                                                        Processing response from /10.1.0.5 | 17:27:50,830 |  10.1.0.1 |           1514\n                                                                                                   Executing single-partition query on users | 17:27:50,830 |  10.1.0.2 |             78\n                                                                                                 Seeking to partition beginning in data file | 17:27:50,830 |  10.1.0.5 |            264\n                                                                                                              Sending message to /10.1.0.2 | 17:27:50,830 |  10.1.0.1 |           1517\n                                                                                                                Acquiring sstable references | 17:27:50,830 |  10.1.0.2 |             85\n                                                                   Skipped 0/1 non-slice-intersecting sstables, included 0 due to tombstones | 17:27:50,830 |  10.1.0.5 |            453\n                                                                                                           Determining replicas for mutation | 17:27:50,830 |  10.1.0.1 |           1746\n                                                                                                                 Merging memtable tombstones | 17:27:50,830 |  10.1.0.2 |             97\n                                                                                                  Merging data from memtables and 1 sstables | 17:27:50,830 |  10.1.0.5 |            476\n                                                                                                           Message received from /10.1.0.2 | 17:27:50,830 |  10.1.0.1 |           2369\n                                                                                                                 Key cache hit for sstable 2 | 17:27:50,830 |  10.1.0.2 |            120\n                                                                                                          Read 1 live and 0 tombstoned cells | 17:27:50,830 |  10.1.0.5 |            506\n                                                                                                 Seeking to partition beginning in data file | 17:27:50,830 |  10.1.0.2 |            123\n                                                                                                           Enqueuing response to /10.1.0.1 | 17:27:50,830 |  10.1.0.5 |            570\n                                                                   Skipped 0/1 non-slice-intersecting sstables, included 0 due to tombstones | 17:27:50,830 |  10.1.0.2 |            288\n                                                                                                              Sending message to /10.1.0.1 | 17:27:50,830 |  10.1.0.5 |            617\n                                                                                                  Merging data from memtables and 1 sstables | 17:27:50,830 |  10.1.0.2 |            297\n                                                                                                          Read 1 live and 0 tombstoned cells | 17:27:50,830 |  10.1.0.2 |            319\n                                                                                                           Enqueuing response to /10.1.0.1 | 17:27:50,830 |  10.1.0.2 |            362\n                                                                                                              Sending message to /10.1.0.1 | 17:27:50,830 |  10.1.0.2 |            420\n                                                                                                           Message received from /10.1.0.1 | 17:27:50,831 |   10.1.0.4 |             17\n                                                                                                              Sending message to /10.1.0.2 | 17:27:50,831 |  10.1.0.1 |           2435\n                                                                                                           Message received from /10.1.0.1 | 17:27:50,831 |  10.1.0.2 |              8\n                                                                                                              Acquiring switchLock read lock | 17:27:50,831 |   10.1.0.4 |             61\n                                                                                                        Processing response from /10.1.0.2 | 17:27:50,831 |  10.1.0.1 |           2488\n                                                                                                              Acquiring switchLock read lock | 17:27:50,831 |  10.1.0.2 |             44\n                                                                                                                      Appending to commitlog | 17:27:50,831 |   10.1.0.4 |             78\n                                                                                    Not hinting /10.2.0.4 which has been down 364809650ms | 17:27:50,831 |  10.1.0.1 |           2503\n                                                                                                                      Appending to commitlog | 17:27:50,831 |  10.1.0.2 |             62\n                                                                                                                    Adding to event memtable | 17:27:50,831 |   10.1.0.4 |             96\n                                                                                                               Sending message to /10.1.0.4 | 17:27:50,831 |  10.1.0.1 |           2557\n                                                                                                                    Adding to event memtable | 17:27:50,831 |  10.1.0.2 |             80\n                                                                                                           Enqueuing response to /10.1.0.1 | 17:27:50,831 |   10.1.0.4 |            177\n                                                                                                              Acquiring switchLock read lock | 17:27:50,831 |  10.1.0.1 |           2669\n                                                                                                           Enqueuing response to /10.1.0.1 | 17:27:50,831 |  10.1.0.2 |            160\n                                                                                                              Sending message to /10.1.0.1 | 17:27:50,831 |   10.1.0.4 |            333\n                                                                                                                      Appending to commitlog | 17:27:50,831 |  10.1.0.1 |           2682\n                                                                                                              Sending message to /10.1.0.1 | 17:27:50,831 |  10.1.0.2 |            266\n                                                                                                                    Adding to event memtable | 17:27:50,831 |  10.1.0.1 |           2720\n                                                                                                             Sending message to /10.2.0.5 | 17:27:50,831 |  10.1.0.1 |           2758\n                                                                                                           Message received from /10.1.0.2 | 17:27:50,831 |  10.1.0.1 |           2989\n                                                                                                        Processing response from /10.1.0.2 | 17:27:50,831 |  10.1.0.1 |           3024\n                                                                                                            Message received from /10.1.0.4 | 17:27:50,832 |  10.1.0.1 |           3764\n                                                                                                         Processing response from /10.1.0.4 | 17:27:50,832 |  10.1.0.1 |           3805\n                                                                                                           Message received from /10.1.0.1 | 17:27:50,841 | 10.2.0.5 |             24\n                                                                                                   Enqueuing forwarded write to /10.2.0.7 | 17:27:50,841 | 10.2.0.5 |            255\n                                                                                                   Enqueuing forwarded write to /10.2.0.3 | 17:27:50,841 | 10.2.0.5 |            283\n                                                                                                    Enqueuing forwarded write to /10.2.0.6 | 17:27:50,841 | 10.2.0.5 |            307\n                                                                                                              Acquiring switchLock read lock | 17:27:50,841 | 10.2.0.5 |            362\n                                                                                                                      Appending to commitlog | 17:27:50,841 | 10.2.0.5 |            380\n                                                                                                             Sending message to /10.2.0.7 | 17:27:50,841 | 10.2.0.5 |            382\n                                                                                                                    Adding to event memtable | 17:27:50,841 | 10.2.0.5 |            411\n                                                                                                              Sending message to /10.2.0.6 | 17:27:50,841 | 10.2.0.5 |            429\n                                                                                                           Enqueuing response to /10.1.0.1 | 17:27:50,841 | 10.2.0.5 |            484\n                                                                                                             Sending message to /10.2.0.3 | 17:27:50,841 | 10.2.0.5 |            561\n                                                                                                              Sending message to /10.1.0.1 | 17:27:50,841 | 10.2.0.5 |            625\n                                                                                                              Acquiring switchLock read lock | 17:27:50,842 |  10.2.0.6 |           1031\n                                                                                                              Acquiring switchLock read lock | 17:27:50,842 | 10.2.0.7 |            178\n                                                                                                                      Appending to commitlog | 17:27:50,842 |  10.2.0.6 |           1066\n                                                                                                                      Appending to commitlog | 17:27:50,842 | 10.2.0.7 |            196\n                                                                                                                    Adding to event memtable | 17:27:50,842 |  10.2.0.6 |           1118\n                                                                                                                    Adding to event memtable | 17:27:50,842 | 10.2.0.7 |            231\n                                                                                                           Enqueuing response to /10.1.0.1 | 17:27:50,842 |  10.2.0.6 |           1181\n                                                                                                           Enqueuing response to /10.1.0.1 | 17:27:50,842 | 10.2.0.7 |            286\n                                                                                                              Sending message to /10.1.0.1 | 17:27:50,842 | 10.2.0.7 |            421\n                                                                                                              Acquiring switchLock read lock | 17:27:50,843 | 10.2.0.3 |           1216\n                                                                                                              Sending message to /10.1.0.1 | 17:27:50,843 |  10.2.0.6 |           1382\n                                                                                                                      Appending to commitlog | 17:27:50,843 | 10.2.0.3 |           1239\n                                                                                                                    Adding to event memtable | 17:27:50,843 | 10.2.0.3 |           1313\n                                                                                                           Enqueuing response to /10.1.0.1 | 17:27:50,843 | 10.2.0.3 |           1407\n                                                                                                              Sending message to /10.1.0.1 | 17:27:50,843 | 10.2.0.3 |           1631\n                                                                                                          Message received from /10.2.0.5 | 17:27:50,851 |  10.1.0.1 |          23333\n                                                                                                       Processing response from /10.2.0.5 | 17:27:50,851 |  10.1.0.1 |          23380\n                                                                                                          Message received from /10.2.0.7 | 17:27:50,852 |  10.1.0.1 |          23908\n                                                                                                       Processing response from /10.2.0.7 | 17:27:50,852 |  10.1.0.1 |          23953\n                                                                                                           Message received from /10.2.0.6 | 17:27:50,853 |  10.1.0.1 |          25143\n                                                                                                        Processing response from /10.2.0.6 | 17:27:50,853 |  10.1.0.1 |          25178\n                                                                                                          Message received from /10.2.0.3 | 17:27:50,854 |  10.1.0.1 |          25478\n                                                                                                       Processing response from /10.2.0.3 | 17:27:50,854 |  10.1.0.1 |          25516\n                                                                                             Write timeout; received 3 of 4 required replies | 17:27:52,831 |  10.1.0.1 |        2002873\n                                                                                                                            Request complete | 17:27:52,833 |  10.1.0.1 |        2005989\n{code}\ncqlsh:XXXX> CONSISTENCY\nCurrent consistency level is LOCAL_QUORUM.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "LOCAL_QUORUM writes returns wrong message"
   },
   {
      "_id": "12772443",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-02-04 18:12:40",
      "description": "When picking compaction candidates in LCS, we check that we won't cause any overlap in the higher level. Problem is that we compare the files that have had their start positions moved meaning we can cause overlap. We need to also include the tmplink files when checking this.\n\nNote that in 2.1 overlap is not as big problem as earlier, if adding an sstable would cause overlap, we send it back to L0 instead, meaning we do a bit more compaction but we never actually have overlap.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't check for overlap with sstables that have had their start positions moved in LCS"
   },
   {
      "_id": "12771386",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2015-01-30 17:58:59",
      "description": "For non-mmap'ed I/O on Windows, using nio channels will give us substantially more flexibility w/regards to renaming and moving files around while writing them.  This change in conjunction with CASSANDRA-4050 should allow us to remove the Windows bypass code in SSTableRewriter for non-memory-mapped I/O.\n\nIn general, migrating from instances of RandomAccessFile to nio channels will help make Windows and linux behavior more consistent.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Convert SequentialWriter from using RandomAccessFile to nio channel"
   },
   {
      "_id": "12768797",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-01-20 21:19:43",
      "description": "LongLeveledCompactionStrategyTest periodically fails with:\n{noformat}\n    [junit] Testsuite: org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest\n    [junit] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 54.412 sec\n    [junit] \n    [junit] Testcase: testParallelLeveledCompaction(org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest):      Caused an ERROR\n    [junit] java.util.concurrent.ExecutionException: java.lang.RuntimeException: Last written key DecoratedKey(3133, 3133) >= current key DecoratedKey(313236, 313236) writing into build/test/cassandra/data/Keyspace1/StandardLeveled/Keyspace1-StandardLeveled-tmp-jb-304-Data.db\n    [junit] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Last written key DecoratedKey(3133, 3133) >= current key DecoratedKey(313236, 313236) writing into build/test/cassandra/data/Keyspace1/StandardLeveled/Keyspace1-StandardLeveled-tmp-jb-304-Data.db\n    [junit]     at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:413)\n    [junit]     at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:402)\n    [junit]     at org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest.testParallelLeveledCompaction(LongLeveledCompactionStrategyTest.java:97)\n    [junit] Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Last written key DecoratedKey(3133, 3133) >= current key DecoratedKey(313236, 313236) writing into build/test/cassandra/data/Keyspace1/StandardLeveled/Keyspace1-StandardLeveled-tmp-jb-304-Data.db\n    [junit]     at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n    [junit]     at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n    [junit]     at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:409)\n    [junit] Caused by: java.lang.RuntimeException: Last written key DecoratedKey(3133, 3133) >= current key DecoratedKey(313236, 313236) writing into build/test/cassandra/data/Keyspace1/StandardLeveled/Keyspace1-StandardLeveled-tmp-jb-304-Data.db\n    [junit]     at org.apache.cassandra.io.sstable.SSTableWriter.beforeAppend(SSTableWriter.java:143)\n    [junit]     at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:166)\n    [junit]     at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:167)\n    [junit]     at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n    [junit]     at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:60)\n    [junit]     at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59)\n    [junit]     at org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest$1.run(LongLeveledCompactionStrategyTest.java:87)\n    [junit]     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    [junit]     at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    [junit]     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    [junit]     at java.lang.Thread.run(Thread.java:745)\n    [junit] \n    [junit] \n    [junit] Test org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest FAILED\n{noformat}\n\nI would guess the failure is 10-20% of the time, looping over the test repeatedly.\n\n----\n\nOn the 2.1 branch, the failure is different, so perhaps this could also be updated.\n{noformat}\n    [junit] Testsuite: org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest\n    [junit] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 7.04 sec\n    [junit] \n    [junit] Testcase: testParallelLeveledCompaction(org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest):      Caused an ERROR\n    [junit] org.apache.cassandra.db.compaction.WrappingCompactionStrategy cannot be cast to org.apache.cassandra.db.compaction.LeveledCompactionStrategy\n    [junit] java.lang.ClassCastException: org.apache.cassandra.db.compaction.WrappingCompactionStrategy cannot be cast to org.apache.cassandra.db.compaction.LeveledCompactionStrategy\n    [junit]     at org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest.testParallelLeveledCompaction(LongLeveledCompactionStrategyTest.java:45)\n    [junit] \n    [junit] \n    [junit] Test org.apache.cassandra.db.compaction.LongLeveledCompactionStrategyTest FAILED\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "long-test LongLeveledCompactionStrategyTest flaps in 2.0"
   },
   {
      "_id": "12767804",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-01-15 18:45:33",
      "description": "When node is doing a lot of sequencial IO (streaming, compacting, etc) a lot of CPU is lost in calls to RAF's int read() and DataOutputStream's write(int).\nThis is because default implementations of readShort,readLong, etc as well as their matching write* are implemented with numerous calls of byte by byte read and write. \nThis makes a lot of syscalls as well.\n\nA quick microbench shows than just reimplementation of these methods in either way gives 8x speed increase.\n\nA patch attached implements RandomAccessReader.read<Type> and SequencialWriter.write<Type> methods in more efficient way.\nI also eliminated some extra byte copies in CompositeType.split and ColumnNameHelper.maxComponents, which were on my profiler's hotspot method list during tests.\n\nA stress tests on my laptop show that this patch makes compaction 25-30% faster  on uncompressed sstables and 15% faster for compressed ones.\n\nA deployment to production shows much less CPU load for compaction. \n(I attached a cpu load graph from one of our production, orange is niced CPU load - i.e. compaction; yellow is user - i.e. not compaction related tasks)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Faster sequential IO (on compaction, streaming, etc)"
   },
   {
      "_id": "12767650",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2015-01-15 03:40:43",
      "description": "I'm experiencing an issue related to sstablesplit. I would like to understand if I am doing something wrong or there is an issue in the split process. The process fails randomly with the following exception:\n{code}\nERROR 02:17:36 Error in ThreadPoolExecutor\njava.lang.AssertionError: Data component is missing for sstable./tools/bin/../../data/data/system/compactions_in_progress-55080ab05d9c388690a4acb25fe1f77b/system-compactions_in_progress-ka-16\n{code}\n\nSee attached output.log file. The process never stops after this exception and I've also seen the dataset growing indefinitely (number of sstables).  \n\n* I have not been able to reproduce the issue with a single sstablesplit command. ie, specifying all files with glob matching.\n* I can reproduce the bug if I call multiple sstablesplit one file at the time (the way ccm does)\n\nHere is the test case file to reproduce the bug:\n\nhttps://drive.google.com/file/d/0BwZ_GPM33j6KdVh0NTdkOWV2R1E/view?usp=sharing\n\n1. Download the split_issue.tar.gz file. It includes latest cassandra-2.1 branch binaries.\n2. Extract it\n3. CD inside the use case directory\n4. Download the dataset (2G) just to be sure we have the same thing, and place it in the working directory.\n   https://docs.google.com/uc?id=0BwZ_GPM33j6KV3ViNnpPcVFndUU&export=download\n5. The first time, run ./test.sh. This will setup and run a test.\n6. The next times, you can only run ./test --no-setup . This will only reset the dataset as its initial state and re-run the test. You might have to run the tests some times before experiencing it... but I'm always able with only 2-3 runs.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "sstablesplit fails *randomly* with Data component is missing"
   },
   {
      "_id": "12766905",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2015-01-12 18:16:26",
      "description": "Right at the top of the test, we see:\n\n{noformat}\n    [junit] ERROR 18:15:05 Unable to delete build\\test\\cassandra\\data;0\\SSTableRewriterTest\\Standard1-e63f49c09a8611e4bebb8ff5e6ab1035\\tmplink-la-27-big-Data.db (it will be removed on server restart; we'll also retry after GC)\n    [junit] ERROR 18:15:05 Unable to delete build\\test\\cassandra\\data;0\\SSTableRewriterTest\\Standard1-e63f49c09a8611e4bebb8ff5e6ab1035\\tmplink-la-27-big-Data.db (it will be removed on server restart; we'll also retry after GC)\n    [junit] ------------- ---------------- ---------------\n    [junit] Testcase: testFileRemoval(org.apache.cassandra.io.sstable.SSTableRewriterTest):     FAILED\n    [junit] expected:<0> but was:<2>\n    [junit] junit.framework.AssertionFailedError: expected:<0> but was:<2>\n    [junit]     at org.apache.cassandra.io.sstable.SSTableRewriterTest.assertFileCounts(SSTableRewriterTest.java:758)\n    [junit]     at org.apache.cassandra.io.sstable.SSTableRewriterTest.testFileRemoval(SSTableRewriterTest.java:229)\n{noformat}\n\nThe rest cascade after that.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows - SSTableRewriterTest fails on trunk"
   },
   {
      "_id": "12765749",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-01-08 12:03:08",
      "description": "During our upgrade of Cassandra from version 2.0.7 to 2.1.2 we experienced a serious problem regarding the setting unchecked_tombstone_compaction in combination with leveled compaction strategy.\n\nIn order to prevent tombstone-threshold-warnings we activated the setting for a specific table after the upgrade. Some time after that we observed new errors in our log files:\n{code}\nINFO  [CompactionExecutor:184] 2014-12-11 12:36:06,597 CompactionTask.java:136 - Compacting [SSTableReader(path='/data/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-ka-1848-Data.db'), SSTableReader(path='/\ndata/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-ka-1847-Data.db'), SSTableReader(path='/data/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-ka-1845-Data.db'), SSTableReader\n(path='/data/cassandra/data/system/compactions_in_progress/system-compactions_in_progress-ka-1846-Data.db')]\nERROR [CompactionExecutor:183] 2014-12-11 12:36:06,613 CassandraDaemon.java:153 - Exception in thread Thread[CompactionExecutor:183,1,main]\njava.lang.AssertionError: /data/cassandra/data/metrigo_prod/new_user_data/metrigo_prod-new_user_data-tmplink-ka-705732-Data.db\n        at org.apache.cassandra.io.sstable.SSTableReader.getApproximateKeyCount(SSTableReader.java:243) ~[apache-cassandra-2.1.2.jar:2.1.2]\n        at org.apache.cassandra.db.compaction.CompactionTask.runWith(CompactionTask.java:146) ~[apache-cassandra-2.1.2.jar:2.1.2]\n        at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:48) ~[apache-cassandra-2.1.2.jar:2.1.2]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-2.1.2.jar:2.1.2]\n        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:75) ~[apache-cassandra-2.1.2.jar:2.1.2]\n        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59) ~[apache-cassandra-2.1.2.jar:2.1.2]\n        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:232) ~[apache-cassandra-2.1.2.jar:2.1.2]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_45]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_45]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_45]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_45]\n        at java.lang.Thread.run(Thread.java:744) [na:1.7.0_45]\n        {code}\nObviously that error aborted the compaction and after some time the number of pending compactions became very high on every node. Of course, this in turn had a negative impact on several other metrics.\n\nAfter reverting the setting we had to restart all nodes. After that compactions could finish again and the pending compactions could be worked off.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "AssertionErrors after activating unchecked_tombstone_compaction with leveled compaction"
   },
   {
      "_id": "12764841",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2015-01-05 05:19:50",
      "description": "When running with high amount of tombstones the error message generation from CASSANDRA-6117 can lead to out of memory situation with the default setting.\n\nAttached a heapdump viewed in visualvm showing how this construct created two 777mb strings to print the error message for a read query and then crashed OOM.\n\n{code}\n        if (respectTombstoneThresholds() && columnCounter.ignored() > DatabaseDescriptor.getTombstoneWarnThreshold())\n        {\n            StringBuilder sb = new StringBuilder();\n            CellNameType type = container.metadata().comparator;\n            for (ColumnSlice sl : slices)\n            {\n                assert sl != null;\n\n                sb.append('[');\n                sb.append(type.getString(sl.start));\n                sb.append('-');\n                sb.append(type.getString(sl.finish));\n                sb.append(']');\n            }\n\n            logger.warn(\"Read {} live and {} tombstoned cells in {}.{} (see tombstone_warn_threshold). {} columns was requested, slices={}, delInfo={}\",\n                        columnCounter.live(), columnCounter.ignored(), container.metadata().ksName, container.metadata().cfName, count, sb, container.deletionInfo());\n        }\n{code}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tombstone"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "OOM caused by large tombstone warning."
   },
   {
      "_id": "12764771",
      "assignee": "slebresne",
      "components": [],
      "created": "2015-01-04 09:40:08",
      "description": "first\n{code}CREATE  KEYSPACE space1 WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3};\nCREATE  TABLE space1.table3(a int, b int, c text,primary key(a,b));\nCREATE  KEYSPACE space2 WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3};{code}\nsecond\n{code}CREATE  TABLE space2.table1(a int, b int, c int, primary key(a,b));\nCREATE  TABLE space2.table2(a int, b int, c int, primary key(a,b));\nINSERT INTO space1.table3(a,b,c) VALUES(1,1,'1');\ndrop table space2.table1;\nDELETE FROM space1.table3 where a=1 and b=1;\ndrop table space2.table2;\nselect * from space1.table3 where a=1 and b=1;{code}\n\nyou will find that the row (a=1 and b=1)  in space1.table3 is not deleted.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "deleted row still can be selected out"
   },
   {
      "_id": "12764439",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2015-01-01 00:13:16",
      "description": "This occurs on both 2.1 and trunk on Windows.\n\nThe error is as follows:\n{noformat}\nERROR 21:42:48 Fatal exception in thread Thread[CompactionExecutor:3,1,main]\njava.lang.RuntimeException: Failed to rename build\\test\\cassandra\\data;0\\system\\schema_columns-296e9c049bec3085827dc17d3df2122a\\system-schema_columns-tmp-ka-10-Index.db to build\\test\\cassandra\\data;0\\system\\schema_columns-296e9c049bec3085827dc17d3df2122a\\system-schema_columns-ka-10-Index.db\nat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:170) ~[main/:na]\nat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:154) ~[main/:na]\nat org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.java:569) ~[main/:na]\nat org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.java:561) ~[main/:na]\nat org.apache.cassandra.io.sstable.SSTableWriter.close(SSTableWriter.java:535) ~[main/:na]\nat org.apache.cassandra.io.sstable.SSTableWriter.finish(SSTableWriter.java:470) ~[main/:na]\nat org.apache.cassandra.io.sstable.SSTableRewriter.finishAndMaybeThrow(SSTableRewriter.java:349) ~[main/:na]\nat org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewriter.java:324) ~[main/:na]\nat org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewriter.java:304) ~[main/:na]\nat org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:201) ~[main/:na]\nat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\nat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:75) ~[main/:na]\nat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59) ~[main/:na]\nat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:226) ~[main/:na]\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_71]\nat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_71]\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_71]\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_71]\nat java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]\nCaused by: java.nio.file.FileSystemException: build\\test\\cassandra\\data;0\\system\\schema_columns-296e9c049bec3085827dc17d3df2122a\\system-schema_columns-tmp-ka-10-Index.db -> build\\test\\cassandra\\data;0\\system\\schema_columns-296e9c049bec3085827dc17d3df2122a\\system-schema_columns-ka-10-Index.db: The process cannot access the file because it is being used by another process.\n{noformat}\n\nThe rename operation from -tmp to final sstable name fails on Windows as something still has a handle open to the file.  This occurs during unit tests only so marking as minor, but it's incredibly noisy so it's best to fix it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows - Failure to rename file during compaction - unit test only"
   },
   {
      "_id": "12764055",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-12-29 17:51:48",
      "description": "I would like to propose a change of the data structure used in the RangeTombstoneList to store and insert tombstone ranges to something with at least O(log N) insert in the middle and at near O(1) and start AND end. Here is why:\n\nWhen having tombstone heavy work-loads the current implementation of RangeTombstoneList becomes a bottleneck with slice queries.\n\nScanning the number of tombstones up to the default maximum (100k) can take up to 3 minutes of how addInternal() scales on insertion of middle and start elements.\n\nThe attached test shows that with 50k deletes from both sides of a range.\n\nINSERT 1...110000\nflush()\nDELETE 1...50000\nDELETE 110000...60000\n\nWhile one direction performs ok (~400ms on my notebook):\n{code}\nSELECT * FROM timeseries WHERE name = 'a' ORDER BY timestamp DESC LIMIT 1\n{code}\n\nThe other direction underperforms (~7seconds on my notebook)\n{code}\nSELECT * FROM timeseries WHERE name = 'a' ORDER BY timestamp ASC LIMIT 1\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tombstone"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "RangeTombstoneList becoming bottleneck on tombstone heavy tasks"
   },
   {
      "_id": "12764043",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328322",
            "id": "12328322",
            "name": "Local/Startup and Shutdown",
            "description": "Startup and Shutdown"
         }
      ],
      "created": "2014-12-29 16:29:27",
      "description": "It happens sometimes after restarts caused by undeletable files under Windows.\n\n{quote}\nCaused by: java.lang.NullPointerException\n    at org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:579)\n    at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:232)\n    at org.apache.cassandra.service.CassandraDaemon.init(CassandraDaemon.java:377)\n    at com.jetbrains.cassandra.service.CassandraServiceMain.start(CassandraServiceMain.java:81)\n    ... 6 more\n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Cassandra could not start with NPE in ColumnFamilyStore.removeUnfinishedCompactionLeftovers"
   },
   {
      "_id": "12763538",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2014-12-23 20:04:28",
      "description": "{code}\njava.lang.RuntimeException: Failed to rename build\\test\\cassandra\\data;0\\system\\schema_keyspaces-b0f2235744583cdb9631c43e59ce3676\\system-schema_keyspaces-tmp-ka-5-Index.db to build\\test\\cassandra\\data;0\\system\\schema_keyspaces-b0f2235744583cdb9631c43e59ce3676\\system-schema_keyspaces-ka-5-Index.db\n\tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:170) ~[main/:na]\n\tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:154) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.java:569) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.java:561) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.SSTableWriter.close(SSTableWriter.java:535) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.SSTableWriter.finish(SSTableWriter.java:470) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.SSTableRewriter.finishAndMaybeThrow(SSTableRewriter.java:349) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewriter.java:324) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewriter.java:304) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:200) ~[main/:na]\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:75) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59) ~[main/:na]\n\tat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:226) ~[main/:na]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_45]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_45]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_45]\n\tat java.lang.Thread.run(Thread.java:744) [na:1.7.0_45]\nCaused by: java.nio.file.FileSystemException: build\\test\\cassandra\\data;0\\system\\schema_keyspaces-b0f2235744583cdb9631c43e59ce3676\\system-schema_keyspaces-tmp-ka-5-Index.db -> build\\test\\cassandra\\data;0\\system\\schema_keyspaces-b0f2235744583cdb9631c43e59ce3676\\system-schema_keyspaces-ka-5-Index.db: The process cannot access the file because it is being used by another process.\n\n\tat sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86) ~[na:1.7.0_45]\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97) ~[na:1.7.0_45]\n\tat sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301) ~[na:1.7.0_45]\n\tat sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287) ~[na:1.7.0_45]\n\tat java.nio.file.Files.move(Files.java:1345) ~[na:1.7.0_45]\n\tat org.apache.cassandra.io.util.FileUtils.atomicMoveWithFallback(FileUtils.java:184) ~[main/:na]\n\tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:166) ~[main/:na]\n\t... 18 common frames omitted\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "java.lang.RuntimeException: Failed to rename XXX to YYY"
   },
   {
      "_id": "12761143",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-12-11 19:22:16",
      "description": "It appears that tables configured with LCS will completely re-compact themselves over some period of time after upgrading from 2.0 to 2.1 (2.0.11 -> 2.1.2, specifically). It starts out with <10 pending tasks for an hour or so, then starts building up, now with 50-100 tasks pending across the cluster after 12 hours. These nodes are under heavy write load, but were easily able to keep up in 2.0 (they rarely had >5 pending compaction tasks), so I don't think it's LCS in 2.1 actually being worse, just perhaps some different LCS behavior that causes the layout of tables from 2.0 to prompt the compactor to reorganize them?\n\nThe nodes flushed ~11MB SSTables under 2.0. They're currently flushing ~36MB SSTables due to the improved memtable setup in 2.1. Before I upgraded the entire cluster to 2.1, I noticed the problem and tried several variations on the flush size, thinking perhaps the larger tables in L0 were causing some kind of cascading compactions. Even if they're sized roughly like the 2.0 flushes were, same behavior occurs. I also tried both enabling & disabling STCS in L0 with no real change other than L0 began to back up faster, so I left the STCS in L0 enabled.\n\nTables are configured with 32MB sstable_size_in_mb, which was found to be an improvement on the 160MB table size for compaction performance. Maybe this is wrong now? Otherwise, the tables are configured with defaults. Compaction has been unthrottled to help them catch-up. The compaction threads stay very busy, with the cluster-wide CPU at 45% \"nice\" time. No nodes have completely caught up yet. I'll update JIRA with status about their progress if anything interesting happens.\n\nFrom a node around 12 hours ago, around an hour after the upgrade, with 19 pending compaction tasks:\nSSTables in each level: [6/4, 10, 105/100, 268, 0, 0, 0, 0, 0]\nSSTables in each level: [6/4, 10, 106/100, 271, 0, 0, 0, 0, 0]\nSSTables in each level: [1, 16/10, 105/100, 269, 0, 0, 0, 0, 0]\nSSTables in each level: [5/4, 10, 103/100, 272, 0, 0, 0, 0, 0]\nSSTables in each level: [4, 11/10, 105/100, 270, 0, 0, 0, 0, 0]\nSSTables in each level: [1, 12/10, 105/100, 271, 0, 0, 0, 0, 0]\nSSTables in each level: [1, 14/10, 104/100, 267, 0, 0, 0, 0, 0]\nSSTables in each level: [9/4, 10, 103/100, 265, 0, 0, 0, 0, 0]\n\nRecently, with 41 pending compaction tasks:\nSSTables in each level: [4, 13/10, 106/100, 269, 0, 0, 0, 0, 0]\nSSTables in each level: [4, 12/10, 106/100, 273, 0, 0, 0, 0, 0]\nSSTables in each level: [5/4, 11/10, 106/100, 271, 0, 0, 0, 0, 0]\nSSTables in each level: [4, 12/10, 103/100, 275, 0, 0, 0, 0, 0]\nSSTables in each level: [2, 13/10, 106/100, 273, 0, 0, 0, 0, 0]\nSSTables in each level: [3, 10, 104/100, 275, 0, 0, 0, 0, 0]\nSSTables in each level: [6/4, 11/10, 103/100, 269, 0, 0, 0, 0, 0]\nSSTables in each level: [4, 16/10, 105/100, 264, 0, 0, 0, 0, 0]\n\nMore information about the use case: writes are roughly uniform across these tables. The data is \"sharded\" across these 8 tables by key to improve compaction parallelism. Each node receives up to 75,000 writes/sec sustained at peak, and a small number of reads. This is a pre-production cluster that's being warmed up with new data, so the low volume of reads (~100/sec per node) is just from automatic sampled data checks, otherwise we'd just use STCS :)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Constant compaction under LCS"
   },
   {
      "_id": "12759729",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-12-05 17:12:25",
      "description": "After CASSANDRA-8004, the compaction strategy for a column family will not be instanceof LeveledCompactionStrategy (StandaloneScrubber.java:100), so we don't check the manifest.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Standalone Scrubber broken for LCS"
   },
   {
      "_id": "12759478",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-12-04 17:53:01",
      "description": "While using ccm with the current C* 2.1-HEAD code on Windows, I frequently see this exception.\n{code}[node1 ERROR] Exception calling \"BeginConnect\" with \"4\" argument(s): \"The requested address \nis not valid in its context\"\nAt \nD:\\jenkins\\workspace\\cassandra-2.1_dtest_win32\\cassandra\\bin\\cassandra.ps1:358 \nchar:9\n+         $connect = $tcpobject.BeginConnect($listenAddress, $port, $null, \n$null)\n+         \n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : NotSpecified: (:) [], MethodInvocationException\n    + FullyQualifiedErrorId : SocketException\n \nYou cannot call a method on a null-valued expression.\nAt \nD:\\jenkins\\workspace\\cassandra-2.1_dtest_win32\\cassandra\\bin\\cassandra.ps1:359 \nchar:9\n+         $wait = $connect.AsyncWaitHandle.WaitOne(25, $false)\n+         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : InvalidOperation: (:) [], RuntimeException\n    + FullyQualifiedErrorId : InvokeMethodOnNull{code}\n\nI have not yet seen this exception when psutil is not installed, but that may not be relevant, as I dont know how that could possibly matter.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Error during start up on windows"
   },
   {
      "_id": "12758861",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-12-02 10:46:05",
      "description": "Using days as the unit for max_sstable_age in DTCS might be too much, add option to set it in seconds",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting",
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Add option to set max_sstable_age in fractional days in DTCS"
   },
   {
      "_id": "12755926",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-11-17 21:43:42",
      "description": "Because we fall back to STCS for L0 when LCS gets behind, the sstables in L0 can get quite large during sustained periods of heavy writes.  This can result in large imbalances between data volumes when using JBOD support.  \n\nEventually these large files get broken up as L0 sstables are moved up into higher levels; however, because LCS only chooses a single volume on which to write all of the sstables created during a single compaction, the imbalance is persisted.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "LeveledCompactionStrategy should split large files across data directories when compacting"
   },
   {
      "_id": "12755467",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-11-14 20:02:10",
      "description": "The dtest sstablesplit_test.py has begun failing due to an incorrect number of sstables being created after running sstablesplit.\n\nhttp://cassci.datastax.com/job/cassandra-2.1_dtest/559/changes#detail1\nis the run where the failure began.\n\nIn 2.1.x, the test expects 7 sstables to be created after split, but instead 12 are being created. All of the data is there, and the sstables add up to the expected size, so this simply may be a change in default behavior. The test runs sstablesplit without the --size argument, and the default has not changed, so it is unexpected that the behavior would change in a minor point release.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "SStablesplit behavior changed"
   },
   {
      "_id": "12755154",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-11-13 20:34:51",
      "description": "{noformat}\n    [junit] [main] WARN org.apache.cassandra.repair.messages.RepairOption - Snapshot-based repair is not yet supported on Windows.  Reverting to parallel repair.\n    [junit] ------------- ---------------- ---------------\n    [junit] Testcase: testParseOptions(org.apache.cassandra.repair.messages.RepairOptionTest):  FAILED\n    [junit]\n    [junit] junit.framework.AssertionFailedError:\n    [junit]     at org.apache.cassandra.repair.messages.RepairOptionTest.testParseOptions(RepairOptionTest.java:45)\n{noformat}\n\nJust need to re-enable snapshot-based repairs on trunk on Windows (since that works)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows: RepairOptionTest fails on trunk"
   },
   {
      "_id": "12755148",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-11-13 20:20:01",
      "description": "We have four unit tests failing on trunk on Windows, all with FileSystemException's related to the SchemaLoader:\n\n{noformat}\n[junit] Test org.apache.cassandra.db.compaction.DateTieredCompactionStrategyTest FAILED\n[junit] Test org.apache.cassandra.cql3.ThriftCompatibilityTest FAILED\n[junit] Test org.apache.cassandra.io.sstable.SSTableRewriterTest FAILED\n[junit] Test org.apache.cassandra.repair.LocalSyncTaskTest FAILED\n{noformat}\n\nExample error:\n{noformat}\n    [junit] Caused by: java.nio.file.FileSystemException: build\\test\\cassandra\\commitlog;0\\CommitLog-5-1415908745965.log: The process cannot access the file because it is being used by another process.\n    [junit]\n    [junit]     at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)\n    [junit]     at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)\n    [junit]     at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)\n    [junit]     at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)\n    [junit]     at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)\n    [junit]     at java.nio.file.Files.delete(Files.java:1079)\n    [junit]     at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:125)\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows: Commitlog access violations on unit tests"
   },
   {
      "_id": "12754861",
      "assignee": "krummas",
      "components": [],
      "created": "2014-11-12 19:41:40",
      "description": "In old versions of cassandra (i.e. not trunk/3.0), when bootstrapping a new node, you will end up with a ton of files in L0 and it might be extremely painful to get LCS to compact into a new leveling\n\nWe could probably exploit the fact that we have many non-overlapping sstables in L0, and offline-bump those sstables into higher levels. It does not need to be perfect, just get the majority of the data into L1+ without creating overlaps.\n\nSo, suggestion is to create an offline tool that looks at the range each sstable covers and tries to bump it as high as possible in the leveling.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Create a tool that given a bunch of sstables creates a \"decent\" sstable leveling"
   },
   {
      "_id": "12753195",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-11-05 22:05:34",
      "description": "CASSANDRA-6910 introduced changes to the cqlsh function {{parse_for_table_meta}} that cause an error to be thrown whenever a query does not have its grammar defined in cql3handling.py. However, this is affecting queries that are legitimate cql syntax and are accepted by Cassandra, but aren't defined in cqlsh. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "parse_for_table_meta errors out on queries with undefined grammars"
   },
   {
      "_id": "12753125",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-11-05 18:43:31",
      "description": "{code:title=Cassandra 2.1.1, Oracle Java 1.7.0_72, Ubuntu 14.04.1 64 bit}\ncqlsh:blink> show version;\n[cqlsh 5.0.1 | Cassandra 2.1.1 | CQL spec 3.2.0 | Native protocol v3]\ncqlsh:blink> select token(id) from users limit 1;\nlist index out of range\n{code}\n\nversus\n\n{code:title=Cassandra 2.1.0, Oracle Java 1.7.0_67, Ubuntu 12.04.5 64 bit}\ncqlsh:blink> show version;\n[cqlsh 5.0.1 | Cassandra 2.1.0 | CQL spec 3.2.0 | Native protocol v3]\ncqlsh:blink> select token(id) from users limit 1;\n\n token(id)\n----------------------\n -9223237793432919630\n\n(1 rows)\n{code}\n\nIt also fails with C* 2.1.1, Java 1.7.0_72, Ubuntu 12.04.5.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "SELECT ... TOKEN() function broken in C* 2.1.1"
   },
   {
      "_id": "12751745",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-10-30 17:33:34",
      "description": "When porting launch-script functionality over some of the disabled-by-default options in cassandra-env.ps1 weren't modified.  They're decidedly non-Windows:\n{code}\n   # Configure the following for JEMallocAllocator and if jemalloc is not available in the system\n    # library path (Example: /usr/local/lib/). Usually \"make install\" will do the right thing.\n{code}\n\nTrivial effort - just update those to reflect sane windows defaults/paths/ecosystem.  Should have 0 effect on runtime defaults as they're all already Windows-ified.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Make comments/default paths in cassandra-env.ps1 more Windows-centric"
   },
   {
      "_id": "12751446",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-10-29 18:02:48",
      "description": "The dtest auth_test.py:TestAuth.alter_cf_auth_test is failing. \n\n{code}\n        cassandra.execute(\"GRANT ALTER ON ks.cf TO cathy\")\n        cathy.execute(\"ALTER TABLE ks.cf ADD val int\")\n\n        cassandra.execute(\"REVOKE ALTER ON ks.cf FROM cathy\")\n        self.assertUnauthorized(\"User cathy has no ALTER permission on <table ks.cf> or any of its parents\",\n                                cathy, \"CREATE INDEX ON ks.cf(val)\")\n\n        cassandra.execute(\"GRANT ALTER ON ks.cf TO cathy\")\n        cathy.execute(\"CREATE INDEX ON ks.cf(val)\")\n{code}\n\nIn this section of code, the user cathy is granted \"ALTER\" permissions on 'ks.cf', then they are revoked, then granted again. Monitoring system_auth.permissions during this section of code show that the permission is added with the initial grant, and revoked properly, but the table remains empty after the second grant.\n\nWhen the cathy user attempts to create an index, the following exception is thrown:\n\n{code}\nUnauthorized: code=2100 [Unauthorized] message=\"User cathy has no ALTER permission on <table ks.cf> or any of its parents\"\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Grant Permission fails if permission had been revoked previously"
   },
   {
      "_id": "12751429",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-10-29 17:02:31",
      "description": "The test snapshot_test.TestArchiveCommitlog.test_archive_commitlog is failing on 2.0.11, but not 2.1.1. We attempt to replay 65000 rows, but in 2.0.11 only 63000 rows succeed. URL for test output:\n\nhttp://cassci.datastax.com/job/cassandra-2.0_dtest/lastCompletedBuild/testReport/snapshot_test/TestArchiveCommitlog/test_archive_commitlog/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Archive Commitlog Test Failing"
   },
   {
      "_id": "12751400",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-10-29 15:33:01",
      "description": "Seems we have a bug that can create overlapping sstables in L1:\n\n{code}\nWARN [main] 2014-10-28 04:09:42,295 LeveledManifest.java (line 164) At level 2, SSTableReader(path='<sstable>') [DecoratedKey(2838397575996053472, 00\n10000000001111000000000000066059b200001000000000066059b200000000111100000000100000000000004000000000000000000100), DecoratedKey(5516674013223138308, 001000000000111100000000000000ff2d160000100000000000ff2d1600000\n000111100000000100000000000004000000000000000000100)] overlaps SSTableReader(path='<sstable>') [DecoratedKey(2839992722300822584, 00100000000011110000\n0000000000229ad20000100000000000229ad200000000111100000000100000000000004000000000000000000100), DecoratedKey(5532836928694021724, 0010000000001111000000000000034b05a600001000000000034b05a600000000111100000000100\n000000000004000000000000000000100)].  This could be caused by a bug in Cassandra 1.1.0 .. 1.1.3 or due to the fact that you have dropped sstables from another node into the data directory. Sending back to L0.  If\n you didn't drop in sstables, and have not yet run scrub, you should do so since you may also have rows out-of-order within an sstable\n{code}\n\nWhich might manifest itself during compaction with this exception:\n{code}\nERROR [CompactionExecutor:3152] 2014-10-28 00:24:06,134 CassandraDaemon.java (line 199) Exception in thread Thread[CompactionExecutor:3152,1,main]\njava.lang.RuntimeException: Last written key DecoratedKey(5516674013223138308, 001000000000111100000000000000ff2d160000100000000000ff2d1600000000111100000000100000000000004000000000000000000100) >= current key DecoratedKey(2839992722300822584, 001000000000111100000000000000229ad20000100000000000229ad200000000111100000000100000000000004000000000000000000100) writing into <sstable>\n{code}\nsince we use LeveledScanner when compacting (the backing sstable scanner might go beyond the start of the next sstable scanner)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Overlapping sstables in L1+"
   },
   {
      "_id": "12751333",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2014-10-29 08:35:11",
      "description": "Removing items from a set breaks index for field {{id}}:\n\n{noformat}\ncqlsh:cs> CREATE TABLE buckets (\n      ...   tenant int,\n      ...   id int,\n      ...   items set<text>,\n      ...   PRIMARY KEY (tenant, id)\n      ... );\ncqlsh:cs> CREATE INDEX buckets_ids ON buckets(id);\ncqlsh:cs> INSERT INTO buckets (tenant, id, items) VALUES (1, 1, {'foo', 'bar'});\ncqlsh:cs> SELECT * FROM buckets;\n\n tenant | id | items\n--------+----+----------------\n      1 |  1 | {'bar', 'foo'}\n\n(1 rows)\n\ncqlsh:cs> SELECT * FROM buckets WHERE id = 1;\n\n tenant | id | items\n--------+----+----------------\n      1 |  1 | {'bar', 'foo'}\n\n(1 rows)\n\ncqlsh:cs> UPDATE buckets SET items=items-{'foo'} WHERE tenant=1 AND id=1;\ncqlsh:cs> SELECT * FROM buckets;\n\n tenant | id | items\n--------+----+---------\n      1 |  1 | {'bar'}\n\n(1 rows)\n\ncqlsh:cs> SELECT * FROM buckets WHERE id = 1;\n\n(0 rows)\n{noformat}\n\nRe-building the index fixes the issue:\n\n{noformat}\ncqlsh:cs> DROP INDEX buckets_ids;\ncqlsh:cs> CREATE INDEX buckets_ids ON buckets(id);\ncqlsh:cs> SELECT * FROM buckets WHERE id = 1;\n\n tenant | id | items\n--------+----+---------\n      1 |  1 | {'bar'}\n\n(1 rows)\n{noformat}\n\nAdding items does not cause similar failure, only delete. Also didn't test if other collections are also affected(?)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Deleting columns breaks secondary index on clustering column"
   },
   {
      "_id": "12751061",
      "assignee": "krummas",
      "components": [],
      "created": "2014-10-28 11:51:48",
      "description": "The {{CREATE TABLE}} section of the CQL Specification isn't up to date for the latest {{DateTieredCompactionStrategy}} that has been added in 2.0.11 and 2.1.1. We need to cover all its options just like it's done for the other strategies.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "dtcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL Spec needs to be updated with DateTieredCompactionStrategy"
   },
   {
      "_id": "12750639",
      "assignee": "krummas",
      "components": [],
      "created": "2014-10-26 23:17:10",
      "description": "I have a cluster that is recovering from being overloaded with writes.  I am using the workaround from CASSANDRA-6621 to prevent the STCS fallback (which is killing the cluster - see CASSANDRA-7949). \n\nI have observed that after one or more exceptions like this\n\n{code}\nERROR [CompactionExecutor:4087] 2014-10-26 22:50:05,016 CassandraDaemon.java (line 199) Exception in thread Thread[CompactionExecutor:4087,1,main]\njava.lang.RuntimeException: Last written key DecoratedKey(425124616570337476, 0010000000001111000000000000033523da00001000000000033523da000000001111000000001000000000\n00004000000000000000000100) >= current key DecoratedKey(-8778432288598355336, 0010000000001111000000000000040c7a8f00001000000000040c7a8f000000001111000000001000000000\n00004000000000000000000100) writing into /cassandra-data/disk2/myks/mytable/myks-mytable-tmp-jb-130379-Data.db\n        at org.apache.cassandra.io.sstable.SSTableWriter.beforeAppend(SSTableWriter.java:142)\n        at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:165)\n        at org.apache.cassandra.db.compaction.CompactionTask.runWith(CompactionTask.java:160)\n        at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:48)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:60)\n        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59)\n        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:198)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n{code}\n\nthe node completely stops the compactions and I end up in the state like this:\n\n{code}\n# nodetool compactionstats\npending tasks: 1288\n          compaction type        keyspace           table       completed           total      unit  progress\nActive compaction remaining time :        n/a\n{code}\n\nThe node recovers if restarted and starts compactions - until getting more exceptions like this.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Compactions stop completely because of RuntimeException in CompactionExecutor"
   },
   {
      "_id": "12750196",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-10-23 20:29:15",
      "description": "The output from running cassandra.bat while Cassandra is already running gives no indication that Cassandra was already running, or that the command failed. Instead it prints out {code}Starting Cassandra Server.{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "No error message shown when starting Cassandra on Windows if Cassandra is already running"
   },
   {
      "_id": "12749501",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-10-21 13:10:51",
      "description": "CASSANDRA-8034 notifies the listeners whenever we replace an sstable to make sure we have track the right instance.\n\nProblem is though that when we open early and finish a compaction, we try to re-add the same sstable to the manifest which drops it to level 0 since it overlaps with the one that is already there",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Opening results early with leveled compactions broken"
   },
   {
      "_id": "12748955",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328322",
            "id": "12328322",
            "name": "Local/Startup and Shutdown",
            "description": "Startup and Shutdown"
         }
      ],
      "created": "2014-10-17 19:22:00",
      "description": "When using procrun and the -install combination on Windows and starting cassandra via services.msc, stopping the service never completes and gets stuck in \"stopping\" status forever.  Probably related to:\n\n{code}\n    public void stop()\n    {\n        // this doesn't entirely shut down Cassandra, just the RPC server.\n        // jsvc takes care of taking the rest down\n        logger.info(\"Cassandra shutting down...\");\n        thriftServer.stop();\n        nativeServer.stop();\n    }\n{code}\n\nprocrun calls the StopMethod as CassandraDaemon.stop so we may need to either a) augment what procrun's doing or b) add a more comprehensive stop to be called on Windows shutdown.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows Service never finishes shutting down"
   },
   {
      "_id": "12748313",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-10-15 15:40:38",
      "description": "In leveled compaction we generally create many files during compaction, in 2.0 we left the ones we had written as -tmp- files, in 2.1 we close and open the readers, removing the -tmp- markers.\n\nThis means that any ongoing compactions will leave the resulting files around if we restart. Note that stop:ing the compaction will cause an exception and that makes us call abort() on the SSTableRewriter which removes the files.\n\nGuess a fix could be to keep the -tmp- marker and make -tmplink- files until we are actually done with the compaction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "triaged"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Stopping a node during compaction can make already written files stay around"
   },
   {
      "_id": "12748069",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-10-14 16:14:16",
      "description": "After CASSANDRA-7136, the install scripts to run Cassandra as a service fail on both the legacy and the powershell paths.  Looks like they need to have\n{code}\n++JvmOptions=-Dcassandra.logdir=%CASSANDRA_HOME%\\logs ^\n++JvmOptions=-Dcassandra.storagedir=%CASSANDRA_HOME%\\data\n{code}\nadded to function correctly.\n\nWe should take this opportunity to make sure the source of the java options is uniform for both running and installation to prevent mismatches like this in the future.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows install scripts fail to set logdir and datadir"
   },
   {
      "_id": "12747344",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-10-10 17:11:19",
      "description": "cassandra-cli updates and prints out a min_compaction_threshold that is not shown by cqlsh (it shows a different min_threshold attribute)\n\ncqlsh updates \"both\" values but only shows one of them\n\n{code}\ncassandra-cli:\nUPDATE COLUMN FAMILY foo WITH min_compaction_threshold = 8;\n\n$ echo \"describe foo;\" | cassandra-cli -h `hostname` -k bar\n      Compaction min/max thresholds: 8/32\n\n$ echo \"describe table foo;\" | cqlsh -k bar `hostname`\n  compaction={'class': 'SizeTieredCompactionStrategy'} AND\n{code}\n\n{code}\ncqlsh:\nALTER TABLE foo WITH compaction = {'class' : 'SizeTieredCompactionStrategy', 'min_threshold' : 16};\n\ncassandra-cli:\n      Compaction min/max thresholds: 16/32\n      Compaction Strategy Options:\n        min_threshold: 16\ncqlsh:\n  compaction={'min_threshold': '16', 'class': 'SizeTieredCompactionStrategy'} AND\n{code}\n\n{code}\ncassandra-cli:\nUPDATE COLUMN FAMILY foo WITH min_compaction_threshold = 8;\n\ncassandra-cli:\n      Compaction min/max thresholds: 8/32\n      Compaction Strategy Options:\n        min_threshold: 16\n\ncqlsh:\n  compaction={'min_threshold': '16', 'class': 'SizeTieredCompactionStrategy'} AND\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cli",
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cassandra-cli and cqlsh report two different values for a setting, partially update it and partially report it"
   },
   {
      "_id": "12745532",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-10-02 16:10:11",
      "description": "mingw (and other) packages comes with a version of uname so we need to check the output of the uname call rather than just check to confirm it's present.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Current check for cygwin environment in cassandra.ps1 is too greedy"
   },
   {
      "_id": "12745524",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-10-02 15:35:34",
      "description": "Example error:\n{noformat}\nC:\\vm-shared\\src\\test space\\cassandra>Processing -File 'C:\\vm-shared\\src\\test' failed because the file does not have a '.ps1' extension. Specify a valid PowerShell script file name, and then try again.\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "stop-server.bat fails to call powershell if there's a space in the directory name"
   },
   {
      "_id": "12744723",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2014-09-29 17:41:06",
      "description": "Currently a large number of dtests and unit tests are erroring on windows with the following error in the node log:\n{code}\nERROR [NonPeriodicTasks:1] 2014-09-29 11:05:04,383 SSTableDeletingTask.java:89 - Unable to delete c:\\\\users\\\\username\\\\appdata\\\\local\\\\temp\\\\dtest-vr6qgw\\\\test\\\\node1\\\\data\\\\system\\\\local-7ad54392bcdd35a684174e047860b377\\\\system-local-ka-4-Data.db (it will be removed on server restart; we'll also retry after GC)\\n\n{code}\n\ngit bisect points to the following commit:\n{code}\n0e831007760bffced8687f51b99525b650d7e193 is the first bad commit\ncommit 0e831007760bffced8687f51b99525b650d7e193\nAuthor: Benedict Elliott Smith <benedict@apache.org>\nDate:  Fri Sep 19 18:17:19 2014 +0100\n\n    Fix resource leak in event of corrupt sstable\n\n    patch by benedict; review by yukim for CASSANDRA-7932\n\n:100644 100644 d3ee7d99179dce03307503a8093eb47bd0161681 f55e5d27c1c53db3485154cd16201fc5419f32df M      CHANGES.txt\n:040000 040000 194f4c0569b6be9cc9e129c441433c5c14de7249 3c62b53b2b2bd4b212ab6005eab38f8a8e228923 M  src\n:040000 040000 64f49266e328b9fdacc516c52ef1921fe42e994f de2ca38232bee6d2a6a5e068ed9ee0fbbc5aaebe M  test\n{code}\n\nYou can reproduce this by running simple_bootstrap_test.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows Unit tests and Dtests erroring due to sstable deleting task error"
   },
   {
      "_id": "12744024",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-09-25 13:24:42",
      "description": "If a user has leveled compaction configured, we should run that for both the unrepaired and the repaired data. I think this would make things a lot easier for end users\n\nIt would simplify migration to incremental repairs as well, if a user runs incremental repair on its nice leveled unrepaired data, we wont need to drop it all to L0, instead we can just start moving sstables from the unrepaired leveling straight into the repaired leveling\n\nIdea could be to have two instances of LeveledCompactionStrategy and move sstables between the instances after an incremental repair run (and let LCS be totally oblivious to whether it handles repaired or unrepaired data). Same should probably apply to any compaction strategy, run two instances and remove all repaired/unrepaired logic from the strategy itself.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Run LCS for both repaired and unrepaired data"
   },
   {
      "_id": "12742613",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320019",
            "id": "12320019",
            "name": "Local/Config",
            "description": "Configuration and environment"
         }
      ],
      "created": "2014-09-19 00:05:16",
      "description": "It appears that if you want to increase the sampling in *-Summary.db files, you would change the default for {{index_interval}} table property from the {{128}} default value to {{256}} on a given CQL {{TABLE}}.\n\nHowever, if you {{ALTER TABLE}} after setting the value, {{index_interval}} returns to the default, {{128}}. This is unexpected behavior. I would expect the value for {{index_interval}} to not be affected by subsequent {{ALTER TABLE}} statements.\n\nAs noted in Environment, this was seen with a 2.0.9-SNAPSHOT built w/ `ccm`. \n\nIf I just use a table from one of DataStax documentation tutorials (musicdb as mdb):\n\n{noformat}\ncqlsh:mdb> DESC TABLE songs;\n\nCREATE TABLE songs (\n  id uuid,\n  album text,\n  artist text,\n  data blob,\n  reviews list<text>,\n  tags set<text>,\n  title text,\n  venue map<timestamp, text>,\n  PRIMARY KEY ((id))\n) WITH\n  bloom_filter_fp_chance=0.010000 AND\n  caching='KEYS_ONLY' AND\n  comment='' AND\n  dclocal_read_repair_chance=0.100000 AND\n  gc_grace_seconds=864000 AND\n  index_interval=128 AND\n  read_repair_chance=0.000000 AND\n  replicate_on_write='true' AND\n  populate_io_cache_on_flush='false' AND\n  default_time_to_live=0 AND\n  speculative_retry='99.0PERCENTILE' AND\n  memtable_flush_period_in_ms=0 AND\n  compaction={'class': 'SizeTieredCompactionStrategy'} AND\n  compression={'sstable_compression': 'LZ4Compressor'};\n{noformat}\n\nWe've got {{128}} as expected.\n\nWe alter it:\n\n{noformat}\ncqlsh:mdb> ALTER TABLE songs WITH index_interval = 256; \n{noformat}\n\nAnd the change appears: \n\n{noformat}\ncqlsh:mdb> DESC TABLE songs;\n\nCREATE TABLE songs (\n  id uuid,\n  album text,\n  artist text,\n  data blob,\n  reviews list<text>,\n  tags set<text>,\n  title text,\n  venue map<timestamp, text>,\n  PRIMARY KEY ((id))\n) WITH\n  bloom_filter_fp_chance=0.010000 AND\n  caching='KEYS_ONLY' AND\n  comment='' AND\n  dclocal_read_repair_chance=0.100000 AND\n  gc_grace_seconds=864000 AND\n  index_interval=256 AND\n  read_repair_chance=0.000000 AND\n  replicate_on_write='true' AND\n  populate_io_cache_on_flush='false' AND\n  default_time_to_live=0 AND\n  speculative_retry='99.0PERCENTILE' AND\n  memtable_flush_period_in_ms=0 AND\n  compaction={'class': 'SizeTieredCompactionStrategy'} AND\n  compression={'sstable_compression': 'LZ4Compressor'};\n{noformat}\n\nBut if do another {{ALTER TABLE}}, say, change the caching or comment, the {{index_interval}} will revert back to {{128}}.\n\n{noformat}\ncqlsh:mdb> ALTER TABLE songs WITH caching = 'none'; \ncqlsh:mdb> DESC TABLE songs; \n\nCREATE TABLE songs (\n  id uuid,\n  album text,\n  artist text,\n  data blob,\n  reviews list<text>,\n  tags set<text>,\n  title text,\n  venue map<timestamp, text>,\n  PRIMARY KEY ((id))\n) WITH\n  bloom_filter_fp_chance=0.010000 AND\n  caching='NONE' AND\n  comment='' AND\n  dclocal_read_repair_chance=0.100000 AND\n  gc_grace_seconds=864000 AND\n  index_interval=128 AND\n  read_repair_chance=0.000000 AND\n  replicate_on_write='true' AND\n  populate_io_cache_on_flush='false' AND\n  default_time_to_live=0 AND\n  speculative_retry='99.0PERCENTILE' AND\n  memtable_flush_period_in_ms=0 AND\n  compaction={'class': 'SizeTieredCompactionStrategy'} AND\n  compression={'sstable_compression': 'LZ4Compressor'};\n{noformat}\n\nIt should be {{index_interval=256}}.\n\nI know that 2.1 will replace {{index_interval}}. \n\nI have not confirmed any behavior with {{min_index_interval}} nor {{max_index_interval}} (which is described in resolved #6379). \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3",
         "metadata"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Changes to index_interval table properties revert after subsequent modifications"
   },
   {
      "_id": "12742575",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-09-18 20:57:47",
      "description": "When using cqlsh (Cassandra 2.1.0) with ssl, python 2.6.9. I get Connection error: ('Unable to connect to any servers', {...: TypeError(\"'member_descriptor' object is not callable\",)}) \nI am able to connect from another machine using python 2.7.5.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh connect error \"member_descriptor' object is not callable\""
   },
   {
      "_id": "12742573",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-09-18 20:56:21",
      "description": "http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/create_index_r.html?scroll=reference_ds_eqm_nmd_xj__CreatIdxCollKey",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cqlsh",
         "lhf",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add \"CREATE INDEX ... ON ..(KEYS())\" syntax to cqlsh and CQL.textile"
   },
   {
      "_id": "12739899",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-09-08 16:03:17",
      "description": "Stop-server.bat lists \"-f\" as an argument but does not handle it inside of stop-server.ps1. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Implement -f functionality in stop-server.bat"
   },
   {
      "_id": "12739560",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-09-05 18:48:54",
      "description": "Create the following data model:\n{noformat}\nCREATE TYPE address (\nstreet text,\ncity text,\nzip_code int,\nphones set<text>\n );\n \nCREATE TYPE fullname (\nfirstname text,\nlastname text\n);\n\nCREATE TABLE users (\nid uuid PRIMARY KEY,\nname FROZEN <fullname>,\naddresses map<text, FROZEN <address>>\n);\n\nINSERT INTO users (id, name) \nVALUES (62c36092-82a1-3a00-93d1-46196ee77204, {firstname: 'Marie-Claude', lastname: 'Josset'});\n{noformat}\n\nWhen trying to select a sub-field in the name type:\n{noformat}\nSELECT name.lastname FROM users WHERE id=62c36092-82a1-3a00-93d1-46196ee77204;\n{noformat}\n\nYou get the following error:\n{noformat}\nlist index out of range\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Select an element inside a UDT throws an index error"
   },
   {
      "_id": "12737546",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-08-28 19:08:11",
      "description": "Four of the snapshot_test.py:TestArchiveCommitlog tests are failing on 2.1.0 and 2.1-HEAD:\nhttp://cassci.datastax.com/job/cassandra-2.1.0_dtest/lastCompletedBuild/testReport/snapshot_test/\n\nThe tests restore archived commit logs and check how many rows exist after restoring. They are passing on 2.0-HEAD.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Archive Commitlog Tests Failings"
   },
   {
      "_id": "12736811",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-08-26 14:13:13",
      "description": "create table counter_bug (t int, c counter, primary key (t));\nupdate counter_bug set c = c +1 where t = 1;\nselect * from counter_bug ;\n \n t | c\n---+---\n 1 | 1\n \n(1 rows)\n \nalter table counter_bug drop c;\nalter table counter_bug add c counter;\nupdate counter_bug set c = c +1 where t = 1;\nselect * from counter_bug;\n \n(0 rows)\n\nupdate counter_bug set c = c +1 where t = 2;\nselect * from counter_bug;\n \n(0 rows)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "recreating a counter column after dropping it leaves in unusable state"
   },
   {
      "_id": "12735865",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-08-21 18:47:10",
      "description": "Describe index should be supported, right now, the only way is to export the schema and find what it really is before updating/dropping the index.\n\nverified in \n[cqlsh 3.1.8 | Cassandra 1.2.18.1 | CQL spec 3.0.0 | Thrift protocol 19.36.2]\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "enable describe on indices"
   },
   {
      "_id": "12735784",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-08-21 13:52:15",
      "description": "The current code for UDF is largely not reusing the pre-existing mechanics/code for native/hardcoded functions. I don't see a good reason for that but I do see downsides: it's more code to maintain and makes it much easier to have inconsitent behavior between hard-coded and user-defined function. More concretely, {{UDFRegistery/UDFFunctionOverloads}} fundamentally do the same thing than {{Functions}}, we should just merge both. I'm also not sure there is a need for both {{UFMetadata}} and {{UDFunction}} since {{UFMetadata}} really only store infos on a given function (contrarly to what the javadoc pretends).  I suggest we consolidate all this to cleanup the code, but also as a way to fix 2 problems that the UDF code has but that the existing code for \"native\" functions don't:\n* if there is multiple overloads of a function, the UDF code picks the first version whose argument types are compatible with the concrete arguments provided. This is broken for bind markers: we don't know the type of markers and so the first function match may not at all be what the user want. The only sensible choice is to detect that type of ambiguity and reject the query, asking the user to explicitly type-cast their bind marker (which is what the code for hard-coded function does).\n* the UDF code builds a function signature using the CQL type names of the arguments and use that to distinguish multiple overrides in the schema. This means in particular that {{f(v text)}} and {{f(v varchar)}} are considered distinct, which is wrong since CQL considers {{varchar}} as a simple alias of {{text}}. And in fact, the function resolution does consider them aliases leading to seemingly broken behavior.\n\nThere is a few other small problems that I'm proposing to fix while doing this cleanup:\n* Function creation only use the function name when checking if the function exists, which is not enough since we allow multiple over-loadings. You can bypass the check by using \"OR REPLACE\" but that's obviously broken.\n* {{IF NOT EXISTS}} for function creation is broken.\n* The code allows to replace a function (with {{OR REPLACE}}) by a new function with an incompatible return type. Imo that's dodgy and we should refuse it (users can still drop and re-create the method if they really want).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "UDF cleanups (#7395 follow-up)"
   },
   {
      "_id": "12735390",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-08-20 12:11:59",
      "description": "During tests of new features of 2.1 like: \n- incremental repairs \n- leveled compaction\nI interrupted a compaction, which left the following ERROR in the _system.log_\n{quote}\norg.apache.cassandra.db.compaction.CompactionInterruptedException: Compaction interrupted: Compaction@152e6e70-1975-11e4-ba09-61f0d75c60c6(xx, xxx, 378505918/1993581634)bytes\n\tat org.apache.cassandra.db.compaction.CompactionTask.runWith(CompactionTask.java:174)\n\tat org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:48)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n\tat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:74)\n\tat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59)\n\tat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:235)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_09]\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) ~[na:1.7.0_09]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:166) ~[na:1.7.0_09]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) ~[na:1.7.0_09]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) [na:1.7.0_09]\n\tat java.lang.Thread.run(Thread.java:722) [na:1.7.0_09]\n{quote}\n\nRight after that, a cascade of reoccurring errors was being emitted till the restart:\n{quote}\nERROR [NonPeriodicTasks:1] 2014-08-19 13:38:41,258 SSTableDeletingTask.java:81 - Unable to delete /grid/data04/cassandra/data/xx/xxx-152e6e70197511e4ba0961f0d75c60c6/xx-xxx-ka-55058-Data.db (it will be removed on server restart; we'll also retry after GC)\n{quote}\nwhich made this node blinking (noted from the other nodes gossiper log entries).\nAfter restart, the node is healthy and fully operational.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "When compaction is interrupted, it leaves locked, undeletable files"
   },
   {
      "_id": "12735336",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2014-08-20 07:01:51",
      "description": "When I run a loop with CQL statements to DELETE, INSERT with CAS and then a GET.\nThe INSERT opertion is successful (Applied), but no data is stored in the database. I have checked the database manually after the test to verify that the DB is empty.\n{code}\n        for (int i = 0; i < 10000; ++i)\n        {\n            try\n            {\n                t.del();\n                t.cas();\n                t.select();\n            }\n            catch (Exception e)\n            {\n                System.err.println(\"i=\" + i);\n                e.printStackTrace();\n                break;\n            }\n        }\n\n\n        myCluster = Cluster.builder().addContactPoint(\"localhost\").withPort(12742).build();\n        mySession = myCluster.connect();\n\n        mySession.execute(\"CREATE KEYSPACE IF NOT EXISTS castest WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };\");\n        mySession.execute(\"CREATE TABLE IF NOT EXISTS castest.users (userid text PRIMARY KEY, name text)\");\n\n        myInsert = mySession.prepare(\"INSERT INTO castest.users (userid, name) values ('user1', 'calle') IF NOT EXISTS\");\n        myDelete = mySession.prepare(\"DELETE FROM castest.users where userid='user1'\");\n        myGet = mySession.prepare(\"SELECT * FROM castest.users where userid='user1'\");\n    }\n{code}\n\nI can reproduce the fault with the attached program on a PC with windows 7.\nYou need a cassandra runing and you need to set the port in the program.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "A successful INSERT with CAS does not always store data in the DB after a DELETE"
   },
   {
      "_id": "12734252",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2014-08-14 20:59:01",
      "description": "We currently use CLibrary fsync linux-native calls to flush to disk.  Given the role this plays in our SequentialWriter and data integrity in general we need some analog to this function on Windows.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows - fsync-analog, flush data to disk"
   },
   {
      "_id": "12733346",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-08-11 21:03:31",
      "description": "Windows python doesn't come with readline functionality by default and tab completion in cqlsh is silently unavailable due to this.  Installing pyreadline is an easy fix - it would be nice to prompt users to install this dependency if it's not available on Windows.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows cqlsh: prompt for install of pyreadline if missing during cqlsh init"
   },
   {
      "_id": "12733330",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-08-11 20:03:18",
      "description": "linux was here first.  In the PowerShell launch scripts, -v is verbose right now as I missed that it's used for 'version' on linux.  Add version print functionality to Windows launch using -v and find another sane flag to use for verbose env output printing.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Get Windows command-line flags in-line with linux"
   },
   {
      "_id": "12733053",
      "assignee": "slebresne",
      "components": [],
      "created": "2014-08-09 19:12:40",
      "description": "cqlsh:test_ks> create TABLE foo ( bar int, primary key (bar));\ncqlsh:test_ks> alter table foo add bar2 text static;\ncqlsh:test_ks> describe table foo;\n\nCREATE TABLE foo (\n  bar int,\n  bar2 text static,\n  PRIMARY KEY ((bar))\n) \n\ncqlsh:test_ks> select * from foo;\nTSocket read 0 bytes\n\n\nERROR [Thrift:12] 2014-08-09 15:08:22,518 CassandraDaemon.java (line 199) Exception in thread Thread[Thrift:12,5,main]\njava.lang.AssertionError\n\tat org.apache.cassandra.config.CFMetaData.getStaticColumnNameBuilder(CFMetaData.java:2142)\n\tat org.apache.cassandra.cql3.statements.SelectStatement.makeFilter(SelectStatement.java:454)\n\tat org.apache.cassandra.cql3.statements.SelectStatement.getRangeCommand(SelectStatement.java:360)\n\tat org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:206)\n\tat org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:61)\n\tat org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:158)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "altering a table to add a static column bypasses clustering column requirement check"
   },
   {
      "_id": "12732683",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2014-08-07 21:29:30",
      "description": "This test fails about 20-25% of the time - ran about 10 times through looping the test, and it typically fails on the 4th or 5th test.\n{noformat}\n(master)mshuler@hana:~/git/cassandra-dtest$ ../loop_dtest.sh \"cql_tests.py:TestCQL.cql3_insert_thrift_test\"\n<...>\n\n==== Run #4 ====\nnose.config: INFO: Ignoring files matching ['^\\\\.', '^_', '^setup\\\\.py$']\ncql3_insert_thrift_test (cql_tests.TestCQL) ... cluster ccm directory: /tmp/dtest-Drwunj\n[node1 ERROR] \n[node1 ERROR] \nFAIL\nremoving ccm cluster test at: /tmp/dtest-Drwunj\n\n======================================================================\nFAIL: cql3_insert_thrift_test (cql_tests.TestCQL)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/cql_tests.py\", line 1627, in cql3_insert_thrift_test\n    assert res == [ [2, 4, 200] ], res\nAssertionError: []\n\n----------------------------------------------------------------------\nRan 1 test in 7.192s\n{noformat}\n\nloop_dtest.sh:\n{noformat}\n#!/bin/bash\nif [ ${1} ]; then\n    export MAX_HEAP_SIZE=\"1G\"\n    export HEAP_NEWSIZE=\"256M\"\n    export PRINT_DEBUG=true\n    COUNT=0\n    while true; do\n        echo\n        echo \"==== Run #$COUNT ====\"\n        nosetests --nocapture --nologcapture --verbosity=3 ${1}\n        if [ $? -ne 0 ]; then\n            exit 1\n        fi\n        ((COUNT++))\n        sleep 0.5\n    done\n    unset MAX_HEAP_SIZE HEAP_NEWSIZE PRINT_DEBUG\nelse\n    echo \"  ${0} needs a test to run..\"\n    exit 255\nfi\n{noformat}\n\nI find no ERROR/WARN log entries from the failed test - attached node log anyway.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "dtest cql_tests.py:TestCQL.cql3_insert_thrift_test fails intermittently"
   },
   {
      "_id": "12732568",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-08-07 14:54:05",
      "description": "Replicate changes from CASSANDRA-7432.\n\nRelevant patch contents:\n{noformat}\n # note: bash evals '1.7.x' as > '1.7' so this is really a >= 1.7 jvm check\n+if { [ \"$JVM_VERSION\" \\> \"1.7\" ] && [ \"$JVM_VERSION\" \\< \"1.8.0\" ] && [ \"$JVM_PATCH_VERSION\" -ge \"60\" ]; } || [ \"$JVM_VERSION\" \\> \"1.8\" ] ; then\n+    JVM_OPTS=\"$JVM_OPTS -XX:+CMSParallelInitialMarkEnabled -XX:+CMSEdenChunksRecordAlways\"\n+fi\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Add new CMS GC flags to Windows startup scripts for JVM later than 1.7.0_60"
   },
   {
      "_id": "12732028",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-08-05 14:29:36",
      "description": "As seen in the attached log, occasionally a major compaction will interrupt other running compactions. This is not an error and is expected behavior. However this is logged at ERROR. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Expected Compaction Interruption is logged as ERROR"
   },
   {
      "_id": "12731452",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-08-01 23:00:31",
      "description": "From the conversation on CASSANDRA-6312 it seems we should not allow user types to contain counters. Presently, user types can be defined with field types of counter, and these user types can also be associated with tables without error.\n\nI'm not certain if there's a compelling case for counters within user types, but I don't think there's any syntax existing presently that would allow updating them anyway.\n\nTo repro:\n{noformat}\nCREATE KEYSPACE test WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;\n\nUSE test;\n\nCREATE TYPE t_item (\n  sub_one counter\n); \n\nCREATE TYPE item (\n  sub_one counter\n); \n\nCREATE TABLE test.mytable (\n    value1 text PRIMARY KEY,\n    item t_item,\n    value2 text\n);\n\ncqlsh:test> insert into mytable (value1, value2) VALUES ( 'foo', 'bar');\ncqlsh:test> select * from mytable;\n\n value1 | item | value2\n--------+------+--------\n    foo | null |    bar\n\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "user types allow counters"
   },
   {
      "_id": "12730632",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-07-29 22:17:40",
      "description": "Nobody needs to trace their traces while they're tracing.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh should automatically disable tracing when selecting from system_traces"
   },
   {
      "_id": "12730584",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-07-29 19:37:56",
      "description": "When performing COPY table FROM 'test.csv' on cqlsh across any of the three major branches (1.2, 2.0, 2.1), the following error is thrown:\n\n{code}new-line character seen in unquoted field - do you need to open the file in universal-newline mode?{code}\n\nThis happens if the .csv file has windows style line endings, such as if it was created by saving a .csv from excel. This reproduces in both unix and windows environments. This is a simple enough fix. I found that running dos2unix on csv files generated by excel was not sufficient to correct the issue.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "osx"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Cqlsh cannot use .csv files exported by Excel"
   },
   {
      "_id": "12729931",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-07-25 21:03:47",
      "description": "Line endings on .ps1 files are currently LF only.  In the Windows ecosystem it's more appropriate to be CRLF.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Change line-endings for all .ps1 files to be CRLF"
   },
   {
      "_id": "12729610",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-07-24 23:07:12",
      "description": "Reference CASSANDRA-7587.  We don't currently have something analogous to cassandra.in.sh for Windows so there's no single point of insertion to add something to the environment for those tools to run.  Along with that, there's a bunch of duplicated code in those .bat files to determine classpath, home dir, etc.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Normalize windows tool batch file environments"
   },
   {
      "_id": "12729191",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-07-23 15:52:53",
      "description": "Although system errors are always reported when they happen, dtest does not show the full message. You have to go to the log file yourself to see the actual error. This takes two seconds when running a test by hand, but it's more difficult when viewing results run on cassci. We should be able to parse this out and pump it into the top most exception that is spit out by nosetests.\n\nExample of a useless error message: http://cassci.datastax.com/job/cassandra_upgrade_dtest/66/testReport/upgrade_through_versions_test/TestUpgradeThroughVersions/upgrade_test_2/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Dtest errors should show full system log message"
   },
   {
      "_id": "12727108",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328217",
            "id": "12328217",
            "name": "Legacy/Streaming and Messaging",
            "description": "MessagingService, Bootstrap, Repair, Bulk Loading"
         }
      ],
      "created": "2014-07-14 15:53:18",
      "description": "Looks like we missed this in CASSANDRA-6907 - range-based repair still defaults to snapshot-based on Windows.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows: IOException when repairing a range of tokens"
   },
   {
      "_id": "12726245",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-07-09 04:33:00",
      "description": "http://www.postgresql.org/docs/9.1/static/datatype-datetime.html\n\n(we already have timestamp; interval is out of scope for now, and see CASSANDRA-6350 for discussion on timestamp-with-time-zone.  but date/time should be pretty easy to add.)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "docs",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "add date and time types"
   },
   {
      "_id": "12726104",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-07-08 15:18:04",
      "description": "Currently cassandra.ps1 doesn't work if run directly from within PowerShell and the use-case seems pretty common.  Modify the script to work correctly without the .bat wrapper.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Support starting of daemon from within powershell"
   },
   {
      "_id": "12725783",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-07-07 17:03:04",
      "description": "{code:title=failure}\nC:\\src\\cassandra>bin\\cassandra.bat -f\nDetected powershell execution permissions.  Running with enhanced startup scripts.\nSetting up Cassandra environment\nStarting cassandra server\nInvalid initial heap size: -Xms0M\nError: Could not create the Java Virtual Machine.\nError: A fatal exception has occurred. Program will exit.\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cassandra fails to start if WMI memory query fails on Windows"
   },
   {
      "_id": "12725650",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-07-06 22:08:21",
      "description": "While running IT tests for *Achilles*, I ran into a strange bug:\n\n*With CQLSH*\n\n{code:sql}\ncqlsh:test> CREATE TABLE cas_update(id int PRIMARY KEY,name text,friends list<text>);\ncqlsh:test> INSERT INTO cas_update (id, name , friends ) VALUES ( 10,'John',['Paul','George']);\ncqlsh:test> SELECT * FROM cas_update WHERE id=10;\n\n id | friends            | name\n----+--------------------+------\n 10 | ['Paul', 'George'] | John\n\ncqlsh:test> UPDATE cas_update SET friends[0]='Helen' WHERE id=10 IF name='John';\nBad Request: List index 0 out of bound, list has size 0\n\ncqlsh:test> UPDATE cas_update SET friends[0]='Helen' WHERE id=10;\ncqlsh:test> SELECT * FROM cas_update WHERE id=10;\n\n id | friends             | name\n----+---------------------+------\n 10 | ['Helen', 'George'] | John\n{code}\n\nIt seems that we cannot update list element by index with a CAS condition.\n\n*With Java driver 2.0.2 or 2.0.3*\n\n{code:java}\n ACHILLES_DML_STATEMENT@:writeDMLStatementLog Prepared statement : [INSERT INTO CompleteBean(id,followers,friends,name,preferences) VALUES (:id,:followers,:friends,:name,:preferences) USING TTL :ttl;] with CONSISTENCY LEVEL [ONE] \n ACHILLES_DML_STATEMENT@:writeDMLStatementLog    bound values : [621309709026375591, [], [Paul, Andrew], John, {}, 0] \n ACHILLES_DML_STATEMENT@:writeDMLStartBatch  \n ACHILLES_DML_STATEMENT@:writeDMLStartBatch  \n ACHILLES_DML_STATEMENT@:writeDMLStartBatch ****** BATCH UNLOGGED START ****** \n ACHILLES_DML_STATEMENT@:writeDMLStartBatch  \n ACHILLES_DML_STATEMENT@:writeDMLStatementLog Parameterized statement : [UPDATE CompleteBean USING TTL 100 SET friends[0]=? WHERE id=621309709026375591 IF name=?;] with CONSISTENCY LEVEL [ONE] \n ACHILLES_DML_STATEMENT@:writeDMLStatementLog    bound values : [100, 0, Helen, 621309709026375591, John] \n ACHILLES_DML_STATEMENT@:writeDMLStatementLog Parameterized statement : [UPDATE CompleteBean USING TTL 100 SET friends[1]=null WHERE id=621309709026375591 IF name=?;] with CONSISTENCY LEVEL [ONE] \n ACHILLES_DML_STATEMENT@:writeDMLStatementLog    bound values : [100, 1, null, 621309709026375591, John] \n ACHILLES_DML_STATEMENT@:writeDMLEndBatch  \n ACHILLES_DML_STATEMENT@:writeDMLEndBatch   ****** BATCH UNLOGGED END with CONSISTENCY LEVEL [DEFAULT] ****** \n ACHILLES_DML_STATEMENT@:writeDMLEndBatch  \n ACHILLES_DML_STATEMENT@:writeDMLEndBatch  \n ACHILLES_DML_STATEMENT@:truncateTable   Simple query : [TRUNCATE entity_with_enum] with CONSISTENCY LEVEL [ALL] \n ACHILLES_DML_STATEMENT@:truncateTable   Simple query : [TRUNCATE CompleteBean] with CONSISTENCY LEVEL [ALL] \n\ncom.datastax.driver.core.exceptions.InvalidQueryException: List index 0 out of bound, list has size 0\n        at com.datastax.driver.core.exceptions.InvalidQueryException.copy(InvalidQueryException.java:35)\n        at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:256)\n        at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:172)\n        at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52)\n{code}\n\n\nWith Cassandra *2.0.8* and Java Driver 2.0.2 or 2.0.3, *the test passed* so it seems that there is a regression somewhere in the CAS update code\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Unable to update list element by index using CAS condition"
   },
   {
      "_id": "12724685",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-07-01 09:24:28",
      "description": "Currently, the following code:\n{noformat}\nCREATE TYPE foo (f : int);\nCREATE TABLE test (k int PRIMARY KEY, v foo);\n\nINSERT INTO test (k, v) VALUES (0, { s : ?})\n{noformat}\nwill crash, because the {{s}} field is not part of type {{foo}} and it's not caught. The consequence being that the metadata for the bindMarker ends up being {{null}} and some NPE is thrown. We should throw a proper exception instead.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Throw exception on unknown UDT field"
   },
   {
      "_id": "12724679",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-07-01 08:58:42",
      "description": "The current version of the COPY command chokes on diacritical characters such as \u00f1 \u00eb \u00e1 and \u00f9. It would be great if the COPY command would support these characters.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "COPY FROM doesn't accept diacritical characters"
   },
   {
      "_id": "12724501",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2014-06-30 18:21:24",
      "description": "Have a few windows-specific failures in this test.\n\n{code:title=test_eat_glass}\n======================================================================\nERROR: test_eat_glass (cqlsh_tests.TestCqlsh)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"C:\\src\\cassandra-dtest\\cqlsh_tests.py\", line 158, in test_eat_glass\n    \"\"\".encode(\"utf-8\"))\n  File \"build\\bdist.win32\\egg\\ccmlib\\node.py\", line 613, in run_cqlsh\n    p.stdin.write(cmd + ';\\n')\nIOError: [Errno 22] Invalid argument\n{code}\n\n{code:title=test_simple_insert}\n======================================================================\nERROR: test_simple_insert (cqlsh_tests.TestCqlsh)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"C:\\src\\cassandra-dtest\\cqlsh_tests.py\", line 35, in test_simple_insert\n    cursor.execute(\"select id, value from simple.simple\");\n  File \"c:\\src\\cassandra-dbapi2\\cql\\cursor.py\", line 80, in execute\n    response = self.get_response(prepared_q, cl)\n  File \"c:\\src\\cassandra-dbapi2\\cql\\thrifteries.py\", line 77, in get_response\n    return self.handle_cql_execution_errors(doquery, compressed_q, compress, cl)\n  File \"c:\\src\\cassandra-dbapi2\\cql\\thrifteries.py\", line 98, in handle_cql_execution_errors\n    raise cql.ProgrammingError(\"Bad Request: %s\" % ire.why)\nProgrammingError: Bad Request: Keyspace simple does not exist\n{code}\n\n{code:title=test_with_empty_values}\n======================================================================\nERROR: test_with_empty_values (cqlsh_tests.TestCqlsh)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"C:\\src\\cassandra-dtest\\cqlsh_tests.py\", line 347, in test_with_empty_values\n    output = self.run_cqlsh(node1, \"select intcol, bigintcol, varintcol from CASSANDRA_7196.has_all_types where num in (0, 1, 2, 3, 4)\")\n  File \"C:\\src\\cassandra-dtest\\cqlsh_tests.py\", line 373, in run_cqlsh\n    p = subprocess.Popen([ cli ] + args, env=env, stdin=subprocess.PIPE, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n  File \"C:\\Python27\\lib\\subprocess.py\", line 710, in __init__\n    errread, errwrite)\n  File \"C:\\Python27\\lib\\subprocess.py\", line 958, in _execute_child\n    startupinfo)\nWindowsError: [Error 193] %1 is not a valid Win32 application\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Dtest: Windows - various cqlsh_tests errors"
   },
   {
      "_id": "12724484",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2014-06-30 17:02:50",
      "description": "Windows-specific dtest failure:\n\n{code:title=failure message}\n======================================================================\nFAIL: sc_with_row_cache_test (super_column_cache_test.TestSCCache)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"C:\\src\\cassandra-dtest\\super_column_cache_test.py\", line 44, in sc_with_row_cache_test\n    assert_columns(cli, ['name'])\n  File \"C:\\src\\cassandra-dtest\\super_column_cache_test.py\", line 10, in assert_columns\n    assert not cli.has_errors(), cli.errors()\nAssertionError: 'org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused: connect\\r\\n\\tat org.apache.thrift.transport.TSocket.open(TSocket.java:185)\\r\\n\\tat org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)\\r\\n\\tat org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)\\r\\n\\tat org.apache.cassandra.cli.CliMain.connect(CliMain.java:65)\\r\\n\\tat org.apache.cassandra.cli.CliMain.main(CliMain.java:237)\\r\\nCaused by: java.net.ConnectException: Connection refused: connect\\r\\n\\tat java.net.DualStackPlainSocketImpl.connect0(Native Method)\\r\\n\\tat java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)\\r\\n\\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)\\r\\n\\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)\\r\\n\\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)\\r\\n\\tat java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)\\r\\n\\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\\r\\n\\tat java.net.Socket.connect(Socket.java:579)\\r\\n\\tat org.apache.thrift.transport.TSocket.open(TSocket.java:180)\\r\\n\\t... 4 more\\r\\nException connecting to 127.0.0.1/9160. Reason: Connection refused: connect.\\r\\n'\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Dtest: Windows-specific failure: sc_with_row_cache_test (super_column_cache_test.TestSCCache)"
   },
   {
      "_id": "12724070",
      "assignee": "krummas",
      "components": [],
      "created": "2014-06-27 07:01:42",
      "description": "When replacing or bootstrapping a new node we can keep the source sstable level to avoid doing alot of compaction after bootstrap",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Send source sstable level when bootstrapping or replacing nodes"
   },
   {
      "_id": "12723879",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-06-26 14:16:57",
      "description": "There's also some .ps1 problems after we get past just the .bat.  Should be some trivial escaping to fix.\n\nC:\\src - Copy\\cassandra\\bin>cassandra.bat\nDetected powershell execution permissions.  Running with enhanced startup scripts.\nProcessing -File 'C:\\src' failed because the file does not have a '.ps1' extension. Specify a valid PowerShell script file name, and then try again.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Launch scripts on Windows don't handle spaces gracefully"
   },
   {
      "_id": "12723162",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-06-23 17:15:43",
      "description": "Looks like there was an undocumented ability to pass in -D params to the JVM in the linux environment I missed while porting the logic over to Windows.\n\n{code:title=-D}\n-D)\n   properties=\"$properties -D$2\"\n   shift 2\n;;\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add -D command-line parsing to Windows powershell launch scripts"
   },
   {
      "_id": "12722195",
      "assignee": "krummas",
      "components": [],
      "created": "2014-06-18 11:38:17",
      "description": "If we run cleanup (or increase sstable size) on a node with LCS, we could end up with a bunch of sstables in higher levels that are \"never\" compacted.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "After cleanup we can end up with non-compacting high level sstables"
   },
   {
      "_id": "12721816",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-06-17 23:39:52",
      "description": "Native protocol v3 changes the EVENT (opcode 12) SCHEMA_CHANGE to include the target type that changed : <change><target><keyspace><name>.\n\nThe RESULT (opcode 8) SCHEMA_CHANGE has the old layout (<change><keyspace><table>.\n\nIs this difference intentional or does the protocol spec needs change for RESULT/SCHEMA_CHANGE?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Native Protocol V3 CREATE Response"
   },
   {
      "_id": "12721750",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-06-17 18:17:15",
      "description": "According to cassandra.yaml, in the information for the num_tokens setting, \"Specifying initial_token will override this setting.\" So if exactly one initial token is set, then vnodes are disabled, regardless of if or what num_tokens are set to. This behavior is inconsistent when a node is started, versus if it has been bounced.\n\nFrom a fresh checkout of C*, if I build, then edit cassandra.yaml so that:\n\nnum_tokens: 256\ninitial_token: -9223372036854775808\n\nthen run bin/cassandra, C* will start correctly. I can run bin/nodetool ring and see that the node has exactly one token and it is what I set in initial_token. If I gracefully shutdown C*, then restart the node, running bin/nodetool ring shows that the node now has vnodes enabled and has 256 tokens.\n\nI have been able to reproduce this locally on OSX using 2.0.8, 2.1 rc1, and trunk. I have not yet tested in Linux or Windows to see if it occurs there.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Node enables vnodes when bounced"
   },
   {
      "_id": "12721216",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-06-13 23:43:25",
      "description": "The parameter in the VM options -Dcassandra.config= needs file:///\nAllow the user to have optional \"file:///\" when loading the config file from the filesystem",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lhf",
         "patch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Missing flexibility to have file://<server>/<etc> vs. file:/// when loading config file cassandra.yaml"
   },
   {
      "_id": "12720965",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-06-12 19:51:51",
      "description": "Allow \"SELECT map['key]\" and \"SELECT list[index].\"  (Selecting a UDT subfield is already supported.)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow selecting Map values and Set elements"
   },
   {
      "_id": "12719029",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-06-07 19:11:35",
      "description": "compaction do not works under windows due to file rename fails: (Pro\nes nem\u00df p\u00b0\u00ddstup k souboru, nebo\u0141 jej pr\u00dfv\u00fd vyu\u00d7\u00ddv\u00df jin\u0159 proces = process can not access file because its in use by another process). Not all compactions are broken. compactions done during server startup on system tables works fine.\n\nINFO  18:30:27 Completed flushing c:\\cassandra-2.1\\data\\system\\compactions_in_progress-55080ab05d9c388690a4acb25fe1f77b\\system-compactions_in_progress-ka-6-Dat.db (42 bytes) for commitlog position ReplayPosition(segmentId=1402165543361, psition=8024611)\nERROR 18:30:27 Exception in thread hread[CompactionExecutor:5,1,RMI Runtime]\njava.lang.RuntimeException: Failed to rename c:\\cassandra-2.1\\data\\test\\sipdb-5\nf51090ee6511e3815625991ef2b954\\test-sipdb-tmp-ka-7-Index.db to c:\\cassandra-2.1\ndata\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-7-Index.db\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:167) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:151) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.j\nva:512) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.j\nva:504) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.close(SSTableWriter.ja\na:479) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SST\nbleWriter.java:427) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SST\nbleWriter.java:422) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewrit\nr.java:312) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewrit\nr.java:306) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionTask.runWith(Compaction\nask.java:188) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAware\nunnable.java:48) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:\n8) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(Co\npactionTask.java:74) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(Ab\ntractCompactionTask.java:59) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompa\ntionTask.run(CompactionManager.java:235) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0\nrc1]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:4\n1) ~[na:1.7.0_60]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_\n0]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor\njava:1145) ~[na:1.7.0_60]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecuto\n.java:615) [na:1.7.0_60]\n        at java.lang.Thread.run(Thread.java:745) [na:1.7.0_60]\nCaused by: java.nio.file.FileSystemException: c:\\cassandra-2.1\\data\\test\\sipdb-\n8f51090ee6511e3815625991ef2b954\\test-sipdb-tmp-ka-7-Index.db -> c:\\cassandra-2.\n\\data\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-7-Index.db: Pro\nes nem\u00df p\u00b0\u00ddstup k souboru, nebo\u0141 jej pr\u00dfv\u00fd vyu\u00d7\u00ddv\u00df jin\u0159 proces.\n\n        at sun.nio.fs.WindowsException.translateToIOException(WindowsException.\nava:86) ~[na:1.7.0_60]\n        at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.ja\na:97) ~[na:1.7.0_60]\n        at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301) ~[na:1.7.0\n60]\n        at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.\nava:287) ~[na:1.7.0_60]\n        at java.nio.file.Files.move(Files.java:1347) ~[na:1.7.0_60]\n        at org.apache.cassandra.io.util.FileUtils.atomicMoveWithFallback(FileUt\nls.java:181) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:163) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        ... 19 common frames omitted\nINFO  18:30:27 Compacting [SSTableReader(path='c:\\cassandra-2.1\\data\\system\\com\nactions_in_progress-55080ab05d9c388690a4acb25fe1f77b\\system-compactions_in_prog\ness-ka-3-Data.db'), SSTableReader(path='c:\\cassandra-2.1\\data\\system\\compaction\n_in_progress-55080ab05d9c388690a4acb25fe1f77b\\system-compactions_in_progress-ka\n5-Data.db'), SSTableReader(path='c:\\cassandra-2.1\\data\\system\\compactions_in_pr\ngress-55080ab05d9c388690a4acb25fe1f77b\\system-compactions_in_progress-ka-4-Data\ndb'), SSTableReader(path='c:\\cassandra-2.1\\data\\system\\compactions_in_progress-\n5080ab05d9c388690a4acb25fe1f77b\\system-compactions_in_progress-ka-6-Data.db')]\nERROR 18:30:27 Exception in thread Thread[CompactionExecutor:5,1,RMI Runtime]\njava.lang.RuntimeException: Failed to rename c:\\cassandra-2.1\\data\\test\\sipdb-5\nf51090ee6511e3815625991ef2b954\\test-sipdb-tmp-ka-7-Index.db to c:\\cassandra-2.1\ndata\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-7-Index.db\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:167) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:151) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.j\nva:512) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.j\nva:504) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.close(SSTableWriter.ja\na:479) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SST\nbleWriter.java:427) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SST\nbleWriter.java:422) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewrit\nr.java:312) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewrit\nr.java:306) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionTask.runWith(Compaction\nask.java:188) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAware\nunnable.java:48) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:\n8) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(Co\npactionTask.java:74) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(Ab\ntractCompactionTask.java:59) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompa\ntionTask.run(CompactionManager.java:235) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0\nrc1]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:4\n1) ~[na:1.7.0_60]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_\n0]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor\njava:1145) ~[na:1.7.0_60]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecuto\n.java:615) [na:1.7.0_60]\n        at java.lang.Thread.run(Thread.java:745) [na:1.7.0_60]\nCaused by: java.nio.file.FileSystemException: c:\\cassandra-2.1\\data\\test\\sipdb-\n8f51090ee6511e3815625991ef2b954\\test-sipdb-tmp-ka-7-Index.db -> c:\\cassandra-2.\n\\data\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-7-Index.db: Pro\nes nem\u00df p\u00b0\u00ddstup k souboru, nebo\u0141 jej pr\u00dfv\u00fd vyu\u00d7\u00ddv\u00df jin\u0159 proces.\n\n        at sun.nio.fs.WindowsException.translateToIOException(WindowsException.\nava:86) ~[na:1.7.0_60]\n        at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.ja\na:97) ~[na:1.7.0_60]\n        at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301) ~[na:1.7.0\n60]\n        at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.\nava:287) ~[na:1.7.0_60]\n        at java.nio.file.Files.move(Files.java:1347) ~[na:1.7.0_60]\n        at org.apache.cassandra.io.util.FileUtils.atomicMoveWithFallback(FileUt\nls.java:181) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:163) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        ... 19 common frames omitted\nINFO  18:30:27 Compacted 4 sstables to [].  423 bytes to 0 (~0% of original) in\n39ms = 0,000000MB/s.  4 total partitions merged to 0.  Partition merge counts w\nre {2:2, }\nINFO  18:30:45 Enqueuing flush of compactions_in_progress: 1345 (0%) on-heap, 0\n(0%) off-heap\nINFO  18:30:45 Writing Memtable-compactions_in_progress@15659113(153 serialized\nbytes, 10 ops, 0%/0% of on/off-heap limit)\nINFO  18:30:45 Completed flushing c:\\cassandra-2.1\\data\\system\\compactions_in_p\nogress-55080ab05d9c388690a4acb25fe1f77b\\system-compactions_in_progress-ka-8-Dat\n.db (173 bytes) for commitlog position ReplayPosition(segmentId=1402165543361,\nosition=8025407)\nINFO  18:30:45 Compacting [SSTableReader(path='c:\\cassandra-2.1\\data\\test\\sipdb\n58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-3-Data.db'), SSTableReader(path=\nc:\\cassandra-2.1\\data\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka\n1-Data.db'), SSTableReader(path='c:\\cassandra-2.1\\data\\test\\sipdb-58f51090ee651\ne3815625991ef2b954\\test-sipdb-ka-4-Data.db'), SSTableReader(path='c:\\cassandra-\n.1\\data\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-2-Data.db'),\nSTableReader(path='c:\\cassandra-2.1\\data\\test\\sipdb-58f51090ee6511e3815625991ef\nb954\\test-sipdb-ka-6-Data.db')]\nERROR 18:31:41 Unable to delete c:\\cassandra-2.1\\data\\test\\sipdb-58f51090ee6511\n3815625991ef2b954\\test-sipdb-ka-8-Data.db (it will be removed on server restart\n we'll also retry after GC)\nERROR 18:31:41 Missing component: c:\\cassandra-2.1\\data\\test\\sipdb-58f51090ee65\n1e3815625991ef2b954\\test-sipdb-tmp-ka-8-Digest.sha1\nERROR 18:31:41 Missing component: c:\\cassandra-2.1\\data\\test\\sipdb-58f51090ee65\n1e3815625991ef2b954\\test-sipdb-tmp-ka-8-Summary.db\nERROR 18:31:41 Missing component: c:\\cassandra-2.1\\data\\test\\sipdb-58f51090ee65\n1e3815625991ef2b954\\test-sipdb-tmp-ka-8-Statistics.db\nINFO  18:31:41 Enqueuing flush of compactions_in_progress: 148 (0%) on-heap, 0\n0%) off-heap\nINFO  18:31:41 Writing Memtable-compactions_in_progress@6888852(0 serialized by\nes, 1 ops, 0%/0% of on/off-heap limit)\nINFO  18:31:41 Completed flushing c:\\cassandra-2.1\\data\\system\\compactions_in_p\nogress-55080ab05d9c388690a4acb25fe1f77b\\system-compactions_in_progress-ka-9-Dat\n.db (42 bytes) for commitlog position ReplayPosition(segmentId=1402165543361, p\nsition=8025563)\nERROR 18:31:41 Exception in thread Thread[CompactionExecutor:6,1,RMI Runtime]\njava.lang.RuntimeException: Failed to rename c:\\cassandra-2.1\\data\\test\\sipdb-5\nf51090ee6511e3815625991ef2b954\\test-sipdb-tmp-ka-8-Index.db to c:\\cassandra-2.1\ndata\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-8-Index.db\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:167) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:151) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.j\nva:512) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.j\nva:504) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.close(SSTableWriter.ja\na:479) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SST\nbleWriter.java:427) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SST\nbleWriter.java:422) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewrit\nr.java:312) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewrit\nr.java:306) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionTask.runWith(Compaction\nask.java:188) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAware\nunnable.java:48) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:\n8) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(Co\npactionTask.java:74) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(Ab\ntractCompactionTask.java:59) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompa\ntionTask.run(CompactionManager.java:235) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0\nrc1]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:4\n1) ~[na:1.7.0_60]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_\n0]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor\njava:1145) ~[na:1.7.0_60]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecuto\n.java:615) [na:1.7.0_60]\n        at java.lang.Thread.run(Thread.java:745) [na:1.7.0_60]\nCaused by: java.nio.file.FileSystemException: c:\\cassandra-2.1\\data\\test\\sipdb-\n8f51090ee6511e3815625991ef2b954\\test-sipdb-tmp-ka-8-Index.db -> c:\\cassandra-2.\n\\data\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-8-Index.db: Pro\nes nem\u00df p\u00b0\u00ddstup k souboru, nebo\u0141 jej pr\u00dfv\u00fd vyu\u00d7\u00ddv\u00df jin\u0159 proces.\n\n        at sun.nio.fs.WindowsException.translateToIOException(WindowsException.\nava:86) ~[na:1.7.0_60]\n        at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.ja\na:97) ~[na:1.7.0_60]\n        at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301) ~[na:1.7.0\n60]\n        at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.\nava:287) ~[na:1.7.0_60]\n        at java.nio.file.Files.move(Files.java:1347) ~[na:1.7.0_60]\n        at org.apache.cassandra.io.util.FileUtils.atomicMoveWithFallback(FileUt\nls.java:181) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:163) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        ... 19 common frames omitted\nERROR 18:31:41 Exception in thread Thread[CompactionExecutor:6,1,RMI Runtime]\njava.lang.RuntimeException: Failed to rename c:\\cassandra-2.1\\data\\test\\sipdb-5\nf51090ee6511e3815625991ef2b954\\test-sipdb-tmp-ka-8-Index.db to c:\\cassandra-2.1\ndata\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-8-Index.db\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:167) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:151) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.j\nva:512) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.j\nva:504) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.close(SSTableWriter.ja\na:479) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SST\nbleWriter.java:427) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SST\nbleWriter.java:422) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewrit\nr.java:312) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.sstable.SSTableRewriter.finish(SSTableRewrit\nr.java:306) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionTask.runWith(Compaction\nask.java:188) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAware\nunnable.java:48) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:\n8) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(Co\npactionTask.java:74) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(Ab\ntractCompactionTask.java:59) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompa\ntionTask.run(CompactionManager.java:235) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0\nrc1]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:4\n1) ~[na:1.7.0_60]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_\n0]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor\njava:1145) ~[na:1.7.0_60]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecuto\n.java:615) [na:1.7.0_60]\n        at java.lang.Thread.run(Thread.java:745) [na:1.7.0_60]\nCaused by: java.nio.file.FileSystemException: c:\\cassandra-2.1\\data\\test\\sipdb-\n8f51090ee6511e3815625991ef2b954\\test-sipdb-tmp-ka-8-Index.db -> c:\\cassandra-2.\n\\data\\test\\sipdb-58f51090ee6511e3815625991ef2b954\\test-sipdb-ka-8-Index.db: Pro\nes nem\u00df p\u00b0\u00ddstup k souboru, nebo\u0141 jej pr\u00dfv\u00fd vyu\u00d7\u00ddv\u00df jin\u0159 proces.\n\n        at sun.nio.fs.WindowsException.translateToIOException(WindowsException.\nava:86) ~[na:1.7.0_60]\n        at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.ja\na:97) ~[na:1.7.0_60]\n        at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301) ~[na:1.7.0\n60]\n        at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.\nava:287) ~[na:1.7.0_60]\n        at java.nio.file.Files.move(Files.java:1347) ~[na:1.7.0_60]\n        at org.apache.cassandra.io.util.FileUtils.atomicMoveWithFallback(FileUt\nls.java:181) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.j\nva:163) ~[apache-cassandra-2.1.0-rc1.jar:2.1.0-rc1]\n        ... 19 common frames omitted",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "some compactions do not works under windows (file in use during rename)"
   },
   {
      "_id": "12718506",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-06-04 22:56:27",
      "description": "On windows, the JVM settings for max heap size and new gen heap size are set based on the total system memory. When the system has 8G of RAM, the max heap size is set to 2048M. However, according to http://goo.gl/1ElbLm, the recommended max heap for a 32 bit JVM on Windows is 1.8G.\n\nWhen cassandra is started on Windows under these conditions, the following error is seen:\n\nError occurred during initialization of VM\nCould not reserve enough space for object heap\nError: Could not create the Java Virtual Machine.\nError: A fatal exception has occurred. Program will exit.\n\nSwitching to a 64-bit JVM on the same machine solves the issue. If a 32-bit JVM is being used, cassandra should be started up with a smaller heap than would be normally used to prevent the error.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Java heap being set too large on Windows with 32-bit JVM"
   },
   {
      "_id": "12718454",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-06-04 19:59:52",
      "description": "In conf/cassandra-env.ps1 max heap size is set based on system memory. New generation heap size is then set based on max heap size. Integer division is not used, and thus floating point results are possible, which will prevent cassandra from being started up. The following error is seen:\n\nInvalid initial eden size: -Xmn511.75M\nError: Could not create the Java Virtual Machine.\nError: A fatal exception has occurred. Program will exit.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Java heap flags are being set to invalid values on Windows"
   },
   {
      "_id": "12718178",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-06-03 15:42:01",
      "description": "Reference CASSANDRA-3569\n\nWe need to change the powershell installation scripts to also update the registry w/a 5 minute tcp keepalive timer timeout.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Modify system tcp keepalive settings on Windows install scripts"
   },
   {
      "_id": "12717788",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-06-01 19:51:36",
      "description": "{code:failure message}\n    [junit] Testcase: testAutoReloadConfig(org.apache.cassandra.locator.GossipingPropertyFileSnitchTest):       Caused an ERROR\n    [junit] Illegal char <:> at index 2: /C:/vm-shared/src/cassandra/test/conf/cassandra-rackdc.properties\n    [junit] java.nio.file.InvalidPathException: Illegal char <:> at index 2: /C:/vm-shared/src/cassandra/test/conf/cassandra-rackdc.properties\n    [junit]     at sun.nio.fs.WindowsPathParser.normalize(WindowsPathParser.java:182)\n    [junit]     at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:153)\n    [junit]     at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77)\n    [junit]     at sun.nio.fs.WindowsPath.parse(WindowsPath.java:94)\n    [junit]     at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:255)\n    [junit]     at java.nio.file.Paths.get(Paths.java:84)\n    [junit]     at org.apache.cassandra.locator.GossipingPropertyFileSnitchTest.testAutoReloadConfig(GossipingPropertyFileSnitchTest.java:40)\n    [junit]\n    [junit]\n    [junit] Test org.apache.cassandra.locator.GossipingPropertyFileSnitchTest FAILED\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "GossipingPropertyFileSnitchTest fails on Windows"
   },
   {
      "_id": "12717652",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328217",
            "id": "12328217",
            "name": "Legacy/Streaming and Messaging",
            "description": "MessagingService, Bootstrap, Repair, Bulk Loading"
         }
      ],
      "created": "2014-05-30 21:02:45",
      "description": "InputStream.skip is returning -1 during exception conditions which leads the following logic to infinite loop:\n\n{code:title=loop}\nprotected void drain(InputStream dis, long bytesRead) throws IOException\n{\n    long toSkip = totalSize() - bytesRead;\n    toSkip = toSkip - dis.skip(toSkip);\n    while (toSkip > 0)\n        toSkip = toSkip - dis.skip(toSkip);\n}\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Core"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Infinite loop in StreamReader.read during exception condition while running repair"
   },
   {
      "_id": "12717141",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328322",
            "id": "12328322",
            "name": "Local/Startup and Shutdown",
            "description": "Startup and Shutdown"
         }
      ],
      "created": "2014-05-28 21:33:47",
      "description": "Similar to mlockall() in CLibrary.java for linux, it would be nice to lock the virtual address space on Windows to prevent page faults.\n\nOne option: Reference API:  http://msdn.microsoft.com/en-us/library/windows/desktop/aa366895(v=vs.85).aspx",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows: address potential JVM swapping"
   },
   {
      "_id": "12716401",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-05-23 18:49:46",
      "description": "Commit 1147ee3 for CASSANDRA-6975 introduced a regression for BatchlogManagerTest in 2.1 and trunk:\n\n{noformat}\n    [junit] Testsuite: org.apache.cassandra.db.BatchlogManagerTest\n    [junit] Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 45.795 sec\n    [junit] \n    [junit] ------------- Standard Output ---------------\n    [junit] WARN  18:43:57 Changing /127.0.0.1's host ID from 1c3d6470-e2aa-11e3-beb0-9b2001e5c823 to 32f21350-e2aa-11e3-beb0-9b2001e5c823\n    [junit] WARN  18:43:57 Changing /127.0.0.1's host ID from 1c3d6470-e2aa-11e3-beb0-9b2001e5c823 to 32f21350-e2aa-11e3-beb0-9b2001e5c823\n    [junit] ------------- ---------------- ---------------\n    [junit] Testcase: testReplay(org.apache.cassandra.db.BatchlogManagerTest):  Caused an ERROR\n    [junit] Error validating SELECT count(*) FROM %s.%s\n    [junit] java.lang.RuntimeException: Error validating SELECT count(*) FROM %s.%s\n    [junit]     at org.apache.cassandra.cql3.QueryProcessor.executeInternal(QueryProcessor.java:275)\n    [junit]     at org.apache.cassandra.db.BatchlogManager.countAllBatches(BatchlogManager.java:102)\n    [junit]     at org.apache.cassandra.db.BatchlogManagerTest.testReplay(BatchlogManagerTest.java:60)\n    [junit] Caused by: org.apache.cassandra.exceptions.SyntaxException: line 1:24 no viable alternative at character '%'\n    [junit]     at org.apache.cassandra.cql3.CqlLexer.throwLastRecognitionError(CqlLexer.java:201)\n    [junit]     at org.apache.cassandra.cql3.QueryProcessor.parseStatement(QueryProcessor.java:455)\n    [junit]     at org.apache.cassandra.cql3.QueryProcessor.getStatement(QueryProcessor.java:430)\n    [junit]     at org.apache.cassandra.cql3.QueryProcessor.parseStatement(QueryProcessor.java:211)\n    [junit]     at org.apache.cassandra.cql3.QueryProcessor.prepareInternal(QueryProcessor.java:252)\n    [junit]     at org.apache.cassandra.cql3.QueryProcessor.executeInternal(QueryProcessor.java:262)\n    [junit] \n    [junit] \n    [junit] Test org.apache.cassandra.db.BatchlogManagerTest FAILED\n{noformat}\n\nhttp://cassci.datastax.com/job/cassandra-2.1_utest/291/testReport/org.apache.cassandra.db/BatchlogManagerTest/testReplay/\nhttp://cassci.datastax.com/job/trunk_utest/627/testReport/junit/org.apache.cassandra.db/BatchlogManagerTest/testReplay/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "BatchlogManagerTest unit test failing in 2.1 & trunk"
   },
   {
      "_id": "12715776",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-05-21 15:37:47",
      "description": "Example:\nhttps://cassci.datastax.com/job/trunk_utest/623/testReport/org.apache.cassandra.thrift/MultiSliceTest/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "MultiSliceTest.test_with_overlap* unit tests failing in trunk"
   },
   {
      "_id": "12715471",
      "assignee": "krummas",
      "components": [],
      "created": "2014-05-20 13:23:46",
      "description": "LCS has a number of minor issues (maybe major depending on your perspective).\n\nLCS is primarily used for wide rows so for instance when you repair data in LCS you end up with a copy of an entire repaired row in L0.  Over time if you repair you end up with multiple copies of a row in L0 - L5.  This can make predicting disk usage confusing.  \n\nAnother issue is cleaning up tombstoned data.  If a tombstone lives in level 1 and data for the cell lives in level 5 the data will not be reclaimed from disk until the tombstone reaches level 5.\n\nI propose we add a \"major\" compaction for LCS that forces consolidation of data to level 5 to address these.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add \"Major\" Compaction to LCS and split sstables during STCS major compaction"
   },
   {
      "_id": "12714922",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-05-17 01:20:21",
      "description": "created a 3 node datacenter  called existing.\n\nran cassandra-stress:\n\n{{cassandra-stress -R NetworkTopologyStrategy -O existing:2 -d existing0 -n 2000000 -k}}\n\nAdded a 2nd datacenter called new with 3 nodes started it with {{auto_bootstrap: false}}\n{code}\nalter keyspace \"Keyspace1\" with replication = {'class':'NetworkTopologyStrategy','existing':2,'new':2};\n{code}\nI then discovered that cassandra-stress --operation=read failed with LOCAL_QUORUM if a node was down in the local datacenter - this occured in both, but should not have, so decided to try again.\n\nI shut down the new datacenter and removed all 3 nodes.  I then tried to drop the Keyspace1 keyspace.  cqlsh disconnected, and the log shows the error below.\n{code}\nERROR [MigrationStage:1] 2014-05-16 23:57:03,085 CassandraDaemon.java (line 198) Exception in thread Thread[MigrationStage:1,5,main]\njava.lang.IllegalStateException: One row required, 0 found\nat org.apache.cassandra.cql3.UntypedResultSet.one(UntypedResultSet.java:53)\nat org.apache.cassandra.config.KSMetaData.fromSchema(KSMetaData.java:263)\nat org.apache.cassandra.db.DefsTables.mergeKeyspaces(DefsTables.java:227)\nat org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:182)\nat org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:303)\nat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\nat java.util.concurrent.FutureTask.run(FutureTask.java:262)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\nat java.lang.Thread.run(Thread.java:744)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "schema"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Error when dropping keyspace."
   },
   {
      "_id": "12714791",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-05-16 15:54:18",
      "description": "    [junit] Testsuite: org.apache.cassandra.db.DirectoriesTest\n    [junit] Tests run: 4, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 1.297 sec\n    [junit]\n    [junit] Testcase: testDiskFailurePolicy_best_effort(org.apache.cassandra.db.DirectoriesTest):       FAILED\n    [junit]\n    [junit] junit.framework.AssertionFailedError:\n    [junit]     at org.apache.cassandra.db.DirectoriesTest.testDiskFailurePolicy_best_effort(DirectoriesTest.java:207)\n    [junit]\n    [junit]\n    [junit] Test org.apache.cassandra.db.DirectoriesTest FAILED\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "testDiskFailurePolicy_best_effort assertion error"
   },
   {
      "_id": "12714777",
      "assignee": "krummas",
      "components": [],
      "created": "2014-05-16 14:27:07",
      "description": "To get more testing etc, we should make incremental repair default in trunk",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Make incremental repair default in 3.0"
   },
   {
      "_id": "12714754",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-05-16 11:45:17",
      "description": "For CASSANDRA-6875 we need to be able to talk about tuples values and types (for prepared variables). Since we need it there, clients will need to support them anyway and so I think it would be a lot cleaner to start supporting those more generally. Besides, having tuples is a relatively simple and natural extension to what we have. I'll note in particular that tuple have a close relationship to user type in the sense that a tuple will be really just like an anonymous with no name for the fields and in particular a tuple value will be the same than a user type value.\n\nThe syntax would simply look like that:\n{noformat}\nCREATE TABLE foo (\n    k int PRIMARY KEY,\n    v tuple<int, text, float>\n)\n\nINSERT INTO foo(k, v) VALUES(0, (3, 'bar', 2.1));\n{noformat}\nWe can also add projections in selects if we want:\n{noformat}\nSELECT v[0], v[2] FROM foo WHERE k = 0;\n{noformat}\nbut that can come later (after all, we still don't have projections for collections and it's not a big deal).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Tuple type"
   },
   {
      "_id": "12714284",
      "assignee": "krummas",
      "components": [],
      "created": "2014-05-14 20:35:32",
      "description": "In CompactionTask.java, after a compaction finishes, we do this:\n\n{code}\n        replaceCompactedSSTables(toCompact, sstables);\n        // TODO: this doesn't belong here, it should be part of the reader to load when the tracker is wired up\n        for (SSTableReader sstable : sstables)\n            sstable.preheat(cachedKeyMap.get(sstable.descriptor));\n{code}\n\nThe problem is that if the table was dropped, {{replaceCompactedSSTables}} will release its references on the new {{sstables}}, resulting in them being closed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Post-compaction cache preheating can result in FileNotFoundExceptions when tables are dropped"
   },
   {
      "_id": "12713401",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-05-09 22:15:25",
      "description": "The new .bat launch script changes will require changes to ccm and dtests so we can get windows dtests running on cassci.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Update ccm for windows launch script changes from #7001"
   },
   {
      "_id": "12713178",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-05-08 20:29:35",
      "description": "Looks like files aren't getting deleted correctly during testLoadNewSSTablesAvoidsOverwrites during a sanity check.  Test passes on linux.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "ColumnFamilyStoreTest unit tests fails on Windows"
   },
   {
      "_id": "12713135",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-05-08 17:38:01",
      "description": "looks like a newline mismatch error",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CliTest unit test fails on Windows"
   },
   {
      "_id": "12712881",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-05-07 16:26:38",
      "description": "When migrating a cluster of 6 nodes from 1.2.11 to 2.0.7, we started to see on the first migrated node this error:\n{noformat}\nERROR [ReplicateOnWriteStage:1] 2014-05-07 11:26:59,779 CassandraDaemon.java (line 198) Exception in thread Thread[ReplicateOnWriteStage:1,5,main]\njava.lang.AssertionError: Wrong class type: class org.apache.cassandra.db.Column\n        at org.apache.cassandra.db.CounterColumn.reconcile(CounterColumn.java:159)\n        at org.apache.cassandra.db.filter.QueryFilter$1.reduce(QueryFilter.java:109)\n        at org.apache.cassandra.db.filter.QueryFilter$1.reduce(QueryFilter.java:103)\n        at org.apache.cassandra.utils.MergeIterator$ManyToOne.consume(MergeIterator.java:112)\n        at org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:98)\n        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n        at org.apache.cassandra.db.filter.NamesQueryFilter.collectReducedColumns(NamesQueryFilter.java:98)\n        at org.apache.cassandra.db.filter.QueryFilter.collateColumns(QueryFilter.java:122)\n        at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:80)\n        at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:72)\n        at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:297)\n        at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:53)\n        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1540)\n        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1369)\n        at org.apache.cassandra.db.Keyspace.getRow(Keyspace.java:327)\n        at org.apache.cassandra.db.SliceByNamesReadCommand.getRow(SliceByNamesReadCommand.java:55)\n        at org.apache.cassandra.db.CounterMutation.makeReplicationMutation(CounterMutation.java:100)\n        at org.apache.cassandra.service.StorageProxy$8$1.runMayThrow(StorageProxy.java:1085)\n        at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1916)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:744)\n{noformat}\n\nWe then saw on the other 5 nodes, still on 1.2.x, this error:\n{noformat}\nERROR [MutationStage:2793] 2014-05-07 11:46:12,301 CassandraDaemon.java (line 191) Exception in thread Thread[MutationStage:2793,5,main]\njava.lang.AssertionError: Wrong class type: class org.apache.cassandra.db.Column\n        at org.apache.cassandra.db.CounterColumn.reconcile(CounterColumn.java:165)\n        at org.apache.cassandra.db.AtomicSortedColumns$Holder.addColumn(AtomicSortedColumns.java:378)\n        at org.apache.cassandra.db.AtomicSortedColumns.addColumn(AtomicSortedColumns.java:166)\n        at org.apache.cassandra.db.AbstractColumnContainer.addColumn(AbstractColumnContainer.java:119)\n        at org.apache.cassandra.db.SuperColumn.addColumn(SuperColumn.java:218)\n        at org.apache.cassandra.db.SuperColumn.putColumn(SuperColumn.java:229)\n        at org.apache.cassandra.db.ThreadSafeSortedColumns.addColumnInternal(ThreadSafeSortedColumns.java:108)\n        at org.apache.cassandra.db.ThreadSafeSortedColumns.addAllWithSizeDelta(ThreadSafeSortedColumns.java:138)\n        at org.apache.cassandra.db.AbstractColumnContainer.addAllWithSizeDelta(AbstractColumnContainer.java:99)\n        at org.apache.cassandra.db.Memtable.resolve(Memtable.java:205)\n        at org.apache.cassandra.db.Memtable.put(Memtable.java:168)\n        at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:742)\n        at org.apache.cassandra.db.Table.apply(Table.java:388)\n        at org.apache.cassandra.db.Table.apply(Table.java:353)\n        at org.apache.cassandra.db.RowMutation.apply(RowMutation.java:280)\n        at org.apache.cassandra.db.CounterMutation.apply(CounterMutation.java:137)\n        at org.apache.cassandra.service.StorageProxy$7.runMayThrow(StorageProxy.java:773)\n        at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:1651)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:679)\n{noformat}\nHere some other stack we also on the 5 unmigrated nodes:\n{noformat}\nERROR [ReadStage:4242] 2014-05-07 11:46:12,259 CassandraDaemon.java (line 191) Exception in thread Thread[ReadStage:4242,5,main]\njava.lang.AssertionError: Wrong class type: class org.apache.cassandra.db.Column\n        at org.apache.cassandra.db.CounterColumn.reconcile(CounterColumn.java:165)\n        at org.apache.cassandra.db.AtomicSortedColumns$Holder.addColumn(AtomicSortedColumns.java:378)\n        at org.apache.cassandra.db.AtomicSortedColumns.addColumn(AtomicSortedColumns.java:166)\n        at org.apache.cassandra.db.AbstractColumnContainer.addColumn(AbstractColumnContainer.java:119)\n        at org.apache.cassandra.db.SuperColumn.addColumn(SuperColumn.java:218)\n        at org.apache.cassandra.db.SuperColumn.putColumn(SuperColumn.java:229)\n        at org.apache.cassandra.db.ArrayBackedSortedColumns.resolveAgainst(ArrayBackedSortedColumns.java:164)\n        at org.apache.cassandra.db.ArrayBackedSortedColumns.addColumn(ArrayBackedSortedColumns.java:141)\n        at org.apache.cassandra.db.AbstractColumnContainer.addColumn(AbstractColumnContainer.java:119)\n        at org.apache.cassandra.db.AbstractColumnContainer.addColumn(AbstractColumnContainer.java:114)\n        at org.apache.cassandra.db.filter.QueryFilter$1.reduce(QueryFilter.java:112)\n        at org.apache.cassandra.db.filter.QueryFilter$1.reduce(QueryFilter.java:96)\n        at org.apache.cassandra.utils.MergeIterator$ManyToOne.consume(MergeIterator.java:111)\n        at org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:97)\n        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n        at org.apache.cassandra.db.filter.NamesQueryFilter.collectReducedColumns(NamesQueryFilter.java:103)\n        at org.apache.cassandra.db.filter.QueryFilter.collateColumns(QueryFilter.java:136)\n        at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:84)\n        at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:291)\n        at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:65)\n        at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1391)\n        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1207)\n        at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1123)\n        at org.apache.cassandra.db.Table.getRow(Table.java:347)\n        at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:70)\n        at org.apache.cassandra.db.ReadVerbHandler.doVerb(ReadVerbHandler.java:44)\n        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:56)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:679)\n{noformat}\n\nAnd the client side, it is failing with:\n{noformat}\nCaused by: org.apache.cassandra.thrift.UnavailableException: null\n        at org.apache.cassandra.thrift.Cassandra$get_slice_result.read(Cassandra.java:7866)\n        at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)\n        at org.apache.cassandra.thrift.Cassandra$Client.recv_get_slice(Cassandra.java:594)\n        at org.apache.cassandra.thrift.Cassandra$Client.get_slice(Cassandra.java:578)\n        at me.prettyprint.cassandra.service.KeyspaceServiceImpl$7.execute(KeyspaceServiceImpl.java:274)\n{noformat}\n\nAfter seeing such errors, we just shut down the first migrated node, hoping it would avoid all these client errors. But errors continue to be logged, even if there were only the 5 1.2.x nodes in the ring.\nAs the usual wild guess, let's reboot a node to fix it. At our damned surprise, it would restart and would fail with:\n{noformat}\n INFO 11:33:40,190 Initializing system.LocationInfo\njava.lang.AssertionError\n        at org.apache.cassandra.cql3.CFDefinition.<init>(CFDefinition.java:162)\n        at org.apache.cassandra.config.CFMetaData.updateCfDef(CFMetaData.java:1541)\n        at org.apache.cassandra.config.CFMetaData.fromSchema(CFMetaData.java:1456)\n        at org.apache.cassandra.config.KSMetaData.deserializeColumnFamilies(KSMetaData.java:306)\n        at org.apache.cassandra.config.KSMetaData.fromSchema(KSMetaData.java:287)\n        at org.apache.cassandra.db.DefsTable.loadFromTable(DefsTable.java:154)\n        at org.apache.cassandra.config.DatabaseDescriptor.loadSchemas(DatabaseDescriptor.java:574)\n        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:253)\n        at org.apache.cassandra.service.CassandraDaemon.init(CassandraDaemon.java:381)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:616)\n        at org.apache.commons.daemon.support.DaemonLoader.load(DaemonLoader.java:212)\nCannot load daemon\nService exit with a return value of 3\n{noformat}\n\nFrom there we only had 4 running nodes, with errors spreading around. So we halted everything, put the first node back to 1.2.11 and restored the data which has been snapshot just before the first node was migrated. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Wrong class type: class org.apache.cassandra.db.Column in CounterColumn.reconcile"
   },
   {
      "_id": "12712461",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-05-06 00:16:25",
      "description": "bisecting..",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "o.a.c.service.RemoveTest unit test failing in 2.1"
   },
   {
      "_id": "12712444",
      "assignee": "philipthompson",
      "components": [],
      "created": "2014-05-05 22:25:24",
      "description": "Many dtests don't require special setup, specifically the cql tests. We can reuse the clusters we setup across multiple tests to save time.\n\nSuggestion: only share clusters across a single test suite, and don't share the cluster by default, turn it on per-class. If we share them more broadly than that we may get into weird states because some tests definitely do mess with the cluster setup.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "dtests should reuse existing clusters where possible"
   },
   {
      "_id": "12712426",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-05-05 21:39:07",
      "description": "bisecting..",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "o.a.c.db.marshal.CollectionTypeTest unit test failing in 2.1"
   },
   {
      "_id": "12712423",
      "assignee": "jbellis",
      "components": [],
      "created": "2014-05-05 21:13:38",
      "description": "bisecting...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "o.a.c.db.ColumnFamilyTest.testDigest failing in 2.1"
   },
   {
      "_id": "12712386",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-05-05 19:04:35",
      "description": "It would be nice if the sstablemetadata command printed out some more of the stuff we track.  Like the Min/Max column names and the min/max token in the file.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "sstablemetadata command should print some more stuff"
   },
   {
      "_id": "12712320",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2014-05-05 14:24:45",
      "description": "The patch for CASSANDRA-6914 left a few stuffs not properly handled:\n# A condition like {{IF m['foo'] = null}} is not handled and throw a NPE.\n# It's using ByteBuffer.equals() to compare 2 collection values which is generally incorrect (the actual comparator should be used).\n# If 2 conditions on 2 elements of the same collection were provided and the CAS failed, then the collection was duplicated in the resultSet.\n# The ColumnCondition.WithVariables was generally a bit inefficient/ugly: it can lead to bind multiple times the same terms which is unnecessary. It's cleaner to directly create a condition with bound values.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Followup to 6914: null handling, duplicate column in resultSet and cleanup"
   },
   {
      "_id": "12710662",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-04-25 21:25:23",
      "description": "Keyspaces which are named starting with capital letters (and perhaps other things) sometimes require double quotes and sometimes do not.\n\nFor example, describe works without quotes:\n\ncqlsh> describe keyspace ProductGenomeLocal;\n\nCREATE KEYSPACE \"ProductGenomeLocal\" WITH replication = {\n  'class': 'SimpleStrategy',\n  'replication_factor': '3'\n};\n\nUSE \"ProductGenomeLocal\";\n[...]\n\nBut use will not:\n\ncqlsh> use ProductGenomeLocal;\nBad Request: Keyspace 'productgenomelocal' does not exist\n\nIt seems that qoutes should only really be necessary when there's spaces or other symbols that need to be quoted. \n\nAt the least, the acceptance or failures of quotes should be consistent.\n\nOther minor annoyance: tab expansion works in use and describe with quotes, but will not work in either without quotes.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh: DESCRIBE is not case-insensitive"
   },
   {
      "_id": "12709810",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2014-04-22 16:51:26",
      "description": "Cassandra must refuse  BATCHes with {{TIMESTAMP}}, if they contain a CAS statement(s). Like this one:\n{code}\nBEGIN BATCH USING TIMESTAMP 1111111111111111\nINSERT INTO users (id, firstname, lastname) VALUES (999, 'Jack', 'Sparrow')  IF NOT EXISTS\nAPPLY BATCH\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "LWT",
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Refuse CAS batch that have a 'USING TIMESTAMP'"
   },
   {
      "_id": "12709760",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2014-04-22 13:10:35",
      "description": "Currently we manage a list of in-progress compactions in a system table, which we use to cleanup incomplete compactions when we're done. The problem with this is that 1) it's a bit clunky (and leaves us in positions where we can unnecessarily cleanup completed files, or conversely not cleanup files that have been superceded); and 2) it's only used for a regular compaction - no other compaction types are guarded in the same way, so can result in duplication if we fail before deleting the replacements.\n\nI'd like to see each sstable store in its metadata its direct ancestors, and on startup we simply delete any sstables that occur in the union of all ancestor sets. This way as soon as we finish writing we're capable of cleaning up any leftovers, so we never get duplication. It's also much easier to reason about.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "benedict-to-commit",
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Simplify (and unify) cleanup of compaction leftovers"
   },
   {
      "_id": "12709550",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2014-04-21 13:49:09",
      "description": "Currently we have unit tests failing on Windows that aren't failing on Unix.  We need to have parity on unit tests between platforms for future multi-platform development.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Clean up unit tests on Windows"
   },
   {
      "_id": "12707312",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2014-04-09 00:12:18",
      "description": "This looks like something fundamentally wrong with the sstable_generation_loading_test.py dtest - 1.2 and 2.0 look like:\n{noformat}\n$ export MAX_HEAP_SIZE=\"1G\"; export HEAP_NEWSIZE=\"256M\"; PRINT_DEBUG=true nosetests --nocapture --nologcapture --verbosity=3 sstable_generation_loading_test.py\nnose.config: INFO: Ignoring files matching ['^\\\\.', '^_', '^setup\\\\.py$']\nincompressible_data_in_compressed_table_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-sJDYKB\nok\nremove_index_file_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-gRTcgb\nCreated keyspaces. Sleeping 1s for propagation.\ntotal,interval_op_rate,interval_key_rate,latency/95th/99.9th,elapsed_time\n10000,1000,1000,11.5,80.3,280.6,5\nEND\nok\nsstableloader_compression_deflate_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-xneocV\nTesting sstableloader with pre_compression=Deflate and post_compression=Deflate\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\nsstableloader_compression_deflate_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-_iJ1tD\nTesting sstableloader with pre_compression=Deflate and post_compression=None\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\nsstableloader_compression_deflate_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-FZAci9\nTesting sstableloader with pre_compression=Deflate and post_compression=Snappy\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\nsstableloader_compression_none_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-AsoepN\nTesting sstableloader with pre_compression=None and post_compression=Deflate\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\nsstableloader_compression_none_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-Cfiwh8\nTesting sstableloader with pre_compression=None and post_compression=None\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\nsstableloader_compression_none_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-tTuQQg\nTesting sstableloader with pre_compression=None and post_compression=Snappy\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\nsstableloader_compression_snappy_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-lA0rXi\nTesting sstableloader with pre_compression=Snappy and post_compression=Deflate\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\nsstableloader_compression_snappy_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-jJ5iub\nTesting sstableloader with pre_compression=Snappy and post_compression=None\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\nsstableloader_compression_snappy_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-JTMBKg\nTesting sstableloader with pre_compression=Snappy and post_compression=Snappy\ncreating keyspace and inserting\nMaking a copy of the sstables\nWiping out the data and restarting cluster\nre-creating the keyspace and column families.\nCalling sstableloader\nNo sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]No sstables to stream\n\nprogress: [total: 100 - 0MB/s (avg: 0MB/s)]Reading data back\nFAIL\n\n======================================================================\nFAIL: sstableloader_compression_deflate_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 108, in sstableloader_compression_deflate_to_deflate_test\n    self.load_sstable_with_configuration('Deflate', 'Deflate')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n======================================================================\nFAIL: sstableloader_compression_deflate_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 102, in sstableloader_compression_deflate_to_none_test\n    self.load_sstable_with_configuration('Deflate', None)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n======================================================================\nFAIL: sstableloader_compression_deflate_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 105, in sstableloader_compression_deflate_to_snappy_test\n    self.load_sstable_with_configuration('Deflate', 'Snappy')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n======================================================================\nFAIL: sstableloader_compression_none_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 90, in sstableloader_compression_none_to_deflate_test\n    self.load_sstable_with_configuration(None, 'Deflate')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n======================================================================\nFAIL: sstableloader_compression_none_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 84, in sstableloader_compression_none_to_none_test\n    self.load_sstable_with_configuration(None, None)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n======================================================================\nFAIL: sstableloader_compression_none_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 87, in sstableloader_compression_none_to_snappy_test\n    self.load_sstable_with_configuration(None, 'Snappy')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n======================================================================\nFAIL: sstableloader_compression_snappy_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 99, in sstableloader_compression_snappy_to_deflate_test\n    self.load_sstable_with_configuration('Snappy', 'Deflate')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n======================================================================\nFAIL: sstableloader_compression_snappy_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 93, in sstableloader_compression_snappy_to_none_test\n    self.load_sstable_with_configuration('Snappy', None)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n======================================================================\nFAIL: sstableloader_compression_snappy_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 96, in sstableloader_compression_snappy_to_snappy_test\n    self.load_sstable_with_configuration('Snappy', 'Snappy')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 197, in load_sstable_with_configuration\n    read_and_validate_data(cursor)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 190, in read_and_validate_data\n    self.assertEquals([str(i), 'col', str(i)], cursor.fetchone())\nAssertionError: ['0', 'col', '0'] != None\n\n----------------------------------------------------------------------\nRan 11 tests in 336.704s\n\nFAILED (failures=9)\n{noformat}\n\n2.1 looks like:\n{noformat}\n$ export MAX_HEAP_SIZE=\"1G\"; export HEAP_NEWSIZE=\"256M\"; PRINT_DEBUG=true nosetests --nocapture --nologcapture --verbosity=3 sstable_generation_loading_test.py\nnose.config: INFO: Ignoring files matching ['^\\\\.', '^_', '^setup\\\\.py$']\nincompressible_data_in_compressed_table_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-gPkstl\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nremove_index_file_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-Vx3Bsj\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_deflate_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-Ap0VwZ\nTesting sstableloader with pre_compression=Deflate and post_compression=Deflate\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_deflate_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-Nsy44b\nTesting sstableloader with pre_compression=Deflate and post_compression=None\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_deflate_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-77_xIH\nTesting sstableloader with pre_compression=Deflate and post_compression=Snappy\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_none_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-x3esB0\nTesting sstableloader with pre_compression=None and post_compression=Deflate\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_none_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-HgJni9\nTesting sstableloader with pre_compression=None and post_compression=None\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_none_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-QkUEf5\nTesting sstableloader with pre_compression=None and post_compression=Snappy\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_snappy_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-mgv9zG\nTesting sstableloader with pre_compression=Snappy and post_compression=Deflate\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_snappy_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-e0mEVq\nTesting sstableloader with pre_compression=Snappy and post_compression=None\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\nsstableloader_compression_snappy_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading) ... cluster ccm directory: /tmp/dtest-x3D6Bu\nTesting sstableloader with pre_compression=Snappy and post_compression=Snappy\n[node1 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node1 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node1 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node1 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node1 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node1 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node1 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node1 ERROR]   ... 8 more\n[node1 ERROR] Caused by: java.lang.AssertionError\n[node1 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node1 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node1 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node1 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node1 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node1 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node1 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node1 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node1 ERROR]   at java.lang.Thread.run(Thread.java:744)\n[node2 ERROR] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625)\n[node2 ERROR]   at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454)\n[node2 ERROR]   at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543)\n[node2 ERROR] Caused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n[node2 ERROR]   at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n[node2 ERROR]   at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n[node2 ERROR]   at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407)\n[node2 ERROR]   ... 8 more\n[node2 ERROR] Caused by: java.lang.AssertionError\n[node2 ERROR]   at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340)\n[node2 ERROR]   at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380)\n[node2 ERROR]   at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188)\n[node2 ERROR]   at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316)\n[node2 ERROR]   at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n[node2 ERROR]   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n[node2 ERROR]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[node2 ERROR]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[node2 ERROR]   at java.lang.Thread.run(Thread.java:744)\nERROR\n\n======================================================================\nERROR: incompressible_data_in_compressed_table_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 25, in incompressible_data_in_compressed_table_test\n    cluster.populate(1).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: remove_index_file_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 55, in remove_index_file_test\n    cluster.populate(1).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_deflate_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 108, in sstableloader_compression_deflate_to_deflate_test\n    self.load_sstable_with_configuration('Deflate', 'Deflate')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_deflate_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 102, in sstableloader_compression_deflate_to_none_test\n    self.load_sstable_with_configuration('Deflate', None)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_deflate_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 105, in sstableloader_compression_deflate_to_snappy_test\n    self.load_sstable_with_configuration('Deflate', 'Snappy')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_none_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 90, in sstableloader_compression_none_to_deflate_test\n    self.load_sstable_with_configuration(None, 'Deflate')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_none_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 84, in sstableloader_compression_none_to_none_test\n    self.load_sstable_with_configuration(None, None)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_none_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 87, in sstableloader_compression_none_to_snappy_test\n    self.load_sstable_with_configuration(None, 'Snappy')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_snappy_to_deflate_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 99, in sstableloader_compression_snappy_to_deflate_test\n    self.load_sstable_with_configuration('Snappy', 'Deflate')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_snappy_to_none_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 93, in sstableloader_compression_snappy_to_none_test\n    self.load_sstable_with_configuration('Snappy', None)\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n======================================================================\nERROR: sstableloader_compression_snappy_to_snappy_test (sstable_generation_loading_test.TestSSTableGenerationAndLoading)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 96, in sstableloader_compression_snappy_to_snappy_test\n    self.load_sstable_with_configuration('Snappy', 'Snappy')\n  File \"/home/mshuler/git/cassandra-dtest/sstable_generation_loading_test.py\", line 127, in load_sstable_with_configuration\n    cluster.populate(2).start()\n  File \"/home/mshuler/git/ccm/ccmlib/cluster.py\", line 230, in start\n    raise NodeError(\"Error starting {0}.\".format(node.name), p)\nNodeError: Error starting node1.\n\n----------------------------------------------------------------------\nRan 11 tests in 56.599s\n\nFAILED (errors=11)\n{noformat}\n\n2.1 last ccm node1 log (node2 is the same):\n{noformat}\nINFO  [main] 2014-04-08 19:20:33,339 CassandraDaemon.java:102 - Hostname: hana.12.am\nINFO  [main] 2014-04-08 19:20:33,396 YamlConfigurationLoader.java:80 - Loading settings from file:/tmp/dtest-x3D6Bu/test/node1/conf/cassandra.yaml\nINFO  [main] 2014-04-08 19:20:33,514 YamlConfigurationLoader.java:123 - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=false; auto_snapshot=true; batchlog_replay_throttle_in_kb=1024; cas_contention_timeout_in_ms=1000; client_encryption_options=<REDACTED>; cluster_name=test; column_index_size_in_kb=64; commitlog_directory=/tmp/dtest-x3D6Bu/test/node1/commitlogs; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_preheat_key_cache=true; compaction_throughput_mb_per_sec=16; concurrent_counter_writes=32; concurrent_reads=32; concurrent_writes=32; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; cross_node_timeout=false; data_file_directories=[/tmp/dtest-x3D6Bu/test/node1/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; endpoint_snitch=SimpleSnitch; flush_directory=/tmp/dtest-x3D6Bu/test/node1/flush; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; in_memory_compaction_limit_in_mb=64; incremental_backups=false; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=-9223372036854775808; inter_dc_tcp_nodelay=false; internode_compression=all; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=0.4; native_transport_port=9042; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; phi_convict_threshold=5; preheat_kernel_page_cache=false; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=10000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=127.0.0.1; rpc_keepalive=true; rpc_port=9160; rpc_server_type=sync; saved_caches_directory=/tmp/dtest-x3D6Bu/test/node1/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; server_encryption_options=<REDACTED>; snapshot_before_compaction=false; ssl_storage_port=7001; start_native_transport=true; start_rpc=true; storage_port=7000; thrift_framed_transport_size_in_mb=15; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=10000; write_request_timeout_in_ms=10000]\nINFO  [main] 2014-04-08 19:20:33,740 DatabaseDescriptor.java:197 - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap\nINFO  [main] 2014-04-08 19:20:33,746 DatabaseDescriptor.java:285 - Global memtable on-heap threshold is enabled at 249MB\nINFO  [main] 2014-04-08 19:20:33,747 DatabaseDescriptor.java:289 - Global memtable off-heap threshold is enabled at 249MB\nINFO  [main] 2014-04-08 19:20:34,141 CassandraDaemon.java:113 - JVM vendor/version: Java HotSpot(TM) 64-Bit Server VM/1.7.0_51\nINFO  [main] 2014-04-08 19:20:34,141 CassandraDaemon.java:141 - Heap size: 1046937600/1046937600\nINFO  [main] 2014-04-08 19:20:34,141 CassandraDaemon.java:143 - Code Cache Non-heap memory: init = 2555904(2496K) used = 675712(659K) committed = 2555904(2496K) max = 50331648(49152K)\nINFO  [main] 2014-04-08 19:20:34,142 CassandraDaemon.java:143 - Par Eden Space Heap memory: init = 214827008(209792K) used = 81668768(79754K) committed = 214827008(209792K) max = 214827008(209792K)\nINFO  [main] 2014-04-08 19:20:34,142 CassandraDaemon.java:143 - Par Survivor Space Heap memory: init = 26804224(26176K) used = 0(0K) committed = 26804224(26176K) max = 26804224(26176K)\nINFO  [main] 2014-04-08 19:20:34,142 CassandraDaemon.java:143 - CMS Old Gen Heap memory: init = 805306368(786432K) used = 0(0K) committed = 805306368(786432K) max = 805306368(786432K)\nINFO  [main] 2014-04-08 19:20:34,142 CassandraDaemon.java:143 - CMS Perm Gen Non-heap memory: init = 21757952(21248K) used = 16716776(16324K) committed = 21757952(21248K) max = 85983232(83968K)\nINFO  [main] 2014-04-08 19:20:34,143 CassandraDaemon.java:144 - Classpath: /home/mshuler/git/cassandra/build/cobertura/classes:/tmp/dtest-x3D6Bu/test/node1/conf:/home/mshuler/git/cassandra/build/classes/main:/home/mshuler/git/cassandra/build/classes/thrift:/home/mshuler/git/cassandra/lib/airline-0.6.jar:/home/mshuler/git/cassandra/lib/antlr-3.2.jar:/home/mshuler/git/cassandra/lib/commons-cli-1.1.jar:/home/mshuler/git/cassandra/lib/commons-codec-1.2.jar:/home/mshuler/git/cassandra/lib/commons-lang3-3.1.jar:/home/mshuler/git/cassandra/lib/commons-math3-3.2.jar:/home/mshuler/git/cassandra/lib/compress-lzf-0.8.4.jar:/home/mshuler/git/cassandra/lib/concurrentlinkedhashmap-lru-1.4.jar:/home/mshuler/git/cassandra/lib/disruptor-3.0.1.jar:/home/mshuler/git/cassandra/lib/guava-16.0.jar:/home/mshuler/git/cassandra/lib/high-scale-lib-1.1.2.jar:/home/mshuler/git/cassandra/lib/jackson-core-asl-1.9.2.jar:/home/mshuler/git/cassandra/lib/jackson-mapper-asl-1.9.2.jar:/home/mshuler/git/cassandra/lib/jamm-0.2.6.jar:/home/mshuler/git/cassandra/lib/javax.inject.jar:/home/mshuler/git/cassandra/lib/jbcrypt-0.3m.jar:/home/mshuler/git/cassandra/lib/jline-1.0.jar:/home/mshuler/git/cassandra/lib/jna-4.0.0.jar:/home/mshuler/git/cassandra/lib/json-simple-1.1.jar:/home/mshuler/git/cassandra/lib/libthrift-0.9.1.jar:/home/mshuler/git/cassandra/lib/logback-classic-1.1.2.jar:/home/mshuler/git/cassandra/lib/logback-core-1.1.12.jar:/home/mshuler/git/cassandra/lib/lz4-1.2.0.jar:/home/mshuler/git/cassandra/lib/metrics-core-2.2.0.jar:/home/mshuler/git/cassandra/lib/netty-all-4.0.17.Final.jar:/home/mshuler/git/cassandra/lib/reporter-config-2.1.0.jar:/home/mshuler/git/cassandra/lib/slf4j-api-1.7.2.jar:/home/mshuler/git/cassandra/lib/snakeyaml-1.11.jar:/home/mshuler/git/cassandra/lib/snappy-java-1.0.5.jar:/home/mshuler/git/cassandra/lib/stream-2.5.2.jar:/home/mshuler/git/cassandra/lib/super-csv-2.1.0.jar:/home/mshuler/git/cassandra/lib/thrift-server-0.3.3.jar:/home/mshuler/.m2/repository/net/sourceforge/cobertura/cobertura/1.9.4.1/cobertura-1.9.4.1.jar:/home/mshuler/git/cassandra/lib/jamm-0.2.6.jar\nWARN  [main] 2014-04-08 19:20:34,204 CLibrary.java:130 - Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.\nINFO  [main] 2014-04-08 19:20:34,227 CacheService.java:111 - Initializing key cache with capacity of 49 MBs.\nINFO  [main] 2014-04-08 19:20:34,237 CacheService.java:133 - Initializing row cache with capacity of 0 MBs\nINFO  [main] 2014-04-08 19:20:34,244 CacheService.java:150 - Initializing counter cache with capacity of 24 MBs\nINFO  [main] 2014-04-08 19:20:34,246 CacheService.java:161 - Scheduling counter cache save to every 7200 seconds (going to save all keys).\nINFO  [main] 2014-04-08 19:20:34,360 ColumnFamilyStore.java:283 - Initializing system.schema_triggers\nINFO  [main] 2014-04-08 19:20:35,608 ColumnFamilyStore.java:283 - Initializing system.compaction_history\nINFO  [main] 2014-04-08 19:20:35,618 ColumnFamilyStore.java:283 - Initializing system.batchlog\nINFO  [main] 2014-04-08 19:20:35,624 ColumnFamilyStore.java:283 - Initializing system.sstable_activity\nINFO  [main] 2014-04-08 19:20:35,630 ColumnFamilyStore.java:283 - Initializing system.peer_events\nINFO  [main] 2014-04-08 19:20:35,643 ColumnFamilyStore.java:283 - Initializing system.compactions_in_progress\nINFO  [main] 2014-04-08 19:20:35,652 ColumnFamilyStore.java:283 - Initializing system.hints\nINFO  [main] 2014-04-08 19:20:35,656 ColumnFamilyStore.java:283 - Initializing system.schema_keyspaces\nINFO  [main] 2014-04-08 19:20:35,660 ColumnFamilyStore.java:283 - Initializing system.range_xfers\nINFO  [main] 2014-04-08 19:20:35,664 ColumnFamilyStore.java:283 - Initializing system.schema_columnfamilies\nINFO  [main] 2014-04-08 19:20:35,669 ColumnFamilyStore.java:283 - Initializing system.NodeIdInfo\nINFO  [main] 2014-04-08 19:20:35,677 ColumnFamilyStore.java:283 - Initializing system.paxos\nINFO  [main] 2014-04-08 19:20:35,682 ColumnFamilyStore.java:283 - Initializing system.schema_usertypes\nINFO  [main] 2014-04-08 19:20:35,686 ColumnFamilyStore.java:283 - Initializing system.schema_columns\nINFO  [main] 2014-04-08 19:20:35,691 ColumnFamilyStore.java:283 - Initializing system.IndexInfo\nINFO  [main] 2014-04-08 19:20:35,695 ColumnFamilyStore.java:283 - Initializing system.peers\nINFO  [main] 2014-04-08 19:20:35,700 ColumnFamilyStore.java:283 - Initializing system.local\nINFO  [main] 2014-04-08 19:20:35,820 DatabaseDescriptor.java:587 - Couldn't detect any schema definitions in local storage.\nINFO  [main] 2014-04-08 19:20:35,821 DatabaseDescriptor.java:592 - To create keyspaces and column families, see 'help create' in cqlsh.\nINFO  [main] 2014-04-08 19:20:35,903 ColumnFamilyStore.java:853 - Enqueuing flush of local: 1109 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 19:20:35,921 Memtable.java:344 - Writing Memtable-local@1878619947(220 serialized bytes, 5 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:1] 2014-04-08 19:20:36,021 Memtable.java:378 - Completed flushing /tmp/dtest-x3D6Bu/test/node1/flush/system/local-7ad54392bcdd35a684174e047860b377/system-local-ka-1-Data.db (171 bytes) for commitlog position ReplayPosition(segmentId=1397002835560, position=403)\nINFO  [main] 2014-04-08 19:20:36,038 CommitLog.java:108 - No commitlog files found; skipping replay\nINFO  [main] 2014-04-08 19:20:36,535 StorageService.java:510 - Cassandra version: 2.1.0-beta1-SNAPSHOT\nINFO  [main] 2014-04-08 19:20:36,535 StorageService.java:511 - Thrift API version: 19.39.0\nINFO  [main] 2014-04-08 19:20:36,559 StorageService.java:512 - CQL supported versions: 2.0.0,3.1.5 (default: 3.1.5)\nINFO  [main] 2014-04-08 19:20:36,595 IndexSummaryManager.java:99 - Initializing index summary manager with a memory pool size of 49 MB and a resize interval of 60 minutes\nINFO  [main] 2014-04-08 19:20:36,607 StorageService.java:537 - Loading persisted ring state\nINFO  [main] 2014-04-08 19:20:36,679 StorageService.java:858 - Saved tokens not found. Using configuration value: [-9223372036854775808]\nINFO  [main] 2014-04-08 19:20:36,701 MigrationManager.java:206 - Create new Keyspace: KSMetaData{name=system_traces, strategyClass=SimpleStrategy, strategyOptions={replication_factor=2}, cfMetaData={sessions=org.apache.cassandra.config.CFMetaData@7892cf41[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces,cfName=sessions,cfType=Standard,comparator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.ColumnToCollectionType(706172616d6574657273:org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type))),comment=traced sessions,readRepairChance=0.0,dclocalReadRepairChance=0.0,gcGraceSeconds=0,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.UUIDType,minCompactionThreshold=4,maxCompactionThreshold=32,columnMetadata={java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]=ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, componentIndex=null, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]=ColumnDefinition{name=duration, type=org.apache.cassandra.db.marshal.Int32Type, kind=REGULAR, componentIndex=0, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]=ColumnDefinition{name=parameters, type=org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, componentIndex=0, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]=ColumnDefinition{name=started_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, componentIndex=0, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=7 cap=7]=ColumnDefinition{name=request, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, componentIndex=0, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=11 cap=11]=ColumnDefinition{name=coordinator, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, componentIndex=0, indexName=null, indexType=null}},compactionStrategyClass=class org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy,compactionStrategyOptions={},compressionParameters={sstable_compression=org.apache.cassandra.io.compress.LZ4Compressor},bloomFilterFpChance=0.01,memtableFlushPeriod=3600000,caching={\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"},defaultTimeToLive=0,minIndexInterval=128,maxIndexInterval=2048,speculativeRetry=99.0PERCENTILE,populateIoCacheOnFlush=false,droppedColumns={},triggers={}], events=org.apache.cassandra.config.CFMetaData@3a437a40[cfId=8826e8e9-e16a-3728-8753-3bc1fc713c25,ksName=system_traces,cfName=events,cfType=Standard,comparator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.TimeUUIDType,org.apache.cassandra.db.marshal.UTF8Type),comment=,readRepairChance=0.0,dclocalReadRepairChance=0.0,gcGraceSeconds=0,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.UUIDType,minCompactionThreshold=4,maxCompactionThreshold=32,columnMetadata={java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]=ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, componentIndex=null, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=6 cap=6]=ColumnDefinition{name=source, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=6 cap=6]=ColumnDefinition{name=thread, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]=ColumnDefinition{name=activity, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=14 cap=14]=ColumnDefinition{name=source_elapsed, type=org.apache.cassandra.db.marshal.Int32Type, kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]=ColumnDefinition{name=event_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING_COLUMN, componentIndex=0, indexName=null, indexType=null}},compactionStrategyClass=class org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy,compactionStrategyOptions={},compressionParameters={sstable_compression=org.apache.cassandra.io.compress.LZ4Compressor},bloomFilterFpChance=0.01,memtableFlushPeriod=3600000,caching={\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"},defaultTimeToLive=0,minIndexInterval=128,maxIndexInterval=2048,speculativeRetry=99.0PERCENTILE,populateIoCacheOnFlush=false,droppedColumns={},triggers={}]}, durableWrites=true, userTypes=org.apache.cassandra.config.UTMetaData@240f1da2}\nINFO  [MigrationStage:1] 2014-04-08 19:20:36,826 ColumnFamilyStore.java:853 - Enqueuing flush of schema_keyspaces: 990 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:2] 2014-04-08 19:20:36,834 Memtable.java:344 - Writing Memtable-schema_keyspaces@2107075397(251 serialized bytes, 7 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:2] 2014-04-08 19:20:36,915 Memtable.java:378 - Completed flushing /tmp/dtest-x3D6Bu/test/node1/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-1-Data.db (216 bytes) for commitlog position ReplayPosition(segmentId=1397002835560, position=99535)\nINFO  [MigrationStage:1] 2014-04-08 19:20:36,920 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columnfamilies: 164066 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 19:20:36,921 Memtable.java:344 - Writing Memtable-schema_columnfamilies@1732384250(30202 serialized bytes, 514 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:1] 2014-04-08 19:20:37,019 Memtable.java:378 - Completed flushing /tmp/dtest-x3D6Bu/test/node1/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-1-Data.db (6720 bytes) for commitlog position ReplayPosition(segmentId=1397002835560, position=99535)\nINFO  [MigrationStage:1] 2014-04-08 19:20:37,033 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columns: 288881 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:2] 2014-04-08 19:20:37,034 Memtable.java:344 - Writing Memtable-schema_columns@985819426(46627 serialized bytes, 904 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:2] 2014-04-08 19:20:37,140 Memtable.java:378 - Completed flushing /tmp/dtest-x3D6Bu/test/node1/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-1-Data.db (10835 bytes) for commitlog position ReplayPosition(segmentId=1397002835560, position=99535)\nINFO  [MigrationStage:1] 2014-04-08 19:20:37,351 DefsTables.java:388 - Loading org.apache.cassandra.config.CFMetaData@40e9da6[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces,cfName=sessions,cfType=Standard,comparator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.ColumnToCollectionType(706172616d6574657273:org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type))),comment=traced sessions,readRepairChance=0.0,dclocalReadRepairChance=0.0,gcGraceSeconds=0,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.UUIDType,minCompactionThreshold=4,maxCompactionThreshold=32,columnMetadata={java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]=ColumnDefinition{name=duration, type=org.apache.cassandra.db.marshal.Int32Type, kind=REGULAR, componentIndex=0, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]=ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, componentIndex=null, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]=ColumnDefinition{name=parameters, type=org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, componentIndex=0, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]=ColumnDefinition{name=started_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, componentIndex=0, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=7 cap=7]=ColumnDefinition{name=request, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, componentIndex=0, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=11 cap=11]=ColumnDefinition{name=coordinator, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, componentIndex=0, indexName=null, indexType=null}},compactionStrategyClass=class org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy,compactionStrategyOptions={},compressionParameters={sstable_compression=org.apache.cassandra.io.compress.LZ4Compressor},bloomFilterFpChance=0.01,memtableFlushPeriod=3600000,caching={\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"},defaultTimeToLive=0,minIndexInterval=128,maxIndexInterval=2048,speculativeRetry=99.0PERCENTILE,populateIoCacheOnFlush=false,droppedColumns={},triggers={}]\nINFO  [MigrationStage:1] 2014-04-08 19:20:37,357 ColumnFamilyStore.java:283 - Initializing system_traces.sessions\nINFO  [MigrationStage:1] 2014-04-08 19:20:37,358 DefsTables.java:388 - Loading org.apache.cassandra.config.CFMetaData@5b8fff5e[cfId=8826e8e9-e16a-3728-8753-3bc1fc713c25,ksName=system_traces,cfName=events,cfType=Standard,comparator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.TimeUUIDType,org.apache.cassandra.db.marshal.UTF8Type),comment=,readRepairChance=0.0,dclocalReadRepairChance=0.0,gcGraceSeconds=0,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.UUIDType,minCompactionThreshold=4,maxCompactionThreshold=32,columnMetadata={java.nio.HeapByteBuffer[pos=0 lim=10 cap=10]=ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, componentIndex=null, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=6 cap=6]=ColumnDefinition{name=source, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=6 cap=6]=ColumnDefinition{name=thread, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]=ColumnDefinition{name=activity, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=14 cap=14]=ColumnDefinition{name=source_elapsed, type=org.apache.cassandra.db.marshal.Int32Type, kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]=ColumnDefinition{name=event_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING_COLUMN, componentIndex=0, indexName=null, indexType=null}},compactionStrategyClass=class org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy,compactionStrategyOptions={},compressionParameters={sstable_compression=org.apache.cassandra.io.compress.LZ4Compressor},bloomFilterFpChance=0.01,memtableFlushPeriod=3600000,caching={\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"},defaultTimeToLive=0,minIndexInterval=128,maxIndexInterval=2048,speculativeRetry=99.0PERCENTILE,populateIoCacheOnFlush=false,droppedColumns={},triggers={}]\nINFO  [MigrationStage:1] 2014-04-08 19:20:37,363 ColumnFamilyStore.java:283 - Initializing system_traces.events\nERROR [MigrationStage:1] 2014-04-08 19:20:37,426 CassandraDaemon.java:166 - Exception in thread Thread[MigrationStage:1,5,main]\njava.lang.AssertionError: null\n        at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256) ~[main/:na]\n        at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340) ~[main/:na]\n        at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380) ~[main/:na]\n        at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188) ~[main/:na]\n        at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316) ~[main/:na]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_51]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_51]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_51]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51]\n        at java.lang.Thread.run(Thread.java:744) [na:1.7.0_51]\nERROR [main] 2014-04-08 19:20:37,427 CassandraDaemon.java:471 - Exception encountered during startup\njava.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.AssertionError\n        at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:411) ~[main/:na]\n        at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:298) ~[main/:na]\n        at org.apache.cassandra.service.MigrationManager.announceNewKeyspace(MigrationManager.java:207) ~[main/:na]\n        at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:915) ~[main/:na]\n        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:625) ~[main/:na]\n        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:505) ~[main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:335) [main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:454) [main/:na]\n        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:543) [main/:na]\nCaused by: java.util.concurrent.ExecutionException: java.lang.AssertionError\n        at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.7.0_51]\n        at java.util.concurrent.FutureTask.get(FutureTask.java:188) ~[na:1.7.0_51]\n        at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:407) ~[main/:na]\n        ... 8 common frames omitted\nCaused by: java.lang.AssertionError: null\n        at org.apache.cassandra.gms.Gossiper.addLocalApplicationState(Gossiper.java:1256) ~[main/:na]\n        at org.apache.cassandra.service.MigrationManager.passiveAnnounce(MigrationManager.java:340) ~[main/:na]\n        at org.apache.cassandra.config.Schema.updateVersionAndAnnounce(Schema.java:380) ~[main/:na]\n        at org.apache.cassandra.db.DefsTables.mergeSchema(DefsTables.java:188) ~[main/:na]\n        at org.apache.cassandra.service.MigrationManager$2.runMayThrow(MigrationManager.java:316) ~[main/:na]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_51]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_51]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_51]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_51]\n        at java.lang.Thread.run(Thread.java:744) ~[na:1.7.0_51]\nERROR [StorageServiceShutdownHook] 2014-04-08 19:20:37,437 CassandraDaemon.java:166 - Exception in thread Thread[StorageServiceShutdownHook,5,main]\njava.lang.NullPointerException: null\n        at org.apache.cassandra.gms.Gossiper.stop(Gossiper.java:1270) ~[main/:na]\n        at org.apache.cassandra.service.StorageService$1.runMayThrow(StorageService.java:581) ~[main/:na]\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n        at java.lang.Thread.run(Thread.java:744) ~[na:1.7.0_51]\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "sstable_generation_loading_test sstableloader_compression_* dtests fail in 1.2, 2.0, and 2.1"
   },
   {
      "_id": "12707271",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2014-04-08 21:56:40",
      "description": "This test hangs forever. When I hit ctl-c after running the test, then the ccm nodes actually continue running - I think ccm is looking for log lines that never occur until the test is killed(?).\n{noformat}\n$ export MAX_HEAP_SIZE=\"1G\"; export HEAP_NEWSIZE=\"256M\"; ENABLE_VNODES=true PRINT_DEBUG=true nosetests --nocapture --nologcapture --verbosity=3 auth_test.py:TestAuth.system_auth_ks_is_alterable_test\nnose.config: INFO: Ignoring files matching ['^\\\\.', '^_', '^setup\\\\.py$']\nsystem_auth_ks_is_alterable_test (auth_test.TestAuth) ... cluster ccm directory: /tmp/dtest-O3AAJr\n^C\n{noformat}\nSearch for (hanging here) below - I typed this prior to hitting ctl-c. Then the nodes start running again and I see \"Listening for thrift clients\" later on.\n{noformat}\nmshuler@hana:~$ tail -f /tmp/dtest-O3AAJr/test/node*/logs/system.log\n==> /tmp/dtest-O3AAJr/test/node1/logs/system.log <==\nINFO  [MemtableFlushWriter:2] 2014-04-08 16:45:12,599 Memtable.java:344 - Writing Memtable-schema_columnfamilies@1792243696(1627 serialized bytes, 27 ops, 0%/0% of on/off-heap limit)\nINFO  [CompactionExecutor:2] 2014-04-08 16:45:12,603 CompactionTask.java:287 - Compacted 4 sstables to [/tmp/dtest-O3AAJr/test/node1/data/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-13,].  14,454 bytes to 11,603 (~80% of original) in 105ms = 0.105386MB/s.  7 total partitions merged to 3.  Partition merge counts were {1:1, 2:1, 4:1, }\nINFO  [MemtableFlushWriter:2] 2014-04-08 16:45:12,668 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node1/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-14-Data.db (956 bytes) for commitlog position ReplayPosition(segmentId=1396993504671, position=193292)\nINFO  [MigrationStage:1] 2014-04-08 16:45:12,669 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columns: 6806 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:12,670 Memtable.java:344 - Writing Memtable-schema_columns@352928691(1014 serialized bytes, 21 ops, 0%/0% of on/off-heap limit)\nINFO  [CompactionExecutor:1] 2014-04-08 16:45:12,672 CompactionTask.java:287 - Compacted 4 sstables to [/tmp/dtest-O3AAJr/test/node1/data/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-17,].  710 bytes to 233 (~32% of original) in 70ms = 0.003174MB/s.  6 total partitions merged to 3.  Partition merge counts were {1:2, 4:1, }\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:12,721 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node1/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-14-Data.db (435 bytes) for commitlog position ReplayPosition(segmentId=1396993504671, position=193830)\nWARN  [NonPeriodicTasks:1] 2014-04-08 16:45:20,566 FBUtilities.java:359 - Trigger directory doesn't exist, please create it and try again.\nINFO  [NonPeriodicTasks:1] 2014-04-08 16:45:20,570 PasswordAuthenticator.java:220 - PasswordAuthenticator created default user 'cassandra'\nINFO  [NonPeriodicTasks:1] 2014-04-08 16:45:21,806 Auth.java:232 - Created default superuser 'cassandra'\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [InternalResponseStage:4] 2014-04-08 16:45:12,214 ColumnFamilyStore.java:853 - Enqueuing flush of schema_keyspaces: 1004 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:12,215 Memtable.java:344 - Writing Memtable-schema_keyspaces@781373873(276 serialized bytes, 6 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:12,295 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-15-Data.db (179 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=243552)\nINFO  [InternalResponseStage:4] 2014-04-08 16:45:12,296 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columnfamilies: 34190 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:2] 2014-04-08 16:45:12,297 Memtable.java:344 - Writing Memtable-schema_columnfamilies@2077216447(5746 serialized bytes, 108 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:2] 2014-04-08 16:45:12,369 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-12-Data.db (2088 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=243552)\nINFO  [InternalResponseStage:4] 2014-04-08 16:45:12,370 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columns: 37408 (0%) on-heap, 0 (0%) off-heap\nINFO  [CompactionExecutor:4] 2014-04-08 16:45:12,371 CompactionTask.java:131 - Compacting [SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/data/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-9-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-11-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-10-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-12-Data.db')]\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:12,371 Memtable.java:344 - Writing Memtable-schema_columns@2003573271(5173 serialized bytes, 119 ops, 0%/0% of on/off-heap limit)\nWARN  [NonPeriodicTasks:1] 2014-04-08 16:45:20,248 FBUtilities.java:359 - Trigger directory doesn't exist, please create it and try again.\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:11,654 Memtable.java:344 - Writing Memtable-schema_keyspaces@789549279(276 serialized bytes, 6 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:11,788 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-14-Data.db (179 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=193958)\nINFO  [InternalResponseStage:1] 2014-04-08 16:45:11,789 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columnfamilies: 34192 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:2] 2014-04-08 16:45:11,790 Memtable.java:344 - Writing Memtable-schema_columnfamilies@1695849916(5746 serialized bytes, 108 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:2] 2014-04-08 16:45:11,898 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-11-Data.db (2087 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=194091)\nINFO  [InternalResponseStage:1] 2014-04-08 16:45:11,899 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columns: 37410 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:11,900 Memtable.java:344 - Writing Memtable-schema_columns@2090391222(5173 serialized bytes, 119 ops, 0%/0% of on/off-heap limit)\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:45:11,998 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-11-Data.db (1700 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=194091)\nINFO  [main] 2014-04-08 16:45:18,654 CassandraDaemon.java:533 - No gossip backlog; proceeding\nWARN  [NonPeriodicTasks:1] 2014-04-08 16:45:20,131 FBUtilities.java:359 - Trigger directory doesn't exist, please create it and try again.\n\n(hanging here)\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [NonPeriodicTasks:1] 2014-04-08 16:49:02,863 PasswordAuthenticator.java:220 - PasswordAuthenticator created default user 'cassandra'\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [NonPeriodicTasks:1] 2014-04-08 16:49:02,888 PasswordAuthenticator.java:220 - PasswordAuthenticator created default user 'cassandra'\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:02,919 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-12-Data.db (1699 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=243552)\nINFO  [CompactionExecutor:5] 2014-04-08 16:49:02,922 CompactionTask.java:131 - Compacting [SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/data/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-9-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-11-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-10-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-12-Data.db')]\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [InternalResponseStage:3] 2014-04-08 16:49:02,959 ColumnFamilyStore.java:853 - Enqueuing flush of schema_keyspaces: 1006 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:02,960 Memtable.java:344 - Writing Memtable-schema_keyspaces@44265998(276 serialized bytes, 6 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MigrationStage:1] 2014-04-08 16:49:02,970 ColumnFamilyStore.java:853 - Enqueuing flush of schema_keyspaces: 501 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:02,972 Memtable.java:344 - Writing Memtable-schema_keyspaces@603519674(138 serialized bytes, 3 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [main] 2014-04-08 16:49:03,029 Server.java:159 - Starting listening for CQL clients on /127.0.0.3:9042...\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [CompactionExecutor:4] 2014-04-08 16:49:03,064 CompactionTask.java:287 - Compacted 4 sstables to [/tmp/dtest-O3AAJr/test/node2/data/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-13,].  13,907 bytes to 7,643 (~54% of original) in 213ms = 0.034220MB/s.  9 total partitions merged to 3.  Partition merge counts were {1:1, 4:2, }\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,069 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-15-Data.db (179 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=213470)\nINFO  [InternalResponseStage:3] 2014-04-08 16:49:03,071 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columnfamilies: 42850 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,071 Memtable.java:344 - Writing Memtable-schema_columnfamilies@666219518(7373 serialized bytes, 135 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,087 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-16-Data.db (159 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=247475)\nINFO  [CompactionExecutor:5] 2014-04-08 16:49:03,090 CompactionTask.java:287 - Compacted 4 sstables to [/tmp/dtest-O3AAJr/test/node2/data/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-13,].  16,411 bytes to 11,314 (~68% of original) in 165ms = 0.065393MB/s.  9 total partitions merged to 3.  Partition merge counts were {1:1, 4:2, }\nINFO  [CompactionExecutor:6] 2014-04-08 16:49:03,090 CompactionTask.java:131 - Compacting [SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-14-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/data/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-13-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-15-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node2/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-16-Data.db')]\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,091 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columnfamilies: 8799 (0%) on-heap, 0 (0%) off-heap\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [main] 2014-04-08 16:49:03,091 ThriftServer.java:119 - Binding thrift service to /127.0.0.3:9160\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,091 Memtable.java:344 - Writing Memtable-schema_columnfamilies@1821762369(1609 serialized bytes, 27 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [Thread-8] 2014-04-08 16:49:03,098 ThriftServer.java:136 - Listening for thrift clients...\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,166 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-12-Data.db (2536 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=213470)\nINFO  [InternalResponseStage:3] 2014-04-08 16:49:03,167 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columns: 44033 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,168 Memtable.java:344 - Writing Memtable-schema_columns@1052245443(6187 serialized bytes, 140 ops, 0%/0% of on/off-heap limit)\nINFO  [CompactionExecutor:8] 2014-04-08 16:49:03,168 CompactionTask.java:131 - Compacting [SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-11-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-10-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-12-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/data/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-9-Data.db')]\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,203 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-14-Data.db (949 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=248454)\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,204 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columns: 6833 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,205 Memtable.java:344 - Writing Memtable-schema_columns@1698728310(1041 serialized bytes, 21 ops, 0%/0% of on/off-heap limit)\nINFO  [CompactionExecutor:6] 2014-04-08 16:49:03,218 CompactionTask.java:287 - Compacted 4 sstables to [/tmp/dtest-O3AAJr/test/node2/data/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-17,].  750 bytes to 233 (~31% of original) in 125ms = 0.001778MB/s.  8 total partitions merged to 3.  Partition merge counts were {1:1, 3:1, 4:1, }\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,278 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-12-Data.db (1990 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=213470)\nINFO  [CompactionExecutor:5] 2014-04-08 16:49:03,279 CompactionTask.java:131 - Compacting [SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-10-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-11-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/data/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-9-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-12-Data.db')]\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,310 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-14-Data.db (431 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=248454)\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [CompactionExecutor:8] 2014-04-08 16:49:03,313 CompactionTask.java:287 - Compacted 4 sstables to [/tmp/dtest-O3AAJr/test/node3/data/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-13,].  14,821 bytes to 8,115 (~54% of original) in 140ms = 0.055279MB/s.  9 total partitions merged to 3.  Partition merge counts were {1:1, 4:2, }\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,313 ColumnFamilyStore.java:853 - Enqueuing flush of schema_keyspaces: 502 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,315 Memtable.java:344 - Writing Memtable-schema_keyspaces@901379409(138 serialized bytes, 3 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,332 ColumnFamilyStore.java:853 - Enqueuing flush of schema_keyspaces: 501 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,333 Memtable.java:344 - Writing Memtable-schema_keyspaces@1181313624(138 serialized bytes, 3 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,392 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-16-Data.db (159 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=217732)\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,397 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columnfamilies: 8818 (0%) on-heap, 0 (0%) off-heap\nINFO  [CompactionExecutor:7] 2014-04-08 16:49:03,397 CompactionTask.java:131 - Compacting [SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-14-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/data/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-13-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-15-Data.db'), SSTableReader(path='/tmp/dtest-O3AAJr/test/node3/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-16-Data.db')]\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,400 Memtable.java:344 - Writing Memtable-schema_columnfamilies@2077765501(1627 serialized bytes, 27 ops, 0%/0% of on/off-heap limit)\nINFO  [CompactionExecutor:5] 2014-04-08 16:49:03,405 CompactionTask.java:287 - Compacted 4 sstables to [/tmp/dtest-O3AAJr/test/node3/data/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-13,].  16,987 bytes to 11,600 (~68% of original) in 123ms = 0.089940MB/s.  9 total partitions merged to 3.  Partition merge counts were {1:1, 4:2, }\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,418 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-18-Data.db (159 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=252763)\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,419 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columnfamilies: 8817 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,420 Memtable.java:344 - Writing Memtable-schema_columnfamilies@495883972(1627 serialized bytes, 27 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,483 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-14-Data.db (956 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=217732)\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,484 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columns: 6807 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,485 Memtable.java:344 - Writing Memtable-schema_columns@365627698(1014 serialized bytes, 21 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,519 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_columnfamilies-45f5b36024bc3f83a3631034ea4fa697/system-schema_columnfamilies-ka-15-Data.db (956 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=252896)\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,520 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columns: 6806 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,521 Memtable.java:344 - Writing Memtable-schema_columns@1830789468(1014 serialized bytes, 21 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [CompactionExecutor:7] 2014-04-08 16:49:03,523 CompactionTask.java:287 - Compacted 4 sstables to [/tmp/dtest-O3AAJr/test/node3/data/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-17,].  750 bytes to 233 (~31% of original) in 122ms = 0.001821MB/s.  8 total partitions merged to 3.  Partition merge counts were {1:1, 3:1, 4:1, }\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,562 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-14-Data.db (435 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=218351)\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,581 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node2/flush/system/schema_columns-296e9c049bec3085827dc17d3df2122a/system-schema_columns-ka-15-Data.db (435 bytes) for commitlog position ReplayPosition(segmentId=1396993504760, position=252896)\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,586 ColumnFamilyStore.java:853 - Enqueuing flush of schema_keyspaces: 502 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,586 Memtable.java:344 - Writing Memtable-schema_keyspaces@543512535(138 serialized bytes, 3 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node2/logs/system.log <==\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,604 DefsTables.java:388 - Loading org.apache.cassandra.config.CFMetaData@1327e4ff[cfId=2d324e48-3275-3517-8dd5-9a2c5b0856c5,ksName=system_auth,cfName=permissions,cfType=Standard,comparator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.ColumnToCollectionType(7065726d697373696f6e73:org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type))),comment=,readRepairChance=0.1,dclocalReadRepairChance=0.0,gcGraceSeconds=7776000,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.UTF8Type,minCompactionThreshold=4,maxCompactionThreshold=32,columnMetadata={java.nio.HeapByteBuffer[pos=0 lim=11 cap=11]=ColumnDefinition{name=permissions, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, componentIndex=1, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]=ColumnDefinition{name=username, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, componentIndex=null, indexName=null, indexType=null}, java.nio.HeapByteBuffer[pos=0 lim=8 cap=8]=ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING_COLUMN, componentIndex=0, indexName=null, indexType=null}},compactionStrategyClass=class org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy,compactionStrategyOptions={},compressionParameters={sstable_compression=org.apache.cassandra.io.compress.LZ4Compressor},bloomFilterFpChance=0.01,memtableFlushPeriod=0,caching={\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"},defaultTimeToLive=0,minIndexInterval=128,maxIndexInterval=2048,speculativeRetry=99.0PERCENTILE,populateIoCacheOnFlush=false,droppedColumns={},triggers={}]\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,610 ColumnFamilyStore.java:283 - Initializing system_auth.permissions\nINFO  [main] 2014-04-08 16:49:03,622 CassandraDaemon.java:501 - Waiting for gossip to settle before accepting client requests...\nINFO  [InternalResponseStage:5] 2014-04-08 16:49:03,625 ColumnFamilyStore.java:853 - Enqueuing flush of schema_keyspaces: 1004 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,626 Memtable.java:344 - Writing Memtable-schema_keyspaces@2064761560(276 serialized bytes, 6 ops, 0%/0% of on/off-heap limit)\n\n==> /tmp/dtest-O3AAJr/test/node3/logs/system.log <==\nINFO  [MemtableFlushWriter:3] 2014-04-08 16:49:03,664 Memtable.java:378 - Completed flushing /tmp/dtest-O3AAJr/test/node3/flush/system/schema_keyspaces-b0f2235744583cdb9631c43e59ce3676/system-schema_keyspaces-ka-18-Data.db (159 bytes) for commitlog position ReplayPosition(segmentId=1396993504533, position=222660)\nINFO  [MigrationStage:1] 2014-04-08 16:49:03,665 ColumnFamilyStore.java:853 - Enqueuing flush of schema_columnfamilies: 8818 (0%) on-heap, 0 (0%) off-heap\nINFO  [MemtableFlushWriter:1] 2014-04-08 16:49:03,666 Memtable.java:344 - Writing Memtable-schema_columnfamilies@1464552123(1627 serialized bytes, 27 ops, 0%/0% of on/off-heap limit)\n<...>\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "auth_test system_auth_ks_is_alterable_test dtest hangs in 2.1 and 2.0"
   },
   {
      "_id": "12707261",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334949",
            "id": "12334949",
            "name": "Test/dtest/python"
         }
      ],
      "created": "2014-04-08 21:19:29",
      "description": "I patched ccm with https://github.com/pcmanus/ccm/pull/109 and got an error from simple_bootstrap:\n{noformat}\n======================================================================\nFAIL: simple_bootstrap_test (bootstrap_test.TestBootstrap)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/home/mshuler/git/cassandra-dtest/bootstrap_test.py\", line 58, in simple_bootstrap_test\n    assert_almost_equal(initial_size, 2 * size1)\n  File \"/home/mshuler/git/cassandra-dtest/assertions.py\", line 26, in assert_almost_equal\n    assert vmin > vmax * (1.0 - error), \"values not within %.2f%% of the max: %s\" % (error * 100, args)\nAssertionError: values not within 16.00% of the max: (0, 186396)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "bootstrap_test simple_bootstrap_test dtest fails in 2.1"
   },
   {
      "_id": "12707218",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12313619",
            "id": "12313619",
            "name": "Packaging"
         }
      ],
      "created": "2014-04-08 17:30:59",
      "description": "The current .bat-based launching has neither the logic nor robustness of a bash or PowerShell-based solution.  In pursuit of making Windows a 1st-class citizen for C*, we need to augment the launch-process using something like PowerShell to get as close to feature-parity as possible with Linux.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows launch feature parity - augment launch process using PowerShell to match capabilities of *nix launching"
   },
   {
      "_id": "12707157",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-04-08 11:16:31",
      "description": "For tests purposes, DC2 was shut down for 1 day. The _hints_ table was filled with millions of rows. Now, when _HintedHandOffManager_ tries to _doDeliverHintsToEndpoint_  it queries the store with QueryFilter.getSliceFilter which counts deleted (TTLed) cells and throws org.apache.cassandra.db.filter.TombstoneOverwhelmingException. \nThrowing this exception stops the manager from running compaction as it is run only after successful handoff. This leaves the HH practically disabled till administrator runs truncateAllHints. \nWouldn't it be nicer if on org.apache.cassandra.db.filter.TombstoneOverwhelmingException run compaction? That would remove TTLed hints leaving whole HH mechanism in a healthy state.\n\nThe stacktrace is:\n{quote}\norg.apache.cassandra.db.filter.TombstoneOverwhelmingException\n\tat org.apache.cassandra.db.filter.SliceQueryFilter.collectReducedColumns(SliceQueryFilter.java:201)\n\tat org.apache.cassandra.db.filter.QueryFilter.collateColumns(QueryFilter.java:122)\n\tat org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:80)\n\tat org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:72)\n\tat org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:297)\n\tat org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:53)\n\tat org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1487)\n\tat org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1306)\n\tat org.apache.cassandra.db.HintedHandOffManager.doDeliverHintsToEndpoint(HintedHandOffManager.java:351)\n\tat org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:309)\n\tat org.apache.cassandra.db.HintedHandOffManager.access$300(HintedHandOffManager.java:92)\n\tat org.apache.cassandra.db.HintedHandOffManager$4.run(HintedHandOffManager.java:530)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n\tat java.lang.Thread.run(Thread.java:722)\n{quote}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "HintedHandoff",
         "TTL"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "HintedHandoff - expired hints may block future hints deliveries"
   },
   {
      "_id": "12707042",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2014-04-07 22:26:56",
      "description": "Memory-mapped I/O on Windows causes issues with hard-links; we're unable to delete hard-links to open files with memory-mapped segments even using nio.  We'll need to push for close to performance parity between mmap'ed I/O and buffered going forward as the buffered / compressed path offers other benefits.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows: remove mmap'ed I/O for index files and force standard file access"
   },
   {
      "_id": "12705654",
      "assignee": "krummas",
      "components": [],
      "created": "2014-03-31 13:50:32",
      "description": "Initially ran into this issue on a DSE 3.2 (C* 1.2) to DSE 4.0 (C* 2.0) upgrade, and then I was able to reproduce it when testing an upgrade from C* 2.0.5 to C* 2.1-beta so the problem still exists in the latest code.\n\nBasically after you've upgraded to the new version and run \"nodetool upgradesstables\" on a CF/table that has been using LCS, then all of the non-L0 SSTables will be changed to L0 in the upgraded SSTables. In other words, they don't maintain their level and will have to go through the compaction again. The problem is that if you've got thousands of non-L0 SSTables before the upgrade, then all of these files showing up in L0 will push the system to do STCS and start to build some huge L0 tables. If a user doesn't budget enough free space (for example, if they used the recommended guideline and only budgeted 10% of free space because LCS is in use), then this STCS in L0 effect will have them run out of space.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "upgradesstables does not maintain levels for existing SSTables"
   },
   {
      "_id": "12705579",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312980",
            "id": "12312980",
            "name": "Legacy/Documentation and Website"
         }
      ],
      "created": "2014-03-31 02:57:14",
      "description": "Native protocol v2 spec is missing column type definition for text. Should be 0x000A.\n\nhttps://github.com/apache/cassandra/blob/trunk/doc/native_protocol_v2.spec#L526",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "native_protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Native protocol v2 spec is missing column type definition for text"
   },
   {
      "_id": "12704100",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-03-27 20:49:52",
      "description": "liveRatio calculation on an empty memtable results in a value of Infinity since memtable.currentSize=0.  Infinity then gets capped at the liveRatio max of 64.\n\n{noformat}\nWARN [MemoryMeter:1] 2014-03-19 09:26:59,483 Memtable.java (line 441) setting live ratio to maximum of 64.0 instead of Infinity\nINFO [MemoryMeter:1] 2014-03-19 09:26:59,485 Memtable.java (line 452) CFS(Keyspace='system', ColumnFamily='compactions_in_progress') liveRatio is 64.0 (just-counted was 64.0).  calculation took 7ms for 0 cells\n{noformat}\n\nJumping liveRatio to the max value based on an empty Memtable leads to more frequent flushing than may be necessary.\n\nCASSANDRA-4243 previously addressed this issue, but was resolved as fixed by CASSANDRA-3741.  It does not appear this issue has been fixed as of 2.0.5",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "memtables"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "liveRatio jumps to max when Memtable is empty"
   },
   {
      "_id": "12703505",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2014-03-25 16:14:18",
      "description": "This is due to CASSANDRA-6595: we call blockFor() for the paxos consistency, but we never added SERIAL/LOCAL_SERIAL in that method. Attaching trivial patch to add it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix UnsupportedOperationException on CAS timeout"
   },
   {
      "_id": "12703187",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2014-03-24 12:53:47",
      "description": "{code}\nCREATE TABLE test (id int, data map<text,text>, PRIMARY KEY(id));\n\nINSERT INTO test (id, data) VALUES (1,{'a':'1'});\n\nDELETE FROM test WHERE id=1 IF data['a']=null;\nBad Request: line 1:40 missing EOF at '='\n\nUPDATE test SET data['b']='2' WHERE id=1 IF data['a']='1';\nBad Request: line 1:53 missing EOF at '='\n{code}\nThese queries was successfuly executed with cassandra 2.0.5, but don't work in 2.0.6 release",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Map element is not allowed in CAS condition with DELETE/UPDATE query"
   },
   {
      "_id": "12703004",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-03-22 01:02:41",
      "description": "Per discussion in CASSANDRA-4050, we should ignore the snapshot repair flag on windows, and log a warning while proceeding to do non-snapshot repair.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "ignore snapshot repair flag on Windows"
   },
   {
      "_id": "12702597",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2014-03-20 10:14:48",
      "description": "After updated to 2.0.6, I have encountered the strange behavior of conditional updates.\n\nWhen I executed CQL like UPDATE test SET value = ? WHERE id = ? IF value = ? in concurrent, sometimes cassandra returns true even if value is not satisfied the condition.\n\nI have attached the program which reproduce this issue. The program works fine in cassandra 2.0.5. But it seems that resets values while execution in 2.0.6.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Unintended update with conditional statement"
   },
   {
      "_id": "12702474",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2014-03-19 20:43:49",
      "description": "Since we actively unmap unreferenced SSTR's and also copy data out of those readers on the read path, the current memory mapped i/o is a lot of complexity for very little payoff.  Clean out the mmapp'ed i/o on the read path.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Standardize on a single read path"
   },
   {
      "_id": "12701462",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2014-03-14 13:07:27",
      "description": "I think we need a V3 of the protocol for 2.1. The things that this could/should includes are:\n# Adding an optional Serial CL for protocol batches (like we have for QUERY and EXECUTE). It was an oversight of V2 of not adding it, and now that we can batch conditional updates, it's definitively missing.\n# Proper type codes for UDT. This is not *strictly* needed to be able to support UDT since currently a UDT will be sent as a \"custom type\" with his fully class name + arguments. But parsing that is no fun nor convenient for clients. It's also not particular space efficient (though that's probably not a huge concern since with prepared statement you can avoid sending the ResultSet metadata every time).\n# Serialization format for collections. Currently the serialization format only allow for 65K elements, each of 65K bytes size at most. While collections are not meant to store large amount of data, having the limitation in the protocol serialization format is the wrong way to deal with that. Concretely, the current workaround for CASSANDRA-5428 is ugly. I'll note that the current serialization format is also an obstacle to supporting null inside collections (whether or not we want to support null there is a good question, but here again I'm not sure being limited by the serialization format is a good idea).\n# CASSANDRA-6178: I continue to believe that in many case it makes somewhat more sense to have the default timestamp provided by the client (this is a necessary condition for true idempotent retries in particular). I'm absolutely fine making that optional and leaving server-side generated timestamps by default, but since client can already provide timestamp in query string anyway, I don't see a big deal in making it easier for client driver to control that without messing with the query string.\n# Optional names for values in QUERY messages: it has been brought to my attention that while V2 allows to send a query string with values for a one-roundtrip bind-and-execute, a driver can't really support named bind marker with that feature properly without parsing the query. The proposition is thus to make it (optionally) possible to ship the name of the marker each value is supposed to be bound to.\n\nI think that 1) and 2) are enough reason to make a V3 (even if there is disagreement on the rest that is).\n\n3) is a little bit more involved tbh but I do think having the current limitations bolted in the protocol serialization format is wrong in the long run, and it turns out that due to UDT we will start storing serialized collections internally so if we want to lift said limitation in the serialization format, we should do it now and everywhere, as doing it afterwards will be a lot more painful.\n\n4) and 5) are probably somewhat more minor, but at the same time, both are completely optional (a driver won't have to support those if he doesn't want). They are really just about making things more flexible for client drivers and they are not particularly hard to support so I don't see too many reasons not to include them.\n\nLast but not least, I know that some may find it wrong to do a new protocol version with each major of C*, so let me state my view here: I fully agree that we shouldn't make an habit of that in the long run and that's definitively *not* my objective. However, it would be silly to expect that we could get everything right and forget nothing in the very first version. It shouldn't be surprising that we'll have to burn a few versions (and there might be a few more yet) before getting something more stable and complete and I think that delaying the addition of stuffs that are useful to create some fake notion of stability would be even more silly. On the bright side, the additions of this V3 are comparatively much more simple to implement for a client that those of V2 (in fact, for clients that want to support UDT, it will probably require less effort to add the changes for this new version than to try to support UDT without it), so I do think we make good progress on getting the protocol stabilized \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Native protocol V3"
   },
   {
      "_id": "12701241",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2014-03-13 14:26:41",
      "description": "We allow\n\n{code}\nSELECT a, d FROM t.t WHERE b = 'b1' AND a = 'a14521'\n{code}\n\nand\n\n{code}\nSELECT a, d FROM t.t WHERE b = 'b1' AND token(a)  > token( 'a14521')\n{code}\n\nbut not\n{code}\nSELECT a, d FROM t.t WHERE b = 'b1' AND a  > 'a14521'\n{code}\n\n(given an index on {{b}}, with primary key {{a}})\n\nwe allow combining other predicates with an indexed one and filtering those in a nested loop; we should allow the same for primary keys",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "indexes"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow filtering on primary key expressions in 2i queries"
   },
   {
      "_id": "12700738",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2014-03-11 16:04:49",
      "description": "The batch CAS feature introduced in Cassandra 2.0.6 does not support the LOCAL_SERIAL consistency level, and always uses SERIAL.\n\nCreate a cluster with 4 nodes with the following topology:\n\n{code}\nDatacenter: DC2\n===============\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns   Host ID                               Rack\nUN  127.0.0.3  269 KB     256     26.3%  ae92d997-6042-42d9-b447-943080569742  RAC1\nUN  127.0.0.4  197.81 KB  256     25.1%  3edc92d7-9d1b-472a-8452-24dddbc4502c  RAC1\nDatacenter: DC1\n===============\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns   Host ID                               Rack\nUN  127.0.0.1  226.92 KB  256     24.8%  dbc17bd7-1ede-47a2-9b31-6063752d6eb3  RAC1\nUN  127.0.0.2  179.27 KB  256     23.7%  bb0ad285-34d2-4989-a664-b068986ab6fa  RAC1\n{code}\n\nIn cqlsh:\n{code}\ncqlsh> CREATE KEYSPACE foo WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': 2, 'DC2': 2};\ncqlsh> USE foo;\ncqlsh:foo> CREATE TABLE bar (x text, y bigint, z bigint, t bigint, PRIMARY KEY(x,y));\n{code}\n\nKill nodes 127.0.0.3 and 127.0.0.4:\n\n{code}\nDatacenter: DC2\n===============\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns   Host ID                               Rack\nDN  127.0.0.3  262.37 KB  256     26.3%  ae92d997-6042-42d9-b447-943080569742  RAC1\nDN  127.0.0.4  208.04 KB  256     25.1%  3edc92d7-9d1b-472a-8452-24dddbc4502c  RAC1\nDatacenter: DC1\n===============\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address    Load       Tokens  Owns   Host ID                               Rack\nUN  127.0.0.1  214.82 KB  256     24.8%  dbc17bd7-1ede-47a2-9b31-6063752d6eb3  RAC1\nUN  127.0.0.2  178.23 KB  256     23.7%  bb0ad285-34d2-4989-a664-b068986ab6fa  RAC1\n{code}\n\nConnect to 127.0.0.1 in DC1 and run a CAS batch at CL.LOCAL_SERIAL+LOCAL_QUORUM:\n\n{code}\n        final Cluster cluster = new Cluster.Builder()\n                .addContactPoint(\"127.0.0.1\")\n                .withLoadBalancingPolicy(new DCAwareRoundRobinPolicy(\"DC1\"))\n                .build();\n\n        final Session session = cluster.connect(\"foo\");\n\n        Batch batch = QueryBuilder.batch();\n        batch.add(new SimpleStatement(\"INSERT INTO bar (x,y,z) VALUES ('abc', 123, 1) IF NOT EXISTS\"));\n        batch.add(new SimpleStatement(\"UPDATE bar SET t=2 WHERE x='abc' AND y=123\"));\n\n        batch.setConsistencyLevel(ConsistencyLevel.LOCAL_QUORUM);\n        batch.setSerialConsistencyLevel(ConsistencyLevel.LOCAL_SERIAL);\n\n        session.execute(batch);\n{code}\n\nThe batch fails with:\n\n{code}\nCaused by: com.datastax.driver.core.exceptions.UnavailableException: Not enough replica available for query at consistency SERIAL (3 required but only 2 alive)\n\tat com.datastax.driver.core.Responses$Error$1.decode(Responses.java:44)\n\tat com.datastax.driver.core.Responses$Error$1.decode(Responses.java:33)\n\tat com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:182)\n\tat org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:66)\n\t... 21 more\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Batch CAS does not support LOCAL_SERIAL"
   },
   {
      "_id": "12698552",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328322",
            "id": "12328322",
            "name": "Local/Startup and Shutdown",
            "description": "Startup and Shutdown"
         }
      ],
      "created": "2014-03-04 02:02:52",
      "description": " \nHi,  \n\nOn doing a rolling restarting of a 2.0.5 cluster in several environments I'm seeing the following error:\n{code}\n\n INFO [CompactionExecutor:1] 2014-03-03 17:11:07,549 CompactionTask.java (line 115) Compacting [SSTableReader(path='/Users/Matthew/.ccm/compaction_race/node1/data/system/local/system-local-jb-13-Data.db'), SSTableReader(path='/Users/Matthew/.ccm/compactio\nn_race/node1/data/system/local/system-local-jb-15-Data.db'), SSTableReader(path='/Users/Matthew/.ccm/compaction_race/node1/data/system/local/system-local-jb-16-Data.db'), SSTableReader(path='/Users/Matthew/.ccm/compaction_race/node1/data/system/local/syst\nem-local-jb-14-Data.db')]\n INFO [CompactionExecutor:1] 2014-03-03 17:11:07,557 ColumnFamilyStore.java (line 254) Initializing system_traces.sessions\n INFO [CompactionExecutor:1] 2014-03-03 17:11:07,560 ColumnFamilyStore.java (line 254) Initializing system_traces.events\n WARN [main] 2014-03-03 17:11:07,608 ColumnFamilyStore.java (line 473) Removing orphans for /Users/Matthew/.ccm/compaction_race/node1/data/system/local/system-local-jb-13: [CompressionInfo.db, Filter.db, Index.db, TOC.txt, Summary.db, Data.db, Statistics.\ndb]\nERROR [main] 2014-03-03 17:11:07,609 CassandraDaemon.java (line 479) Exception encountered during startup\njava.lang.AssertionError: attempted to delete non-existing file system-local-jb-13-CompressionInfo.db\n        at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:111)\n        at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:106)\n        at org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:476)\n        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:264)\n        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:462)\n        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:552)\n INFO [CompactionExecutor:1] 2014-03-03 17:11:07,612 CompactionTask.java (line 275) Compacted 4 sstables to [/Users/Matthew/.ccm/compaction_race/node1/data/system/local/system-local-jb-17,].  10,963 bytes to 5,572 (~50% of original) in 57ms = 0.093226MB/s.  4 total partitions merged to 1.  Partition merge counts were {4:1, }\n\n{code}\nSeems like a potential race, since compactions are occurring whilst the existing data directories are being scrubbed.\nProbably an in progress compaction looks like an incomplete one and results in it being attempted to be scrubbed whilst in progress. \nOn the attempt to delete in the scrubDataDirectories we discover that it no longer exists, presumably because it has now been compacted away. \nThis then causes an assertion error and the node fails to start up. \n\nHere is a ccm script which just stops and starts a 3 node 2.0.5 cluster repeatedly. \nIt seems to fairly reliably reproduce the problem, in less than ten iterations: \n\n{code}\n#!/bin/bash\n\nccm create compaction_race -v 2.0.5\nccm populate -n 3\nccm start\n\nfor i in $(seq 0 1000); do \n    echo $i;\n    ccm stop\n    ccm start\n    grep ERR ~/.ccm/compaction_race/*/logs/system.log;\ndone\n\n{code}\n \nSomeone else should probably confirm that this is what is going wrong,  \nhowever if it is, the solution might be as simple as to disable autocompactions slightly earlier in CassandraDaemon.setup. \n \nOr alternatively if there isn't a good reason why we are first scrubbing the system tables and then scrubbing all keyspaces (including the system keyspace), you could perhaps just scrub solely the non system keyspaces on the second scrub.\n\nPlease let me know if there is anything else I can provide.\nThanks,\nMatt\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "concurrency",
         "starting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "compaction and scrub data directories race on startup"
   },
   {
      "_id": "12698449",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328322",
            "id": "12328322",
            "name": "Local/Startup and Shutdown",
            "description": "Startup and Shutdown"
         }
      ],
      "created": "2014-03-03 15:54:45",
      "description": "From comments on CASSANDRA-6736 (Bill Mitchell):\n\nTrying to be polite, I started using Drain to shutdown Cassandra before rebooting the machine. In one case, this provoked numerous ThreadPoolExecutor has shutdown messages underneath the compactor:\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:23,743 StorageService.java (line 947) DRAINING: starting drain process\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:23,783 ThriftServer.java (line 141) Stop listening to thrift clients\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:24,980 Server.java (line 181) Stop listening for CQL clients\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:24,980 Gossiper.java (line 1251) Announcing shutdown\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:27,001 MessagingService.java (line 665) Waiting for messaging service to quiesce\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:27,040 ColumnFamilyStore.java (line 784) Enqueuing flush of Memtable-sr@1217138300(1825983/4411193 serialized/live bytes, 29946 ops)\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:27,040 ColumnFamilyStore.java (line 784) Enqueuing flush of Memtable-etol@703118381(2963818/46129889 serialized/live bytes, 68926 ops)\nINFO [FlushWriter:272] 2014-02-24 08:34:27,040 Memtable.java (line 333) Writing Memtable-sr@1217138300(1825983/4411193 serialized/live bytes, 29946 ops)\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:27,054 ColumnFamilyStore.java (line 784) Enqueuing flush of Memtable-events@899982591(188/1880 serialized/live bytes, 7 ops)\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:27,075 ColumnFamilyStore.java (line 784) Enqueuing flush of Memtable-events_timeline@1379706298(16/160 serialized/live bytes, 1 ops)\nINFO [FlushWriter:273] 2014-02-24 08:34:27,075 Memtable.java (line 333) Writing Memtable-etol@703118381(2963818/46129889 serialized/live bytes, 68926 ops)\nINFO [ACCEPT-localhost/127.0.0.1] 2014-02-24 08:34:27,144 MessagingService.java (line 875) MessagingService has terminated the accept() thread\nINFO [FlushWriter:272] 2014-02-24 08:34:27,411 Memtable.java (line 373) Completed flushing C:\\Program Files\\DataStax Community\\data\\data\\testdb_1393207231382\\sr\\testdb_1393207231382-sr-jb-473-Data.db (428854 bytes) for commitlog position ReplayPosition(segmentId=1393178353775, position=18771262)\nINFO [FlushWriter:272] 2014-02-24 08:34:27,411 Memtable.java (line 333) Writing Memtable-events@899982591(188/1880 serialized/live bytes, 7 ops)\nINFO [FlushWriter:273] 2014-02-24 08:34:27,932 Memtable.java (line 373) Completed flushing C:\\Program Files\\DataStax Community\\data\\data\\testdb_1393207231382\\etol\\testdb_1393207231382-etol-jb-1563-Data.db (1012805 bytes) for commitlog position ReplayPosition(segmentId=1393178353775, position=18771262)\nINFO [FlushWriter:273] 2014-02-24 08:34:27,933 Memtable.java (line 333) Writing Memtable-events_timeline@1379706298(16/160 serialized/live bytes, 1 ops)\nINFO [FlushWriter:272] 2014-02-24 08:34:28,366 Memtable.java (line 373) Completed flushing C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-32-Data.db (184 bytes) for commitlog position ReplayPosition(segmentId=1393178353775, position=18771262)\nINFO [FlushWriter:273] 2014-02-24 08:34:28,456 Memtable.java (line 373) Completed flushing C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events_timeline\\OpsCenter-events_timeline-jb-39-Data.db (47 bytes) for commitlog position ReplayPosition(segmentId=1393178353775, position=18771262)\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:28,457 ColumnFamilyStore.java (line 784) Enqueuing flush of Memtable-compaction_history@814197203(1725/19675 serialized/live bytes, 45 ops)\nINFO [FlushWriter:272] 2014-02-24 08:34:28,458 Memtable.java (line 333) Writing Memtable-compaction_history@814197203(1725/19675 serialized/live bytes, 45 ops)\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:28,458 ColumnFamilyStore.java (line 784) Enqueuing flush of Memtable-sstable_activity@446592137(13500/207410 serialized/live bytes, 1442 ops)\nINFO [FlushWriter:273] 2014-02-24 08:34:28,458 Memtable.java (line 333) Writing Memtable-sstable_activity@446592137(13500/207410 serialized/live bytes, 1442 ops)\nINFO [FlushWriter:273] 2014-02-24 08:34:28,732 Memtable.java (line 373) Completed flushing C:\\Program Files\\DataStax Community\\data\\data\\system\\sstable_activity\\system-sstable_activity-jb-428-Data.db (4072 bytes) for commitlog position ReplayPosition(segmentId=1393178353775, position=18771471)\nINFO [FlushWriter:272] 2014-02-24 08:34:28,761 Memtable.java (line 373) Completed flushing C:\\Program Files\\DataStax Community\\data\\data\\system\\compaction_history\\system-compaction_history-jb-315-Data.db (823 bytes) for commitlog position ReplayPosition(segmentId=1393178353775, position=18771471)\nINFO [RMI TCP Connection(2095)-127.0.0.1] 2014-02-24 08:34:29,089 StorageService.java (line 947) DRAINED\nINFO [CompactionExecutor:70] 2014-02-24 08:34:43,085 ColumnFamilyStore.java (line 784) Enqueuing flush of Memtable-compactions_in_progress@1194966346(0/0 serialized/live bytes, 1 ops)\nINFO [FlushWriter:273] 2014-02-24 08:34:43,086 Memtable.java (line 333) Writing Memtable-compactions_in_progress@1194966346(0/0 serialized/live bytes, 1 ops)\nERROR [CompactionExecutor:70] 2014-02-24 08:34:43,114 CassandraDaemon.java (line 192) Exception in thread Thread[CompactionExecutor:70,1,main]\njava.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down\nat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:61)\nat java.util.concurrent.ThreadPoolExecutor.reject(Unknown Source)\nat java.util.concurrent.ThreadPoolExecutor.execute(Unknown Source)\nat org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:145)\nat java.util.concurrent.AbstractExecutorService.submit(Unknown Source)\nat org.apache.cassandra.db.ColumnFamilyStore.switchMemtable(ColumnFamilyStore.java:796)\nat org.apache.cassandra.db.ColumnFamilyStore.forceFlush(ColumnFamilyStore.java:861)\nat org.apache.cassandra.db.SystemKeyspace.forceBlockingFlush(SystemKeyspace.java:435)\nat org.apache.cassandra.db.SystemKeyspace.finishCompaction(SystemKeyspace.java:202)\nat org.apache.cassandra.db.compaction.CompactionTask.runWith(CompactionTask.java:225)\nat org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:48)\nat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\nat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:60)\nat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59)\nat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:197)\nat java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\nat java.util.concurrent.FutureTask.run(Unknown Source)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\nat java.lang.Thread.run(Unknown Source)\nOn restart, there was an FSWriteError in deleteWithConfirm:\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,196 ColumnFamilyStore.java (line 254) Initializing testdb_1393204279041.sr\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,199 ColumnFamilyStore.java (line 254) Initializing testdb_1393204279041.etol\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,203 ColumnFamilyStore.java (line 254) Initializing testdb_1393206475253.sr\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,206 ColumnFamilyStore.java (line 254) Initializing testdb_1393206475253.etol\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,209 ColumnFamilyStore.java (line 254) Initializing testdb_1393206779625.sr\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,212 ColumnFamilyStore.java (line 254) Initializing testdb_1393206779625.etol\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,215 ColumnFamilyStore.java (line 254) Initializing OpsCenter.pdps\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,218 ColumnFamilyStore.java (line 254) Initializing OpsCenter.rollups86400\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,223 ColumnFamilyStore.java (line 254) Initializing OpsCenter.rollups7200\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,241 ColumnFamilyStore.java (line 254) Initializing OpsCenter.events\nINFO [SSTableBatchOpen:1] 2014-02-24 09:27:27,246 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-28 (150 bytes)\nINFO [SSTableBatchOpen:2] 2014-02-24 09:27:27,247 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-26 (186 bytes)\nINFO [SSTableBatchOpen:1] 2014-02-24 09:27:27,295 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-31 (149 bytes)\nINFO [SSTableBatchOpen:2] 2014-02-24 09:27:27,314 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-25 (2239 bytes)\nINFO [SSTableBatchOpen:1] 2014-02-24 09:27:27,330 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-27 (149 bytes)\nINFO [SSTableBatchOpen:1] 2014-02-24 09:27:27,360 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-29 (186 bytes)\nINFO [SSTableBatchOpen:2] 2014-02-24 09:27:27,383 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-32 (184 bytes)\nINFO [SSTableBatchOpen:1] 2014-02-24 09:27:27,403 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events\\OpsCenter-events-jb-30 (149 bytes)\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,427 ColumnFamilyStore.java (line 254) Initializing OpsCenter.rollups300\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,434 ColumnFamilyStore.java (line 254) Initializing OpsCenter.events_timeline\nINFO [SSTableBatchOpen:1] 2014-02-24 09:27:27,437 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events_timeline\\OpsCenter-events_timeline-jb-39 (47 bytes)\nINFO [SSTableBatchOpen:2] 2014-02-24 09:27:27,438 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\events_timeline\\OpsCenter-events_timeline-jb-38 (706 bytes)\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,476 ColumnFamilyStore.java (line 254) Initializing OpsCenter.settings\nINFO [SSTableBatchOpen:1] 2014-02-24 09:27:27,478 SSTableReader.java (line 223) Opening C:\\Program Files\\DataStax Community\\data\\data\\OpsCenter\\settings\\OpsCenter-settings-jb-25 (232 bytes)\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,522 ColumnFamilyStore.java (line 254) Initializing OpsCenter.rollups60\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,526 ColumnFamilyStore.java (line 254) Initializing system_traces.sessions\nINFO [CompactionExecutor:1] 2014-02-24 09:27:27,529 ColumnFamilyStore.java (line 254) Initializing system_traces.events\nINFO [CompactionExecutor:1] 2014-02-24 09:27:29,930 CompactionTask.java (line 275) Compacted 32 sstables to [C:\\Program Files\\DataStax Community\\data\\data\\system\\compactions_in_progress\\system-compactions_in_progress-jb-596,]. 2,522 bytes to 322 (~12% of original) in 21,049ms = 0.000015MB/s. 32 total partitions merged to 15. Partition merge counts were\n{1:14, 2:9, }\nINFO [CompactionExecutor:2] 2014-02-24 09:27:29,958 CompactionTask.java (line 275) Compacted 16 sstables to [C:\\Program Files\\DataStax Community\\data\\data\\system\\compactions_in_progress\\system-compactions_in_progress-jb-597,]. 3,550 bytes to 1,832 (~51% of original) in 19,577ms = 0.000089MB/s. 16 total partitions merged to 14. Partition merge counts were\n{1:14, 2:1, }\nINFO [main] 2014-02-24 09:27:29,972 ColumnFamilyStore.java (line 784) Enqueuing flush of Memtable-local@2117211498(114/1140 serialized/live bytes, 4 ops)\nINFO [FlushWriter:2] 2014-02-24 09:27:29,972 Memtable.java (line 333) Writing Memtable-local@2117211498(114/1140 serialized/live bytes, 4 ops)\nINFO [FlushWriter:2] 2014-02-24 09:27:30,365 Memtable.java (line 373) Completed flushing C:\\Program Files\\DataStax Community\\data\\data\\system\\local\\system-local-jb-631-Data.db (150 bytes) for commitlog position ReplayPosition(segmentId=1393255627523, position=1437)\nINFO [CompactionExecutor:1] 2014-02-24 09:27:30,366 CompactionTask.java (line 115) Compacting [SSTableReader(path='C:\\Program Files\\DataStax Community\\data\\data\\system\\local\\system-local-jb-628-Data.db'), SSTableReader(path='C:\\Program Files\\DataStax Community\\data\\data\\system\\local\\system-local-jb-629-Data.db'), SSTableReader(path='C:\\Program Files\\DataStax Community\\data\\data\\system\\local\\system-local-jb-631-Data.db'), SSTableReader(path='C:\\Program Files\\DataStax Community\\data\\data\\system\\local\\system-local-jb-630-Data.db')]\nERROR [main] 2014-02-24 09:27:30,512 CassandraDaemon.java (line 479) Exception encountered during startup\nFSWriteError in C:\\Program Files\\DataStax Community\\data\\data\\system\\local\\system-local-tmp-jb-632-Data.db\nat org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:120)\nat org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:106)\nat org.apache.cassandra.io.sstable.SSTable.delete(SSTable.java:139)\nat org.apache.cassandra.db.ColumnFamilyStore.scrubDataDirectories(ColumnFamilyStore.java:463)\nat org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:264)\nat org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:462)\nat org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:552)\nCaused by: java.nio.file.FileSystemException: C:\\Program Files\\DataStax Community\\data\\data\\system\\local\\system-local-tmp-jb-632-Data.db: The process cannot access the file because it is being used by another process.\nat sun.nio.fs.WindowsException.translateToIOException(Unknown Source)\nat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\nat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\nat sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)\nat sun.nio.fs.AbstractFileSystemProvider.delete(Unknown Source)\nat java.nio.file.Files.delete(Unknown Source)\nat org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:116)\n... 6 more\n_________________\nNote: I've reproduced this while working on cleaning up ccm on Windows.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Forceful restart of C* during compaction on windows leads to exceptions on startup in scrubDataDirectories"
   },
   {
      "_id": "12696037",
      "assignee": "slebresne",
      "components": [],
      "created": "2014-02-19 18:23:51",
      "description": "BatchStatement creates a new ColumnFamily object (as well as a new RowMutation object) for every update in the batch, even if all those update are actually on the same partition. This is particularly inefficient when bulkloading data into a single partition (which is not all that uncommon).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "A batch statements on a single partition should not create a new CF object for each update"
   },
   {
      "_id": "12696033",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2014-02-19 18:16:01",
      "description": "Similar to the data file deletion of CASSANDRA-6283, under heavy load with logged batches, I am seeing a problem where the Commit log cannot be deleted:\n ERROR [COMMIT-LOG-ALLOCATOR] 2014-02-18 22:15:58,252 CassandraDaemon.java (line 192) Exception in thread Thread[COMMIT-LOG-ALLOCATOR,5,main]\n FSWriteError in C:\\Program Files\\DataStax Community\\data\\commitlog\\CommitLog-3-1392761510706.log\n\tat org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:120)\n\tat org.apache.cassandra.db.commitlog.CommitLogSegment.discard(CommitLogSegment.java:150)\n\tat org.apache.cassandra.db.commitlog.CommitLogAllocator$4.run(CommitLogAllocator.java:217)\n\tat org.apache.cassandra.db.commitlog.CommitLogAllocator$1.runMayThrow(CommitLogAllocator.java:95)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n\tat java.lang.Thread.run(Unknown Source)\nCaused by: java.nio.file.AccessDeniedException: C:\\Program Files\\DataStax Community\\data\\commitlog\\CommitLog-3-1392761510706.log\n\tat sun.nio.fs.WindowsException.translateToIOException(Unknown Source)\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\n\tat sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)\n\tat sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)\n\tat sun.nio.fs.AbstractFileSystemProvider.delete(Unknown Source)\n\tat java.nio.file.Files.delete(Unknown Source)\n\tat org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:116)\n\t... 5 more\n(Attached in 2014-02-18-22-16.log is a larger excerpt from the cassandra.log.)\n\nIn this particular case, I was trying to do 100 million inserts into two tables in parallel, one with a single wide row and one with narrow rows, and the error appeared after inserting 43,151,232 rows.  So it does take a while to trip over this timing issue.  \n\nIt may be aggravated by the size of the batches. This test was writing 10,000 rows to each table in a batch.  \n\nWhen I try switching the same test from using a logged batch to an unlogged batch, and no such failure appears. So the issue could be related to the use of large, logged batches, or it could be that unlogged batches just change the probability of failure.  \n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows7 AccessDeniedException on commit log "
   },
   {
      "_id": "12695739",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2014-02-18 17:45:31",
      "description": "CFSMBean.loadNewSSTables scans data directories for new sstables dropped there by an external agent.  This is dangerous because of possible filename conflicts with existing or newly generated sstables.\n\nInstead, we should support leaving the new sstables in a separate directory (specified by a parameter, or configured as a new location in yaml) and take care of renaming as necessary automagically.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "redesign loadnewsstables"
   },
   {
      "_id": "12695662",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-02-18 10:20:46",
      "description": "There is a few problems/improvements that can be done with the way we store schema:\n# CASSANDRA-4988: as explained on the ticket, storing the comparator is now redundant (or almost, we'd need to store whether the table is COMPACT or not too, which we don't currently is easy and probably a good idea anyway), it can be entirely reconstructed from the infos in schema_columns (the same is true of key_validator and subcomparator, and replacing default_validator by a COMPACT_VALUE column in all case is relatively simple). And storing the comparator as an opaque string broke concurrent updates of sub-part of said comparator (concurrent collection addition or altering 2 separate clustering columns typically) so it's really worth removing it.\n# CASSANDRA-4603: it's time to get rid of those ugly json maps. I'll note that schema_keyspaces is a problem due to its use of COMPACT STORAGE, but I think we should fix it once and for-all nonetheless (see below).\n# For CASSANDRA-6382 and to allow indexing both map keys and values at the same time, we'd need to be able to have more than one index definition for a given column.\n# There is a few mismatches in table options between the one stored in the schema and the one used when declaring/altering a table which would be nice to fix. The compaction, compression and replication maps are one already mentioned from CASSANDRA-4603, but also for some reason 'dclocal_read_repair_chance' in CQL is called just 'local_read_repair_chance' in the schema table, and 'min/max_compaction_threshold' are column families option in the schema but just compaction options for CQL (which makes more sense).\n\nNone of those issues are major, and we could probably deal with them independently but it might be simpler to just fix them all in one shot so I wanted to sum them all up here. In particular, the fact that 'schema_keyspaces' uses COMPACT STORAGE is annoying (for the replication map, but it may limit future stuff too) which suggest we should migrate it to a new, non COMPACT table. And while that's arguably a detail, it wouldn't hurt to rename schema_columnfamilies to schema_tables for the years to come since that's the prefered vernacular for CQL.\n\nOverall, what I would suggest is to move all schema tables to a new keyspace, named 'schema' for instance (or 'system_schema' but I prefer the shorter version), and fix all the issues above at once. Since we currently don't exchange schema between nodes of different versions, all we'd need to do that is a one shot startup migration, and overall, I think it could be simpler for clients to deal with one clear migration than to have to handle minor individual changes all over the place. I also think it's somewhat cleaner conceptually to have schema tables in their own keyspace since they are replicated through a different mechanism than other system tables.\n\nIf we do that, we could, for instance, migrate to the following schema tables (details up for discussion of course):\n{noformat}\nCREATE TYPE user_type (\n  name text,\n  column_names list<text>,\n  column_types list<text>\n)\n\nCREATE TABLE keyspaces (\n  name text PRIMARY KEY,\n  durable_writes boolean,\n  replication map<string, string>,\n  user_types map<string, user_type>\n)\n\nCREATE TYPE trigger_definition (\n  name text,\n  options map<tex, text>\n)\n\nCREATE TABLE tables (\n  keyspace text,\n  name text,\n  id uuid,\n  table_type text, // COMPACT, CQL or SUPER\n  dropped_columns map<text, bigint>,\n  triggers map<text, trigger_definition>,\n\n  // options\n  comment text,\n  compaction map<text, text>,\n  compression map<text, text>,\n  read_repair_chance double,\n  dclocal_read_repair_chance double,\n  gc_grace_seconds int,\n  caching text,\n  rows_per_partition_to_cache text,\n  default_time_to_live int,\n  min_index_interval int,\n  max_index_interval int,\n  speculative_retry text,\n  populate_io_cache_on_flush boolean,\n  bloom_filter_fp_chance double\n  memtable_flush_period_in_ms int,\n\n  PRIMARY KEY (keyspace, name)\n)\n\nCREATE TYPE index_definition (\n  name text,\n  index_type text,\n  options map<text, text>\n)\n\nCREATE TABLE columns (\n  keyspace text,\n  table text,\n  name text,\n  kind text, // PARTITION_KEY, CLUSTERING_COLUMN, REGULAR or COMPACT_VALUE\n  component_index int;\n  type text,\n  indexes map<text, index_definition>,\n\n  PRIMARY KEY (keyspace, table, name)\n)\n{noformat}\n\nNit: wouldn't hurt to create a simple enum that is reuse by both CFMetaData and CFPropDefs for table options names while we're at it once they are the same instead of repeating string constants which is fragile.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Modernize schema tables"
   },
   {
      "_id": "12695522",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2014-02-17 14:08:54",
      "description": "Our docs, and code, both explicitly say that you should drain a node before upgrading to a new major release.\n\nIf you don't do what the docs explicitly tell you to do, however, Cassandra won't scream at you. Also, we *do* currently have logic to replay 1.2 commitlog in 2.0, but it seems to be slightly broken, unfortunately.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix replaying old (1.2) commitlog in Cassandra 2.0"
   },
   {
      "_id": "12694767",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2014-02-12 16:17:47",
      "description": "In JBOD, when someone gets a bad drive, the bad drive is replaced with a new empty one and repair is run. \nThis can cause deleted data to come back in some cases. Also this is true for corrupt stables in which we delete the corrupt stable and run repair. \nHere is an example:\nSay we have 3 nodes A,B and C and RF=3 and GC grace=10days. \nrow=sankalp col=sankalp is written 20 days back and successfully went to all three nodes. \nThen a delete/tombstone was written successfully for the same row column 15 days back. \nSince this tombstone is more than gc grace, it got compacted in Nodes A and B since it got compacted with the actual data. So there is no trace of this row column in node A and B.\nNow in node C, say the original data is in drive1 and tombstone is in drive2. Compaction has not yet reclaimed the data and tombstone.  \nDrive2 becomes corrupt and was replaced with new empty drive. \nDue to the replacement, the tombstone in now gone and row=sankalp col=sankalp has come back to life. \nNow after replacing the drive we run repair. This data will be propagated to all nodes. \n\nNote: This is still a problem even if we run repair every gc grace. \n ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "correctness",
         "dense-storage",
         "doc-impacting",
         "jbod-aware-compaction",
         "lcs",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Partition sstables by token range"
   },
   {
      "_id": "12694431",
      "assignee": "krummas",
      "components": [],
      "created": "2014-02-11 06:31:28",
      "description": "Two cases where we can end up with overlapping sstables in the leveled manifest;\n\nFIrst one is when we skip levels during compaction. Here we need to make sure we are not compacting in newLevel - 1 since if, for example, we are doing a L1 -> L2 compaction and then start a new L0 compaction where we decide to skip L1, we could have overlapping sstables in L2 when the compactions are done. This case is new in 2.0 since we check if we skip levels before the compaction starts.\n\nSecond case is where we try to include as many overlapping L0 sstables as possible, here we could add sstables that are not compacting, but overlap sstables that are.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Avoid possible sstable overlaps with leveled compaction"
   },
   {
      "_id": "12693358",
      "assignee": "krummas",
      "components": [],
      "created": "2014-02-05 14:42:04",
      "description": "JMX is showing that one of our CQL3 LCS tables has a droppable tombstone ratio above 20% and increasing (currently at 28%).  Compactions are not falling behind and we are using the OOTB setting for this feature so I would expect not to go above 20% (will attach screen shot from JMX).   Table description:\n\nCREATE TABLE global_user (\n  user_id timeuuid,\n  app_id int,\n  type text,\n  name text,\n  extra_param map<text, text>,\n  last timestamp,\n  paid boolean,\n  sku_time map<text, timestamp>,\n  values map<timestamp, float>,\n  PRIMARY KEY (user_id, app_id, type, name)\n) WITH\n  bloom_filter_fp_chance=0.100000 AND\n  caching='KEYS_ONLY' AND\n  comment='' AND\n  dclocal_read_repair_chance=0.000000 AND\n  gc_grace_seconds=86400 AND\n  read_repair_chance=0.100000 AND\n  replicate_on_write='true' AND\n  populate_io_cache_on_flush='false' AND\n  compaction={'sstable_size_in_mb': '160', 'class': 'LeveledCompactionStrategy'} AND\n  compression={'chunk_length_kb': '8', 'crc_check_chance': '0.1', 'sstable_compression': 'LZ4Compressor'}; ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Droppable tombstones are not being removed from LCS table despite being above 20%"
   },
   {
      "_id": "12691271",
      "assignee": "krummas",
      "components": [],
      "created": "2014-01-26 16:23:30",
      "description": "The initial discussion started in (closed) CASSANDRA-5371. I've rewritten my last comment here...\n\nAfter streaming (e.g. during boostrap) Cassandra places all sstables at L0. At the end of the process we end up with huge number of sstables at the lowest level. \n\nCurrently, Cassandra falls back to STCS until the number of sstables at L0 reaches the reasonable level (32 or something).\n\nI'm not sure if falling back to STCS is the best way to handle this particular situation. I've read the comment in the code and I'm aware why it is a good thing to do if we have to many sstables at L0 as a result of too many random inserts. We have a lot of sstables, each of them covers the whole ring, there's simply no better option.\n\nHowever, after the bootstrap situation looks a bit different. The loaded sstables already have very small ranges! We just have to tidy up a bit and everything should be OK. STCS ignores that completely and after a while we have a bit less sstables but each of them covers the whole ring instead of just a small part. I believe that in that case letting LCS do the job is a better option that allowing STCS mix everything up before.\n\nIs there a way to disable STCS fallback? I'd like to test that scenario in practice during our next bootstrap...\n\nDoes Cassandra really have to put streamed sstables at L0? The only thing we have to assure is that sstables at any given level do not overlap. If we stream different regions from different nodes how can we get any overlaps?\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "lcs",
         "streaming"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add flag to disable STCS in L0"
   },
   {
      "_id": "12689250",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2014-01-16 14:33:33",
      "description": "For CAS, we send a few timeouts with -1 as received and expected counts, but it's kind of confusing from a user perspective (meaning that it could easily break user code that check those numbers just because they didn't expected a negative number). Suggesting to return 0 for received and whatever we block for for the CL involved for required instead.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Avoid special casing received/expected counts in CAS timeout exceptions"
   },
   {
      "_id": "12688424",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334946",
            "id": "12334946",
            "name": "Tool/nodetool"
         }
      ],
      "created": "2014-01-12 03:53:00",
      "description": "The node is leaving and I wanted to check its netstats, but it raises ConcurrentModificationException.\n\n{code}\n[ubuntu@ip-10-4-202-48 :~]# /mnt/cassandra_latest/bin/nodetool netstats\nMode: LEAVING\nException in thread \"main\" java.util.ConcurrentModificationException\n\tat java.util.HashMap$HashIterator.nextEntry(HashMap.java:926)\n\tat java.util.HashMap$ValueIterator.next(HashMap.java:954)\n\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:48)\n\tat com.google.common.collect.Iterators.addAll(Iterators.java:357)\n\tat com.google.common.collect.Lists.newArrayList(Lists.java:146)\n\tat com.google.common.collect.Lists.newArrayList(Lists.java:128)\n\tat org.apache.cassandra.streaming.management.SessionInfoCompositeData.toArrayOfCompositeData(SessionInfoCompositeData.java:161)\n\tat org.apache.cassandra.streaming.management.SessionInfoCompositeData.toCompositeData(SessionInfoCompositeData.java:98)\n\tat org.apache.cassandra.streaming.management.StreamStateCompositeData$1.apply(StreamStateCompositeData.java:82)\n\tat org.apache.cassandra.streaming.management.StreamStateCompositeData$1.apply(StreamStateCompositeData.java:79)\n\tat com.google.common.collect.Iterators$8.transform(Iterators.java:794)\n\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:48)\n\tat com.google.common.collect.Iterators.addAll(Iterators.java:357)\n\tat com.google.common.collect.Lists.newArrayList(Lists.java:146)\n\tat com.google.common.collect.Lists.newArrayList(Lists.java:128)\n\tat org.apache.cassandra.streaming.management.StreamStateCompositeData.toCompositeData(StreamStateCompositeData.java:78)\n\tat org.apache.cassandra.streaming.StreamManager$1.apply(StreamManager.java:87)\n\tat org.apache.cassandra.streaming.StreamManager$1.apply(StreamManager.java:84)\n\tat com.google.common.collect.Iterators$8.transform(Iterators.java:794)\n\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:48)\n\tat com.google.common.collect.Iterators.addAll(Iterators.java:357)\n\tat com.google.common.collect.Sets.newHashSet(Sets.java:238)\n\tat com.google.common.collect.Sets.newHashSet(Sets.java:218)\n\tat org.apache.cassandra.streaming.StreamManager.getCurrentStreams(StreamManager.java:83)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat sun.reflect.misc.Trampoline.invoke(MethodUtil.java:75)\n\tat sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:279)\n\tat com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)\n\tat com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)\n\tat com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)\n\tat com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)\n\tat com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)\n\tat com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)\n\tat javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1464)\n\tat javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:97)\n\tat javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1328)\n\tat javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1420)\n\tat javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:657)\n\tat sun.reflect.GeneratedMethodAccessor54.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:177)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:174)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.Transport.serviceCall(Transport.java:173)\n\tat sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:556)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:811)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:670)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:724)\n{code}\n\nThe gossip info is as follows:\n{code}\n/10.215.114.239\n  SCHEMA:e2a4b7b2-df50-3cc4-97f6-2ce7fb77982b\n  NET_VERSION:7\n  LOAD:6.42655250606E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1305722878370288637\n  HOST_ID:d13374d8-e4ae-466d-ad5a-44229a2fa190\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.122.218.80\n  SCHEMA:548308e6-bd1c-388f-ad1e-5ecf39f994fd\n  NET_VERSION:7\n  LOAD:2.71405175303E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1796000685025988745\n  HOST_ID:7746a875-1e53-4ebe-aef6-ad59fadd6ea7\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.178.13.230\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.34997966591E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:LEAVING,-1646882803236172485\n  HOST_ID:160d83bf-4cc0-4872-aec6-7908446eccbf\n  DC:pagedb-backend\n  SEVERITY:1.5584415197372437\n/10.71.141.179\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.21492186385E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1277850891915823266\n  HOST_ID:baa81888-6417-4e7c-8d7b-2bb79c38ca40\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.251.114.31\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.95280061394E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1b\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1866613386904756042\n  HOST_ID:a71e7037-c4f8-4ff9-864d-e83b6d3037d7\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.95.128.214\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.90628204861E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1e\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1896996972976095280\n  HOST_ID:3e5e6e75-56cb-4664-abf4-de8c2801bd5d\n  DC:pagedb-backend\n  SEVERITY:0.0\n/10.228.26.240\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.46469437383E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1359255731430490566\n  HOST_ID:8df816c9-7875-4106-aeda-b372b9f1fdc9\n  DC:pagedb-frontend\n  SEVERITY:1.5037593841552734\n/10.185.67.195\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:4.6531989096E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1295072457639851651\n  HOST_ID:37fe7cc7-3481-48b3-96ff-c92df17a4132\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.220.195.198\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:7.8265401144E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1514821029440891529\n  HOST_ID:0bd7f3ab-d347-4c59-9f1a-1b7104e34a6b\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.62.39.130\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.7020827919E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1089815038805941976\n  HOST_ID:13b12ee3-36a4-462c-9013-ccc1b83a70ff\n  DC:pagedb-frontend\n  SEVERITY:0.9411764144897461\n/10.137.11.197\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.17329728527E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:LEAVING,-1708596056219631840\n  HOST_ID:76d339f4-ac4a-4f95-bada-1ec17f67f4e3\n  DC:pagedb-backend\n  SEVERITY:0.5555555820465088\n/10.87.145.85\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:5.78714900637E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-2223601356751123985\n  HOST_ID:bdad1b28-3fb7-4788-8f34-01caace03ca9\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.97.135.36\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:9.3081789914E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1146411778648768253\n  HOST_ID:40fb13d6-0803-45cc-9b4f-45b3ad7194fa\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.95.128.6\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.56500409995E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1e\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1025262993714352739\n  HOST_ID:80b583a5-8f7d-4fee-91db-b948c090d055\n  DC:pagedb-backend\n  SEVERITY:0.7518796920776367\n/10.154.136.39\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.70485777643E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  HOST_ID:0e391fea-e4e9-4a46-b9af-87948459876c\n  STATUS:LEAVING,-2690692580263318876\n  DC:pagedb-backend\n  SEVERITY:0.0\n/10.185.9.84\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.87054930947E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:LEAVING,-1468213189211385280\n  HOST_ID:080241a9-eadd-48b4-8f94-efbe35bfd6e1\n  DC:pagedb-backend\n  SEVERITY:0.2557544708251953\n/10.251.114.15\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.86231038729E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1b\n  RPC_ADDRESS:0.0.0.0\n  HOST_ID:99e3e672-8410-4850-8257-edc7b814a776\n  STATUS:NORMAL,-1117031336072704821\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.97.135.32\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.1249908096E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1176341277720804881\n  HOST_ID:e9ac8ad9-c3cc-44ff-81e7-af28a4d5f576\n  DC:pagedb-backend\n  SEVERITY:0.0\n/10.99.144.60\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:8.9296442414E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1695890443918261320\n  HOST_ID:01b323c1-3f0e-40de-8ef7-3e1d33b391c5\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.121.13.216\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.70269351421E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1081159627867819835\n  HOST_ID:05f06b6f-ddb7-42a9-9e56-8efd41cf1545\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.99.144.97\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.95197366549E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1188304416367949186\n  HOST_ID:7a84853a-2c0a-448c-84e2-cceaa98c7523\n  DC:pagedb-backend\n  SEVERITY:0.26178011298179626\n/10.95.132.5\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:9.8325409989E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1e\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1168449340133292844\n  HOST_ID:6480a3a2-cbbe-44f4-b67b-7310f885b307\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.178.2.177\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.8547129498E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1337943409437095727\n  HOST_ID:aa7fd551-8a47-4e59-869e-ae0afaadf27e\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.201.206.166\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.02276920825E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-2302424866842171501\n  HOST_ID:f9651587-8f34-4dbc-af5c-64f19bc85ad6\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.93.6.87\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:5.55645040614E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1767037199861003446\n  HOST_ID:2ca596b1-fa0a-40a8-ace1-bc7b21e82c45\n  DC:pagedb-frontend\n  SEVERITY:1.0230178833007812\n/10.123.74.248\n  SCHEMA:b2c3e6ec-3b3f-3ad9-baef-e9e311a24eb9\n  NET_VERSION:7\n  LOAD:3.09054824961E11\n  REMOVAL_COORDINATOR:REMOVER,76d339f4-ac4a-4f95-bada-1ec17f67f4e3\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:removed,94daf57d-838d-4285-8048-e60f97629dba,1389650189822\n  HOST_ID:94daf57d-838d-4285-8048-e60f97629dba\n  DC:pagedb-backend\n  SEVERITY:0.2493765652179718\n/10.71.141.12\n  SCHEMA:26cf5f29-f7f9-321d-b5c4-ac9314d90653\n  NET_VERSION:7\n  LOAD:1.91108857556E11\n  REMOVAL_COORDINATOR:REMOVER,c7a0edfd-629e-47c3-b79c-32a9c2c98801\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:removed,4b9f63e5-8561-4e59-8011-e11fb3e8d627,1389562451886\n  HOST_ID:4b9f63e5-8561-4e59-8011-e11fb3e8d627\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.185.0.80\n  SCHEMA:039db936-c2e7-3f53-9c94-efdf2b861d53\n  NET_VERSION:7\n  LOAD:2.22049506986E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:removed,9885866e-af4d-4129-ad33-d465c8a7cd58,1389732020477\n  HOST_ID:9885866e-af4d-4129-ad33-d465c8a7cd58\n  DC:pagedb-backend\n  SEVERITY:2.7707808017730713\n/10.185.47.50\n  SCHEMA:b13a987f-adbe-3c19-afc9-419e595d9002\n  NET_VERSION:7\n  LOAD:2.19790952307E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  HOST_ID:73c27c92-1f3e-4628-9c91-a1e0a03a9e21\n  STATUS:removed,73c27c92-1f3e-4628-9c91-a1e0a03a9e21,1389731586723\n  DC:pagedb-backend\n  SEVERITY:6.6137566566467285\n/10.93.49.164\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.03359005906E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1102475930390387446\n  HOST_ID:19f401cb-b418-4ce3-b0e0-ea1530ab2121\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.206.97.184\n  SCHEMA:ede9498d-befd-3153-87ee-2ea329001466\n  NET_VERSION:7\n  LOAD:2.34212215287E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  HOST_ID:8d3d9e79-5a72-4561-99f0-0817cd6ad6cc\n  STATUS:LEAVING,-1397201050646007911\n  DC:pagedb-backend\n  SEVERITY:2.236421823501587\n/10.71.141.42\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:6.0594679857E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1008058669507434673\n  HOST_ID:2113b135-8566-4ed9-b74b-5e302d240c42\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.154.148.5\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:4.91232885735E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1261154574760184756\n  HOST_ID:86642aef-f625-4561-be7b-ab8f58066294\n  DC:pagedb-frontend\n  SEVERITY:0.7672634720802307\n/10.183.153.179\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.17986161259E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1e\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1486604450347152783\n  HOST_ID:5988d85d-663c-4597-9422-7f5bc195ec5b\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.97.131.247\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.43618302855E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1087382214101550882\n  HOST_ID:811a2966-b6f0-41fd-ba29-fc980763a69c\n  DC:pagedb-backend\n  SEVERITY:0.0\n/10.99.144.54\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:8.9936707476E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-3327961952466683302\n  HOST_ID:675e8de7-641f-4914-beeb-fad29942381f\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.210.91.83\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.19028851441E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1375725999837634215\n  HOST_ID:b0726b39-1587-4443-853e-6e668658b1cc\n  DC:pagedb-frontend\n  SEVERITY:17.39130401611328\n/10.71.141.158\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.11308980882E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1306761067597910068\n  HOST_ID:31c7690b-30fa-455c-9f69-e98f11d4c235\n  DC:pagedb-backend\n  SEVERITY:0.0\n/10.38.169.32\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.3296808983E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:LEAVING,-137637605179813169\n  HOST_ID:67ec4857-c867-46c8-9c62-778fd26360eb\n  DC:pagedb-backend\n  SEVERITY:1.671309232711792\n/10.87.94.230\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.52091238152E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:LEAVING,-1519665921822534263\n  HOST_ID:604b0268-187a-4a5f-a51e-b94608111825\n  DC:pagedb-backend\n  SEVERITY:0.27397260069847107\n/10.99.144.91\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.96583444544E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-3103769032004455685\n  HOST_ID:010613b8-9d0b-487d-bdd1-64e80ddc60e6\n  DC:pagedb-backend\n  SEVERITY:1.0204081535339355\n/10.71.141.130\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.45733317443E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1099965132011727160\n  HOST_ID:3c30b5fb-bf8c-4169-a60f-6ffad2c28598\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.99.146.244\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.6041541835E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1404826323347485057\n  HOST_ID:6a96c2e0-6376-461d-bac5-0dcbe3cd1eb5\n  DC:pagedb-backend\n  SEVERITY:0.0\n/10.95.129.124\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.61026008599E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1e\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-2498420976414553971\n  HOST_ID:2a987ea1-4037-4b9e-a403-27a6d7995621\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.122.50.31\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.18914643786E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  HOST_ID:b9e40521-bf2e-4833-8f6a-a8e3297df042\n  STATUS:NORMAL,-1277185879546496035\n  DC:pagedb-backend\n  SEVERITY:0.0\n/10.4.197.53\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.15526897917E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:LEAVING,-1388643925813439514\n  HOST_ID:9f76061b-43a7-432b-9e6d-612a628534cf\n  DC:pagedb-backend\n  SEVERITY:0.7537688612937927\n/10.44.183.111\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.10331330719E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:LEAVING,-283520605333269313\n  HOST_ID:1e0e3870-5026-452b-8050-dad7fcd5bd88\n  DC:pagedb-backend\n  SEVERITY:7.416880130767822\n/10.238.138.32\n  SCHEMA:b13a987f-adbe-3c19-afc9-419e595d9002\n  NET_VERSION:7\n  REMOVAL_COORDINATOR:REMOVER,3c30b5fb-bf8c-4169-a60f-6ffad2c28598\n  LOAD:1.92772802904E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  HOST_ID:e225c748-ffd8-4905-91bf-4e745b26fa44\n  STATUS:removed,e225c748-ffd8-4905-91bf-4e745b26fa44,1389731792774\n  DC:pagedb-backend\n  SEVERITY:0.0\n/10.95.129.103\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.50386165884E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1e\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1389777754931898083\n  HOST_ID:18031026-e20c-40eb-8bb3-d771b641fb26\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.125.10.14\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:7.2903902818E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1a\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1822845329295703853\n  HOST_ID:5764492f-31f8-4c3f-8bec-d8a2c1af4b4d\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.4.202.48\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:3.05065515518E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  HOST_ID:76f98456-2029-4bb6-b3de-e08157220fc9\n  STATUS:LEAVING,-2184837513740789816\n  DC:pagedb-backend\n  SEVERITY:28.76344108581543\n/10.95.132.44\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.97019107429E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1e\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-243162178282959980\n  HOST_ID:c7a0edfd-629e-47c3-b79c-32a9c2c98801\n  DC:pagedb-backend\n  SEVERITY:0.5076141953468323\n/10.96.31.80\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:2.29408976299E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1c\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1236217677726412210\n  HOST_ID:fa3ea99e-f9b6-4f83-9234-21d8059e6eb4\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.40.245.193\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:1.27656537169E11\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1237220198988914368\n  HOST_ID:d2383010-fd55-4364-8868-5dc8a937778f\n  DC:pagedb-frontend\n  SEVERITY:0.0\n/10.99.144.75\n  SCHEMA:f9832569-f987-3545-8c36-196342655a7f\n  NET_VERSION:7\n  LOAD:8.2445952994E10\n  RELEASE_VERSION:2.0.1\n  RACK:us-east-1d\n  RPC_ADDRESS:0.0.0.0\n  STATUS:NORMAL,-1022810197871922800\n  HOST_ID:c085c62d-74ea-45e5-9ed6-6a26a72ec3bb\n  DC:pagedb-frontend\n  SEVERITY:0.0\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "decommission",
         "nodetool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "ConcurrentModificationException during nodetool netstats"
   },
   {
      "_id": "12686569",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-12-27 20:53:20",
      "description": "We had a severe power outage in the lab that resulted in unclean shutdown of the Cassandra servers. After the power was back I tried to start the cluster. Two out of 6 nodes cannot start because of this exception:\n\n{code}\n INFO 20:47:11,003 Initializing system.local\n INFO [main] 2013-12-27 20:47:11,003 ColumnFamilyStore.java (line 251) Initializing system.local\n INFO 20:47:11,006 Opening /hadoop/disk1/cassandra/data/system/local/system-local-jb-2478 (5836 bytes)\n INFO [SSTableBatchOpen:1] 2013-12-27 20:47:11,006 SSTableReader.java (line 223) Opening /hadoop/disk1/cassandra/data/system/local/system-local-jb-2478 (5836 bytes)\n INFO 20:47:11,006 Opening /hadoop/disk4/cassandra/data/system/local/system-local-jb-2479 (144 bytes)\n INFO [SSTableBatchOpen:2] 2013-12-27 20:47:11,006 SSTableReader.java (line 223) Opening /hadoop/disk4/cassandra/data/system/local/system-local-jb-2479 (144 bytes)\nERROR 20:47:12,366 Exception encountered during startup\njava.lang.IllegalArgumentException: bufferSize must be positive\n        at org.apache.cassandra.io.util.RandomAccessReader.<init>(RandomAccessReader.java:67)\n        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.<init>(CompressedRandomAccessReader.java:76)\n        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.open(CompressedRandomAccessReader.java:55)\n        at org.apache.cassandra.io.sstable.SSTableReader.openDataReader(SSTableReader.java:1363)\n        at org.apache.cassandra.io.sstable.SSTableScanner.<init>(SSTableScanner.java:67)\n        at org.apache.cassandra.io.sstable.SSTableReader.getScanner(SSTableReader.java:1147)\n        at org.apache.cassandra.db.RowIteratorFactory.getIterator(RowIteratorFactory.java:69)\n        at org.apache.cassandra.db.ColumnFamilyStore.getSequentialIterator(ColumnFamilyStore.java:1526)\n        at org.apache.cassandra.db.ColumnFamilyStore.getRangeSlice(ColumnFamilyStore.java:1645)\n        at org.apache.cassandra.db.RangeSliceCommand.executeLocally(RangeSliceCommand.java:137)\n        at org.apache.cassandra.cql3.statements.SelectStatement.executeInternal(SelectStatement.java:236)\n        at org.apache.cassandra.cql3.statements.SelectStatement.executeInternal(SelectStatement.java:1)\n        at org.apache.cassandra.cql3.QueryProcessor.processInternal(QueryProcessor.java:255)\n        at org.apache.cassandra.db.SystemKeyspace.getUnfinishedCompactions(SystemKeyspace.java:206)\n        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:261)\n        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:461)\n        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:504)\n{code}\n\nCollecting the logs now, will attach to the issue in a moment. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Failure to start after unclean shutdown - java.lang.IllegalArgumentException: bufferSize must be positive"
   },
   {
      "_id": "12685496",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-12-19 02:05:12",
      "description": "Continuing CASSANDRA-4775 here.\n\nWe are changing counter write path to explicitly lock-read-modify-unlock-replicate, thus getting rid of the previously used 'local' (deltas) and 'remote' shards distinction. Unfortunately, we can't simply start using 'remote' shards exclusively, since shard merge rules prioritize the 'local' shards. Which is why we are introducing the third shard type - 'global', the only shard type to be used in 2.1+.\n\nThe updated merge rules are going to look like this:\n\nglobal + global = keep the shard with the highest logical clock\nglobal + local or remote = keep the global one\nlocal + local = sum counts (and logical clock)\nlocal + remote = keep the local one\nremote + remote = keep the shard with highest logical clock\n\nThis is required for backward compatibility with pre-2.1 counters. To make 2.0-2.1 live upgrade possible, 'global' shard merge logic will have to be back ported to 2.0. 2.0 will not produce them, but will be able to understand the global shards coming from the 2.1 nodes during the live upgrade. See CASSANDRA-6505.\n\nOther changes introduced in this issue:\n\n1. replicate_on_write is gone. From now on we only avoid replication at RF 1.\n2. REPLICATE_ON_WRITE stage is gone\n3. counter mutations are running in their own COUNTER_MUTATION stage now\n4. counter mutations have a separate counter_write_request_timeout setting\n5. mergeAndRemoveOldShards() code is gone, for now, until/unless a better solution is found\n6. we only replicate the fresh global shard now, not the complete (potentially quite large) counter context\n7. to help with concurrency and reduce lock contention, we cache node's global shards in a new counter cache ({cf id, partition key, cell name} -> {count, clock}). The cache is only used by counter writes, to help with 'hot' counters being simultaneously updated.\n\nImprovements to be handled by separate JIRA issues:\n\n1. Split counter context into separate cells - one shard per cell. See CASSANDRA-6506. This goes into either 2.1 or 3.0.\n\nPotential improvements still being debated:\n\n1. Coalesce the mutations in COUNTER_MUTATION stage if they share the same partition key, and apply them together, to improve the locking situation when updating different counter cells in one partition. See CASSANDRA-6508. Will to into 2.1 or 3.0, if deemed beneficial.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "counters++"
   },
   {
      "_id": "12685087",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-12-17 03:00:55",
      "description": "I have first described the problem here: http://stackoverflow.com/questions/20589324/cassandra-2-0-3-endless-compactions-with-no-traffic\n\nI think I have really abused my system with the traffic (mix of reads, heavy updates and some deletes). Now after stopping the traffic I see the compactions that are going on endlessly for over 4 days.\n\nFor a specific CF I have about 4700 sstable data files right now.  The compaction estimates are logged as \"[3312, 4, 0, 0, 0, 0, 0, 0, 0]\". sstable_size_in_mb=256.  3214 files are about 256Mb (+/1 few megs), other files are smaller or much smaller than that. No sstables are larger than 256Mb. What I observe is that LCS picks 32 sstables from L0 and compacts them into 32 sstables of approximately the same size. So, what my system is doing for last 4 days (no traffic at all) is compacting groups of 32 sstables into groups of 32 sstables without any changes. Seems like a bug to me regardless of what did I do to get the system into this state...\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Endless L0 LCS compactions"
   },
   {
      "_id": "12684425",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-12-13 08:53:34",
      "description": "When enabling authentication for a cassandra cluster the tool cassandra-shuffle is unable to connect.\n\nThe reason is, that cassandra-shuffle doesn't take any parameter for username and password for the thrift connection.\n\nTo solve that problem, parameter for username and password should be added, It should also be able to interpret cqlshrc or a separate file file with authentication data.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cassandra-shuffle not working with authentication"
   },
   {
      "_id": "12684297",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2013-12-12 16:33:29",
      "description": "The CQL3 \"create index\" statement syntax does not allow to specify the options map internally used by custom indexes. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3",
         "index"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Custom secondary index options in CQL3"
   },
   {
      "_id": "12683593",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-12-09 12:24:02",
      "description": "I enlarged the cluseter from 4 to 8 nodes. During cleaning up the \"old\" nodes with \"nodetool cleanup\" it breaks up with exception. I started cleanup from a different computer to manage them sequentially.\n{panel:title=cmd.exe}\nError occurred during cleanup\njava.util.concurrent.ExecutionException: java.lang.ClassCastException: org.apach\ne.cassandra.io.sstable.SSTableReader$EmptyCompactionScanner cannot be cast to or\ng.apache.cassandra.io.sstable.SSTableScanner\n        at java.util.concurrent.FutureTask.report(Unknown Source)\n        at java.util.concurrent.FutureTask.get(Unknown Source)\n        at org.apache.cassandra.db.compaction.CompactionManager.performAllSSTabl\neOperation(CompactionManager.java:227)\n        at org.apache.cassandra.db.compaction.CompactionManager.performCleanup(C\nompactionManager.java:265)\n        at org.apache.cassandra.db.ColumnFamilyStore.forceCleanup(ColumnFamilySt\nore.java:1054)\n        at org.apache.cassandra.service.StorageService.forceKeyspaceCleanup(Stor\nageService.java:2038)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n        at java.lang.reflect.Method.invoke(Unknown Source)\n        at sun.reflect.misc.Trampoline.invoke(Unknown Source)\n        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n        at java.lang.reflect.Method.invoke(Unknown Source)\n        at sun.reflect.misc.MethodUtil.invoke(Unknown Source)\n        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(Unknown So\nurce)\n        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(Unknown So\nurce)\n        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(Unknown Source)\n        at com.sun.jmx.mbeanserver.PerInterface.invoke(Unknown Source)\n        at com.sun.jmx.mbeanserver.MBeanSupport.invoke(Unknown Source)\n        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(Unknown\nSource)\n        at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(Unknown Source)\n        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(Unknown Sou\nrce)\n        at javax.management.remote.rmi.RMIConnectionImpl.access$300(Unknown Sour\nce)\n        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run\n(Unknown Source)\n        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(U\nnknown Source)\n        at javax.management.remote.rmi.RMIConnectionImpl.invoke(Unknown Source)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n        at java.lang.reflect.Method.invoke(Unknown Source)\n        at sun.rmi.server.UnicastServerRef.dispatch(Unknown Source)\n        at sun.rmi.transport.Transport$1.run(Unknown Source)\n        at sun.rmi.transport.Transport$1.run(Unknown Source)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at sun.rmi.transport.Transport.serviceCall(Unknown Source)\n        at sun.rmi.transport.tcp.TCPTransport.handleMessages(Unknown Source)\n        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(Unknown Sou\nrce)\n        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(Unknown Sour\nce)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n        at java.lang.Thread.run(Unknown Source)\nCaused by: java.lang.ClassCastException: org.apache.cassandra.io.sstable.SSTable\nReader$EmptyCompactionScanner cannot be cast to org.apache.cassandra.io.sstable.\nSSTableScanner\n        at org.apache.cassandra.db.compaction.CompactionManager.doCleanupCompact\nion(CompactionManager.java:563)\n        at org.apache.cassandra.db.compaction.CompactionManager.access$400(Compa\nctionManager.java:62)\n        at org.apache.cassandra.db.compaction.CompactionManager$5.perform(Compac\ntionManager.java:274)\n        at org.apache.cassandra.db.compaction.CompactionManager$2.call(Compactio\nnManager.java:222)\n        at java.util.concurrent.FutureTask.run(Unknown Source)\n        ... 3 more\n{panel}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cleanup ClassCastException"
   },
   {
      "_id": "12683140",
      "assignee": "philipthompson",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334946",
            "id": "12334946",
            "name": "Tool/nodetool"
         }
      ],
      "created": "2013-12-06 15:40:24",
      "description": "I have a complex row key.\n\n$ create table b (x int, s text, ((x,s)) primary key);\n\nIn cqlsh I cannot fill row key partially:\n\n{noformat}\n$ insert into b (x) values(4);\nBad Request: Missing mandatory PRIMARY KEY part s\n{noformat}\n\nBut nodetool can find hosts by incomplete key\n{noformat}\n$ nodetool -h cas3 getendpoints anti_portal b 12\n192.168.4.4\n192.168.4.5\n192.168.4.6\n{noformat}\n\nNo error is reported.\n\nI found that columns are separated by \":\".\nAnd If I pass to many elements then the error happens.\n\n{noformat}\n$ nodetool -h cas3 getendpoints anit_portal b 12:dd:dd\nException in thread \"main\" org.apache.cassandra.serializers.MarshalException: unable to make int from '12:dd:dd'\n    at org.apache.cassandra.db.marshal.Int32Type.fromString(Int32Type.java:69)\n    at org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:2495)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:75)\n    at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:279)\n    at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)\n    at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)\n    at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)\n    at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)\n    at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:252)\n    at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819)\n    at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801)\n    at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1487)\n    at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:97)\n    at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1328)\n    at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1420)\n    at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:848)\n    at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)\n    at sun.rmi.transport.Transport$1.run(Transport.java:177)\n    at sun.rmi.transport.Transport$1.run(Transport.java:174)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at sun.rmi.transport.Transport.serviceCall(Transport.java:173)\n    at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:556)\n    at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:811)\n    at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:670)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.lang.NumberFormatException: For input string: \"12:dd:dd\"\n    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n    at java.lang.Integer.parseInt(Integer.java:492)\n    at java.lang.Integer.parseInt(Integer.java:527)\n    at org.apache.cassandra.db.marshal.Int32Type.fromString(Int32Type.java:65)\n    ... 36 more\n{noformat}\n\nI think showing huge stack trace is not proper behavior.\nError message should be printer if arity of passed key and table key are not equal.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "nodetool getendpoints doesn't validate key arity"
   },
   {
      "_id": "12679553",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328219",
            "id": "12328219",
            "name": "Legacy/Coordination",
            "description": "StorageProxy, Hints, Batchlog, Counters, LWT, Partitioner/Tokens"
         }
      ],
      "created": "2013-11-16 07:37:13",
      "description": "CREATE TABLE session (\n  id text,\n  usr text,\n  valid int,\n  PRIMARY KEY (id)\n);\ninsert into session (id, usr) values ('abc', 'abc');\nupdate session using ttl 1 set valid = 1 where id = 'abc';\n(wait 1 sec)\nAnd \ndelete from session where id = 'DSYUCTCLSOEKVLAQWNWYLVQMEQGGXD' if usr ='demo';\nYields:\n [applied] | usr\n-----------+-----\n     False | abc\nRather than applying the delete.\n\nExecuting:\nupdate session set valid = null where id = 'abc';\nand again\ndelete from session where id = 'DSYUCTCLSOEKVLAQWNWYLVQMEQGGXD' if usr ='demo';\nPositively deletes the row.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CAS not applied on rows containing an expired ttl column"
   },
   {
      "_id": "12679492",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-11-15 21:24:22",
      "description": "Flush writers are a critical element for keeping a node healthy. When several compactions run on systems with low performing data directories, IO becomes a premium. Once the disk subsystem is saturated, write IO is blocked which will cause flush writer threads to backup. Since memtables are large blocks of memory in the JVM, too much blocking can cause excessive GC over time degrading performance. In the worst case causing an OOM.\n\nSince compaction is running on the data directories. My proposal is to create a separate directory for flushing memtables. Potentially we can use the same methodology of keeping the commit log separate and minimize disk contention against the critical function of the flushwriter. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Flush memtables to separate directory"
   },
   {
      "_id": "12678906",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-11-12 23:38:37",
      "description": "Currently if a single gossip task bogs down the gossip Stage, Gossip will mark everyone down because it hasn't seen updates from them (since they are all queued behind the slow one).\n\nThis means that full GCs can cause gossip \"flapping\" as well as any actually problematic tasks such as recomputing pending ranges.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gossip"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Make gossip tolerate slow Gossip tasks"
   },
   {
      "_id": "12678092",
      "assignee": "philipthompson",
      "components": [],
      "created": "2013-11-07 22:08:35",
      "description": "cassandra-dbapi2 is effectively deprecated. The python driver is the future, we should refactor our dtests to use it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Refactor dtests to use python driver instead of cassandra-dbapi2"
   },
   {
      "_id": "12677050",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328218",
            "id": "12328218",
            "name": "Local/Compaction"
         }
      ],
      "created": "2013-11-01 12:52:25",
      "description": "Files cannot be deleted, patch CASSANDRA-5383 (Win7 deleting problem) doesn't help on Win-7 on Cassandra 2.0.2. Even 2.1 Snapshot is not running. The cause is: Opened file handles seem to be lost and not closed properly. Win 7 blames, that another process is still using the file (but its obviously cassandra). Only restart of the server makes the files deleted. But after heavy using (changes) of tables, there are about 24K files in the data folder (instead of 35 after every restart) and Cassandra crashes. I experiminted and I found out, that a finalizer fixes the problem. So after GC the files will be deleted (not optimal, but working fine). It runs now 2 days continously without problem. Possible fix/test:\nI wrote the following finalizer at the end of class org.apache.cassandra.io.util.RandomAccessReader:\n\n{code:title=RandomAccessReader.java|borderStyle=solid}\n@Override\nprotected void finalize() throws Throwable {\n\tdeallocate();\n\tsuper.finalize();\n}\n{code}\n\nCan somebody test / develop / patch it? Thx.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows",
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows 7 data files kept open / can't be deleted after compaction."
   },
   {
      "_id": "12676860",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-10-31 14:15:58",
      "description": "Getting this AE on destination nodes during repair:\n\nERROR [ValidationExecutor:78] 2013-10-31 04:35:31,243 CassandraDaemon.java (line 187) Exception in thread Thread[ValidationExecutor:78,1,main]\njava.lang.AssertionError\n        at org.apache.cassandra.db.compaction.PrecompactedRow.update(PrecompactedRow.java:171)\n        at org.apache.cassandra.repair.Validator.rowHash(Validator.java:198)\n        at org.apache.cassandra.repair.Validator.add(Validator.java:151)\n        at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:799)\n        at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:62)\n        at org.apache.cassandra.db.compaction.CompactionManager$8.call(CompactionManager.java:397)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:724)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "AE in PrecompactedRow.update(PrecompactedRow.java:171)"
   },
   {
      "_id": "12676559",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-10-30 06:47:10",
      "description": "I'm the author of the Ruby driver for CQL, and I got a bug report about strange errors when running on C* 2.0 and using lightweight transaction queries. The bug report can be found here: https://github.com/iconara/cql-rb/issues/53\n\nThe client sent {{UPDATE table SET val = 42 WHERE row_id = 5 IF val = 41}} and when C* couldn't fulfill SERIAL consistency it sent an error back saying \"Operation timed out - received only -1 responses\".\n\nSo far so good, but it also set the {{consistency}} field in the error response to 8, corresponding to {{SERIAL}} in v2 of the binary protocol, even if the communication with the client was over v1 of the protocol. Since my driver doesn't yet support v2 it doesn't think that 8 is a valid consistency, and fails to parse the frame.\n\nIs this the intended behaviour of C*, or an oversight in how that error is formulated? I could easily add {{SERIAL}} and accept it even if the communication is over v1 of the protocol, but the bigger issue is how C* handles drivers that do not speak the latest version of the protocol. People should be able to use a driver that worked correctly with C* X with C* X+1, right?\n\nDo drivers have to be accepting in what they receive from C* because they might get consistencies, data types, etc. that are from future versions of the protocol, or does C* guarantee that frames will conform to the protocol that the driver says it understands?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "SERIAL consistency in errors to v1 protocol driver"
   },
   {
      "_id": "12675972",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-10-26 23:57:36",
      "description": "With CAS it is possible to simulate a SELECT query using conditional UPDATE IF. Hence all CAS updates should require P.SELECT permission, and not just P.MODIFY.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CAS updates should require P.MODIFY AND P.SELECT"
   },
   {
      "_id": "12674276",
      "assignee": "slebresne",
      "components": [],
      "created": "2013-10-17 08:06:43",
      "description": "I wrote a stresstest to test C* and my code that uses CAS heavily. I see strange exception messages in logs:\n{noformat}\nERROR [MutationStage:320] 2013-10-17 13:59:10,710 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:320,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:328] 2013-10-17 13:59:10,718 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:328,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:327] 2013-10-17 13:59:10,732 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:327,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:325] 2013-10-17 13:59:10,750 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:325,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:326] 2013-10-17 13:59:10,762 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:326,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:330] 2013-10-17 13:59:10,768 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:330,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:331] 2013-10-17 13:59:10,775 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:331,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:334] 2013-10-17 13:59:10,789 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:334,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:329] 2013-10-17 13:59:10,803 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:329,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:335] 2013-10-17 13:59:10,812 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:335,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:333] 2013-10-17 13:59:10,826 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:333,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:332] 2013-10-17 13:59:10,834 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:332,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:337] 2013-10-17 13:59:10,842 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:337,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:336] 2013-10-17 13:59:10,859 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:336,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:338] 2013-10-17 13:59:10,870 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:338,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:339] 2013-10-17 13:59:10,884 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:339,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:341] 2013-10-17 13:59:10,894 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:341,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:340] 2013-10-17 13:59:10,910 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:340,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:344] 2013-10-17 13:59:10,920 CassandraDaemon.java (line 185) Exception in thread Thread[MutationStage:344,5,main]\njava.lang.NullPointerException\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "npe",
         "nullpointerexception"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "NPE in system.log"
   },
   {
      "_id": "12673613",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-10-13 17:39:19",
      "description": "Not sure \"bug\" is the right description, because I can't say for sure that the large number of SSTables is the cause of the memory issues. I'll share my research so far:\n\nUnder high read-load with a very large number of compressed SSTables (caused by the initial default 5mb sstable_size in LCS) it seems memory is exhausted, without any room for GC to fix this. It tries to GC but doesn't reclaim much.\n\nThe node first hits the \"emergency valves\" flushing all memtables, then reducing caches. And finally logs 0.99+ heap usages and hangs with GC failure or crashes with OutOfMemoryError.\n\nI've taken a heapdump and started analysis to find out what's wrong. The memory seems to be used by the byte[] backing the HeapByteBuffer in the \"compressed\" field of org.apache.cassandra.io.compress.CompressedRandomAccessReader. The byte[] are generally 65536 byes in size, matching the block-size of the compression.\n\nLooking further in the heap-dump I can see that these readers are part of the pool in org.apache.cassandra.io.util.CompressedPoolingSegmentedFile. Which is linked to the \"dfile\" field of org.apache.cassandra.io.sstable.SSTableReader. The dump-file lists 45248 instances of CompressedRandomAccessReader.\n\nIs this intended to go this way? Is there a leak somewhere? Or should there be an alternative strategy and/or warning for cases where a node is trying to read far too many SSTables?\n\nEDIT:\nSearching through the code I found that PoolingSegmentedFile keeps a pool of RandomAccessReader for re-use. While the CompressedRandomAccessReader allocates a ByteBuffer in it's constructor and (to make things worse) enlarges it if it's reasing a large chunk. This (sometimes enlarged) ByteBuffer is then kept alive because it becomes part of the CompressedRandomAccessReader which is in turn kept alive as part of the pool in the PoolingSegmentedFile.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add a warning for small sstable size setting in LCS"
   },
   {
      "_id": "12671623",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-10-01 17:22:26",
      "description": "Optimize the auth default super user/default user check by checking for the 'cassandra' user first, and only if that fails, doing the range query.\n\nFor people following our docs (don't drop 'cassandra', just strip its superuser status and change the password), this will always mean performing just one get.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "auth"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Optimize the auth default super user/default user check"
   },
   {
      "_id": "12671563",
      "assignee": "slebresne",
      "components": [],
      "created": "2013-10-01 12:06:33",
      "description": "DDL statements allow boolean constants to be either quoted or unquoted as:\n{code}\nCREATE KEYSPACE ks WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1} AND durable_writes = true;\nCREATE KEYSPACE ks WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1} AND durable_writes = 'true';\n{code}\n\nWhile DML statements only allow unquoted boolean constants.\n\nWhile this is not a big deal, it can introduce a bit of confusion for the users. Fixing this lack of syntax consistency would break the existing scripts, so that's something we might want to consider next time we'll introduce some breaking changes in CQL...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Boolean constants syntax is not consistent between DDL and DML in CQL"
   },
   {
      "_id": "12669574",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-09-19 22:39:04",
      "description": "An {{INSERT}} of a {{set}} column type is not stored when using {{IF NOT EXISTS}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Sets not stored by INSERT with IF NOT EXISTS"
   },
   {
      "_id": "12669202",
      "assignee": "slebresne",
      "components": [],
      "created": "2013-09-18 08:02:30",
      "description": "Query with error: SELECT * FROM user WHERE login='nsv' AND st IN ('1','2') ALLOW FILTERING;\n\nQuery works:\nSELECT * FROM user WHERE login='nsv' AND st IN ('1') ALLOW FILTERING;\n-- Single item inside IN\n\nTable definition: \nCREATE COLUMNFAMILY user (\n     KEY uuid PRIMARY KEY,\n     name text,\n     avatar text,\n     email text,\n     phone text,\n     login text,\n     pw text,\n     st text\n);\n\nFrom /var/log/cassandra/output.log:\nERROR 11:58:52,454 Internal error processing execute_cql3_query\njava.lang.AssertionError\n\tat org.apache.cassandra.cql3.statements.SelectStatement.getIndexExpressions(SelectStatement.java:749)\n\tat org.apache.cassandra.cql3.statements.SelectStatement.getRangeCommand(SelectStatement.java:303)\n\tat org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:155)\n\tat org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:56)\n\tat org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:101)\n\tat org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:117)\n\tat org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:108)\n\tat org.apache.cassandra.thrift.CassandraServer.execute_cql3_query(CassandraServer.java:1920)\n\tat org.apache.cassandra.thrift.Cassandra$Processor$execute_cql3_query.getResult(Cassandra.java:4372)\n\tat org.apache.cassandra.thrift.Cassandra$Processor$execute_cql3_query.getResult(Cassandra.java:4356)\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:194)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:724)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "'Internal application error' on SELECT .. WHERE col1=val AND col2 IN (1,2)"
   },
   {
      "_id": "12668469",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-09-13 11:48:31",
      "description": "Currently, we only keep 1) the most recent promise we've made and 2) the last update we've accepted. But we don't keep the ballot at which that last update was accepted. And because a node always promise to newer ballot, this means an already committed update can be replayed even after another update has been committed. Re-committing a value is fine, but only as long as we've not start a new round yet.\n\nConcretely, we can have the following case (with 3 nodes A, B and C) with the current implementation:\n* A proposer P1 prepare and propose a value X at ballot t1. It is accepted by all nodes.\n* A proposer P2 propose at t2 (wanting to commit a new value Y). If say A and B receive the commit of P1 before the propose of P2 but C receives those in the reverse order, we'll current have the following states:\n{noformat}\nA: in-progress = (t2, _), mrc = (t1, X)\nB: in-progress = (t2, _), mrc = (t1, X)\nC: in-progress = (t2, X), mrc = (t1, X)\n{noformat}\nBecause C has received the t1 commit after promising t2, it won't have removed X during t1 commit (but note that the problem is not during commit, that example still stand if C never receive any commit message).\n* Now, based on the promise of A and B, P2 will propose Y at t2 (C don't see this propose in particular, not before he promise on t3 below at least). A and B accepts, P2 will send a commit for Y.\n* In the meantime a proposer P3 submit a prepare at t3 (for some other irrelevant value) which reaches C before it receives P2 propose&commit. That prepare reaches A and B too, but after the P2 commit. At that point the state will be:\n{noformat}\nA: in-progress = (t3, _), mrc = (t2, Y)\nB: in-progress = (t3, _), mrc = (t2, Y)\nC: in-progress = (t3, X), mrc = (t2, Y)\n{noformat}\nIn particular, C still has X as update because each time it got a commit, it has promised to a more recent ballot and thus skipped the delete. The value is still X because it has received the P2 propose after having promised t3 and has thus refused it.\n* P3 gets back the promise of say C and A. Both response has t3 as in-progress ballot (and it is more recent than any mrc) but C comes with value X. So P3 will replay X. Assuming no more contention this replay will succeed and X will be committed at t3.\n\nAt the end of that example, we've comitted X, Y and then X again, even though only P1 has ever proposed X.\n\nI believe the correct fix is to keep the ballot of when an update is accepted (instead of using the most recent promised ballot). That way, in the example above, P3 would receive from C a promise on t3, but would know that X was accepted at t1. And so P3 would be able to ignore X since the mrc of A will tell him it's an obsolete value.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CAS should distinguish promised and accepted ballots"
   },
   {
      "_id": "12668285",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-09-12 15:31:58",
      "description": "If a Paxos proposer proposes some value/update and that propose fail, there is no guarantee on whether this value will be accepted or not ultimately. Paxos guarantees that we'll agree on \"a\" value (for a given round in our case), but does not guarantee that the proposer of the agreed upon value will know it.  In particular, if for a given proposal at least one accepter has accepted it but not a quorum does, then that value might (but that's not guaranteed either) be replayed (and committed) by another proposer.\n\nCurrently, if a proposer A proposes some update U but it is rejected, A will sleep a bit and retry U. But if U was accepted by at least one acceptor, some other proposer B might replay U, succeed and commit it. If A does its retry after that happens, he will prepare, check the condition, and probably find that the conditions don't apply anymore since U has been committed already. It will thus return false, even though U has been in fact committed.\n\nUnfortunately I'm not sure there is an easy way for a proposer whose propose fails to know if the update will prevail or not eventually. Which mean the only acceptable solution I can see would be to return to the user \"I don't know\" (through some exception for instance). Which is annoying because having a proposal rejected won't be an extremely rare occurrence, even with relatively light contention, and returning \"I don't know\" often is a bit unfriendly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CAS may return false but still commit the insert"
   },
   {
      "_id": "12668284",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-09-12 15:29:48",
      "description": "Paxos says that on receiving the result of a prepare from a quorum of acceptors, the proposer should propose the value of the higher-number proposal accepted amongst the ones returned by the acceptors, and only propose his own value if no acceptor has send us back a previously accepted value.\n\nBut in PrepareCallback we only keep the more recent inProgress commit regardless of whether is has an update. Which means we could ignore a value already accepted by some acceptors if any of the acceptor send us a more recent ballot than the other acceptor but with no values. The net effect is that we can mistakenly accept two different values for the same round.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CAS does not always correctly replay inProgress rounds"
   },
   {
      "_id": "12667986",
      "assignee": "krummas",
      "components": [],
      "created": "2013-09-11 06:17:24",
      "description": "With standalone scrubber in 2.0 we can encounter both the old-style json manifest and the new way, StandaloneScrubber needs to handle this.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "StandaloneScrubber assumes old-style json leveled manifest"
   },
   {
      "_id": "12667944",
      "assignee": "slebresne",
      "components": [],
      "created": "2013-09-10 23:04:59",
      "description": "My actual app uses a Map[UUID, Double], and in the upstream data source, unavailable data is encoded as Double.NaN. But when I try to insert them into C* (currently working with 2.0), I get a \"no viable alternative\" at the syntax immediately following the NaN value. \n\nHere's a tiny test case:\n{code}\ncqlsh> create table test (pk timeuuid primary key, d double);\ncqlsh> insert into test (pk, d) values (now(), NaN);\nBad Request: line 1:43 no viable alternative at input ')'\n{code}\n\nThe workaround suggested by 'iamaleksey' on IRC (Thanks!) allows the data to be inserted, but it's really ugly, and I'm not sure yet whether it will work OK on the read side:\n\n{code}\n// myStuff is a Map[UUID,Double]\nmySuff.mapValues { \n  case x if x.isNaN => QueryBuilder.fcall(\"blobAsDouble\", ByteBufferUtil.EMPTY_BYTE_BUFFER) \n  case x => x: java.lang.Double // explicit boxing, maybe not necessary \n}.asJava\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL: Support NaN and inifinities in Double literals"
   },
   {
      "_id": "12667829",
      "assignee": "krummas",
      "components": [],
      "created": "2013-09-10 15:36:59",
      "description": "We should remove the json leveled manifest migration code from 2.1\n\nthis will require users to atleast start 2.0 before upgrading to 2.1 (manifest is migrated on startup).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Remove leveled manifest json migration code"
   },
   {
      "_id": "12667496",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-09-08 23:07:45",
      "description": "When we replay {{inProgress}}, we need to refresh it with the newly prepared ballot, or it will be (correctly) rejected.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Paxos replay of in progress update is incorrect"
   },
   {
      "_id": "12666577",
      "assignee": "stefania",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-09-02 12:28:47",
      "description": "Can you add a feature request to pass JVM_OPTS to the sstablescrub script -- and other places where java is being called? (Among other things, this lets us run java stuff with \"-Djava.awt.headless=true\" on OS X so that Java processes don't pop up into the foreground -- i.e. we have a script that loops over all CFs and runs sstablescrub, and without that flag being passed in the OS X machine becomes pretty much unusable as it keeps switching focus to the java processes as they start.)\n \n--- a/resources/cassandra/bin/sstablescrub\n+++ b/resources/cassandra/bin/sstablescrub\n@@ -70,7 +70,7 @@ if [ \"x$MAX_HEAP_SIZE\" = \"x\" ]; then\n     MAX_HEAP_SIZE=\"256M\"\n fi\n \n-$JAVA -ea -cp $CLASSPATH -Xmx$MAX_HEAP_SIZE \\\n+$JAVA $JVM_OPTS -ea -cp $CLASSPATH -Xmx$MAX_HEAP_SIZE \\\n         -Dlog4j.configuration=log4j-tools.properties \\\n         org.apache.cassandra.tools.StandaloneScrubber \"$@\"",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow JVM_OPTS to be passed to sstablescrub"
   },
   {
      "_id": "12666414",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-08-30 22:50:02",
      "description": "You can do anything from within ITrigger.augment(), bypassing any authorization checks. The only fix is to require superuser status for CREATE TRIGGER and CF updates via Thrift that involve triggers.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "security",
         "triggers"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Require superuser status for adding triggers"
   },
   {
      "_id": "12665490",
      "assignee": "krummas",
      "components": [],
      "created": "2013-08-26 11:06:33",
      "description": "We could improve the way we pick compaction candidates in level 0 in LCS.\n\nThe most common way for us to get behind on compaction is after repairs, we should exploit the fact that the streamed sstables are most often very narrow in range since the other nodes in the ring will have a similar sstable-range-distribution. We should in theory be able to do 10 concurrent compactions involving L1 - ie, partition L0 in buckets defined by the sstables in L1 to only keep one L1 SSTable busy for every compaction (be it L1 to L2 or L0 to L1).\n\nwe will need some heuristics on when to select candidates from the buckets and when to do it the old way (since L0 sstables can span several L1 sstables)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve the way we pick L0 compaction candidates"
   },
   {
      "_id": "12665231",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-08-23 14:55:14",
      "description": "dateof() return type is TimestampType now, so it won't work with previously created DateType columns\n(Type error: cannot assign result of function dateof (type timestamp) to value (type 'org.apache.cassandra.db.marshal.DateType')).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "dateOf() in 2.0 won't work with timestamp columns created in 1.2-"
   },
   {
      "_id": "12665142",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-08-22 23:17:31",
      "description": "I'm building some tests for a Cassandra PoC.  One scenario I need to test is consumption of 1 time tokens.  These tokens must be consumed exactly once.  The cluster involved is a 3 node cluster.  All queries are run with ConsistencyLevel.QUORUM. I'm using the following queries:\n\nCREATE KEYSPACE IF NOT EXISTS test WITH replication = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 };\n\nCREATE TABLE IF NOT EXISTS tkns (tkn blob, consumed boolean, PRIMARY KEY (tkn));\n\nINSERT INTO tkns (tkn, consumed) VALUES (?,FALSE) USING TTL 30;\n\nUPDATE tkns USING TTL 1 SET consumed = TRUE WHERE tkn = ? IF consumed = FALSE;\n\nI use the '[applied]' column in the result set of the update statement to determine whether the token has been successfully consumed or if the token is being replayed.\n\nMy test involves concurrently executing many sets of 1 insert and 2 update statements (using Session#execute on BoundStatemnts) then checking to make sure that only one of the updates was applied.\n\nWhen I run this test with relatively few iterations (~100) my results are  what I expect (exactly 1 update succeeds).  At ~1000 iterations, I start seeing both updates reporting success in 1-2% of cases.  While my test is running, I see corresponding error entries in the Cassandra log:\n\nERROR 15:34:53,583 Exception in thread Thread[MutationStage:522,5,main]\njava.lang.NullPointerException\nERROR 15:34:53,584 Exception in thread Thread[MutationStage:474,5,main]\njava.lang.NullPointerException\nERROR 15:34:53,584 Exception in thread Thread[MutationStage:536,5,main]\njava.lang.NullPointerException\nERROR 15:34:53,729 Exception in thread Thread[MutationStage:480,5,main]\njava.lang.NullPointerException\nERROR 15:34:53,729 Exception in thread Thread[MutationStage:534,5,main]\njava.lang.NullPointerException\n\n\nThanks.\n\nUpdate:\n\nI'm not sure what's going on with the logging the the dev release.  I grabbed the rc2 source and built that.  The resultant log is a bit more informative:\n\nERROR 11:53:38,967 Exception in thread Thread[MutationStage:114,5,main]\njava.lang.NullPointerException\n\tat org.apache.cassandra.serializers.UUIDSerializer.deserialize(UUIDSerializer.java:32)\n\tat org.apache.cassandra.serializers.UUIDSerializer.deserialize(UUIDSerializer.java:26)\n\tat org.apache.cassandra.db.marshal.AbstractType.compose(AbstractType.java:142)\n\tat org.apache.cassandra.cql3.UntypedResultSet$Row.getUUID(UntypedResultSet.java:131)\n\tat org.apache.cassandra.db.SystemKeyspace.loadPaxosState(SystemKeyspace.java:785)\n\tat org.apache.cassandra.service.paxos.PaxosState.commit(PaxosState.java:118)\n\tat org.apache.cassandra.service.paxos.CommitVerbHandler.doVerb(CommitVerbHandler.java:34)\n\tat org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:56)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n\tat java.lang.Thread.run(Thread.java:722)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Race condition in update lightweight transaction"
   },
   {
      "_id": "12664958",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-08-22 01:10:04",
      "description": "CQL2 is officially no longer worked on since 1.2. cqlsh no longer supports CQL2 as of Cassandra 2.0.\n\nIt's probably the time to deprecate CQL2 in 2.0 and to remove it entirely in 2.2 - there is nothing in CQL2 now that can't be done via CQL3 and two versions advance warning is plenty of time for those few still using CQL2 to switch to CQL3.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Remove CQL2 entirely from Cassandra 3.0"
   },
   {
      "_id": "12664817",
      "assignee": "krummas",
      "components": [],
      "created": "2013-08-21 12:14:07",
      "description": "we need to add all sstables to the leveled manifest on startup, looks like this was introduced in 6968f68cd7c",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Add existing sstables to leveled manifest on startup"
   },
   {
      "_id": "12663200",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-08-12 12:08:36",
      "description": "cqlsh DESCRIBE with all the system keyspaces is less useful than than DESCRIBE output with just the user's keyspaces - you can dump/restore schema directly this way. This seems to be a way better default to me.\n\nAttaching a patch that skips all the system keyspaces for regular DESCRIBE SCHEMA and adds DESCRIBE FULL SCHEMA alternative that includes system, system_auth and system_traces.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "DESCRIBE SCHEMA should omit system keyspaces by default"
   },
   {
      "_id": "12660109",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-07-26 18:05:41",
      "description": "I downloaded Cassandra Beta 2. \nI've tried to use CQLSH against Cassandra. \n\nMy python version is: \nEnthought Canopy Python 2.7.3 | 32-bit | (default, Mar 25 2013, 15:38:39) [MSC v.1500 32 bit (Intel)] on win32\n\nI get the following exception when I run the utility:\n\nc:\\Servers\\apache-cassandra\\bin>python cqlsh 127.0.0.1 9160\nTraceback (most recent call last):\n  File \"cqlsh\", line 131, in <module>\n    if readline is not None and 'libedit' in readline.__doc__:\nTypeError: argument of type 'NoneType' is not iterable",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQLSH Windows: TypeError: argument of type 'NoneType' is not iterable"
   },
   {
      "_id": "12659484",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2013-07-24 03:02:53",
      "description": "For two-datacenter deployments where the second DC is strictly for disaster failover, it would be useful to restrict CAS to a single DC to avoid cross-DC round trips.\n\n(This would require manually truncating {{system.paxos}} when failing over.)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "DC-local CAS"
   },
   {
      "_id": "12659482",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-07-24 02:59:49",
      "description": "Right now cqlsh behave with {{INSERT/UPDATE...IF}} the same way it does for regular {{INSERT/UPDATE}} statements, that is without displaying anything if there were no error.\n\nIdeally it should display the ResultSet returned by these CAS statements as defined in CASSANDRA-5619.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Cqlsh should return a result in the case of a CAS INSERT/UPDATE"
   },
   {
      "_id": "12659037",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-07-22 08:32:48",
      "description": "When querying columns for CAS, we build the SortedSet with:\n{noformat}\nnew NamesQueryFilter(ImmutableSortedSet.copyOf(expected.getColumnNames())\n{noformat}\nbut ImmutableSortedSet.copyOf() uses the natural order of keys unless a comparator is given, which is not what we want.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "StorageProxy#cas() doesn't order columns names correctly when querying"
   },
   {
      "_id": "12659025",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-07-22 06:55:57",
      "description": "CassandraServer#cas() use UnsortedColumns for the \"updates\", which might result later to a\n{noformat}\njava.lang.AssertionError: Added column does not sort as the last column\n        at org.apache.cassandra.db.ArrayBackedSortedColumns.addColumn(ArrayBackedSortedColumns.java:115)\n        at org.apache.cassandra.db.ColumnFamily.addColumn(ColumnFamily.java:117)\n        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:119)\n        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:96)\n        at org.apache.cassandra.db.ColumnFamilySerializer.deserialize(ColumnFamilySerializer.java:91)\n        at org.apache.cassandra.service.paxos.Commit$CommitSerializer.deserialize(Commit.java:139)\n        at org.apache.cassandra.service.paxos.Commit$CommitSerializer.deserialize(Commit.java:128)\n        at org.apache.cassandra.net.MessageIn.read(MessageIn.java:99)\n        at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:175)\n        at org.apache.cassandra.net.IncomingTcpConnection.handleModernVersion(IncomingTcpConnection.java:135)\n        at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:82)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Thrift cas() method crashes if input columns are not sorted."
   },
   {
      "_id": "12658342",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-07-17 19:34:24",
      "description": "Among other things, the patch does the following:\n- adds missing schema_triggers to MigrationManager.resetLocalSchema()\n- adds missing schema_triggers to SystemKeyspace.serializeSchema() - so that triggers would be part of schema version calculation\n- adds missing schema_triggers to DefsTables.flushSchemaCFs()\n- adds missing triggers to CFMetaData.toSchema(), so that CFs created via thrift with triggers from the beginning would serialize triggers\n- removes triggers from CFMetaData.newIndexMetadata(), so that 2i CFs wouldn't inherit the triggers from the parent CF\n\nThere are other minor and not so minor changes, but these were the most critical ones. The patch also (unnecessarily) cleans up ColumnDefinition, but that was done to make it consistent with the new TriggerDefinition class.\n\nThe bulk of the patch is the updated thrift-gen files.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "triggers"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix system.schema_triggers-related trigger/schema issues"
   },
   {
      "_id": "12658129",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-07-16 22:08:10",
      "description": "If compression is not set for a CF, cqlsh omits the compression attribute.  When you replay that very same DDL, you get a CF with Snappy compression.  This may occur with other parameters.  Perhaps describe should always show every parameter in full.  The absence of a setting is a setting.  (Think of the arrow in the FedEx logo).\n\nCreate a CF with cassandra-stress.  cassandra-stress defaults to NO compression.\n\n ~/dse/resources/cassandra/tools/bin/cassandra-stress -S 100 -c 1 --num-keys 1\n\ndescribe it\nCREATE TABLE \"Standard1\" (\n  key blob PRIMARY KEY,\n  \"C0\" blob\n) WITH COMPACT STORAGE AND\n  bloom_filter_fp_chance=0.010000 AND\n  caching='KEYS_ONLY' AND\n  comment='' AND\n  dclocal_read_repair_chance=0.000000 AND\n  gc_grace_seconds=864000 AND\n  read_repair_chance=0.100000 AND\n  replicate_on_write='true' AND\n  populate_io_cache_on_flush='false' AND\n  compaction={'class': 'SizeTieredCompactionStrategy'};\n\nreplay it - I changed the cf name to standard2\n\ndescribe the new CF:\n\nCREATE TABLE standard2 (\n  key blob PRIMARY KEY,\n  \"C0\" blob\n) WITH COMPACT STORAGE AND\n  bloom_filter_fp_chance=0.010000 AND\n  caching='KEYS_ONLY' AND\n  comment='' AND\n  dclocal_read_repair_chance=0.000000 AND\n  gc_grace_seconds=864000 AND\n  read_repair_chance=0.100000 AND\n  replicate_on_write='true' AND\n  populate_io_cache_on_flush='false' AND\n  compaction={'class': 'SizeTieredCompactionStrategy'} AND\n  compression={'sstable_compression': 'SnappyCompressor'};\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "describe"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "The output of the describe command does not necessarily give you the right DDL to re-create the CF"
   },
   {
      "_id": "12658006",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2013-07-16 13:21:55",
      "description": "In addition to the current snappy native client compression support, it would be nice to add lz4 as an option now that lz4 has been vetted for inclusion in CASSANDRA-5038.\n\nThis would enable PYTHON-1 for the python-driver:\nhttps://datastax-oss.atlassian.net/browse/PYTHON-1",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compression",
         "lz4",
         "native_protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "add an lz4 implementation of FrameCompressor for lz4 compressed native cql protocol"
   },
   {
      "_id": "12657651",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2013-07-14 23:19:58",
      "description": "CASSANDRA-5484 and then CASSANDRA-5639 added CREATE CUSTOM INDEX support to CQL3, but cqlsh hasn't been updated to describe such indexes properly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "describe"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh DESCRIBE should properly describe CUSTOM secondary indexes"
   },
   {
      "_id": "12657639",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-07-14 17:17:37",
      "description": "We've got CreateColumnFamilyStatement, AlterTableStatement, and DropColumnFamilyStatement. The patch makes them all use 'Table' consistently.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3",
         "ocd"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Consistencyfy CQL3 create/alter/drop column family/table statement class names"
   },
   {
      "_id": "12657484",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-07-12 16:00:25",
      "description": "In CQL I can create a table with settings introduced in 2.0:\n\n{code}\ncqlsh:Keyspace1> CREATE TABLE r1 ( key int PRIMARY KEY, value varchar) WITH speculative_retry='ALWAYS';\n{code}\n\nBut the settings don't show up when I DESC TABLE:\n{code}\ncqlsh:Keyspace1> DESC TABLE r1;\n\nCREATE TABLE r1 (\n  key int PRIMARY KEY,\n  value text\n) WITH\n  bloom_filter_fp_chance=0.010000 AND\n  caching='KEYS_ONLY' AND\n  comment='' AND\n  dclocal_read_repair_chance=0.000000 AND\n  gc_grace_seconds=864000 AND\n  index_interval=128 AND\n  read_repair_chance=0.100000 AND\n  replicate_on_write='true' AND\n  populate_io_cache_on_flush='false' AND\n  compaction={'class': 'SizeTieredCompactionStrategy'} AND\n  compression={'sstable_compression': 'LZ4Compressor'};\n{code}\n\nFor comparison, here is the same table viewed from cassandra-cli:\n\n{code}\n[default@Keyspace1] describe r1;\n\nWARNING: CQL3 tables are intentionally omitted from 'describe' output.\nSee https://issues.apache.org/jira/browse/CASSANDRA-4377 for details.\n\nWARNING: Could not connect to the JMX on 127.0.0.1:7199 - some information won't be shown.\n\n    ColumnFamily: r1\n      Key Validation Class: org.apache.cassandra.db.marshal.Int32Type\n      Default column value validator: org.apache.cassandra.db.marshal.BytesType\n      Cells sorted by: org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type)\n      GC grace seconds: 0\n      Compaction min/max thresholds: 0/0\n      Read repair chance: 0.0\n      DC Local Read repair chance: 0.0\n      Populate IO Cache on flush: false\n      Replicate on write: false\n      Caching: keys_only\n      Default time to live: 0\n      Bloom Filter FP chance: default\n      Index interval: default\n      Speculative Retry: NONE\n      Compaction Strategy: null\n{code}\n\nIdeally, all of these values that cli shows would be shown by cqlsh.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "DESC TABLE omits some column family settings"
   },
   {
      "_id": "12655554",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-07-01 08:40:16",
      "description": "Given a table with only a primary key, like\n{noformat}\nCREATE TABLE test (k int PRIMARY KEY)\n{noformat}\nthere is currently no way to CAS a row in that table into existing because:\n# INSERT doesn't currently support IF\n# UPDATE has no way to update such table\n\nSo we should probably allow IF conditions on INSERT statements.\n\nIn addition (or alternatively), we could work on allowing UPDATE to update such table. One motivation for that could be to make UPDATE always be more general to INSERT. That is currently, there is a bunch of operation that INSERT cannot do (counter increments, collection appends), but that \"primary key table\" case is, afaik, the only case where you *need* to use INSERT. However, because CQL forces segregation of PK value to the WHERE clause and not to the SET one, the only syntax that I can see work would be:\n{noformat}\nUPDATE WHERE k=0;\n{noformat}\nwhich maybe is too ugly to allow?\n\n ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CAS on 'primary key only' table"
   },
   {
      "_id": "12654636",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-06-25 01:12:27",
      "description": "Concrete operation is as follows.\n---------*---------*---------*---------*---------*---------*---------*---------*\n(1)map type's export/import\n<export>\n[root@castor bin]# ./cqlsh\nConnected to Test Cluster at localhost:9160.\n[cqlsh 3.0.2 | Cassandra 1.2.5 | CQL spec 3.0.0 | Thrift protocol 19.36.0]\nUse HELP for help.\ncqlsh> create keyspace maptestks with replication  = { 'class' : 'SimpleStrategy', 'replication_factor' : '1' };\ncqlsh> use maptestks;\ncqlsh:maptestks> create table maptestcf (rowkey varchar PRIMARY KEY, targetmap map<varchar,varchar>);\ncqlsh:maptestks> insert into maptestcf (rowkey, targetmap) values ('rowkey',{'mapkey':'mapvalue'});\ncqlsh:maptestks> select * from maptestcf;\n\n rowkey | targetmap\n--------+--------------------\n rowkey | {mapkey: mapvalue}\ncqlsh:maptestks>  copy maptestcf to 'maptestcf-20130619.txt';\n1 rows exported in 0.008 seconds.\ncqlsh:maptestks> exit;\n\n[root@castor bin]# cat maptestcf-20130619.txt\nrowkey,{mapkey: mapvalue}\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000<------------------------(a)\n<import>\n[root@castor bin]# ./cqlsh\nConnected to Test Cluster at localhost:9160.\n[cqlsh 3.0.2 | Cassandra 1.2.5 | CQL spec 3.0.0 | Thrift protocol 19.36.0]\nUse HELP for help.\ncqlsh> create keyspace mapimptestks with replication  = { 'class' : 'SimpleStrategy', 'replication_factor' : '1' };\ncqlsh> use mapimptestks;\ncqlsh:mapimptestks> create table mapimptestcf (rowkey varchar PRIMARY KEY, targetmap map<varchar,varchar>);\n\ncqlsh:mapimptestks> copy mapimptestcf from ' maptestcf-20130619.txt ';\nBad Request: line 1:83 no viable alternative at input '}'\nAborting import at record #0 (line 1). Previously-inserted values still present.\n0 rows imported in 0.025 seconds.\n---------*---------*---------*---------*---------*---------*---------*---------*\n(2)list type's export/import\n<export>\n[root@castor bin]#./cqlsh\nConnected to Test Cluster at localhost:9160.\n[cqlsh 3.0.2 | Cassandra 1.2.5 | CQL spec 3.0.0 | Thrift protocol 19.36.0]\nUse HELP for help.\ncqlsh> create keyspace listtestks with replication  = { 'class' : 'SimpleStrategy', 'replication_factor' : '1' };\ncqlsh> use listtestks;\ncqlsh:listtestks> create table listtestcf (rowkey varchar PRIMARY KEY, value list<varchar>);\ncqlsh:listtestks> insert into listtestcf (rowkey,value) values ('rowkey',['value1','value2']);\ncqlsh:listtestks> select * from listtestcf;\n\n rowkey | value\n--------+------------------\n rowkey | [value1, value2]\n\ncqlsh:listtestks> copy listtestcf to 'listtestcf-20130619.txt';\n1 rows exported in 0.014 seconds.\ncqlsh:listtestks> exit;\n\n[root@castor bin]# cat listtestcf-20130619.txt\nrowkey,\"[value1, value2]\"\n\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000<------------------------(b)\n<export>\n[root@castor bin]# ./cqlsh\nConnected to Test Cluster at localhost:9160.\n[cqlsh 3.0.2 | Cassandra 1.2.5 | CQL spec 3.0.0 | Thrift protocol 19.36.0]\nUse HELP for help.\ncqlsh> create keyspace listimptestks with replication  = { 'class' : 'SimpleStrategy', 'replication_factor' : '1' };\ncqlsh> use listimptestks;\ncqlsh:listimptestks> create table listimptestcf (rowkey varchar PRIMARY KEY, value list<varchar>);\ncqlsh:listimptestks> copy listimptestcf from ' listtestcf-20130619.txt ';\nBad Request: line 1:79 no viable alternative at input ']'\nAborting import at record #0 (line 1). Previously-inserted values still present.\n0 rows imported in 0.030 seconds.\n---------*---------*---------*---------*---------*---------*---------*---------*\nReference: (correct, or error, in another dimension)\n\nManually, I have rewritten the export file.\n[root@castor bin]# cat nlisttestcf-20130619.txt\nrowkey,\"['value1',' value2']\"\n\n....\ncqlsh:listimptestks> copy listimptestcf from 'nlisttestcf-20130619.txt';\n1 rows imported in 0.035 seconds.\n\ncqlsh:listimptestks> select * from implisttestcf;\n rowkey | value\n--------+------------------\n rowkey | [value1, value2]\ncqlsh:implisttestks> exit;\n\n[root@castor bin]# cat nmaptestcf-20130619.txt\nrowkey,\u201d{'mapkey': 'mapvalue'}\u201d\n\n[root@castor bin]# ./cqlsh\nConnected to Test Cluster at localhost:9160.\n[cqlsh 3.0.2 | Cassandra 1.2.5 | CQL spec 3.0.0 | Thrift protocol 19.36.0]\nUse HELP for help.\ncqlsh> use  mapimptestks;\ncqlsh:mapimptestks> copy mapimptestcf from 'nmaptestcf-20130619.txt';\n1 rows imported in 0.023 seconds.\ncqlsh:mapimptestks> select * from mapimptestcf;\n\n rowkey | targetmap\n--------+--------------------\n rowkey | {mapkey: mapvalue}\n\n(It appears to be as normal processing.)\n---------*---------*---------*---------*---------*---------*---------*---------*\nPlease confirm from the operation described above.\nComparing the above (a) and (b), in the data format of export file, \nonly the presence or absence of (\"), \nit suggests a lack of consistency of the treatment(?).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "collections",
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh should support collections in COPY FROM"
   },
   {
      "_id": "12654635",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-06-25 00:59:48",
      "description": "The documentation for BATCH statements declares that semicolons are required between update operations. Currently including them results in an error 'expecting K_APPLY'. To match the design specifications, semi-colons should be allowed or optional. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh doesn't allow semicolons in BATCH statements"
   },
   {
      "_id": "12653906",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-06-20 10:36:18",
      "description": "For historical reason (and compatibility with thrift), all type support an empty value, even type like int for which it doesn't really make sense (see CASSANDRA-5674 too on that subject).\n\nIf you input such an empty value for a type like int, cqlsh will display it as null:\n{noformat}\ncqlsh:ks> CREATE TABLE test (k text PRIMARY KEY, v int);\ncqlsh:ks> INSERT INTO test(k, v) VALUES ('someKey', blobAsInt(0x));\ncqlsh:ks> SELECT * FROM test;\n\n k       | v\n---------+------\n someKey | null\n\n{noformat} \n\nBut that's not correct, it suggests {{v}} has no value but that's not true, it has a value, it's just an empty one.\n\nNow, one may argue support empty values for a type like int is broken, and I would agree with that. But thrift allows it so we probably need to preserve that behavior for compatibility sake. And I guess the need to use blobAsInt at least make it clear that it's kind of a hack.\n\nThat being said, cqlsh should not display null as this is confusing. Instead I'd suggest either displaying nothing (that's how an empty string is displayed after all), or to just go with some random explicit syntax like say \"[empty value]\"",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh shouldn't display \"null\" for empty values"
   },
   {
      "_id": "12653785",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-06-19 19:07:51",
      "description": "I get multiple NullPointerException when trying to trace INSERT statements.\n\nTo reproduce:\n{code}\n$ ccm create -v git:trunk\n$ ccm populate -n 3\n$ ccm start\n$ ccm node1 cqlsh < 5668_npe_ddl.cql\n$ ccm node1 cqlsh < 5668_npe_insert.cql\n{code}\n\nAnd see many exceptions like this in the logs of node1:\n{code}\nERROR [WRITE-/127.0.0.3] 2013-06-19 14:54:35,885 OutboundTcpConnection.java (line 197) error writing to /127.0.0.3\njava.lang.NullPointerException\n        at org.apache.cassandra.net.OutboundTcpConnection.writeConnected(OutboundTcpConnection.java:182)\n        at org.apache.cassandra.net.OutboundTcpConnection.run(OutboundTcpConnection.java:144)\n{code}\n\n\nThis is similar to CASSANDRA-5658 and is the reason that npe_ddl and npe_insert are separate files.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "pull-request-available",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "NPE in net.OutputTcpConnection when tracing is enabled"
   },
   {
      "_id": "12653784",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-06-19 19:03:30",
      "description": "The current time is used to generate the timeuuid used for CAS ballots proposals with the logic that if a newer proposal exists then the current one needs to complete that and re-propose. The problem is that if a machine has clock skew and drifts into the future it will propose with a large timestamp (which will get accepted) but then subsequent proposals with lower (but correct) timestamps will not be able to proceed. This will prevent CAS write operations and also reads at serializable consistency level. \n\nThe work around is to initially propose with current time (current behavior) but if the proposal fails due to a larger existing one re-propose (after completing the existing if necessary) with the max of (currentTime, mostRecent+1, proposed+1).\n\nSince small drift is normal between different nodes in the same datacenter this can happen even if NTP is working properly and a write hits one node and a subsequent serialized read hits another. In the case of NTP config issues (or OS bugs with time esp around DST) the unavailability window could be much larger.  \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Change timestamps used in CAS ballot proposals to be more resilient to clock skew"
   },
   {
      "_id": "12652810",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-06-14 05:47:43",
      "description": "CASSANDRA-5484 introduced CREATE CUSTOM INDEX syntax for custom 2i and CASSANDRA-5576 will add CQL3 support for creating/dropping triggers (CREATE TRIGGER <name> ON <table> USING <classname>). For consistency' sake, CREATE CUSTOM INDEX should be updated to also use 'USING' keyword, e.g. CREATE CUSTOM INDEX ON <table>(<column>) USING <classname>.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Update CREATE CUSTOM INDEX syntax to match new CREATE TRIGGER syntax"
   },
   {
      "_id": "12652745",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-06-13 21:01:58",
      "description": "This is handy since counting rows that look mostly alike can be painful; it also makes it clear that cqlsh isn't ignoring you when you select something that doesn't exist.\n\nHere is what psql does:\n\n{noformat}\ncompany=> select fname, salary from employee;\n\nfname   |  salary\n--------+--------\nJohn    |30000.00\nFranklin|40000.00\nAlica   |25000.00\nJennifer|43000.00\nRamish  |38000.00\nJoyce   |25000.00\nAhmad   |25000.00\nJames   |55000.00\n(8 rows)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add row count to select output a la psql"
   },
   {
      "_id": "12652558",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-06-13 04:56:27",
      "description": "This is currently supported via Thrift but not via CQL. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "LWT",
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL support for updating multiple rows in a partition using CAS"
   },
   {
      "_id": "12652101",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-06-10 22:00:21",
      "description": "Parsing goes through ReversedType.fromString() in this case, and that doesn't strip \"0x\" when calling BytesType.fromString().\n\nThe attached patch makes Constants.parsedValue() ReversedType-aware. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Incorrect handling of blob literals when the blob column is in reverse clustering order"
   },
   {
      "_id": "12651915",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-06-09 10:05:35",
      "description": "It would be nice to have support of empty IN queries. \nExample: \"SELECT a FROM t WHERE aKey IN ()\". \nOne of the reasons is to have such support in DataStax Java Driver (see discussion here: https://datastax-oss.atlassian.net/browse/JAVA-106).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Support empty IN queries"
   },
   {
      "_id": "12651400",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         }
      ],
      "created": "2013-06-06 17:53:02",
      "description": "Looking at the new CAS CQL3 support examples [1], if one lost a race for an UPDATE, to save a round trip to get the current values to decide if you need to perform your work, could the columns that were used in the IF clause also be returned to the caller?  Maybe the columns values as part of the SET part could also be returned.\n\nI don't know if this is generally useful though.\n\nIn the case of creating a new user account with a given username which is the partition key, if one lost the race to another person creating an account with the same username, it doesn't matter to the loser what the column values are, just that they lost.\n\nI'm new to Cassandra, so maybe there's other use cases, such as doing incremental amount of work on a row.  In pure Java projects I've done while loops around AtomicReference.html#compareAndSet() until the work was done on the referenced object to handle multiple threads each making forward progress in updating the references object.\n\n[1] https://github.com/riptano/cassandra-dtest/blob/master/cql_tests.py#L3044",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CAS UPDATE for a lost race: save round trip by returning column values"
   },
   {
      "_id": "12651102",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2013-06-05 12:10:37",
      "description": "insert into some_table (id,time) values (?,now())\n\nOn the example above now() will always have the same value, it should probably be evaluated at \"query\" time and not at prepare time. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL now() on prepared statements is evaluated at prepare time and not query execution time"
   },
   {
      "_id": "12650803",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-06-04 02:55:25",
      "description": "See the attached upgrade_through_versions_test.py upgrade_test_mixed().\n\nConceptually this method does the following:\n\n* Instantiates a 3 node 1.1.9 cluster\n* Writes some data\n* Shuts down node 1 and upgrades it to 1.2 (HEAD)\n* Brings the node1 back up, making the cluster a mixed version 1.1/1.2\n* Brings down node2 and node3 and does the same upgrade making it all the same version.\n* At this point, I would run upgradesstables on each of the nodes, but there is already an error on node3 directly after it's upgrade:\n\n{code}\nINFO [FlushWriter:1] 2013-06-03 22:49:46,543 Memtable.java (line 461) Writing Memtable-peers@1023263314(237/237 serialized/live bytes, 14 op\ns)\n INFO [FlushWriter:1] 2013-06-03 22:49:46,556 Memtable.java (line 495) Completed flushing /tmp/dtest-YqMtHN/test/node3/data/system/peers/syst\nem-peers-ic-2-Data.db (291 bytes) for commitlog position ReplayPosition(segmentId=1370314185862, position=58616)\n INFO [GossipStage:1] 2013-06-03 22:49:46,568 StorageService.java (line 1330) Node /127.0.0.2 state jump to normal\nERROR [MigrationStage:1] 2013-06-03 22:49:46,655 CassandraDaemon.java (line 192) Exception in thread Thread[MigrationStage:1,5,main]\njava.lang.NullPointerException\n        at org.apache.cassandra.db.DefsTable.addColumnFamily(DefsTable.java:511)\n        at org.apache.cassandra.db.DefsTable.mergeColumnFamilies(DefsTable.java:445)\n        at org.apache.cassandra.db.DefsTable.mergeSchema(DefsTable.java:355)\n        at org.apache.cassandra.db.DefinitionsUpdateVerbHandler$1.runMayThrow(DefinitionsUpdateVerbHandler.java:55)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n{code}\n\nThis error is repeatable, but inconsistent. Interestingly, it is always node3 with the error.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "NPE when upgrading a mixed version 1.1/1.2 cluster fully to 1.2"
   },
   {
      "_id": "12650728",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-06-03 20:40:38",
      "description": "If you have a reversed text field, COPY chokes on it because the type is\n\"'org.apache.cassandra.db.marshal.ReversedType'<text>\" not just 'text' so the strings don't get quoted in the generated CQL.\n\n{noformat}\n    def do_import_row(self, columns, nullval, layout, row):\n        rowmap = {}\n        for name, value in zip(columns, row):\n            if value != nullval:\n                type = layout.get_column(name).cqltype.cql_parameterized_type()\n                if type in ('ascii', 'text', 'timestamp', 'inet'):\n                    rowmap[name] = self.cql_protect_value(value)\n                else:\n                    rowmap[name] = value\n            else:\n                rowmap[name] = 'null'\n        return self.do_import_insert(layout, rowmap)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "ORDER BY desc breaks cqlsh COPY"
   },
   {
      "_id": "12649394",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-05-24 20:44:49",
      "description": "The query in the authorize method will be extensively, providing you have configured Cassandra to use CassandraAuthorizer. Given the frequency of this query against the permissions CF, a prepared statement should be used here. There is a non-trivial amount of overhead involved with parsing a statement; so, this query would greatly benefit given how much it is run.\n\nWhile I was doing some testing recently, I eventually hit some timeout exceptions, but the timeouts were from the query in the authorize method. Here is a recent stack trace from one such exception,\n\nERROR [Native-Transport-Requests:11] 2013-05-20 16:16:16,702 ErrorMessage.java (line 210) Unexpected exception during request\ncom.google.common.util.concurrent.UncheckedExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.ReadTimeoutException: Operation timed out - received only 0 responses.\n        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2258)\n        at com.google.common.cache.LocalCache.get(LocalCache.java:3990)\n        at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3994)\n        at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4878)\n        at org.apache.cassandra.service.ClientState.authorize(ClientState.java:290)\n        at org.apache.cassandra.service.ClientState.ensureHasPermission(ClientState.java:170)\n        at org.apache.cassandra.service.ClientState.hasAccess(ClientState.java:163)\n        at org.apache.cassandra.service.ClientState.hasColumnFamilyAccess(ClientState.java:147)\n        at org.apache.cassandra.cql3.statements.ModificationStatement.checkAccess(ModificationStatement.java:69)\n        at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:131)\n        at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:257)\n        at org.apache.cassandra.transport.messages.ExecuteMessage.execute(ExecuteMessage.java:121)\n        at org.apache.cassandra.transport.Message$Dispatcher.messageReceived(Message.java:287)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:75)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:565)\n        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:793)\n        at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:45)\n        at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:69)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\nCaused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.ReadTimeoutException: Operation timed out - received only 0 responses.\n        at org.apache.cassandra.auth.Auth.isSuperuser(Auth.java:95)\n        at org.apache.cassandra.auth.AuthenticatedUser.isSuper(AuthenticatedUser.java:50)\n        at org.apache.cassandra.auth.CassandraAuthorizer.authorize(CassandraAuthorizer.java:61)\n        at org.apache.cassandra.service.ClientState$1.load(ClientState.java:276)\n        at org.apache.cassandra.service.ClientState$1.load(ClientState.java:273)\n        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3589)\n        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2374)\n        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2337)\n        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2252)\n        ... 20 more\nCaused by: org.apache.cassandra.exceptions.ReadTimeoutException: Operation timed out - received only 0 responses.\n        at org.apache.cassandra.service.ReadCallback.get(ReadCallback.java:99)\n        at org.apache.cassandra.service.StorageProxy.fetchRows(StorageProxy.java:941)\n        at org.apache.cassandra.service.StorageProxy.read(StorageProxy.java:829)\n        at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:124)\n        at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:56)\n        at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:132)\n        at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:143)\n        at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:151)\n        at org.apache.cassandra.auth.Auth.isSuperuser(Auth.java:90)\n        ... 28 more",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "authorization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CassandraAuthorizer.authorize(AuthenticatedUser, IResource) should use prepared statement"
   },
   {
      "_id": "12649106",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-05-23 12:36:17",
      "description": "The following stack trace was in the system.log:\n\n{quote}\nERROR [CompactionExecutor:2] 2013-05-22 16:19:32,402 CassandraDaemon.java (line 174) Exception in thread Thread[CompactionExecutor:2,1,main]\n java.lang.ArrayIndexOutOfBoundsException: 5\n\tat org.apache.cassandra.db.compaction.LeveledManifest.skipLevels(LeveledManifest.java:176)\n\tat org.apache.cassandra.db.compaction.LeveledManifest.promote(LeveledManifest.java:215)\n\tat org.apache.cassandra.db.compaction.LeveledCompactionStrategy.handleNotification(LeveledCompactionStrategy.java:155)\n\tat org.apache.cassandra.db.DataTracker.notifySSTablesChanged(DataTracker.java:410)\n\tat org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:223)\n\tat org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:991)\n\tat org.apache.cassandra.db.compaction.CompactionTask.runWith(CompactionTask.java:230)\n\tat org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:48)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n\tat org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:58)\n\tat org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:60)\n\tat org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionTask.run(CompactionManager.java:188)\n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "ArrayIndexOutOfBoundsException in LeveledManifest"
   },
   {
      "_id": "12648730",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-05-21 20:45:22",
      "description": "Drop CQL2/CQL3-beta support from cqlsh in 2.0. (If somebody really needs that for some reason in 2.0, they'd still be able to use cqlsh from 1.2).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cql",
         "cql3",
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Drop CQL2/CQL3-beta support from cqlsh"
   },
   {
      "_id": "12646032",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-05-03 19:53:16",
      "description": "When ColumnFamilyInputFormat starts getting splits (via getSplits(...) [ColumnFamilyInputFormat.java:101]) it checks to see if a `jobKeyRange` has been set.  If it has been set it attempts to set the `jobRange`.  However the if block (ColumnFamilyInputFormat.java:124) looks to see if the `jobKeyRange` has tokens but asserts that the OrderPreservingPartitioner must be in use.\n\nThis if block should be looking for keys (not tokens).  Code further down (ColumnFamilyInputFormat.java:147) already manages the range if tokens are used but can never be reached.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hadoop"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "ColumnFamilyInputFormat demands OrderPreservingPartitioner when specifying InputRange with tokens"
   },
   {
      "_id": "12643966",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-04-22 17:27:26",
      "description": "I am evaluating cassandra for a use case with many tiny rows which would result in a node with 1-3TB of storage having billions of rows. Before loading that much data I am hitting GC issues and when looking at the heap dump I noticed that 70+% of the memory was used by IndexSummaries. \n\nThe two major issues seem to be:\n\n1) that the positions are stored as an ArrayList<Long> which results in each position taking 24 bytes (class + flags + 8 byte long). This might make sense when the file is initially written but once it has been serialized it would be a lot more memory efficient to just have an long[] (really a int[] would be fine unless 2GB sstables are allowed).\n\n2) The DecoratedKey for a byte[16] key takes 195 bytes -- this is for the overhead of the ByteBuffer in the key and overhead in the token.\n\nTo somewhat \"work around\" the problem I have increased index_sample but will this many rows that didn't really help starts to have diminishing returns. \n\n\nNOTE: This heap dump was from linux with a 64bit oracle vm. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Reduce memory consumption of IndexSummary"
   },
   {
      "_id": "12643123",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-04-18 04:33:55",
      "description": "With the possible presence of range tombstones, it is erroneous to skip checking for a given column in SSTableNamesIterator because the bloom filter says it is not there.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Backport row-level bloom filter removal to 1.2"
   },
   {
      "_id": "12643007",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-04-17 19:11:44",
      "description": "The idea behind promoted indexes (CASSANDRA-2319) was we could skip a seek to the row header by keeping the column index in the index file.  But, we skip writing the row-level tombstone to the index file unless it also has some column data.  So unless we read the tombstone from the data file (where it is guaranteed to exist) we can return incorrect results.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Promote row-level tombstones to index file"
   },
   {
      "_id": "12642817",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2013-04-16 21:31:15",
      "description": "Through thrift users can add custom secondary indexes to the column metadata.\n\nThe following syntax is used in PLSQL, and I think we could use something similar.\n\nCREATE INDEX <NAME> ON <TABLE> (<COLUMN>) [INDEXTYPE IS (<TYPENAME>) [PARAMETERS (<PARAM>[, <PARAM>])]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3",
         "index"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Support custom secondary indexes in CQL"
   },
   {
      "_id": "12642448",
      "assignee": "slebresne",
      "components": [],
      "created": "2013-04-14 15:07:54",
      "description": "In org.apache.cassandra.transport.Server, the start() method sets the isRunning flag before calling the run() method. In the event of an initialization error like a port conflict an exception will be thrown at line 136 which is,\n\n    Channel channel = bootstrap.bind(socket);\n\nIt seems like it might make more sense to set the isRunning flag after binding to the socket. I have a tool that deploys a node and then verifies it is ready to receive CQL requests. I do this via JMX. Unless I use a delay before making that check, the JMX call will return true even though there is a port conflict. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "jmx",
         "server"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "isRunning flag set prematurely in org.apache.cassandra.transport.Server"
   },
   {
      "_id": "12641685",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-04-09 18:50:47",
      "description": "This would help tracking down which query is causing errors.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Include fatal errors in trace events"
   },
   {
      "_id": "12641116",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-04-05 19:22:51",
      "description": "I would like to make SUPERUSER_SETUP_DELAY configurable for automated tests. I have tests that stand up a local cluster, and sometimes if I just run a single test class, the total execution time to stand up the (usually two) nodes and run the tests takes less than 20 seconds. I am running on fast hardware, so I can probably get by with a lower value in most cases, but maybe one of my teammates runs on slower hardware and needs a larger value.\n\nI do not see this as a problem for production use. It would just be nice to have it configurable for dev environments.\n\nThanks",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "authentication"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Make Auth.SUPERUSER_SETUP_DELAY configurable"
   },
   {
      "_id": "12640545",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-04-03 16:55:20",
      "description": "Evidently with the old authenticator it was allowed to set keyspace, and then login.  With the org.apache.cassandra.auth.PasswordAuthenticator you have to login and then setkeyspace\n\nFor backwards compatibility it would be good to allow setting before login, and perform the actual operation/validation later after the login.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "PasswordAuthenticator is incompatible with various Cassandra clients"
   },
   {
      "_id": "12640329",
      "assignee": "slebresne",
      "components": [],
      "created": "2013-04-02 16:19:31",
      "description": "CompositeType happens to be very useful and is now widely used: CQL3 heavily rely on it, and super columns are now using it too internally. Besides, CompositeType has been advised as a replacement of super columns on the thrift side for a while, so it's safe to assume that it's generally used there too.\n\nCompositeType has initially been introduced as just another AbstractType.  Meaning that the storage engine has no nothing whatsoever of composites being, well, composite. This has the following drawbacks:\n* Because internally a composite value is handled as just a ByteBuffer, we end up doing a lot of extra work. Typically, each time we compare 2 composite value, we end up \"deserializing\" the components (which, while it doesn't copy data per-se because we just slice the global ByteBuffer, still waste some cpu cycles and allocate a bunch of ByteBuffer objects). And since compare can be called *a lot*, this is likely not negligible.\n* This make CQL3 code uglier than necessary. Basically, CQL3 makes extensive use of composites, and since it gets backs ByteBuffer from the internal columns, it always have to check if it's actually a compositeType or not, and then split it and pick the different parts it needs. It's only an API problem, but having things exposed as composites directly would definitively make thinks cleaner. In particular, in most cases, CQL3 don't care whether it has a composite with only one component or a non-really-composite value, but we still always distinguishes both cases.  Lastly, if we do expose composites more directly internally, it's not a lot more work to \"internalize\" better the different parts of the cell name that CQL3 uses (what's the clustering key, what's the actuall CQL3 column name, what's the collection element), making things cleaner. Last but not least, there is currently a bunch of places where methods take a ByteBuffer as argument and it's hard to know whether it expects a cell name or a CQL3 column name. This is pretty error prone.\n* It makes it hard (or impossible) to do a number of performance improvements.  Consider CASSANDRA-4175, I'm not really sure how you can do it properly (in memory) if cell names are just ByteBuffer (since CQL3 column names are just one of the component in general). But we also miss oportunities of sharing prefixes. If we were able to share prefixes of composite names in memory we would 1) lower the memory footprint and 2) potentially speed-up comparison (of the prefixes) by checking reference equality first (also, doing prefix sharing on-disk, which is a separate concern btw, might be easier to do if we do prefix sharing in memory).\n\nSo I suggest pushing CompositeType support inside the storage engine. What I mean by that concretely would be change the internal {{Column.name}} from ByteBuffer to some CellName type. A CellName would API-wise just be a list of ByteBuffer. But in practice, we'd have a specific CellName implementation for not-really-composite names, and the truly composite implementation will allow some prefix sharing. From an external API however, nothing would change, we would pack the composite as usual before sending it back to the client, but at least internally, comparison won't have to deserialize the components every time, and CQL3 code will be cleaner.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Push composites support in the storage engine"
   },
   {
      "_id": "12640301",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-04-02 13:41:31",
      "description": "When I create a prepared statement with the following CQL3 using Thrift protocol:\n{code}\nBEGIN BATCH USING TIMESTAMP <number>\n<some INSERT INTO or UPDATE statements ....>\nAPPLY BATCH\n{code}\n\nand execute this statement in a loop, I randomly get the error:\n*InvalidRequestException(why:Timestamp must be set either on BATCH or individual statements)*\n\nAll statements inside the batch have no individual USING TIMESTAMP.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Batch with timestamp failed"
   },
   {
      "_id": "12640261",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-04-02 09:47:53",
      "description": "The elements in the map <timeuuid,decimal> are returned in cqlsh in an order that is neither sorted by name, value or timestamp.\nBelow is output from cqlsh and cassandra cli. (looks a bit messy here, I have attached a text file without word wrapping)\n\ncqlsh:iBidTest> select * from lots ;\n\n event_id                             | lot_id | bids_accepted | bids_details | bids_temp                                                                                                                                                                                                                                                            | minimum | number | title\n--------------------------------------+--------+---------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+--------+-----------\n a4a70900-24e1-11df-8924-001ff3591711 |      1 |          null |         null |                                                                                                                                                                                                                                                                 null |     200 |      2 | New lot 2\n a4a70900-24e1-11df-8924-001ff3591711 |      3 |          null |         null | {8b457e90-9ae2-11e2-9bcb-a1f164a2d4a3: 1000, 9606ca50-9ae2-11e2-9bcb-a1f164a2d4a3: 650, 908fb640-9ae2-11e2-9bcb-a1f164a2d4a3: 600, 7d930650-9ae2-11e2-9bcb-a1f164a2d4a3: 500, a1ef7f10-9ae2-11e2-9bcb-a1f164a2d4a3: 1250, 9aedd360-9ae2-11e2-9bcb-a1f164a2d4a3: 950} |     100 |      1 | New lot 1\n\n\n[default@ibidtest] get lots[a4a70900-24e1-11df-8924-001ff3591711];\n=> (column=1:, value=, timestamp=1364829909818000)\n=> (column=1:minimum, value=0000000000c8, timestamp=1364829397026000)\n=> (column=1:number, value=32, timestamp=1364829909818000)\n=> (column=1:title, value=4e6577206c6f742032, timestamp=1364829397026000)\n=> (column=3:, value=, timestamp=1364830894466000)\n=> (column=3:bids_temp:7d9306509ae211e29bcba1f164a2d4a3, value=0000000001f4, timestamp=1364830833463000)\n=> (column=3:bids_temp:8b457e909ae211e29bcba1f164a2d4a3, value=0000000003e8, timestamp=1364830856441000)\n=> (column=3:bids_temp:908fb6409ae211e29bcba1f164a2d4a3, value=000000000258, timestamp=1364830865317000)\n=> (column=3:bids_temp:9606ca509ae211e29bcba1f164a2d4a3, value=00000000028a, timestamp=1364830874485000)\n=> (column=3:bids_temp:9aedd3609ae211e29bcba1f164a2d4a3, value=0000000003b6, timestamp=1364830882711000)\n=> (column=3:bids_temp:a1ef7f109ae211e29bcba1f164a2d4a3, value=0000000004e2, timestamp=1364830894466000)\n=> (column=3:minimum, value=0000000064, timestamp=1364829412417000)\n=> (column=3:number, value=31, timestamp=1364829852020000)\n=> (column=3:title, value=4e6577206c6f742031, timestamp=1364829412417000)\nReturned 14 results.\nElapsed time: 130 msec(s).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3",
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh returns map entries in wrong order"
   },
   {
      "_id": "12640117",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-04-01 14:01:01",
      "description": "incremental backups does not mark things referenced or compacting, so it could get compacted away before createLinks runs.  Occasionally you can see this happen during ColumnFamilyStoreTest.  (Since it runs on the background tasks stage, it does not fail the test.)\n\n{noformat}\n    [junit] java.lang.RuntimeException: Tried to hard link to file that does not exist build/test/cassandra/data/Keyspace1/Standard1/Keyspace1-Standard1-ja-8-Statistics.db\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.createHardLink(FileUtils.java:72)\n    [junit] \tat org.apache.cassandra.io.sstable.SSTableReader.createLinks(SSTableReader.java:1066)\n    [junit] \tat org.apache.cassandra.db.DataTracker$1.run(DataTracker.java:168)\n    [junit] \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\n    [junit] \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n    [junit] \tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n    [junit] \tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "incremental backups race"
   },
   {
      "_id": "12639726",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320019",
            "id": "12320019",
            "name": "Local/Config",
            "description": "Configuration and environment"
         }
      ],
      "created": "2013-03-29 01:06:11",
      "description": "It's possible for a node to join an existing cluster (with perhaps more stringent security restrictions i.e. not using AllowAllAuthentication) and issue destructive commands that affect the cluster at large (e.g. drop keyspace via cassandra-cli, etc).  \n\nThis can be circumvented with a pluggable security module that could be used to implement basic node vetting/identification/etc.  \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "configuration",
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Pluggable security feature to prevent node from joining a cluster and running destructive commands"
   },
   {
      "_id": "12639433",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-03-27 19:32:57",
      "description": "PerColumnIndexUpdater ignores updates where the new value is a tombstone.  It should still remove the index entry on oldColumn.\n\n(Note that this will not affect user-visible correctness, since KeysSearcher/CompositeSearcher will issue deletes against stale index entries, but having more stale entries than we \"should\" could affect performance.)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Compaction doesn't remove index entries as designed"
   },
   {
      "_id": "12638924",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12314245",
            "id": "12314245",
            "name": "Legacy/Testing",
            "description": "CCM, dtest"
         }
      ],
      "created": "2013-03-25 17:36:37",
      "description": "Two unit tests are failing on Windows 7 due to errors in renaming/deleting files:\n\n\norg.apache.cassandra.db.ColumnFamilyStoreTest: \n{code}\n    [junit] Testsuite: org.apache.cassandra.db.ColumnFamilyStoreTest\n    [junit] Tests run: 27, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 13.904 sec\n    [junit] \n    [junit] ------------- Standard Error -----------------\n    [junit] ERROR 13:06:46,058 Unable to delete build\\test\\cassandra\\data\\Keyspace1\\Indexed2\\Keyspace1-Indexed2.birthdate_index-ja-1-Data.db (it will be removed on server restart; we'll also retry after GC)\n    [junit] ERROR 13:06:48,508 Fatal exception in thread Thread[NonPeriodicTasks:1,5,main]\n    [junit] java.lang.RuntimeException: Tried to hard link to file that does not exist build\\test\\cassandra\\data\\Keyspace1\\Standard1\\Keyspace1-Standard1-ja-7-Statistics.db\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.createHardLink(FileUtils.java:72)\n    [junit] \tat org.apache.cassandra.io.sstable.SSTableReader.createLinks(SSTableReader.java:1057)\n    [junit] \tat org.apache.cassandra.db.DataTracker$1.run(DataTracker.java:168)\n    [junit] \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\n    [junit] \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n    [junit] \tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n    [junit] \tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)\n    [junit] \tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)\n    [junit] \tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\n    [junit] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\n    [junit] \tat java.lang.Thread.run(Thread.java:662)\n    [junit] ------------- ---------------- ---------------\n    [junit] Testcase: testSliceByNamesCommandOldMetatada(org.apache.cassandra.db.ColumnFamilyStoreTest):\tCaused an ERROR\n    [junit] Failed to rename build\\test\\cassandra\\data\\Keyspace1\\Standard1\\Keyspace1-Standard1-ja-6-Statistics.db-tmp to build\\test\\cassandra\\data\\Keyspace1\\Standard1\\Keyspace1-Standard1-ja-6-Statistics.db\n    [junit] java.lang.RuntimeException: Failed to rename build\\test\\cassandra\\data\\Keyspace1\\Standard1\\Keyspace1-Standard1-ja-6-Statistics.db-tmp to build\\test\\cassandra\\data\\Keyspace1\\Standard1\\Keyspace1-Standard1-ja-6-Statistics.db\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:133)\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:122)\n    [junit] \tat org.apache.cassandra.db.compaction.LeveledManifest.mutateLevel(LeveledManifest.java:575)\n    [junit] \tat org.apache.cassandra.db.ColumnFamilyStore.loadNewSSTables(ColumnFamilyStore.java:589)\n    [junit] \tat org.apache.cassandra.db.ColumnFamilyStoreTest.testSliceByNamesCommandOldMetatada(ColumnFamilyStoreTest.java:885)\n    [junit] \n    [junit] \n    [junit] Testcase: testRemoveUnifinishedCompactionLeftovers(org.apache.cassandra.db.ColumnFamilyStoreTest):\tCaused an ERROR\n    [junit] java.io.IOException: Failed to delete c:\\Users\\Ryan\\git\\cassandra\\build\\test\\cassandra\\data\\Keyspace1\\Standard3\\Keyspace1-Standard3-ja-2-Data.db\n    [junit] FSWriteError in build\\test\\cassandra\\data\\Keyspace1\\Standard3\\Keyspace1-Standard3-ja-2-Data.db\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:112)\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:103)\n    [junit] \tat org.apache.cassandra.io.sstable.SSTable.delete(SSTable.java:139)\n    [junit] \tat org.apache.cassandra.db.ColumnFamilyStore.removeUnfinishedCompactionLeftovers(ColumnFamilyStore.java:507)\n    [junit] \tat org.apache.cassandra.db.ColumnFamilyStoreTest.testRemoveUnifinishedCompactionLeftovers(ColumnFamilyStoreTest.java:1246)\n    [junit] Caused by: java.io.IOException: Failed to delete c:\\Users\\Ryan\\git\\cassandra\\build\\test\\cassandra\\data\\Keyspace1\\Standard3\\Keyspace1-Standard3-ja-2-Data.db\n    [junit] \n    [junit] \n    [junit] Test org.apache.cassandra.db.ColumnFamilyStoreTest FAILED\n{code}\n\n\norg.apache.cassandra.db.ScrubTest:\n{code}\n    [junit] Testcase: testScrubFile(org.apache.cassandra.db.ScrubTest):\tCaused an ERROR\n    [junit] Failed to rename build\\test\\cassandra\\data\\Keyspace1\\Super5\\Keyspace1-Super5-f-2-Statistics.db-tmp to build\\test\\cassandra\\data\\Keyspace1\\Super5\\Keyspace1-Super5-f-2-Statistics.db\n    [junit] java.lang.RuntimeException: Failed to rename build\\test\\cassandra\\data\\Keyspace1\\Super5\\Keyspace1-Super5-f-2-Statistics.db-tmp to build\\test\\cassandra\\data\\Keyspace1\\Super5\\Keyspace1-Super5-f-2-Statistics.db\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:133)\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:122)\n    [junit] \tat org.apache.cassandra.db.compaction.LeveledManifest.mutateLevel(LeveledManifest.java:575)\n    [junit] \tat org.apache.cassandra.db.ColumnFamilyStore.loadNewSSTables(ColumnFamilyStore.java:589)\n    [junit] \tat org.apache.cassandra.db.ScrubTest.testScrubFile(ScrubTest.java:94)\n    [junit] \n    [junit] \n    [junit] Testcase: testScubOutOfOrder(org.apache.cassandra.db.ScrubTest):\tCaused an ERROR\n    [junit] Failed to rename build\\test\\cassandra\\data\\Keyspace1\\Standard3\\Keyspace1-Standard3-ia-1-Statistics.db-tmp to build\\test\\cassandra\\data\\Keyspace1\\Standard3\\Keyspace1-Standard3-ia-1-Statistics.db\n    [junit] java.lang.RuntimeException: Failed to rename build\\test\\cassandra\\data\\Keyspace1\\Standard3\\Keyspace1-Standard3-ia-1-Statistics.db-tmp to build\\test\\cassandra\\data\\Keyspace1\\Standard3\\Keyspace1-Standard3-ia-1-Statistics.db\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:133)\n    [junit] \tat org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:122)\n    [junit] \tat org.apache.cassandra.db.compaction.LeveledManifest.mutateLevel(LeveledManifest.java:575)\n    [junit] \tat org.apache.cassandra.db.ColumnFamilyStore.loadNewSSTables(ColumnFamilyStore.java:589)\n    [junit] \tat org.apache.cassandra.db.ScrubTest.testScubOutOfOrder(ScrubTest.java:201)\n    [junit] \n    [junit] \n    [junit] Test org.apache.cassandra.db.ScrubTest FAILED\n{code}\n\nReproduced in a Windows 7 VM:\njava 1.6.0_43-b01\nant 1.9.0\nC* trunk\nrun 'ant clean test'",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Windows 7 deleting/renaming files problem"
   },
   {
      "_id": "12638256",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-03-21 15:22:30",
      "description": "If LCS gets behind, read performance deteriorates as we have to check bloom filters on man sstables in L0.  For wide rows, this can mean having to seek for each one since the BF doesn't help us reject much.\n\nPerforming size-tiered compaction in L0 will mitigate this until we can catch up on merging it into higher levels.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Perform size-tiered compactions in L0 (\"hybrid compaction\")"
   },
   {
      "_id": "12637842",
      "assignee": "slebresne",
      "components": [],
      "created": "2013-03-19 22:19:59",
      "description": "*Reproduction*\nUsing https://github.com/joaquincasares/java-driver's integrationtests branch, run `mvn test` from the root directory.\n\n*Issue*\nThe test will fail due to https://github.com/joaquincasares/java-driver/blob/integrationtests/driver-core/src/main/java/com/datastax/driver/core/ResultSetFuture.java being swapped here:\n{CODE}\ncase ALREADY_EXISTS:\n    org.apache.cassandra.exceptions.AlreadyExistsException aee = (org.apache.cassandra.exceptions.AlreadyExistsException)te;\n    return new AlreadyExistsException(aee.ksName, aee.cfName);\n{CODE}\n\n*Error*\n{CODE}\nrepeatSchemaDefinition(com.datastax.driver.core.ExceptionsTest)  Time elapsed: 0.501 sec  <<< FAILURE!\norg.junit.ComparisonFailure: expected:<Table repeatschema[ks.repeatschemacf] already exists> but was:<Table repeatschema[cf.repeatschemaks] already exists>\n{CODE}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "datastax_qa"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Transposed KS/CF arguments"
   },
   {
      "_id": "12637053",
      "assignee": "krummas",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2013-03-14 17:12:45",
      "description": "Currently, the binary protocol allows requests as \"string\" or \"[prepared statement] id + bind vars\".  Allowing \"string + bind vars\" as well would simplify life for users with one-off statements and not have to choose between adding boilerplate for PS, and having to manually escape parameters, which is particularly painful for binary data.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cql",
         "protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add binary protocol support for bind variables to non-prepared statements"
   },
   {
      "_id": "12636841",
      "assignee": "krummas",
      "components": [],
      "created": "2013-03-13 19:02:09",
      "description": "We are using LCS and have total of 38000 SSTables for one CF. During LCS, there could be over a thousand SSTable involved. All those SSTable IDs are stored in ancestors field of SSTableMetatdata for the new table. In our case, it consumes more than 1G of heap memory for those field. Put it in perspective, the ancestors consume 2 - 3 times more memory than bloomfilter (fp = 0.1 by default) in LCS. \nWe should remove those ancestors from SSTableMetadata after the compaction is finished and the old SSTable is removed. It  might be a big deal for Sized Compaction since there are small number of SSTable involved. But it consumes a lot of memory for LCS. \nAt least, we shouldn't load those ancestors to the memory during startup if the files are removed. \nI would love to contribute and provide patch. Please let me know how to start. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "ancestors are not cleared in SSTableMetadata after compactions are done and old SSTables are removed"
   },
   {
      "_id": "12636457",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-03-11 22:23:21",
      "description": "I have a mixed version cluster consisting of two 1.1.9 nodes and one 1.2.2 node upgraded from 1.1.9. \n\nThe upgrade works, and I don't see any end user problems, however I see this exception in the logs on the non-upgraded nodes:\n\n{code}\nERROR [MigrationStage:1] 2013-03-11 18:09:09,001 AbstractCassandraDaemon.java (line 135) Exception in thread Thread[MigrationStage:1,5,main]\njava.lang.NullPointerException\n\tat org.apache.cassandra.utils.ByteBufferUtil.string(ByteBufferUtil.java:167)\n\tat org.apache.cassandra.utils.ByteBufferUtil.string(ByteBufferUtil.java:124)\n\tat org.apache.cassandra.cql.jdbc.JdbcUTF8.getString(JdbcUTF8.java:77)\n\tat org.apache.cassandra.cql.jdbc.JdbcUTF8.compose(JdbcUTF8.java:97)\n\tat org.apache.cassandra.db.marshal.UTF8Type.compose(UTF8Type.java:35)\n\tat org.apache.cassandra.cql3.UntypedResultSet$Row.getString(UntypedResultSet.java:87)\n\tat org.apache.cassandra.config.KSMetaData.fromSchema(KSMetaData.java:256)\n\tat org.apache.cassandra.db.DefsTable.mergeKeyspaces(DefsTable.java:397)\n\tat org.apache.cassandra.db.DefsTable.mergeSchema(DefsTable.java:373)\n\tat org.apache.cassandra.db.DefsTable.mergeRemoteSchema(DefsTable.java:352)\n\tat org.apache.cassandra.db.DefinitionsUpdateVerbHandler$1.runMayThrow(DefinitionsUpdateVerbHandler.java:48)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}\n\n\nSteps to reproduce:\n{code}\nccm create -v 1.1.9 1.1.9\nccm populate -n 3\nccm start\nccm node1 stress\nccm node1 stop\n{code}\n\nedit ~/.ccm/1.1.9/cluster.conf and configure cassandra_dir to point to 1.2.2. Edit node1's cassandra.yaml to be 1.2 compliant.\n\n{code}\nccm node1 start\n{code}\n\nThe cluster is now a mixed version, and works for user queries, but with the exception above.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't announce migrations to pre-1.2 nodes"
   },
   {
      "_id": "12636391",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-03-11 16:12:42",
      "description": "Now that we have blobAsX and xAsBlob conversion functions for all the Cassandra types, ASSUME is no longer needed and can be removed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Remove ASSUME from cqlsh"
   },
   {
      "_id": "12636099",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-03-08 19:00:03",
      "description": "Initially added to trunk for CASSANDRA-4872",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Backport on-startup manifest repair to 1.2"
   },
   {
      "_id": "12634867",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-03-01 17:41:13",
      "description": "cqlsh COPY is quoting values when it shouldn't, and that's throwing IRE in 1.2.2.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "clqsh COPY is broken after strictening validation in 1.2.2 (quotes ints)"
   },
   {
      "_id": "12633306",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-02-20 23:43:47",
      "description": "Maybe ActiveRepairService or ManualRepairService.  \"AntiEntropy\" doesn't help anyone find it who knows they want to find the \"repair\" code.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "rename AntiEntropyService"
   },
   {
      "_id": "12633090",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-02-19 22:37:56",
      "description": "For a 12-node EC2 m1.xlarge cluster, restarting a node causes it to get completely overloaded with the default 2-thread, 1024KB setting in 1.2.x. This seemed to be a smaller problem when it was 6-nodes, but still required us to abort handoffs. The old defaults in 1.1.x were WAY more conservative. I've dropped this way down to 128KB on our production cluster which is really conservative, but appears to have solved it. The default seems way too high on any cluster that is non-trivial in size.\n\nAfter putting some thought to this, it seems that this should really be based on cluster size, making the throttle a \"target\" for how much write load a single node can swallow. As the cluster grows, the amount of hints that can be delivered by each other node in the cluster goes down, so the throttle should self-adjust to take that into account.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Hinted Handoff Throttle based on cluster size"
   },
   {
      "_id": "12633066",
      "assignee": "krummas",
      "components": [],
      "created": "2013-02-19 20:20:47",
      "description": "after CASSANDRA-4872 we need a way to reset all sstables to level 0, previously we did this by removing the .json file from the data-directory.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Create tool to drop sstables to level 0"
   },
   {
      "_id": "12632473",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-02-14 21:17:53",
      "description": "When initiating a major compaction with `./nodetool -h localhost compact`, an AssertionError is thrown in the CompactionExecutor from o.a.c.io.util.Memory:\n\nERROR [CompactionExecutor:41495] 2013-02-14 14:38:35,720 CassandraDaemon.java (line 133) Exception in thread Thread[CompactionExecutor:41495,1,RMI Runtime]\njava.lang.AssertionError: Memory was freed\n  at org.apache.cassandra.io.util.Memory.checkPosition(Memory.java:146)\n\tat org.apache.cassandra.io.util.Memory.getLong(Memory.java:116)\n\tat org.apache.cassandra.io.compress.CompressionMetadata.chunkFor(CompressionMetadata.java:176)\n\tat org.apache.cassandra.io.compress.CompressedRandomAccessReader.reBuffer(CompressedRandomAccessReader.java:88)\n\tat org.apache.cassandra.io.util.RandomAccessReader.read(RandomAccessReader.java:327)\n\tat java.io.RandomAccessFile.readInt(RandomAccessFile.java:755)\n\tat java.io.RandomAccessFile.readLong(RandomAccessFile.java:792)\n\tat org.apache.cassandra.utils.BytesReadTracker.readLong(BytesReadTracker.java:114)\n\tat org.apache.cassandra.db.ColumnSerializer.deserializeColumnBody(ColumnSerializer.java:101)\n\tat org.apache.cassandra.db.OnDiskAtom$Serializer.deserializeFromSSTable(OnDiskAtom.java:92)\n\tat org.apache.cassandra.db.ColumnFamilySerializer.deserializeColumnsFromSSTable(ColumnFamilySerializer.java:149)\n\tat org.apache.cassandra.io.sstable.SSTableIdentityIterator.getColumnFamilyWithColumns(SSTableIdentityIterator.java:235)\n\tat org.apache.cassandra.db.compaction.PrecompactedRow.merge(PrecompactedRow.java:109)\n\tat org.apache.cassandra.db.compaction.PrecompactedRow.<init>(PrecompactedRow.java:93)\n\tat org.apache.cassandra.db.compaction.CompactionController.getCompactedRow(CompactionController.java:162)\n\tat org.apache.cassandra.db.compaction.CompactionIterable$Reducer.getReduced(CompactionIterable.java:76)\n\tat org.apache.cassandra.db.compaction.CompactionIterable$Reducer.getReduced(CompactionIterable.java:57)\n\tat org.apache.cassandra.utils.MergeIterator$ManyToOne.consume(MergeIterator.java:114)\n\tat org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:97)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n\tat org.apache.cassandra.db.compaction.CompactionTask.runWith(CompactionTask.java:158)\n\tat org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:48)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n\tat org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:71)\n\tat org.apache.cassandra.db.compaction.CompactionManager$6.runMayThrow(CompactionManager.java:342)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\n\n---\n\nI've invoked the `nodetool compact` three times; this occurred after each. The node has been up for a couple days accepting writes and has not been restarted.\n\nHere's the server's log since it was started a few days ago: https://gist.github.com/cscotta/4956472/raw/95e7cbc68de1aefaeca11812cbb98d5d46f534e8/cassandra.log\n\nHere's the code being used to issue writes to the datastore: https://gist.github.com/cscotta/20cbd36c2503c71d06e9\n\n---\n\nConfiguration: One node, one keyspace, one column family. ~60 writes/second of data with a TTL of 86400, zero reads. Stock cassandra.yaml.\n\nKeyspace DDL:\n\ncreate keyspace jetpack;\nuse jetpack;\ncreate column family Metrics with key_validation_class = 'UTF8Type' and comparator = 'IntegerType';",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "\"Memory was freed\" AssertionError During Major Compaction"
   },
   {
      "_id": "12632213",
      "assignee": "krummas",
      "components": [],
      "created": "2013-02-13 14:38:25",
      "description": "See https://issues.apache.org/jira/browse/CASSANDRA-5222?focusedCommentId=13577420&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13577420",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve LeveledScanner work estimation"
   },
   {
      "_id": "12632211",
      "assignee": "jbellis",
      "components": [],
      "created": "2013-02-13 14:30:30",
      "description": "See https://issues.apache.org/jira/browse/CASSANDRA-5222?focusedCommentId=13577420&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13577420",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Avoid allocateding SSTableBoundedScanner when the range does not intersect the sstable"
   },
   {
      "_id": "12631388",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-02-08 06:18:02",
      "description": "Add cqlsh help for CREATE USER/DROP USER/GRANT/REVOKE etc.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add cqlsh help for auth statements"
   },
   {
      "_id": "12631371",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2013-02-08 01:43:51",
      "description": "Add cqlsh username autocompletion to grant/revoke/list/drop/alter queries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add username autocompletion to cqlsh"
   },
   {
      "_id": "12626258",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2013-01-06 20:29:08",
      "description": "Add an option to EncryptionOptions to require client certication authentication.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add support for SSL sockets to use client certificate authentication."
   },
   {
      "_id": "12625118",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-12-22 18:38:34",
      "description": "Upgraded 1.1.6 to 1.1.8.\n\nNow I'm trying to do a major compaction, and seeing this:\n\nERROR [CompactionExecutor:129] 2012-12-22 10:33:44,217 AbstractCassandraDaemon.java (line 135) Exception in thread Thread[CompactionExecutor:129,1,RMI Runtime]\njava.io.IOError: java.io.IOException: Bad file descriptor\n        at org.apache.cassandra.utils.MergeIterator.close(MergeIterator.java:65)\n        at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:195)\n        at org.apache.cassandra.db.compaction.CompactionManager$7.runMayThrow(CompactionManager.java:298)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:619)\nCaused by: java.io.IOException: Bad file descriptor\n        at sun.nio.ch.FileDispatcher.preClose0(Native Method)\n        at sun.nio.ch.FileDispatcher.preClose(FileDispatcher.java:59)\n        at sun.nio.ch.FileChannelImpl.implCloseChannel(FileChannelImpl.java:96)\n        at java.nio.channels.spi.AbstractInterruptibleChannel.close(AbstractInterruptibleChannel.java:97)\n        at java.io.FileInputStream.close(FileInputStream.java:258)\n        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.close(CompressedRandomAccessReader.java:131)\n        at sun.nio.ch.FileChannelImpl.implCloseChannel(FileChannelImpl.java:121)\n        at java.nio.channels.spi.AbstractInterruptibleChannel.close(AbstractInterruptibleChannel.java:97)\n        at java.io.RandomAccessFile.close(RandomAccessFile.java:541)\n        at org.apache.cassandra.io.util.RandomAccessReader.close(RandomAccessReader.java:224)\n        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.close(CompressedRandomAccessReader.java:130)\n        at org.apache.cassandra.io.sstable.SSTableScanner.close(SSTableScanner.java:89)\n        at org.apache.cassandra.utils.MergeIterator.close(MergeIterator.java:61)\n        ... 9 more\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Major compaction IOException in 1.1.8"
   },
   {
      "_id": "12624114",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-12-15 13:24:37",
      "description": "In SimpleAuthorizer around line 47 we have,\n\nEnumSet<Permission> authorized = EnumSet.copyOf(Permission.NONE);\n\nThis results in an IllegalArgumentException since Permission.NONE is an empty set. I think it should be changed to,\n\nEnumSet<Permission> authorized = EnumSet.noneOf(Permission.class);\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "authentication"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Bug in creating EnumSet in SimpleAuthorizer example"
   },
   {
      "_id": "12623764",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334957",
            "id": "12334957",
            "name": "Feature/Lightweight Transactions"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-12-13 15:24:45",
      "description": "\"Strong\" consistency is not enough to prevent race conditions.  The classic example is user account creation: we want to ensure usernames are unique, so we only want to signal account creation success if nobody else has created the account yet.  But naive read-then-write allows clients to race and both think they have a green light to create.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "LWT"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Support CAS"
   },
   {
      "_id": "12618265",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-11-30 02:55:08",
      "description": "Averages just aren't always enough and it should be easy to wire our existing histogram utils into stress.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "stress"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add a latency histogram option to stress"
   },
   {
      "_id": "12616849",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-11-19 22:30:23",
      "description": "Thousands of the following errors are getting logged to system.log:\n\nERROR [ReadRepairStage:150152] 2012-11-15 12:31:02,815 AbstractCassandraDaemon.java (line 135) Exception in thread Thread[ReadRepairStage:150152,5,main]\njava.lang.AssertionError: Wrong class type.\n        at org.apache.cassandra.db.CounterColumn.diff(CounterColumn.java:110)\n        at org.apache.cassandra.db.ColumnFamily.diff(ColumnFamily.java:248)\n        at org.apache.cassandra.db.ColumnFamily.diff(ColumnFamily.java:342)\n        at org.apache.cassandra.service.RowRepairResolver.scheduleRepairs(RowRepairResolver.java:117)\n        at org.apache.cassandra.service.RowRepairResolver.resolve(RowRepairResolver.java:94)\n        at org.apache.cassandra.service.AsyncRepairCallback$1.runMayThrow(AsyncRepairCallback.java:54)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)\n\nThere are also many of the following errors intermingled with the above:\n\nERROR [ReadRepairStage:150158] 2012-11-15 12:30:34,148 CounterContext.java (line 381) invalid counter shard detected; (b29a5480-e911-11e1-0000-ce481d6d2aff, 3, 916) and (b29a5480-e911-11e1-0000-ce481d6d2aff, 3, -1590) differ only in count; will pick highest to self-heal; this indicates a bug or corruption generated a bad counter shard\n\nI am not 100% sure whether they are related.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "\"AssertionError: Wrong class type\" at CounterColumn.diff()"
   },
   {
      "_id": "12615825",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-11-13 00:52:09",
      "description": "There are times when I'd like to get feedback about when compactions complete.  For example, if I'm deleting data from cassandra and want to know when it is 100% removed from cassandra (tombstones collected and all).  This is completely trivial to implement based on the existing code (the method called by the non-blocking version returns a future, so you could just wait on that, potentially with a timeout).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lhf"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add blocking force compaction (and anything else) calls to NodeProbe"
   },
   {
      "_id": "12615023",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-11-06 21:00:01",
      "description": "Following the changes from CASSANDRA-4377 data created using CQL 3 is not visible via the thrift interface. \n\nThis goes against the spirit of many comments by the project that \"the thrift API is not going away\". These statements and ones such as \"Internally, both CQL3 and thrift use the same storage engine, so all future improvements to this engine will impact both of them equally.\" (http://www.datastax.com/dev/blog/thrift-to-cql3) and the CQL3 and thrift examples given here http://www.datastax.com/dev/blog/cql3-for-cassandra-experts gave the impression CQL 3 was a layer on top of the core storage engine. It now appears to be an incompatible format change. \n\nIt makes it impossible to explain to existing using users how CQL 3 stores it's data. \n\nIt also creates an all or nothing approach to trying CQL 3. \n\nMy request is to make all data written by CQL 3 readable via the thrift API. \n\nAn example of using the current 1.2 trunk is below:\n\n{noformat}\ncqlsh:cass_college> CREATE TABLE UserTweets \n                ... (\n                ...     tweet_id    bigint,\n                ...     user_name   text,\n                ...     body        text,\n                ...     timestamp   timestamp,\n                ...     PRIMARY KEY (user_name, tweet_id)\n                ... );\ncqlsh:cass_college> INSERT INTO \n                ...     UserTweets\n                ...     (tweet_id, body, user_name, timestamp)\n                ... VALUES\n                ...     (1, 'The Tweet', 'fred', 1352150816917);\ncqlsh:cass_college> \ncqlsh:cass_college> \ncqlsh:cass_college> select * from UserTweets;\n\n user_name | tweet_id | body      | timestamp\n-----------+----------+-----------+--------------------------\n      fred |        1 | The Tweet | 2012-11-06 10:26:56+1300\n{noformat}\n\nand in the CLI\n\n{noformat}\n[default@cass_college] show schema;\ncreate keyspace cass_college\n  with placement_strategy = 'SimpleStrategy'\n  and strategy_options = {replication_factor : 3}\n  and durable_writes = true;\n\nuse cass_college;\n\n\n\n[default@cass_college] list UserTweets;\nUserTweets not found in current keyspace.\n[default@cass_college] \n{noformat}\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cli",
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Make CQL 3 data accessible via thrift."
   },
   {
      "_id": "12615018",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-11-06 20:07:13",
      "description": "The cqlsh COPY FROM command requires the primary key to be in the first column of the CSV, even if the field list shows that the primary key is in a different position.\n\nTest data available from ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/cbp01us.txt\n\nCREATE TABLE cbp01us ( \n           naics text PRIMARY KEY \n           ) WITH \n           comment='' AND \n           comparator=text AND \n           read_repair_chance=0.100000 AND \n           gc_grace_seconds=864000 AND \n           default_validation=text AND \n           min_compaction_threshold=4 AND \n           max_compaction_threshold=32 AND \n           replicate_on_write='true' AND \n           compaction_strategy_class='SizeTieredCompactionStrategy' AND \n           compression_parameters:sstable_compression='SnappyCompressor';\n\ncopy cbp01us (uscode,naics,empflag,emp,qp1,ap,est,f1_4,e1_4,q1_4,a1_4,n1_4,f5_9,e5_9,q5_9,a5_9,n5_9,f10_19,e10_19,q10_19,a10_19,n10_19,f20_49,e20_49,q20_49,a20_49,n20_49,f50_99,e50_99,q50_99,a50_99,n50_99,f100_249,e100_249,q100_249,a100_249,n100_249,f250_499,e250_499,q250_499,a250_499,n250_499,f500_999,e500_999,q500_999,a500_999,n500_999,f1000,e1000,q1000,a1000,n1000) from 'cbp01us.txt' with header=true;\nBad Request: Expected key 'NAICS' to be present in WHERE clause for 'cbp01us'\nAborting import at record #0 (line 1). Previously-inserted values still present.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh COPY FROM command requires primary key in first column of CSV"
   },
   {
      "_id": "12614519",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-11-02 14:56:14",
      "description": "I've been working on an implementation for both IAuthority2 and IAuthenticator that uses Cassandra itself to store the necessary credentials. I'm planning on open sourcing this shortly.\n\nIs there any interest in this? It tries to provide reasonable security, for example using PBKDF2 to store passwords with a configurable configuration cycle and managing all the rights available in IAuthority2. \n\nMy main use goal isn't security / confidentiality of the data, but more that I don't want multiple consumers of the cluster to accidentally screw stuff up. Only certain users can write data, others can read it out again and further process it.\n\nI'm planning on releasing this soon under an open source license (probably the same as Cassandra itself). Would there be interest in incorporating it as a new reference implementation instead of the properties file implementation perhaps? Or can I better maintain it separately? I would love if people from the community would want to review it, since I have been dabbling in the Cassandra source code only for a short while now.\n\nDuring the development of this I've encountered a few bumps and I wonder whether they could be addressed or not.\n\n= Moment when validateConfiguration() runs =\n\nIs there a deliberate reason that validateConfiguration() is executed before all information about keyspaces, column families etc. is available? In the current form I therefore can't validate whether column families etc. are available for authentication since they aren't loaded yet.\n\nI've wanted to use this to make relatively easy bootstrapping possible. My approach here would be to only enable authentication if the needed keyspace is available. This allows for configuring the cluster, then import the necessary authentication data for an admin user to bootstrap further and then restart every node in the cluster.\n\nBasically the questions here are, can the moment when validateConfiguration() runs for an authentication provider be changed? Is this approach to bootstrapping reasonable or do people have better ideas?\n\n= AbstractReplicationStrategy has package visible constructor =\n\nI've added a strategy that basically says that data should be available on all nodes. The amount of data use for authentication is very limited. Replicating it to every node is there for not very problematic and allows for every node to have all data locally available for verifying requests.\n\nI wanted to put this strategy into it's own package inside the authentication module, but since the constructor of AbstractReplicationStrategy has no visibility explicitly marked, it's only available inside the same package.\n\nI'm not sure whether implementing a strategy to replicate data to all nodes is a sane idea and whether my implementation of this strategy is correct. What do you people think of this? Would people want to review the implementation?\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "authentication",
         "authorization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Authentication provider in Cassandra itself"
   },
   {
      "_id": "12613989",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-10-30 04:05:37",
      "description": "CASSANDRA-4874 is about general improvements to authorization handling, this one is about IAuthority[2] in particular.\n\n- 'LIST GRANTS OF user should' become 'LIST PERMISSIONS [on resource] [of user]'.\nCurrently there is no way to see all the permissions on the resource, only all the permissions of a particular user.\n- IAuthority2.listPermissions() should return a generic collection of ResoucePermission or something, not CQLResult or ResultMessage.\nThat's a wrong level of abstraction. I know this issue has been raised here - https://issues.apache.org/jira/browse/CASSANDRA-4490?focusedCommentId=13449732&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13449732com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13449732, but I think it's possible to change this. Returning a list of {resource, user, permission, grant_option} tuples should be possible.\n- We should get rid of Permission.NO_ACCESS. An empty list of permissions should mean absence of any permission, not some magical Permission.NO_ACCESS value.\nIt's insecure and error-prone and also ambiguous (what if a user has both FULL_ACCESS and NO_ACCESS permissions? If it's meant to be a way to strip a user\nof all permissions on the resource, then it should be replaced with some form of REVOKE statement. Something like 'REVOKE ALL PERMISSIONS' sounds more logical than GRANT NO_ACCESS to me.\n- Previous point will probably require adding revokeAllPermissions() method to make it explicit, special-casing IAuthority2.revoke() won't do\n- IAuthorize2.grant() and IAuthorize2.revoke() accept CFName instance for a resource, which has its ks and cf fields swapped if cf is omitted. This may cause a real security issue if IAuthorize2 implementer doesn't know about the issue. We must pass the resouce as a collection of strings ([cassandra, keyspaces[, ks_name][, cf_name]]) instead, the way we pass it to IAuthorize.authorize().\n- We should probably get rid of FULL_ACCESS as well, at least as a valid permission value (but maybe allow it in the CQL statement) and add an equivalent IAuthority2.grantAllPermissions(), separately. Why? Imagine the following sequence: GRANT FULL_ACCESS ON resource FOR user; REVOKE SELECT ON resource FROM user; should the user be allowed to SELECT anymore?\nI say no, he shouldn't. Full access should be represented by a list of all permissions, not by a magical special value.\n- P.DELETE probably should go in favour of P.UPDATE even for TRUNCATE. Presence of P.DELETE will definitely confuse users, who might think that it is somehow required to delete data, when it isn't. You can overwrite every value if you have P.UPDATE with TTL=1 and get the same result. We should also drop P.INSERT. Leave P.UPDATE (or rename it to P.MODIFY). P.MODIFY_DATA + P.READ_DATA should replace P.UPDATE, P.SELECT and P.DELETE.\n- I suggest new syntax to allow setting permissions on cassandra/keyspaces resource: GRANT <permission> ON * FOR <user>.\n\nThe interface has to change because of the CFName argument to grant() and revoke(), and since it's going to be broken anyway (and has been introduced recently), I think we are in a position to make some other improvements while at it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Revert IAuthority2 interface"
   },
   {
      "_id": "12613986",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-10-30 03:46:56",
      "description": "I'll create another issue with my suggestions about fixing/improving IAuthority interfaces. This one lists possible improvements that aren't related to grant/revoke methods.\n\nInconsistencies:\n- CREATE COLUMNFAMILY: P.CREATE on the KS in CQL2 vs. P.CREATE on the CF in CQL3 and Thrift\n- BATCH: P.UPDATE or P.DELETE on CF in CQL2 vs. P.UPDATE in CQL3 and Thrift (despite remove* in Thrift asking for P.DELETE)\n- DELETE: P.DELETE in CQL2 and Thrift vs. P.UPDATE in CQL3\n- DROP INDEX: no checks in CQL2 vs. P.ALTER on the CF in CQL3\n\nOther issues/suggestions\n- CQL2 DROP INDEX should require authorization\n- current permission checks are inconsistent since they are performed separately by CQL2 query processor, Thrift CassandraServer and CQL3 statement classes.\nWe should move it to one place. SomeClassWithABetterName.authorize(Operation, KS, CF, User), where operation would be a enum\n(ALTER_KEYSPACE, ALTER_TABLE, CREATE_TABLE, CREATE, USE, UPDATE etc.), CF should be nullable.\n- we don't respect the hierarchy when checking for permissions, or, to be more specific, we are doing it wrong. take  CQL3 INSERT as an example:\nwe require P.UPDATE on the CF or FULL_ACCESS on either KS or CF. However, having P.UPDATE on the KS won't allow you to perform the statement, only FULL_ACCESS will do.\nI doubt this was intentional, and if it was, I say it's wrong. P.UPDATE on the KS should allow you to do updates on KS's cfs.\nExamples in http://www.datastax.com/dev/blog/dynamic-permission-allocation-in-cassandra-1-1 point to it being a bug, since REVOKE UPDATE ON ks FROM omega is there.\n- currently we lack a way to set permission on cassandra/keyspaces resource. I think we should be able to do it. See the following point on why.\n- currently to create a keyspace you must have a P.CREATE permission on that keyspace THAT DOESN'T EVEN EXIST YET. So only a superuser can create a keyspace,\nor a superuser must first grant you a permission to create it. Which doesn't look right to me. P.CREATE on cassandra/keyspaces should allow you to create new\nkeyspaces without an explicit permission for each of them.\n- same goes for CREATE TABLE. you need P.CREATE on that not-yet-existing CF of FULL_ACCESS on the whole KS. P.CREATE on the KS won't do. this is wrong.\n- since permissions don't map directly to statements, we should describe clearly in the documentation what permissions are required by what cql statement/thrift method.\n\nFull list of current permission requirements: https://gist.github.com/3978182\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Possible authorizaton handling impovements"
   },
   {
      "_id": "12613911",
      "assignee": "krummas",
      "components": [],
      "created": "2012-10-29 15:56:49",
      "description": "Now that we have a metadata component it would be better to keep sstable level there, than in a separate manifest.  With information per-sstable we don't need to do a full re-level if there is corruption.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Move manifest into sstable metadata"
   },
   {
      "_id": "12613503",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-10-25 15:12:27",
      "description": "{noformat}\ncqlsh> describe table system_traces.sessions;\n\nUnconfigured column family 'sessions'\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh can't describe system tables"
   },
   {
      "_id": "12612999",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-10-22 17:10:02",
      "description": "BulkLoader in trunk throws below exception at start up and exit abnormally.\n\n{code}\nException in thread \"main\" java.lang.ExceptionInInitializerError\n\tat org.apache.cassandra.io.sstable.SSTableReader.<init>(SSTableReader.java:87)\n\tat org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:180)\n\tat org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:148)\n\tat org.apache.cassandra.io.sstable.SSTableLoader$1.accept(SSTableLoader.java:96)\n\tat java.io.File.list(File.java:1010)\n\tat org.apache.cassandra.io.sstable.SSTableLoader.openSSTables(SSTableLoader.java:67)\n\tat org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:117)\n\tat org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:63)\nCaused by: java.lang.NullPointerException\n\tat org.apache.cassandra.service.CacheService.initRowCache(CacheService.java:154)\n\tat org.apache.cassandra.service.CacheService.<init>(CacheService.java:102)\n\tat org.apache.cassandra.service.CacheService.<clinit>(CacheService.java:83)\n\t... 8 more\n{code}\n\nThis comes from CASSANDRA-4732, which moved keyCache in SSTableReader initialization at instance creation. This causes access to CacheService that did not happen for v1.1 and ends up NPE because BulkLoader does not load cassandra.yaml.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "bulkloader"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "BulkLoader throws NPE at start up"
   },
   {
      "_id": "12612328",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-10-17 22:22:47",
      "description": "CASSANDRA-4734 moved consistency level to the protocol, so cqlsh needs a way to change consistency level from the default (ONE).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Make consistency level configurable in cqlsh"
   },
   {
      "_id": "12612325",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-10-17 21:55:57",
      "description": "created CF with cli:\n\n{noformat}\ncreate column family playlists\nwith key_validation_class = UUIDType\n and comparator = 'CompositeType(UTF8Type, UTF8Type, UTF8Type)'\n and default_validation_class = UUIDType;\n{noformat}\n\nThen get this error with cqlsh:\n\n{noformat}\ncqlsh:music> describe table playlists;\n\n/Users/jonathan/projects/cassandra/git-trunk/bin/../pylib/cqlshlib/cql3handling.py:771: UnexpectedTableStructure: Unexpected table structure; may not translate correctly to CQL. expected composite key CF to have column aliases, but found none\n/Users/jonathan/projects/cassandra/git-trunk/bin/../pylib/cqlshlib/cql3handling.py:794: UnexpectedTableStructure: Unexpected table structure; may not translate correctly to CQL. expected [u'KEY'] length to be 3, but it's 1. comparator='org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type)'\nCREATE TABLE playlists (\n  \"KEY\" uuid PRIMARY KEY\n)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh --cql3 unable to describe CF created with cli"
   },
   {
      "_id": "12611952",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-10-16 02:37:38",
      "description": "cqlsh> help select\nImproper help command.\n\nSame will happen if you look up a help topic for any other cql statement.\n38748b43d8de17375c7cc16e7a4969ca4c1a2aa1 broke it (#4198) 5 months ago.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Some cqlsh help topics don't work (select, create, insert and anything else that is a cql statement)"
   },
   {
      "_id": "12611640",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-10-12 21:37:20",
      "description": "{noformat}\ncreate keyspace foo with replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};\nuse foo;\ncreate table one (id int primary key, c int);\nTRACING ON;\ninsert into one (id, c) values (1, 2);\n\nvalue '\\x7f\\x00\\x00\\x01' (in col 'source') can't be deserialized as inet: 'module' object has no attribute 'inet_ntop'\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "inet datatype does not work with cqlsh on windows"
   },
   {
      "_id": "12611627",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-10-12 20:24:35",
      "description": "For example, new syntax for CREATE KEYSPACE is\n\ncreate keyspace foo with replication = {'class': 'SimpleStrategy', 'replication_factor': 1}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh help is obsolete for cql3"
   },
   {
      "_id": "12610898",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-10-08 22:40:28",
      "description": "We have this code in the candidate loop:\n\n{code}\n.               if (SSTable.getTotalBytes(candidates) > maxSSTableSizeInBytes)\n                {\n                    // add sstables from L1 that overlap candidates\n                    candidates.addAll(overlapping(candidates, generations[1]));\n                    break;\n                }\n{code}\n\nthus, as soon as we have enough to compact to make one L1 sstable's worth of data, we stop collecting candidates.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "leveled compaction does less work in L0 than intended"
   },
   {
      "_id": "12610780",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-10-08 01:20:26",
      "description": "The docs at http://cassandra.apache.org/doc/cql3/CQL.html#identifiers describe using double quotes for an identifier that is a reserved word. The following works as expected,\n\ncqlsh:test> select \"columnfamily\" from system.schema_columnfamilies;\n\nI have a table with a boolean column. In order to insert a boolean value, I have to enclose it in single quotes. The table looks like,\n\nCREATE TABLE bool_test (\n  id int PRIMARY KEY,\n  val boolean\n);\n\nHere is what happens when I try using double quotes,\n\ncqlsh:rhq> insert into bool_test (id, val) values (4, \"false\");\nBad Request: line 1:43 no viable alternative at input 'false'\n\n\nThe use of single quotes here seems inconsistent with what is described in the docs, and makes things a bit confusing. It would be nice if single or double quotes could be used for identifiers that are reserved words. I also think it is a bit counter-intuitive to require quotes for true and false which are literal values.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't require quotes for true and false"
   },
   {
      "_id": "12610765",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-10-07 19:38:57",
      "description": "The existing partitioned counters remain a source of frustration for most users almost two years after being introduced.  The remaining problems are inherent in the design, not something that can be fixed given enough time/eyeballs.\n\nIdeally a solution would give us\n- similar performance\n- less special cases in the code\n- potential for a retry mechanism\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Counters 2.0"
   },
   {
      "_id": "12610588",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-10-05 15:56:15",
      "description": "Seems that we accept {{int}} but we don't accept {{INT}} (that is, the parser accepts it, but we fail later to recognize it).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "(CQL3) data type not in lowercase are not handled correctly."
   },
   {
      "_id": "12610368",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-10-04 18:17:14",
      "description": "Seeing the following error:\n\n\nException in thread Thread[CompactionExecutor:21,1,RMI Runtime]\njava.lang.StackOverflowError\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n        at com.google.common.collect.Sets$1.iterator(Sets.java:578)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "StackOverflowError in CompactionExecutor thread"
   },
   {
      "_id": "12610366",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-10-04 17:46:27",
      "description": "Currently it appears as though bulk loading operations don't run in any stage. Seems like they should be running in STREAM_STAGE.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "streaming"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Clean out STREAM_STAGE vestiges"
   },
   {
      "_id": "12610142",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-10-03 21:23:54",
      "description": "Looks like a predicate logic bug that only happens when you have > 2 primary keys and use COMPACT STORAGE (meaning its using composite columns under the hood)\n\nFirst I'll show it works with just 2 \n{code}\ncqlsh:dev> CREATE TABLE testrev (\n       ...          key text,\n       ...          rdate timestamp,\n       ...          num double,\n       ...          PRIMARY KEY(key,rdate)\n       ...          ) WITH COMPACT STORAGE\n       ...            AND CLUSTERING ORDER BY(rdate DESC);\n\ncqlsh:dev> INSERT INTO testrev(key,rdate,num) VALUES ('foo','2012-01-01',10.5);\ncqlsh:dev> select * from testrev where key='foo' and rdate > '2012-01-01';\ncqlsh:dev> select * from testrev where key='foo' and rdate >= '2012-01-01';\n key | rdate                    | num\n-----+--------------------------+------\n foo | 2012-01-01 00:00:00-0500 | 10.5\n{code}\n\nNow we create with 3 parts to the PRIMARY KEY\n{code}\ncqlsh:dev> drop TABLE testrev ;\ncqlsh:dev> CREATE TABLE testrev (\n       ...          key text,\n       ...          rdate timestamp,\n       ...          rdate2 timestamp,\n       ...          num double,\n       ...          PRIMARY KEY(key,rdate,rdate2)\n       ...          ) WITH COMPACT STORAGE\n       ...          AND CLUSTERING ORDER BY(rdate DESC);\n\ncqlsh:dev> INSERT INTO testrev(key,rdate,rdate2,num) VALUES ('foo','2012-01-01','2012-01-01',10.5);\ncqlsh:dev> select * from testrev where key='foo' and rdate > '2012-01-01';\n key | rdate                    | rdate2                   | num\n-----+--------------------------+--------------------------+------\n foo | 2012-01-01 00:00:00-0500 | 2012-01-01 00:00:00-0500 | 10.5\n\ncqlsh:dev> select * from testrev where key='foo' and rdate >= '2012-01-01';\n{code}\n\nThe last query should return the row...\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3 Predicate logic bug when using composite columns"
   },
   {
      "_id": "12609853",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-10-02 02:09:37",
      "description": "cqlsh> create keyspace test with strategy_class = 'SimpleStrategy' AND strategy_options:replication_factor = 1;\ncqlsh> use test;\ncqlsh:test> create table ts (id int primary key, ts timestamp);\ncqlsh:test> insert into ts (id, ts) values (1, '2012-05-14 07:53:20+0000');\ncqlsh:test> select * from ts;\n id | ts\n----+--------------------------\n  1 | 2012-05-14 10:53:20+0000\n\n\nShould've been 2012-05-14 10:53:20+0300.\n\ncqlsh formats timestamps using '%Y-%m-%d %H:%M:%S%z' format-string and 'the %z escape that expands to the preferred hour/minute offset is not supported by all ANSI C libraries'. In this case it's just replaced with all zeroes.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh timestamp formatting is broken - displays wrong timezone info (at least on Ubuntu)"
   },
   {
      "_id": "12609728",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-10-01 09:22:17",
      "description": "CASSANDRA-4449 seems to have changed the datatype of the query id returned by a RESULT-PREPARED message from an {{int}} to a {{short}} n followed by n bytes (representing a md5sum). The specification at doc/native_protocol.txt doesn't cover this change yet.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "binary_protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "doc/native_protocol.txt isn't up to date"
   },
   {
      "_id": "12609428",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-09-27 18:04:07",
      "description": "cassandra.yaml comments incorrectly imply that Cassandra can listen for unframed thrift connections by setting the frame size to zero.  But DatabaseDescriptor has this check since 0.8:\n\n{code}\n.           if (conf.thrift_framed_transport_size_in_mb <= 0)\n                throw new ConfigurationException(\"thrift_framed_transport_size_in_mb must be positive\");\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "thrift"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "remove vestiges of Thrift unframed mode"
   },
   {
      "_id": "12609349",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-09-27 05:11:01",
      "description": "The following errors are showing under height load\n\nERROR [MutationStage:8294] 2012-09-25 22:01:47,628 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[MutationStage:8294,5,main]\njava.lang.NullPointerException\n\tat org.apache.cassandra.locator.PropertyFileSnitch.getDatacenter(PropertyFileSnitch.java:104)\n\tat com.datastax.bdp.snitch.DseDelegateSnitch.getDatacenter(DseDelegateSnitch.java:69)\n\tat org.apache.cassandra.locator.DynamicEndpointSnitch.getDatacenter(DynamicEndpointSnitch.java:122)\n\tat org.apache.cassandra.locator.NetworkTopologyStrategy.calculateNaturalEndpoints(NetworkTopologyStrategy.java:93)\n\tat org.apache.cassandra.locator.AbstractReplicationStrategy.getNaturalEndpoints(AbstractReplicationStrategy.java:100)\n\tat org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1984)\n\tat org.apache.cassandra.service.StorageService.getNaturalEndpoints(StorageService.java:1972)\n\tat org.apache.cassandra.service.StorageProxy.getWriteEndpoints(StorageProxy.java:262)\n\tat org.apache.cassandra.service.StorageProxy.performWrite(StorageProxy.java:248)\n\tat org.apache.cassandra.service.StorageProxy.applyCounterMutationOnLeader(StorageProxy.java:505)\n\tat org.apache.cassandra.db.CounterMutationVerbHandler.doVerb(CounterMutationVerbHandler.java:56)\n\tat org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:59)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat java.lang.Thread.run(Unknown Source)\n\n\nERROR [MutationStage:13164] 2012-09-25 22:19:06,486 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[MutationStage:13164,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:13170] 2012-09-25 22:19:07,349 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[MutationStage:13170,5,main]\njava.lang.NullPointerException\nERROR [MutationStage:13170] 2012-09-25 22:19:07,349 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[MutationStage:13170,5,main]\njava.lang.NullPointerException\nERROR [Thrift:12] 2012-09-25 22:19:07,433 Cassandra.java (line 3462) Internal error processing batch_mutate\njava.lang.NullPointerException\nERROR [Thrift:16] 2012-09-25 22:19:07,437 Cassandra.java (line 2999) Internal error processing get\n\n\njava.lang.NullPointerException\n INFO [GossipStage:280] 2012-09-26 00:15:15,371 Gossiper.java (line 818) InetAddress /172.16.233.208 is now dead.\nERROR [GossipStage:280] 2012-09-26 00:15:15,372 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[GossipStage:280,5,main]\nj\n\nERROR [MutationStage:40529] 2012-09-26 00:15:21,527 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[MutationStage:40529,5,main]\njava.lang.NullPointerException\n INFO [GossipStage:281] 2012-09-26 00:15:23,013 Gossiper.java (line 818) InetAddress /172.16.232.159 is now dead.\nERROR [GossipStage:281] 2012-09-26 00:15:23,014 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[GossipStage:281,5,main]\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "snitch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "NPE with some load of writes, but possible snitch setting issue for a cluster"
   },
   {
      "_id": "12609115",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-09-25 20:25:32",
      "description": "I tried sending a REGISTER message with an eventlist including the string \"STATUS_FOO\", in order to test error handling in the python driver for that eventuality. But the response from the server (a \"Server error\" with a message of \"java.lang.IllegalArgumentException: No enum const class org.apache.cassandra.transport.Event$Type.STATUS_FOO\") had a stream_id of 0, so the driver was not able to associate it with the request.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "binary_protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "binary protocol: when an invalid event type is watched via a REGISTER message, the response message does not have an associated stream id"
   },
   {
      "_id": "12609084",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-09-25 16:54:36",
      "description": "See the test case for CASSANDRA-4715, but run it on trunk. The ReversedType-wrapped column (rdate) will be displayed as a floating-point integer (it gets deserialized into a native type correctly, but cqlsh's format-according-to-type machinery doesn't know how to handle the cqltypes.ReversedType subclass.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh fails to format values of ReversedType-wrapped classes"
   },
   {
      "_id": "12608475",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-09-20 14:22:55",
      "description": "Currently the only way to insert multiple records on the same partition key, atomically and using PreparedStatements is to use a CQL BATCH command. Unfortunately when doing so the amount of records to be inserted must be known prior to prepare the statement which is rarely the case. Thus the only workaround if one want to keep atomicity is currently to use unprepared statements which send a bulk of CQL strings and is fairly inefficient.\n\nTherefore CQL Protocol should allow clients to send multiple PreparedStatements to be executed with similar guarantees and semantic as CQL BATCH command.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql",
         "protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL Protocol should allow multiple PreparedStatements to be atomically executed"
   },
   {
      "_id": "12608129",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-09-18 20:50:29",
      "description": "When profiling high volume inserts into Cassandra running on a host with fast SSD and CPU, Thread.yield() invoked by SlabAllocator appeared as the top item in CPU samples. The fix is to return a regular byte buffer if current slab is being initialized by another thread. So instead of:\n\n\n               if (oldOffset == UNINITIALIZED)\n                {\n                    // The region doesn't have its data allocated yet.\n                    // Since we found this in currentRegion, we know that whoever\n                    // CAS-ed it there is allocating it right now. So spin-loop\n                    // shouldn't spin long!\n                    Thread.yield();\n                    continue;\n                }\n\ndo:\n\nif (oldOffset == UNINITIALIZED)\n    return ByteBuffer.allocate(size);\n\nI achieved 4x speed up in my (admittedly specialized) benchmark by using an optimized version of SlabAllocator attached. Since this code is in the critical path, even doing excessive atomic instructions or allocating unneeded extra ByteBuffer instances has a measurable effect on performance\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance",
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "SlabAllocator spends a lot of time in Thread.yield"
   },
   {
      "_id": "12607992",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-09-18 01:06:51",
      "description": "cqlsh COPY TO and COPY FROM don't work with cql3 due to previous cql3 changes.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh COPY TO and COPY FROM don't work with cql3"
   },
   {
      "_id": "12607257",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-09-12 15:10:15",
      "description": "If clients connect to a cassandra cluster configured with rpc_server_type: sync with heterogeneous cql versions (2 and 3), the cql version used for execution on the server changes seemingly randomly.\nIt's due to the fact that CustomTThreadPoolServer.java does not set the remoteSocket anytime, or does not clear the cql version in the ThreadLocal clientState object.\nWhen CassandraServer.java calls state() it gets the ThreadLocal object clientState, which has its cqlversion already changed by a previous socket that was using the same thread.\n\n\nThe easiest fix is probably to do a SocketSessionManagementService.instance.set when accepting a new client and SocketSessionManagementService.instance.remove when the client is closed, but if you really want to use the ThreadLocal clientState and not alloc/destroy a ClientState everytime, then you should clear this clientState on accept of a new client.\n\nThe problem can be reproduced with cqlsh -3 on one side and a client that does not set the cql version, expecting to get version 2 by default, but actually gettingv v2/v3 depending on which thread it connects to.\n\nThe problem does not happen with other rpc_server_types, nor with clients that set their cql version at connection.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "features"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cql version race condition with rpc_server_type: sync"
   },
   {
      "_id": "12607241",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-09-12 13:48:11",
      "description": "Steps to reproduce:\n1. Start writing of data to some column family, let name it 'MyCF'\n2. Stop 1 node\n3. Wait some time (until some data will be collected in HintsColumnFamily)\n4. Start node (HintedHandoff will be started automatically for 'MyCF')\n5. Run 'truncate' command for 'MyCF' column family from command from cli\n6. Wait until truncate will be finished\n7. You will see that 'MyCF' is not empty because HintedHandoff is copying data \n\nSo, I suggest to clean HintsColumnFamily (for truncated column family) before we had started to discard sstables. \nI think it should be done in CompactionManager#submitTrucate() method. I can try to create patch but I need to know right way of cleaning HintsColumnFamily. Could you clarify it?\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hintedhandoff",
         "truncate"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Truncate operation doesn't delete rows from HintsColumnFamily."
   },
   {
      "_id": "12607145",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-09-11 23:10:17",
      "description": "During Cassandra 1.1's whole lifecycle, the CREATE KEYSPACE syntax was pretty dramatically and incompatibly different from what is there now for 1.2. That's ok, since we explicitly said there could be breaking changes in the syntax before 3.0.0 final, but at least we should make it clear that 3.0.0 is not compatible with the 3.0.0-beta1 syntax we had out for quite a while.\n\nIf we don't want to reject connections asking for 3.0.0-beta1, we should bump the version number to 3.0.1 or something.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Cassandra 1.2 should not accept CQL version \"3.0.0-beta1\""
   },
   {
      "_id": "12607116",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-09-11 19:39:37",
      "description": "I followed the steps for enabling simple authentication as described here, http://www.datastax.com/docs/1.1/configuration/authentication. I tried starting Cassandra with, \n\ncassandra -f -Dpasswd.properties=conf/passwd.properties -Daccess.properties=conf/access.properties\n\nStart up failed with this exception in my log:\n\nERROR [main] 2012-09-11 15:03:04,642 CassandraDaemon.java (line 403) Exception encountered during startup\njava.lang.AssertionError: org.apache.cassandra.exceptions.InvalidRequestException: You have not logged in\n        at org.apache.cassandra.cql3.QueryProcessor.processInternal(QueryProcessor.java:136)\n        at org.apache.cassandra.db.SystemTable.checkHealth(SystemTable.java:298)\n        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:203)\n        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:386)\n        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:429)\nCaused by: org.apache.cassandra.exceptions.InvalidRequestException: You have not logged in\n        at org.apache.cassandra.service.ClientState.validateLogin(ClientState.java:254)\n        at org.apache.cassandra.service.ClientState.hasColumnFamilyAccess(ClientState.java:235)\n        at org.apache.cassandra.cql3.statements.SelectStatement.checkAccess(SelectStatement.java:105)\n        at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:106)\n        at org.apache.cassandra.cql3.QueryProcessor.processInternal(QueryProcessor.java:124)\n        ... 4 more",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Unable to start Cassandra with simple authentication enabled"
   },
   {
      "_id": "12606412",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-09-06 14:51:17",
      "description": "We're not able to do order by on anything that is a key range. However, we only refuse queries that have an empty where clause, but that doesn't exclude all key ranges at all.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "ORDER BY validation is not restrictive enough"
   },
   {
      "_id": "12606102",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-09-04 15:55:30",
      "description": "Somehow we never added an \"ALTER KEYSPACE\" statement. We should.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add AlterKeyspace statement"
   },
   {
      "_id": "12605940",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-09-03 01:48:42",
      "description": "{replication, compression, compaction}_parameters should be stored as Map type.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "use Map internally in schema_ tables where appropriate"
   },
   {
      "_id": "12605495",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-08-30 09:20:55",
      "description": "while running nodetool repair, the following was logged in system.log:\n\n\nERROR [ValidationExecutor:2] 2012-08-30 10:58:19,490 AbstractCassandraDaemon.java (line 134) Exception in thread Thread[ValidationExecutor:2,1,main]\njava.lang.StackOverflowError\n        at sun.nio.cs.UTF_8.updatePositions(UTF_8.java:76)\n        at sun.nio.cs.UTF_8$Encoder.encodeArrayLoop(UTF_8.java:411)\n        at sun.nio.cs.UTF_8$Encoder.encodeLoop(UTF_8.java:466)\n        at java.nio.charset.CharsetEncoder.encode(CharsetEncoder.java:561)\n        at java.lang.StringCoding$StringEncoder.encode(StringCoding.java:258)\n        at java.lang.StringCoding.encode(StringCoding.java:290)\n        at java.lang.String.getBytes(String.java:954)\n        at java.io.RandomAccessFile.open(Native Method)\n        at java.io.RandomAccessFile.<init>(RandomAccessFile.java:233)\n        at org.apache.cassandra.io.util.RandomAccessReader.<init>(RandomAccessReader.java:67)\n        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.<init>(CompressedRandomAccessReader.java:64)\n        at org.apache.cassandra.io.compress.CompressedRandomAccessReader.open(CompressedRandomAccessReader.java:46)\n        at org.apache.cassandra.io.sstable.SSTableReader.openDataReader(SSTableReader.java:1007)\n        at org.apache.cassandra.io.sstable.SSTableScanner.<init>(SSTableScanner.java:56)\n        at org.apache.cassandra.io.sstable.SSTableBoundedScanner.<init>(SSTableBoundedScanner.java:41)\n        at org.apache.cassandra.io.sstable.SSTableReader.getDirectScanner(SSTableReader.java:869)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:247)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:240)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:248)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:240)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:248)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:240)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:248)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:240)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:248)\n.\n\n(about 900 lines deleted)\n.\n\n\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:240)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:248)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy$LeveledScanner.computeNext(LeveledCompactionStrategy.java:202)\n        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:140)\n        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:135)\n        at org.apache.cassandra.utils.MergeIterator$Candidate.advance(MergeIterator.java:147)\n        at org.apache.cassandra.utils.MergeIterator$ManyToOne.<init>(MergeIterator.java:90)\n        at org.apache.cassandra.utils.MergeIterator.get(MergeIterator.java:47)\n        at org.apache.cassandra.db.compaction.CompactionIterable.iterator(CompactionIterable.java:60)\n        at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:703)\n        at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:69)\n        at org.apache.cassandra.db.compaction.CompactionManager$8.call(CompactionManager.java:442)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:636)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "StackOverflowError in LeveledCompactionStrategy$LeveledScanner.computeNext"
   },
   {
      "_id": "12605133",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-08-27 20:51:01",
      "description": "In certain conditions, CQL queries using LIMIT clauses are not being given all of the expected results (whether unset column values or missing rows).\n\nHere are the condition sets I've been able to identify:\n\nFirst mode: all rows are returned, but in the last row of results, all columns which are not part of the primary key receive no values, except for the first non-primary-key column. Conditions:\n\n * Table has a multi-component primary key\n * Table has more than one column which is not a component of the primary key\n * The number of results which would be returned by a query is equal to or more than the specified LIMIT\n\nSecond mode: result has fewer rows than it should, lower than both the LIMIT and the actual number of matching rows. Conditions:\n\n * Table has a single-column primary key\n * Table has more than one column which is not a component of the primary key\n * The number of results which would be returned by a query is equal to or more than the specified LIMIT\n\nIt would make sense to me that this would have started with CASSANDRA-4329, but bisecting indicates that this behavior started with commit 91bdf7fb4220b27e9566c6673bf5dbd14153017c, implementing CASSANDRA-3647.\n\nTest case for the first failure mode:\n\n{noformat}\nDROP KEYSPACE test;\n\nCREATE KEYSPACE test\n    WITH strategy_class = 'SimpleStrategy'\n    AND strategy_options:replication_factor = 1;\n\nUSE test;\n\nCREATE TABLE testcf (\n    a int,\n    b int,\n    c int,\n    d int,\n    e int,\n    PRIMARY KEY (a, b)\n);\n\nINSERT INTO testcf (a, b, c, d, e) VALUES (1, 11, 111, 1111, 11111);\nINSERT INTO testcf (a, b, c, d, e) VALUES (2, 22, 222, 2222, 22222);\nINSERT INTO testcf (a, b, c, d, e) VALUES (3, 33, 333, 3333, 33333);\nINSERT INTO testcf (a, b, c, d, e) VALUES (4, 44, 444, 4444, 44444);\n\nSELECT * FROM testcf;\n\nSELECT * FROM testcf LIMIT 1; -- columns d and e in result row are null\nSELECT * FROM testcf LIMIT 2; -- columns d and e in last result row are null\nSELECT * FROM testcf LIMIT 3; -- columns d and e in last result row are null\nSELECT * FROM testcf LIMIT 4; -- columns d and e in last result row are null\nSELECT * FROM testcf LIMIT 5; -- results are correct (4 rows returned)\n{noformat}\n\nTest case for the second failure mode:\n\n{noformat}\nCREATE KEYSPACE test\n    WITH strategy_class = 'SimpleStrategy'\n    AND strategy_options:replication_factor = 1;\n\nUSE test;\n\nCREATE TABLE testcf (\n    a int primary key,\n    b int,\n    c int,\n);\n\nINSERT INTO testcf (a, b, c) VALUES (1, 11, 111);\nINSERT INTO testcf (a, b, c) VALUES (2, 22, 222);\nINSERT INTO testcf (a, b, c) VALUES (3, 33, 333);\nINSERT INTO testcf (a, b, c) VALUES (4, 44, 444);\n\nSELECT * FROM testcf;\n\nSELECT * FROM testcf LIMIT 1; -- gives 1 row\nSELECT * FROM testcf LIMIT 2; -- gives 1 row\nSELECT * FROM testcf LIMIT 3; -- gives 2 rows\nSELECT * FROM testcf LIMIT 4; -- gives 2 rows\nSELECT * FROM testcf LIMIT 5; -- gives 3 rows\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql",
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL queries using LIMIT sometimes missing results"
   },
   {
      "_id": "12603683",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-08-16 03:16:49",
      "description": "In the mutation response, WriteResponse.java object is send back to the co-ordinator. This object has keyspace and key in it which is not required. It is not being used at the co-ordiantor. \n\nThis wastes IO specially in case of WAN links between DC. Also since response from each node in multi-DC deployments goes back to the co-ordinator in another DC makes it even worse. \n\nIt also becomes worse if the the keyspace and key are of large size and the data is small. In that case, a node which is not the co-ordinator and purely receiving mutations, the outbound n/w bandwidth could be half of incoming bandwidth.  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "network"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Mutation response(WriteResponse.java) could be smaller and not contain keyspace and key"
   },
   {
      "_id": "12603419",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-08-14 09:06:08",
      "description": "In the text of the native_protocol.spec document, it explains the format for a notation called {{[option]}}, which should represent \"{{a pair of <id><value>}}\".\n\nIn doing a first-draft implementation of the protocol for the python driver, though, I found that I had a misunderstanding. I read that section as saying that {{<value>}} was a {{[value]}}, and that it could have a length of 0 (i.e., the {{[int]}} on the front of the {{[value]}} could be 0). However, it turns out that {{<value>}} might not be there at all, or might be *two* {{[value]}}'s, depending on the option id and message context.\n\nI'm not a fan of this, since\n\n * A protocol parsing library can't simply implement a single function to read in {{[option]}}'s, since the length of the value part is dependent on the message context\n * If we add a new native data type (a new option id which could be used inside a {{<col_spec_i>}} in a RESULT message), then older clients will not know how to read past the value part. Of course they won't know how to interpret the data or deserialize later rows of that unknown type - that's not the problem - the problem is that the older client should be able just to mark that column as unparseable and still handle the rest of the columns.\n\nCan we make {{<value>}} be a {{[value]}}, the contents of which can be re-interpreted as a {{[string]}}, an {{[option]}}, two {{[option]}}'s, or whatever?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql",
         "native_protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "potential backwards incompatibility in native protocol"
   },
   {
      "_id": "12603307",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-08-13 18:58:24",
      "description": "It can be useful to know the set of in-use partition keys (storage engine row keys).  One example given to me was where application data was modeled as a few 10s of 1000s of wide rows, where the app required presenting these rows to the user sorted based on information in the partition key.  The partition count is small enough to do the sort client-side in memory, which is what the app did with the Thrift API--a range slice with an empty columns list.\n\nThis was a problem when migrating to CQL3.  {{SELECT mykey FROM mytable}} includes all the logical rows, which makes the resultset too large to make this a reasonable approach, even with paging.\n\nOne way to add support would be to allow DISTINCT in the special case of {{SELECT DISTINCT mykey FROM mytable}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Ability for CQL3 to list partition keys"
   },
   {
      "_id": "12603138",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-08-12 19:41:01",
      "description": "I posted this question on StackOverflow, because i need a solution. \n\nCreated a table with :\n\n{noformat}\ncreate table compositetest(m_id ascii,i_id int,l_id ascii,body ascii, PRIMARY KEY(m_id,i_id,l_id));\n{noformat}\n\nwanted to slice the results returned, so did something like below, not sure if its the right way. The first one returns data perfectly as expected, second one to get the next 3 columns closes the transport of my cqlsh\n\n{noformat}\ncqlsh:testkeyspace1> select * from compositetest where i_id<=3 limit 3;\n m_id | i_id | l_id | body\n------+------+------+------\n   m1 |    1 |   l1 |   b1\n   m1 |    2 |   l2 |   b2\n   m2 |    1 |   l1 |   b1\n\ncqlsh:testkeyspace1> Was trying to write something for slice range.\n\nTSocket read 0 bytes\n{noformat}\n\nIs there a way to achieve what I am doing here, it would be good if some meaning ful error is sent back, instead of cqlsh closing the transport.\n\nOn the server side I see the following error.\n\n{noformat}\nERROR [Thrift:3] 2012-08-12 15:15:24,414 CustomTThreadPoolServer.java (line 204) Error occurred during processing of message.\njava.lang.NullPointerException\n\tat org.apache.cassandra.cql3.statements.SelectStatement$Restriction.setBound(SelectStatement.java:1277)\n\tat org.apache.cassandra.cql3.statements.SelectStatement$RawStatement.updateRestriction(SelectStatement.java:1151)\n\tat org.apache.cassandra.cql3.statements.SelectStatement$RawStatement.prepare(SelectStatement.java:1001)\n\tat org.apache.cassandra.cql3.QueryProcessor.getStatement(QueryProcessor.java:215)\n\tat org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:121)\n\tat org.apache.cassandra.thrift.CassandraServer.execute_cql_query(CassandraServer.java:1237)\n\tat org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query.getResult(Cassandra.java:3542)\n\tat org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query.getResult(Cassandra.java:3530)\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:32)\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:34)\n\tat org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:186)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:680)\n{noformat}\n\nWith ThriftClient I get :\n\n{noformat}\norg.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)\n\tat org.apache.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)\n\tat org.apache.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:84)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:378)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:297)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:204)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.cassandra.thrift.Cassandra$Client.recv_execute_cql_query(Cassandra.java:1402)\n\tat org.apache.cassandra.thrift.Cassandra$Client.execute_cql_query(Cassandra.java:1388)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Slice",
         "cql",
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "NPE when trying to select a slice from a composite table"
   },
   {
      "_id": "12601437",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-08-03 22:41:40",
      "description": "cqlsh syntax awareness (tab completion, etc) should be aware of several recent changes to CQL:\n\n * CASSANDRA-4179 (row key and column value composites; 1.2 only)\n * CASSANDRA-3647 (sets/lists/maps; 1.2 only)\n * CASSANDRA-4018 (inet type; 1.2 only)\n * CASSANDRA-4278 (hyphens in keyspace properties; 1.1 and up)\n * CASSANDRA-4217 (accessing ttl, timestamp; 1.1 and up)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3",
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "update cqlsh recognized syntax (for tab completion, etc)"
   },
   {
      "_id": "12600923",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-07-31 22:17:44",
      "description": "dtests caught this on trunk:\n\n{noformat}\n  File \"/var/lib/buildbot/cassandra-dtest/cql_tests.py\", line 277, in create_invalid_test\n    assert_invalid(cursor, \"CREATE TABLE test (key1 text PRIMARY KEY, key2 text PRIMARY KEY)\")\n  File \"/var/lib/buildbot/cassandra-dtest/assertions.py\", line 31, in assert_invalid\n    assert False, \"Expecting query to be invalid\"\nAssertionError: Expecting query to be invalid\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cql3: defining more than one pk should be invalid"
   },
   {
      "_id": "12600870",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-07-31 15:01:47",
      "description": "When I run following CQL on trunk, throws exception (only in CQL2). This statement used to work and I think something is broken after CASSANDRA-4179.\n\n{code}\nCREATE TABLE Standard1 (key ascii PRIMARY KEY, c0 ascii);\n{code}\n\nException is:\n\n{code}\nERROR [Thrift:1] 2012-07-31 09:54:02,585 CustomTThreadPoolServer.java (line 202) Error occurred during processing of message.\njava.lang.NullPointerException\n        at org.apache.cassandra.utils.ByteBufferUtil.string(ByteBufferUtil.java:166)\n        at org.apache.cassandra.utils.ByteBufferUtil.string(ByteBufferUtil.java:123)\n        at org.apache.cassandra.cql.jdbc.JdbcUTF8.getString(JdbcUTF8.java:73)\n        at org.apache.cassandra.db.marshal.UTF8Type.getString(UTF8Type.java:49)\n        at org.apache.cassandra.cql3.ColumnIdentifier.<init>(ColumnIdentifier.java:45)\n        at org.apache.cassandra.cql3.CFDefinition.getKeyId(CFDefinition.java:167)\n        at org.apache.cassandra.cql3.CFDefinition.<init>(CFDefinition.java:81)\n        at org.apache.cassandra.config.CFMetaData.updateCfDef(CFMetaData.java:1382)\n        at org.apache.cassandra.config.CFMetaData.keyAliases(CFMetaData.java:235)\n        at org.apache.cassandra.cql.CreateColumnFamilyStatement.getCFMetaData(CreateColumnFamilyStatement.java:170)\n        at org.apache.cassandra.cql.QueryProcessor.processStatement(QueryProcessor.java:692)\n        at org.apache.cassandra.cql.QueryProcessor.process(QueryProcessor.java:846)\n        at org.apache.cassandra.thrift.CassandraServer.execute_cql_query(CassandraServer.java:1237)\n        at org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query.getResult(Cassandra.java:3542)\n        at org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query.getResult(Cassandra.java:3530)\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:32)\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:34)\n        at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:184)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:680)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Using 'key' as primary key throws exception when using CQL2"
   },
   {
      "_id": "12599435",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-07-19 09:50:50",
      "description": "It could be useful to allow the preparation of the consitency level, the timestamp and the ttl. I.e. to allow:\n{noformat}\nUPDATE foo SET .. USING CONSISTENCY ? AND TIMESTAMP ? AND TTL ? \n{noformat}\n\nA slight concern is that when preparing a statement we return the names of the prepared variables, but none of timestamp, ttl and consistency are reserved names currently, so returning those as names could conflict with a column name. We can either:\n* make these reserved identifier (I have to add that I'm not a fan because at least for \"timestamp\", I think that's a potentially useful and common column name).\n* use some specific special character to indicate those are not column names, like returning \"[timestamp]\", \"[ttl]\", \"[consistency]\".",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: Allow preparing the consistency level, timestamp and ttl"
   },
   {
      "_id": "12599426",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-07-19 09:00:04",
      "description": "Currently, prepared statements are connection based. A client can only use a prepared statement on the connection it prepared it on, and if you prepare the same prepared statement on multiple connections, we'll keep multiple times the same prepared statement. This is potentially inefficient but can also be fairly painful for client libraries with pool of connections (a.k.a all reasonable client library ever) as this means you need to make sure you prepare statement on every connection of the pool, including the connection that don't exist yet but might be created later.\n\nThis ticket suggests making prepared statement global (at least for CQL3), i.e. move them out of ClientState. This will likely reduce the number of stored statement on a given node quite a bit, since it's very likely that all clients to a given node will prepare the same statements (and potentially on all of their connection with the node). And given that prepared statement identifiers are the hashCode() of the string, this should be fairly trivial.\n\nI will note that while I think using a hash of the string as identifier is a very good idea, I don't know if the default java hashCode() is good enough. If that's a concern, maybe we should use a safer (bug longer) hash like md5 or sha1. But we'd better do that now.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "binary_protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Make prepared statement global rather than connection based"
   },
   {
      "_id": "12599416",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-07-19 07:47:28",
      "description": "One of the goal of CQL3 is that client library should not have to parse queries to provide a good experience. In particular, that means such client (that don't want to parse queries) won't be able to allow the user to define a specific default read/write consistency level per-CF, forcing user to specific the consistency level with every query, which is not very user friendly.\n\nThis ticket suggests the addition of per-cf default read/write consitency level. Typically the syntax would be:\n{noformat}\nCREATE TABLE foo (...)\nWITH DEFAULT_READ_CONSISTENCY = QUORUM\n AND DEFAULT_WRITE_CONSISTENCY = QUORUM\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: allow to define a per-cf default consistency level"
   },
   {
      "_id": "12597852",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-07-06 23:22:15",
      "description": "minor cqlsh improvement:\n\nthe auto completion in cqlsh rocks, so this is just to make a nitpick improvement: \n\nif i type\n{panel}\ncqlsh> create KEYSPACE test WITH strategy_class = 'SimpleStrategy' and \n{panel}\n\nthen tab tab after it, it will auto complete into:\n{panel}\ncqlsh> create KEYSPACE test WITH strategy_class = 'SimpleStrategy' AND strategy_options:replication_factor = \n{panel}\n\nbut if i use a fully qualified name:\n{panel}\ncqlsh> create KEYSPACE test WITH strategy_class = 'org.apache.cassandra.locator.SimpleStrategy' AND \n                        <strategy_option_name> \n{panel}\n\nit is not smart enough to figured out the available options.\n\nIt'd be nice to make the auto completion works for those fully qualified cases. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "auto completion in cqlsh should work when using fully qualified name"
   },
   {
      "_id": "12597801",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-07-06 16:36:51",
      "description": "The commitlog rewrite for 1.1 uses mmap, anticipating multithreaded commitlog writes.  However, the default commitlog settings will quickly exhaust a 32bit address space.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "commitlog"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Humor 32bit JVMs"
   },
   {
      "_id": "12597658",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-07-05 21:42:43",
      "description": "The `system.schema_keyspaces`, `system.schema_columnfamilies`, and `system.schema_columns` virtual tables allow clients to query schema and layout information through CQL. This will be invaluable when users start to make more use of the CQL-only protocol (CASSANDRA-2478), since there will be no other way to determine certain information about available columnfamilies, keyspaces, or show metadata about them.\n\nHowever, the system keyspace itself, and all the columnfamilies in it, are not represented in the schema_* tables:\n\n{noformat}\ncqlsh> select * from system.schema_keyspaces where \"keyspace\" = 'system';\ncqlsh> \ncqlsh> select * from system.schema_columnfamilies where \"keyspace\" = 'system';\ncqlsh> \ncqlsh> select * from system.schema_columns where \"keyspace\" = 'system';\ncqlsh> \n{noformat}\n\nIt would be greatly helpful to clients which do more introspection than the minimum (say, for example, cqlsh) to be able to get information on the structure and availability of schema-definition tables.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql",
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Include metadata for system keyspace itself in schema_* tables"
   },
   {
      "_id": "12597608",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-07-05 16:45:58",
      "description": "The goal here would be to use a query paging mechanism to the CQL native protocol. Typically the client/server with that would look something like this:\n{noformat}\nC sends query to S.\nS sends N first rows matching the query + flag saying the response is not complete\nC requests the next N rows\nS sends N next rows + flag saying whether there is more\nC requests the next N rows\n...\nS sends last rows + flag saying there is no more result\n{noformat}\n\nThe clear goal is for user to not have to worry about limiting queries and doing manual paging.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql",
         "protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Add cursor API/auto paging to the native CQL protocol"
   },
   {
      "_id": "12597524",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-07-05 04:52:18",
      "description": "As instructed in CASSANDRA-4321 I have raised this issue as a continuation of that issue as it appears the problem still exists.\n\nI have repeatedly run sstablescrub across all my nodes after the 1.1.2 upgrade until sstablescrub shows no errors.  The exceptions described in CASSANDRA-4321 do not occur as frequently now but the integrity check still throws exceptions on a number of nodes.  Once those exceptions occur compactionstats shows a large number of pending tasks with no progression afterwards.\n\n{code}\nERROR [CompactionExecutor:150] 2012-07-05 04:26:15,570 AbstractCassandraDaemon.java (line 134) Exception in thread Thread[CompactionExecutor:150,1,main]\njava.lang.AssertionError\n        at org.apache.cassandra.db.compaction.LeveledManifest.promote(LeveledManifest.java:214)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy.handleNotification(LeveledCompactionStrategy.java:158)\n        at org.apache.cassandra.db.DataTracker.notifySSTablesChanged(DataTracker.java:531)\n        at org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:254)\n        at org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:978)\n        at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:200)\n        at org.apache.cassandra.db.compaction.LeveledCompactionTask.execute(LeveledCompactionTask.java:50)\n        at org.apache.cassandra.db.compaction.CompactionManager$1.runMayThrow(CompactionManager.java:150)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:636)\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Assertion with LCS compaction"
   },
   {
      "_id": "12596836",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-07-02 22:19:20",
      "description": "Introduced in CASSANDRA-1404, CleanupTest is showing this on trunk (on stderr, so test doesn't actually fail):\n\n{noformat}\n    [junit] java.lang.ClassCastException: org.apache.cassandra.dht.Token$KeyBound cannot be cast to org.apache.cassandra.dht.Token\n    [junit]     at org.apache.cassandra.dht.LocalToken.compareTo(LocalToken.java:24)\n    [junit]     at org.apache.cassandra.dht.Range$1.compare(Range.java:386)\n    [junit]     at org.apache.cassandra.dht.Range$1.compare(Range.java:383)\n    [junit]     at java.util.Arrays.mergeSort(Arrays.java:1270)\n    [junit]     at java.util.Arrays.sort(Arrays.java:1210)\n    [junit]     at java.util.Collections.sort(Collections.java:159)\n    [junit]     at org.apache.cassandra.dht.Range.normalize(Range.java:382)\n    [junit]     at org.apache.cassandra.io.sstable.SSTableReader.getSampleIndexesForRanges(SSTableReader.java:570)\n    [junit]     at org.apache.cassandra.io.sstable.SSTableReader.estimatedKeysForRanges(SSTableReader.java:549)\n    [junit]     at org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.getNextBackgroundTask(SizeTieredCompactionStrategy.java:111)\n    [junit]     at org.apache.cassandra.db.compaction.CompactionManager$1.runMayThrow(CompactionManager.java:136)\n    [junit]     at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:26)\n    [junit]     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\n    [junit]     at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n    [junit]     at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n    [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n    [junit]     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n    [junit]     at java.lang.Thread.run(Thread.java:662)\n{noformat}\n\nThis doesn't happen on the 1.1 branch (less robust test?) but the problem is still there.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cleanup uses global partitioner to estimate ranges in index sstables"
   },
   {
      "_id": "12596424",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-06-29 17:34:59",
      "description": "When we compact a tombstone for a super column with the old data for that super column, we end up writing the deleted super column and all the subcolumn data that is now worthless to the new sstable. This is especially inefficient when reads need to scan tombstones during a slice.\n\nHere is the output of a simple test I ran to confirm:\n\ninsert supercolumn, then flush\n{noformat}\nNicks-MacBook-Pro:12:20:52 cassandra-1.0] cassandra$ bin/sstable2json ~/.ccm/1node/node1/data/Keyspace2/Super4-hd-1-Data.db \n{\n\"6b657931\": {\"supercol1\": {\"deletedAt\": -9223372036854775808, \"subColumns\": [[\"737562636f6c31\",\"7468697320697320612074657374\",1340990212532000]]}}\n}\n{noformat}\n\ndelete supercolumn, flush again\n\n{noformat}\n[Nicks-MacBook-Pro:12:20:59 cassandra-1.0] cassandra$ bin/nodetool -h localhost flush\n[Nicks-MacBook-Pro:12:22:41 cassandra-1.0] cassandra$ bin/sstable2json ~/.ccm/1node/node1/data/Keyspace2/Super4-hd-2-Data.db \n{\n\"6b657931\": {\"supercol1\": {\"deletedAt\": 1340990544005000, \"subColumns\": []}}\n}\n{noformat}\n\ncompact and check resulting sstable\n\n{noformat}\n[Nicks-MacBook-Pro:12:22:55 cassandra-1.0] cassandra$ bin/nodetool -h localhost compact \n[Nicks-MacBook-Pro:12:23:09 cassandra-1.0] cassandra$ bin/sstable2json ~/.ccm/1node/node1/data/Keyspace2/Super4-hd-3-Data.db \n{\n\"6b657931\": {\"supercol1\": {\"deletedAt\": 1340990544005000, \"subColumns\": [[\"737562636f6c31\",\"7468697320697320612074657374\",1340990212532000]]}}\n}\n[Nicks-MacBook-Pro:12:23:20 cassandra-1.0] cassandra$ \n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Subcolumns not removed when compacting tombstoned super column"
   },
   {
      "_id": "12595941",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-06-26 17:18:15",
      "description": "introduced by CASSANDRA-4079",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cleanup optimization can delete data but not corresponding index entries"
   },
   {
      "_id": "12595805",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-06-25 16:33:23",
      "description": "Here is a CQL3 range query sample where I get wrong results (tested using cqlsh --cql3) from my perspective:\n\nCREATE KEYSPACE testing WITH strategy_class = 'SimpleStrategy' AND strategy_options:replication_factor = 1;\n\nUSE testing;\n\nCREATE TABLE bug_test (a int, b int, c int, d int, e int, f text, PRIMARY KEY (a, b, c, d, e) );\n\nINSERT INTO bug_test (a, b, c, d, e, f) VALUES (1, 1, 1, 1, 2, '2');\nINSERT INTO bug_test (a, b, c, d, e, f) VALUES (1, 1, 1, 1, 1, '1');\nINSERT INTO bug_test (a, b, c, d, e, f) VALUES (1, 1, 1, 2, 1, '1');\nINSERT INTO bug_test (a, b, c, d, e, f) VALUES (1, 1, 1, 1, 3, '3');\nINSERT INTO bug_test (a, b, c, d, e, f) VALUES (1, 1, 1, 1, 5, '5');\n\n----------\n\nNormal select everything query:\n\nSELECT * FROM bug_test;\n\nResults:\n\n a | b | c | d | e | f\n---+---+---+---+---+---\n 1 | 1 | 1 | 1 | 1 | 1\n 1 | 1 | 1 | 1 | 2 | 2\n 1 | 1 | 1 | 1 | 3 | 3\n 1 | 1 | 1 | 1 | 5 | 5\n 1 | 1 | 1 | 2 | 1 | 1\n\nEverything fine so far.\n\n----------\n\nSelect with greater equal comparison for last column of composite key:\n\nSELECT a, b, c, d, e, f FROM bug_test WHERE a = 1 AND b = 1 AND c = 1 AND d = 1 AND e >= 2;\n\nResults:\n\n a | b | c | d | e | f\n---+---+---+---+---+---\n 1 | 1 | 1 | 1 | 2 | 2\n 1 | 1 | 1 | 1 | 3 | 3\n 1 | 1 | 1 | 1 | 5 | 5\n 1 | 1 | 1 | 2 | 1 | 1\n\nBug:\nWhy was the last row returned? It shouldn't be there, right?\n\n----------\n\nSelect with greater comparison for last column of composite key:\n\nSELECT a, b, c, d, e, f FROM bug_test WHERE a = 1 AND b = 1 AND c = 1 AND d = 1 AND e > 2;\n\nResults:\n a | b | c | d | e | f\n---+---+---+---+---+---\n 1 | 1 | 1 | 1 | 3 | 3\n 1 | 1 | 1 | 1 | 5 | 5\n 1 | 1 | 1 | 2 | 1 | 1\n\nBug:\nWhy was the last row returned? It shouldn't be there, right?\n\nThe same issue is also present with between ranges (e >= 1 AND e <= 2)...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "bug",
         "composite",
         "compositeColumns",
         "cql3",
         "query",
         "range"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3 Range Query contains unwanted results with composite columns"
   },
   {
      "_id": "12595422",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-06-21 12:29:51",
      "description": "Compactions invalidate row cache after CASSANDRA-3862\n\nhttps://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/compaction/CompactionIterable.java#L87",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Compaction invalidates row cache"
   },
   {
      "_id": "12595306",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-06-20 17:38:55",
      "description": "Here is table and data:\n\nCREATE TABLE t1 (\n  a int,\n  b bigint,\n  c varchar,\n  d varchar,\n  PRIMARY KEY (a,b,c)\n) WITH CLUSTERING ORDER BY (b DESC, c DESC);\n\nINSERT INTO db.t1 (a,b,c,d)  VALUES (1,10,'u1','s1');\nINSERT INTO db.t1 (a,b,c,d)  VALUES (1,15,'u1','d1');\nINSERT INTO db.t1 (a,b,c,d)  VALUES (1,21,'u3','ghfgh f1g');\nINSERT INTO db.t1 (a,b,c,d)  VALUES (1,31,'u2','1gh');\nINSERT INTO db.t1 (a,b,c,d)  VALUES (1,41,'u3','fgh1');\n\nAnd here's the query\n\ncqlsh:db> SELECT * FROM t1;\n a | b                                | c  | d\n---+----------------------------------+----+-----------\n 1 |    \\x00\\x00\\x00\\x00\\x00\\x00\\x00) | u3 |      fgh1\n 1 | \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1f | u2 |       1gh\n 1 | \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x15 | u3 | ghfgh f1g\n 1 | \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0f | u1 |        d1\n 1 |   \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n | u1 |        s1\n\n\nAs you can see, cqlsh can't display reversed type values properly ...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh can't display reversed type values properly"
   },
   {
      "_id": "12595294",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-06-20 16:50:41",
      "description": "Currently, in CQL3 and contrarily to SQL, one cannot define a table having only a PK but no other columns. Related to that, a CQL always needs at least one column outside of the PK to be inserted to exist. All that may force people to add 'fake' value that they don't really need.\n\nThe goal of this ticket is to lift that limitation and allow table definition to have only a PK, and to have CQL rows exist even if only the PK has been inserted (in other words, to have CQL rows behave like SQL rows).\n\nFollowing CASSANDRA-4329, one way to do that with the sparse-composite encoding CQL3 uses would be to insert as marker of the CQL row presence a CQL column with an empty name (the underlying column name won't be empty though since it's a composite). The drawback though is that we will need to insert that marker with every insert to the CQL row (in other word, we'll add a slight overhead to the size of each write). The pros is that if we have such marker for the CQL row presence, we will be able to reoptimize back queries that select only a few columns (since following CASSANDRA-3982 we query all columns of a CQL row every time).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: allow definition with only a PK"
   },
   {
      "_id": "12560663",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-06-14 16:39:04",
      "description": "This concerns:\n\nstatic int MAX_COMPACTING_L0 = 32;\n\nRepair can create very small SSTable segments. We should consider moving to a threshold that takes into account the size of the files brought into compaction rather than the number of files for this and similar situations. Bringing the small files from L0 to L1 magnifies the issue.\n\nIf there are too many very small files in L0 perhaps even an intermediate compaction would even reduce the magnifying effect of a L0 to L1 compaction.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Small SSTable Segments Can Hurt Leveling Process"
   },
   {
      "_id": "12560470",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-06-13 09:34:53",
      "description": "h3. Configuration\nCassandra server configuration:\n{noformat}heap size: 4 GB\nseed_provider:\n    - class_name: org.apache.cassandra.locator.SimpleSeedProvider\n      parameters:\n          - seeds: \"xxx.xxx.xxx.10,xxx.xxx.xxx.11\"\nlisten_address: xxx.xxx.xxx.10\nrpc_address: 0.0.0.0\nrpc_port: 9160\nrpc_timeout_in_ms: 20000\nendpoint_snitch: PropertyFileSnitch{noformat}\n\ncassandra-topology.properties\n{noformat}xxx.xxx.xxx.10=datacenter1:rack1\nxxx.xxx.xxx.11=datacenter1:rack1\ndefault=datacenter1:rack1{noformat}\n\nRing configuration:\n{noformat}Address         DC          Rack        Status State   Load            Effective-Ownership Token\n                                                                                           85070591730234615865843651857942052864\nxxx.xxx.xxx.10  datacenter1 rack1       Up     Normal  23,11 kB        100,00%             0\nxxx.xxx.xxx.11  datacenter1 rack1       Up     Normal  23,25 kB        100,00%             85070591730234615865843651857942052864{noformat}\n\nh3.Problem\nI have ctreated keyspace and column family using CLI commands:\n{noformat}create keyspace testks with placement_strategy = 'org.apache.cassandra.locator.NetworkTopologyStrategy' and strategy_options = {datacenter1:2};\nuse testks;\ncreate column family testcf;{noformat}\n\nThen I started my Java application, which inserts 50 000 000 rows to created column family using Hector client. Client is connected to node 1.\nAfter about 30 seconds (160 000 rows were inserted) Cassandra server on node 1 throws an exception:\n{noformat}ERROR [COMMIT-LOG-ALLOCATOR] 2012-06-13 10:26:38,393 AbstractCassandraDaemon.java (line 134) Exception in thread Thread[COMMIT-LOG-ALLOCATOR,5,main]\njava.io.IOError: java.io.IOException: Rename from c:\\apache-cassandra\\storage\\commitlog\\CommitLog-7345742389552.log to 7475933520374 failed\n\tat org.apache.cassandra.db.commitlog.CommitLogSegment.<init>(CommitLogSegment.java:127)\n\tat org.apache.cassandra.db.commitlog.CommitLogSegment.recycle(CommitLogSegment.java:204)\n\tat org.apache.cassandra.db.commitlog.CommitLogAllocator$2.run(CommitLogAllocator.java:166)\n\tat org.apache.cassandra.db.commitlog.CommitLogAllocator$1.runMayThrow(CommitLogAllocator.java:95)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n\tat java.lang.Thread.run(Thread.java:722)\nCaused by: java.io.IOException: Rename from c:\\apache-cassandra\\storage\\commitlog\\CommitLog-7345742389552.log to 7475933520374 failed\n\tat org.apache.cassandra.db.commitlog.CommitLogSegment.<init>(CommitLogSegment.java:105)\n\t... 5 more{noformat}\n\t\nThen, few seconds later Cassandra server on node 2 throws the same exception:\n{noformat}ERROR [COMMIT-LOG-ALLOCATOR] 2012-06-14 10:26:44,005 AbstractCassandraDaemon.java (line 134) Exception in thread Thread[COMMIT-LOG-ALLOCATOR,5,main]\njava.io.IOError: java.io.IOException: Rename from c:\\apache-cassandra\\storage\\commitlog\\CommitLog-7320337904033.log to 7437675489307 failed\n\tat org.apache.cassandra.db.commitlog.CommitLogSegment.<init>(CommitLogSegment.java:127)\n\tat org.apache.cassandra.db.commitlog.CommitLogSegment.recycle(CommitLogSegment.java:204)\n\tat org.apache.cassandra.db.commitlog.CommitLogAllocator$2.run(CommitLogAllocator.java:166)\n\tat org.apache.cassandra.db.commitlog.CommitLogAllocator$1.runMayThrow(CommitLogAllocator.java:95)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n\tat java.lang.Thread.run(Unknown Source)\nCaused by: java.io.IOException: Rename from c:\\apache-cassandra\\storage\\commitlog\\CommitLog-7320337904033.log to 7437675489307 failed\n\tat org.apache.cassandra.db.commitlog.CommitLogSegment.<init>(CommitLogSegment.java:105)\n\t... 5 more{noformat}\n\nAfter that, my application cannot insert any more data. Hector gets TimedOutException from Thrift:\n{noformat}Thread-4 HConnectionManager.java 306 2012-06-14 10:26:56,034 HConnectionManager  operateWithFailover \t WARN  \t %Could not fullfill request on this host CassandraClient<xxx.xxx.xxx.10:9160-10> \nThread-4 HConnectionManager.java 307 2012-06-14 10:26:56,034 HConnectionManager operateWithFailover \t WARN  \t %Exception:  \nme.prettyprint.hector.api.exceptions.HTimedOutException: TimedOutException()\n\tat me.prettyprint.cassandra.service.ExceptionsTranslatorImpl.translate(ExceptionsTranslatorImpl.java:35)\n\tat me.prettyprint.cassandra.connection.HConnectionManager.operateWithFailover(HConnectionManager.java:264)\n\tat me.prettyprint.cassandra.model.ExecutingKeyspace.doExecuteOperation(ExecutingKeyspace.java:97)\n\tat me.prettyprint.cassandra.model.MutatorImpl.execute(MutatorImpl.java:243)\n\tat patrycjusz.nosqltest.db.cassandra.CassandraHectorDbAdapter.commitTransaction(CassandraDbAdapter.java:63)\n\tat patrycjusz.nosqltest.DbTest.insertData(DbTest.java:459)\n\tat patrycjusz.nosqltest.gui.InsertPanel.executeTask(NePanel.java:154)\n\tat patrycjusz.nosqltest.gui.InsertPanel$1.run(NePanel.java:141)\n\tat java.lang.Thread.run(Unknown Source)\nCaused by: TimedOutException()\n\tat org.apache.cassandra.thrift.Cassandra$batch_mutate_result.read(Cassandra.java:20269)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)\n\tat org.apache.cassandra.thrift.Cassandra$Client.recv_batch_mutate(Cassandra.java:922)\n\tat org.apache.cassandra.thrift.Cassandra$Client.batch_mutate(Cassandra.java:908)\n\tat me.prettyprint.cassandra.model.MutatorImpl$3.execute(MutatorImpl.java:246)\n\tat me.prettyprint.cassandra.model.MutatorImpl$3.execute(MutatorImpl.java:243)\n\tat me.prettyprint.cassandra.service.Operation.executeAndSetResult(Operation.java:103)\n\tat me.prettyprint.cassandra.connection.HConnectionManager.operateWithFailover(HConnectionManager.java:258)\n\t... 8 more{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "commitlog"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Data insertion fails because of commitlog rename failure"
   },
   {
      "_id": "12560158",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-06-11 12:22:27",
      "description": "Currently, when defining a table with a single (non-composite) PRIMARY KEY, we don't use a CompositeType in the underlying comparator. This is however a problem for CASSANDRA-3647 as this means those tables cannot use collections.  So this ticket suggests to change that default behavior, and to always use (by default at least, see below) a composite comparator underneath. I'll note that doing so will mean an overhead of 3 bytes per column for non-composite columns, but I believe getting collection is well worth it.\n\nOf course the suggestion above apply to the default behavior and this ticket would also add an option to table creation to get back to the current behavior of not using a composite comparator (if ony for backward compatibility sake).  And I believe that we can actually reuse 'COMPACT STORAGE' for that.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: Always use composite types by default"
   },
   {
      "_id": "12559783",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-06-08 02:00:49",
      "description": "After upgrading to 1.1.1 (from 1.1.0) I have started experiencing StackOverflowError's resulting in compaction backlog and failure to restart. \n\nThe ring currently consists of 6 DC's and 22 nodes using LCS & compression.  This issue was first noted on 2 nodes in one DC and then appears to have spread to various other nodes in the other DC's.  \n\nWhen the first occurrence of this was found I restarted the instance but it failed to start so I cleared its data and treated it as a replacement node for the token it was previously responsible for.  This node successfully streamed all the relevant data back but failed again a number of hours later with the same StackOverflowError and again was unable to restart. \n\nThe initial stack overflow error on a running instance looks like this:\n\nERROR [CompactionExecutor:314] 2012-06-07 09:59:43,017 AbstractCassandraDaemon.java (line 134) Exception in thread Thread[CompactionExecutor:314,1,main]\njava.lang.StackOverflowError\n        at java.util.Arrays.mergeSort(Arrays.java:1157)\n        at java.util.Arrays.sort(Arrays.java:1092)\n        at java.util.Collections.sort(Collections.java:134)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.findMinMedianMax(IntervalNode.java:114)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:49)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n\n[snip - this repeats until stack overflow.  Compactions stop from this point onwards]\n\n\nI restarted this failing instance with DEBUG logging enabled and it throws the following exception part way through startup:\n\nERROR 11:37:51,046 Exception in thread Thread[OptionalTasks:1,5,main]\njava.lang.StackOverflowError\n        at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:307)\n        at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:276)\n        at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:230)\n        at org.slf4j.helpers.MessageFormatter.format(MessageFormatter.java:124)\n        at org.slf4j.impl.Log4jLoggerAdapter.debug(Log4jLoggerAdapter.java:228)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:45)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n\n[snip - this repeats until stack overflow]\n\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:64)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:64)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:64)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalTree.<init>(IntervalTree.java:39)\n        at org.apache.cassandra.db.DataTracker.buildIntervalTree(DataTracker.java:560)\n        at org.apache.cassandra.db.DataTracker$View.replace(DataTracker.java:617)\n        at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:320)\n        at org.apache.cassandra.db.DataTracker.addInitialSSTables(DataTracker.java:259)\n        at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:234)\n        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:331)\n        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:309)\n        at org.apache.cassandra.db.Table.initCf(Table.java:367)\n        at org.apache.cassandra.db.Table.<init>(Table.java:299)\n        at org.apache.cassandra.db.Table.open(Table.java:114)\n        at org.apache.cassandra.db.Table.open(Table.java:97)\n        at org.apache.cassandra.db.Table$2.apply(Table.java:574)\n        at org.apache.cassandra.db.Table$2.apply(Table.java:571)\n        at com.google.common.collect.Iterators$8.next(Iterators.java:751)\n        at org.apache.cassandra.db.ColumnFamilyStore.all(ColumnFamilyStore.java:1625)\n        at org.apache.cassandra.db.MeteredFlusher.countFlushingBytes(MeteredFlusher.java:118)\n        at org.apache.cassandra.db.MeteredFlusher.run(MeteredFlusher.java:45)\n        at org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run(DebuggableScheduledThreadPoolExecutor.java:79)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n        at java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:351)\n        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:178)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:165)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:267)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:636)\nDEBUG 11:37:51,052 Initializing ksU.cfS\n\n\nAnd then finally fails with the following:\n\nDEBUG 11:49:03,752 Creating IntervalNode from [Interval(DecoratedKey(104860264640932324846851821824650966808, 4fcc88eb0218216164673394), DecoratedKey(93975306025956344620001177071135439009, 4fc8fb042c98458c7a58bc3b)), Interval(DecoratedKey(104860264640932324846851821824650966808, 4fcc88eb0218216164673394), DecoratedKey(93975306025956344620001177071135439009, 4fc8fb042c98458c7a58bc3b)), Interval(DecoratedKey(104860264640932324846851821824650966808, 4fcc88eb0218216164673394), DecoratedKey(93975306025956344620001177071135439009, 4fc8fb042c98458c7a58bc3b)), Interval(DecoratedKey(104860264640932324846851821824650966808, 4fcc88eb0218216164673394), DecoratedKey(93975306025956344620001177071135439009, 4fc8fb042c98458c7a58bc3b)), Interval(DecoratedKey(104860264640932324846851821824650966808, 4fcc88eb0218216164673394), DecoratedKey(93975306025956344620001177071135439009, 4fc8fb042c98458c7a58bc3b)), Interval(DecoratedKey(104860264640932324846851821824650966808, 4fcc88eb0218216164673394), DecoratedKey(93975306025956344620001177071135439009, 4fc8fb042c98458c7a58bc3b))]\njava.lang.reflect.InvocationTargetException\nDEBUG 11:49:03,753 Configured datacenter replicas are dc1:2, dc2:2, dc3:2, dc4:2, dc5:0, dc6:2, dc7:0, dc8:0, dc9:2\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:616)\n        at org.apache.commons.daemon.support.DaemonLoader.load(DaemonLoader.java:160)\nCaused by: java.lang.StackOverflowError\n        at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:307)\n        at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:276)\n        at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:230)\n        at org.slf4j.helpers.MessageFormatter.format(MessageFormatter.java:124)\n        at org.slf4j.impl.Log4jLoggerAdapter.debug(Log4jLoggerAdapter.java:228)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:45)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n\n[snip - this repeats until stack overflow]\n\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:64)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:64)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:64)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalNode.<init>(IntervalNode.java:62)\n        at org.apache.cassandra.utils.IntervalTree.IntervalTree.<init>(IntervalTree.java:39)\n        at org.apache.cassandra.db.DataTracker.buildIntervalTree(DataTracker.java:560)\n        at org.apache.cassandra.db.DataTracker$View.replace(DataTracker.java:617)\n        at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:320)\n        at org.apache.cassandra.db.DataTracker.addInitialSSTables(DataTracker.java:259)\n        at org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:234)\n        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:331)\n        at org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:309)\n        at org.apache.cassandra.db.Table.initCf(Table.java:367)\n        at org.apache.cassandra.db.Table.<init>(Table.java:299)\n        at org.apache.cassandra.db.Table.open(Table.java:114)\n        at org.apache.cassandra.db.Table.open(Table.java:97)\n        at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:204)\n        at org.apache.cassandra.service.AbstractCassandraDaemon.init(AbstractCassandraDaemon.java:254)\n        ... 5 more\nCannot load daemon\nService exit with a return value of 3\n\nRunning with assertions enabled allows me to start the instance but when doing so I get errors such as:\n\nERROR 01:22:22,753 Exception in thread Thread[SSTableBatchOpen:2,5,main]java.lang.AssertionError: SSTable first key DecoratedKey(100294972947100949193477090306072672386, 4fcf051ef5067d7f17d9fc35) > last key DecoratedKey(90250429663386465697464050082134975058, 4fce996e3c1eed8c4b17dd66)\nat org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:412)\nat org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:187)\nat org.apache.cassandra.io.sstable.SSTableReader$1.run(SSTableReader.java:225)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\nat java.util.concurrent.FutureTask.run(FutureTask.java:166)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\nat java.lang.Thread.run(Thread.java:636)\n\nand:\n\nERROR 01:27:58,946 Exception in thread Thread[CompactionExecutor:9,1,main]\njava.lang.AssertionError: Last written key DecoratedKey(81958437188197992567937826278457419048, 4fa1aebad23f81e4321d344d) >= current key DecoratedKey(64546479828744423263742604083767363606, 4fcafc0f19f6a8092d4d4f94) writing into /var/lib/XX/data/cassandra/ks1/cf1/ks1-cf1-tmp-hd-657317-Data.db\n        at org.apache.cassandra.io.sstable.SSTableWriter.beforeAppend(SSTableWriter.java:134)\n        at org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:153)\n        at org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:159)\n        at org.apache.cassandra.db.compaction.LeveledCompactionTask.execute(LeveledCompactionTask.java:50)\n        at org.apache.cassandra.db.compaction.CompactionManager$1.runMayThrow(CompactionManager.java:150)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:636)\n\nJust like the initial errors compactions appear to stop occurring after this point.  \n\nGiven the above this looks like sstables are getting corrupted.  By restarting nodes I am able to identify several hundred sstables exhibiting the same problem and this appears to be growing.\n\nI have tried scrubbing those affected nodes but the problem continues to occur.  If this is due to sstable corruptions is there another way of validating sstables for correctness?  Given that it has spread to various servers in other DC's it looks like this is directly related to the 1.1.1 upgrade recently performed on the ring.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "stackoverflow building interval tree & possible sstable corruptions"
   },
   {
      "_id": "12559766",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-06-07 22:25:03",
      "description": "Test uses Column family C defined as follows:\n\ncreate column family C with caching = 'keys_only' and key_validation_class = 'LongType' and compression_options = { sstable_compression: SnappyCompressor, chunk_length_kb: 64 } and max_compaction_threshold=0; \n\nmax_compaction_threshold is set to 0 to disable auto compaction.\n\nSSTables are streamed via sstableloader, after which a major compaction is triggered using \"nodetool compact MyKeyspace C\".\n\nThereafter, attempts to request compaction stats via \"nodetool compactionstats\" fail with the following exception:\n\nException in thread \"main\" java.lang.NullPointerException\n        at org.apache.cassandra.db.compaction.CompactionInfo.asMap(CompactionInfo.java:103)\n        at org.apache.cassandra.db.compaction.CompactionManager.getCompactions(CompactionManager.java:1115)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)\n        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)\n        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)\n        at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:65)\n        at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:216)\n        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:666)\n        at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:638)\n        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1404)\n        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)\n        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265)\n        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360)\n        at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:600)\n        at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:303)\n        at sun.rmi.transport.Transport$1.run(Transport.java:159)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at sun.rmi.transport.Transport.serviceCall(Transport.java:155)\n        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)\n        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)\n        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662) ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "caching"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Nodetool compactionstats fails with NullPointerException"
   },
   {
      "_id": "12559668",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-06-07 10:57:25",
      "description": "In org.apache.cassandra.db.compaction.CompactionIterable the check for compaction throttling occurs once every 1000 rows. In our workload this is much too large as we have many large rows (16 - 100 MB).\n\nWith a 100 MB row, about 100 GB is read (and possibly written) before the compaction throttle sleeps. This causes bursts of essentially unthrottled compaction IO followed by a long sleep which yields inconsistence performance and high error rates during the bursts.\n\nWe applied a workaround to check throttle every row which solved our performance and error issues:\n\nline 116 in org.apache.cassandra.db.compaction.CompactionIterable:\n                if ((row++ % 1000) == 0)\nreplaced with\n                if ((row++ % 1) == 0)\n\nI think the better solution is to calculate how often throttle should be checked based on the throttle rate to apply sleeps more consistently. E.g. if 16MB/sec is the limit then check for sleep after every 16MB is read so sleeps are spaced out about every second.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "qa-resolved"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Compaction Throttle too bursty with large rows"
   },
   {
      "_id": "12559479",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-06-06 02:18:57",
      "description": "Weaknesses of the existing protocol:\n\n- information asymmetry: node A can know what version node B expects, but not vice versa (see CASSANDRA-4101)\n- delayed information: node A will often not know what version node B expects, until after first contacting node B -- forcing it to throw that first message away and retry for the next one\n- protocol cannot handle both cross-dc forwarding and broadcast_address != socket address (see bottom of CASSANDRA-4099)\n- version is partly global, partly per-connection, and partly per-message, resulting in some interesting hacks (CASSANDRA-3166) and difficulty layering more sophisticated OutputStreams on the socket (CASSANDRA-3127, CASSANDRA-4139)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "jmx"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "clean up messagingservice protocol limitations"
   },
   {
      "_id": "12558177",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-05-25 19:47:30",
      "description": "getBuckets first sorts the sstables by size (N log N) then adds each sstable to a bucket (N**2 in the worst case of all sstables the same size, because we use the bucket's contents as a hash key).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "SizeTieredCompactionStrategy.getBuckets is quadradic in the number of sstables"
   },
   {
      "_id": "12558112",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-05-25 14:35:28",
      "description": "Our timestamp type allows to input timestamp as dates like '2012-06-06'. However, those don't work as expected in slice queries, as for instance:\n{noformat}\nSELECT * FROM timeline\n  WHERE k = ...\n  AND time > '2012-06-06'\n  AND time <= '2012-06-09'\n{noformat}\nwill return timestamps from '2012-06-06' and not those from '2012-06-09'. The reason being of course that we always translate a date the same way, using 0 for whichever part is not precised.\n\nA reasonably simple fix could be to add a new fromString(String s, boolean gt) method to AbstractType that is used when the the string should be interpreted in an inequality (the boolean gt would then say which kind of inequality).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: dates are not handled correctly in slices "
   },
   {
      "_id": "12557067",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-05-23 20:51:04",
      "description": "When the threshold changes, we may be eligible for a compaction immediately (without waiting for a flush to trigger the eligibility check).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "kick off background compaction when min/max changed"
   },
   {
      "_id": "12557052",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-05-23 19:24:13",
      "description": "A user using EC2MultiRegionSnitch, where the datacenter name has to match the AWS region names, will not be able to specify a keyspace's replica counts for those datacenters using CQL. AWS region names contain hyphens, which are not valid identifiers in CQL, and CQL keyspace/columnfamily properties must be identifiers or identifiers separated by colons.\n\nExample:\n\n{noformat}\nCREATE KEYSPACE Foo\n  WITH strategy_class = 'NetworkTopologyStrategy'\n      AND strategy_options:\"us-east\"=1\n      AND strategy_options:\"us-west\"=1;\n{noformat}\n\n(see http://mail-archives.apache.org/mod_mbox/cassandra-user/201205.mbox/browser for context)\n\n..will not currently work, with or without the double quotes.\n\nCQL should either allow hyphens in COMPIDENT, or allow quoted parts of a COMPIDENT token.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql",
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Can't specify certain keyspace properties in CQL"
   },
   {
      "_id": "12556274",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-05-17 19:06:45",
      "description": "This query fails:\nselect * from indextest where setid = 0 and row < 1;\nwhen there's a secondary index on 'setid'; row isn't the primary key.\n\n{code:title=CQL3}\nbin$ ./cqlsh --cql3\nConnected to Git at localhost:9160.\n[cqlsh 2.2.0 | Cassandra 1.1.0-SNAPSHOT | CQL spec 3.0.0 | Thrift protocol 19.31.0]\nUse HELP for help.\ncqlsh> use warehouse1;\ncqlsh:warehouse1> create table indextest (id int primary key, row int, setid int);\ncqlsh:warehouse1> create index indextest_setid_idx on indextest (setid);\ncqlsh:warehouse1> insert into indextest (id, row, setid) values (0, 0, 0);\ncqlsh:warehouse1> insert into indextest (id, row, setid) values (1, 1, 0);\ncqlsh:warehouse1> insert into indextest (id, row, setid) values (2, 2, 0);\ncqlsh:warehouse1> select * from indextest where setid = 0;\n id | row | setid\n----+-----+-------\n  0 |   0 |     0\n  1 |   1 |     0\n  2 |   2 |     0\n\ncqlsh:warehouse1> select * from indextest where setid = 0 and row = 1;\n id | row | setid\n----+-----+-------\n  1 |   1 |     0\n\ncqlsh:warehouse1> select * from indextest where setid = 0 and row < 1;\nTSocket read 0 bytes\n{code}\n\n{code:title=Error message}\nERROR 13:36:23,544 Error occurred during processing of message.\njava.lang.NullPointerException\n  at org.apache.cassandra.cql3.statements.SelectStatement.getIndexExpressions(SelectStatement.java:546)\n  at org.apache.cassandra.cql3.statements.SelectStatement.multiRangeSlice(SelectStatement.java:253)\n  at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:132)\n  at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:108)\n  at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:121)\n  at org.apache.cassandra.thrift.CassandraServer.execute_cql_query(CassandraServer.java:1237)\n  at org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query.getResult(Cassandra.java:3542)\n  at org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query.getResult(Cassandra.java:3530)\n  at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:32)\n  at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:34)\n  at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:186)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n  at java.lang.Thread.run(Thread.java:680)\n{code}\n\nWorks fine in CQL2:\n{code:title=CQL2}\nbin$ ./cqlsh_uuid --cql2\nConnected to Git at localhost:9160.\n[cqlsh 2.2.0 | Cassandra 1.1.0-SNAPSHOT | CQL spec 2.0.0 | Thrift protocol 19.31.0]\nUse HELP for help.\ncqlsh> use warehouse1;\ncqlsh:warehouse1> select * from indextest where setid = 0 and row < 1;\n id | row | setid\n----+-----+-------\n  0 |   0 |     0\n\ncqlsh:warehouse1> select * from indextest where setid = 0 and row < 2;\n id | row | setid\n----+-----+-------\n  0 |   0 |     0\n  1 |   1 |     0\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3",
         "index"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3 range query with secondary index fails"
   },
   {
      "_id": "12556268",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-05-17 18:29:34",
      "description": "came across this, will try to figure a way to systematically reprod this. But the problem is the sstable list in the manifest is changing as the repair is triggered:\n\n{panel}\nException in thread \"main\" java.util.ConcurrentModificationException \n at java.util.AbstractList$Itr.checkForComodification(Unknown Source)\n at java.util.AbstractList$Itr.next(Unknown Source)\n at org.apache.cassandra.io.sstable.SSTable.getTotalBytes(SSTable.java:250)\n at org.apache.cassandra.db.compaction.LeveledManifest.getEstimatedTasks(LeveledManifest.java:435)\n at org.apache.cassandra.db.compaction.LeveledCompactionStrategy.getEstimatedRemainingTasks(LeveledCompactionStrategy.java:128)\n at org.apache.cassandra.db.compaction.CompactionManager.getPendingTasks(CompactionManager.java:1063)\n at sun.reflect.GeneratedMethodAccessor73.invoke(Unknown Source)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n at java.lang.reflect.Method.invoke(Unknown Source)\n at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(Unknown Source)\n at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(Unknown Source)\n at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(Unknown Source)\n at com.sun.jmx.mbeanserver.PerInterface.getAttribute(Unknown Source)\n at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(Unknown Source)\n at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(Unknown Source)\n at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(Unknown Source)\n at javax.management.remote.rmi.RMIConnectionImpl.doOperation(Unknown Source)\n at javax.management.remote.rmi.RMIConnectionImpl.access$200(Unknown Source)\n at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(Unknown Source)\n at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(Unknown Source)\n at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(Unknown Source)\n at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n at java.lang.reflect.Method.invoke(Unknown Source)\n at sun.rmi.server.UnicastServerRef.dispatch(Unknown Source)\n at sun.rmi.transport.Transport$1.run(Unknown Source)\n at java.security.AccessController.doPrivileged(Native Method)\n at sun.rmi.transport.Transport.serviceCall(Unknown Source)\n at sun.rmi.transport.tcp.TCPTransport.handleMessages(Unknown Source)\n at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(Unknown Source)\n at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(Unknown Source)\n at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(Unknown Source)\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n at java.lang.Thread.run(Unknown Source)\n{panel}\n\nmaybe we could change the list to a copyOnArrayList? just a suggestion, haven't investigated much yet:\n\n{code:title=LeveledManifest.java}\ngenerations[i] = new ArrayList<SSTableReader>();\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "concurrent modif ex when repair is run on LCS"
   },
   {
      "_id": "12555858",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-05-15 19:05:27",
      "description": "Creating the simplest composite-key cql3 table I can think of, populating it with a few rows of data, then trying to do a query with an ORDER BY does not yield ordered results.\n\nHere's a cql script:\n\n{noformat}\ncreate keyspace test with strategy_class = 'SimpleStrategy'\n   and strategy_options:replication_factor = 1;\nuse test;\ncreate table moo (a int, b int, c int, primary key (a, b));\n\ninsert into moo (a, b, c) values (123, 12, 3400);\ninsert into moo (a, b, c) values (122, 13, 3500);\ninsert into moo (a, b, c) values (124, 10, 3600);\ninsert into moo (a, b, c) values (121, 11, 3700);\n\nselect * from moo;\nselect * from moo order by b;\n{noformat}\n\nHere is the output of those two queries:\n\n{noformat}\n a   | b  | c\n-----+----+------\n 121 | 11 | 3700\n 122 | 13 | 3500\n 124 | 10 | 3600\n 123 | 12 | 3400\n\n a   | b  | c\n-----+----+------\n 121 | 11 | 3700\n 122 | 13 | 3500\n 124 | 10 | 3600\n 123 | 12 | 3400\n{noformat}\n\nI also tried these using the bare thrift interface, to make sure it wasn't python-cql or cqlsh doing something stupid. Same results. Am I totally missing something important here about how this is supposed to work?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cql3 ORDER BY not ordering"
   },
   {
      "_id": "12554549",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-05-09 19:53:39",
      "description": "CASSANDRA-4142 introduces test failures, that are caused by overlapping tables within a level, which Shouldn't Happen.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "overlapping sstables in leveled compaction strategy"
   },
   {
      "_id": "12553794",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-05-03 16:20:12",
      "description": "It would be interesting to allow accessing the timestamp/ttl of a column though some syntax like\n{noformat}\nSELECT key, value, timestamp(value) FROM foo;\n{noformat}\nand the same for ttl.\n\nI'll note that currently timestamp and ttl are returned in the resultset because it includes thrift Column object, but adding such syntax would make our future protocol potentially simpler as we wouldn't then have to care about timestamps explicitely (and more compact in general as we would only return timestamps when asked)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Easy access to column timestamps (and maybe ttl) during queries"
   },
   {
      "_id": "12553679",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-05-02 22:58:14",
      "description": "It's legitimate to only need the column name in a schema, e.g., system.NodeIdInfo.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "COMPACT STORAGE should not require a value to be aliased"
   },
   {
      "_id": "12553427",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-30 22:03:16",
      "description": "Preparing the following (contrived) statement with the C++ Thrift bindings \nthrows a TTransportException (\"No more data to read.\" from TTransport.h:41)\n\nq = \"begin batch insert into crashtest (id, val) values (?, ?); apply batch\";\nclient.prepare_cql_query(pr, q, Compression::NONE);\n\n{code:title=crashtest.cpp}\n#include <protocol/TBinaryProtocol.h>\n#include <thrift/transport/TSocket.h>\n#include <thrift/transport/TTransportUtils.h>\n#include \"Cassandra.h\"\n\nusing namespace std;\nusing namespace apache::thrift;\nusing namespace apache::thrift::protocol;\nusing namespace apache::thrift::transport;\nusing namespace org::apache::cassandra;\nusing namespace boost;\n\nint main(int argc, char **argv) {\n    shared_ptr<TTransport> socket(new TSocket(\"127.0.0.1\", 9160));\n    shared_ptr<TTransport> transport(new TFramedTransport(socket));\n    shared_ptr<TProtocol> protocol(new TBinaryProtocol(transport));\n\n    CassandraClient client(protocol);\n\n    try {\n        transport->open();\n        client.set_keyspace(\"test1\");\n        client.set_cql_version(\"3.0.0\");\n\n        CqlResult cr;\n        CqlPreparedResult pr;\n\n        // In cqlsh: create table crashtest (id int primary key, val text);\n        const char *q;\n        // q = \"insert into crashtest (id, val) values (?, ?)\"; // This works fine\n        q = \"begin batch insert into crashtest (id, val) values (?, ?); apply batch\";\n\n        client.prepare_cql_query(pr,  q, Compression::NONE);\n\n        vector<string> vtypes = pr.variable_types;\n        vector<string>::iterator it;\n\n        for (it = vtypes.begin(); it != vtypes.end(); it++) {\n            cout << *it << endl;\n        }\n    } catch (TException &tx) {\n        cerr << \"TException ERROR: \" << tx.what() << endl;\n    }\n}\n{code}\n\n{code:title=backtrace}\n#0  0x00007fff901800e9 in __cxa_throw ()\n#1  0x0000000100009ab9 in apache::thrift::transport::readAll<apache::thrift::transport::TBufferBase> (trans=@0x100401100, buf=0x7fff5fbfefc0 \"??_\\001\", len=4) at TTransport.h:41\n#2  0x0000000100009c1d in apache::thrift::transport::TBufferBase::readAll (this=0x100401100, buf=0x7fff5fbfefc0 \"??_\\001\", len=4) at TBufferTransports.h:82\n#3  0x0000000100009c5b in apache::thrift::transport::TFramedTransport::readAll (this=0x100401100, buf=0x7fff5fbfefc0 \"??_\\001\", len=4) at TBufferTransports.h:390\n#4  0x0000000100004b45 in apache::thrift::transport::TVirtualTransport<apache::thrift::transport::TFramedTransport, apache::thrift::transport::TBufferBase>::readAll_virt (this=0x100401100, buf=0x7fff5fbfefc0 \"??_\\001\", len=4) at TVirtualTransport.h:99\n#5  0x00000001000034c1 in apache::thrift::transport::TTransport::readAll (this=0x100401100, buf=0x7fff5fbfefc0 \"??_\\001\", len=4) at TTransport.h:126\n#6  0x0000000100009f4c in apache::thrift::protocol::TBinaryProtocolT<apache::thrift::transport::TTransport>::readI32 (this=0x100401370, i32=@0x7fff5fbff020) at TBinaryProtocol.h:372\n#7  0x000000010000b5bf in apache::thrift::protocol::TBinaryProtocolT<apache::thrift::transport::TTransport>::readMessageBegin (this=0x100401370, name=@0x7fff5fbff228, messageType=@0x7fff5fbff224, seqid=@0x7fff5fbff234) at TBinaryProtocol.h:203\n#8  0x0000000100006b07 in apache::thrift::protocol::TVirtualProtocol<apache::thrift::protocol::TBinaryProtocolT<apache::thrift::transport::TTransport>, apache::thrift::protocol::TProtocolDefaults>::readMessageBegin_virt (this=0x100401370, name=@0x7fff5fbff228, messageType=@0x7fff5fbff224, seqid=@0x7fff5fbff234) at TVirtualProtocol.h:432\n#9  0x00000001000abe78 in apache::thrift::protocol::TProtocol::readMessageBegin (this=0x100401370, name=@0x7fff5fbff228, messageType=@0x7fff5fbff224, seqid=@0x7fff5fbff234) at TProtocol.h:518\n#10 0x0000000100069a98 in org::apache::cassandra::CassandraClient::recv_prepare_cql_query (this=0x7fff5fbff5b0, _return=@0x7fff5fbff4c0) at Cassandra.cpp:10231\n#11 0x000000010003bf3f in org::apache::cassandra::CassandraClient::prepare_cql_query (this=0x7fff5fbff5b0, _return=@0x7fff5fbff4c0, query=@0x7fff5fbff6b0, compression=org::apache::cassandra::Compression::NONE) at Cassandra.cpp:10206\n#12 0x00000001000020ea in main (argc=1, argv=0x7fff5fbff8c8) at crashtest.cpp:36\n{code}\n\n{code:title=server error message}\n\nERROR 17:13:55,089 Error occurred during processing of message.\njava.lang.ArrayIndexOutOfBoundsException: 0\n\tat org.apache.cassandra.cql3.statements.UpdateStatement.prepare(UpdateStatement.java:278)\n\tat org.apache.cassandra.cql3.statements.BatchStatement.prepare(BatchStatement.java:157)\n\tat org.apache.cassandra.cql3.QueryProcessor.getStatement(QueryProcessor.java:207)\n\tat org.apache.cassandra.cql3.QueryProcessor.prepare(QueryProcessor.java:158)\n\tat org.apache.cassandra.thrift.CassandraServer.prepare_cql_query(CassandraServer.java:1260)\n\tat org.apache.cassandra.thrift.Cassandra$Processor$prepare_cql_query.getResult(Cassandra.java:3484)\n\tat org.apache.cassandra.thrift.Cassandra$Processor$prepare_cql_query.getResult(Cassandra.java:3472)\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:32)\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:34)\n\tat org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:186)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:680)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "c++",
         "cql3",
         "thrift"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL 3.0 prepare_cql_query fails on \"BEGIN BATCH\""
   },
   {
      "_id": "12553420",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-04-30 21:28:26",
      "description": "1. Create a single node cluster, use default configuration, use cassandra.bat to start the server:\n\n2. run the following commands in cli:\n{code}\ncreate keyspace toto;\nuse toto;\ncreate column family titi;\ntruncate titi;\n{code}\n\n3. the node dies with this error:\n{code}\nERROR 23:23:02,118 Exception in thread Thread[COMMIT-LOG-ALLOCATOR,5,main]\njava.io.IOError: java.io.IOException: Map failed\n        at org.apache.cassandra.db.commitlog.CommitLogSegment.<init>(CommitLogSegment.java:127)\n        at org.apache.cassandra.db.commitlog.CommitLogSegment.recycle(CommitLogSegment.java:202)\n        at org.apache.cassandra.db.commitlog.CommitLogAllocator$2.run(CommitLogAllocator.java:159)\n        at org.apache.cassandra.db.commitlog.CommitLogAllocator$1.runMayThrow(CommitLogAllocator.java:95)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        at java.lang.Thread.run(Unknown Source)\nCaused by: java.io.IOException: Map failed\n        at sun.nio.ch.FileChannelImpl.map(Unknown Source)\n        at org.apache.cassandra.db.commitlog.CommitLogSegment.<init>(CommitLogSegment.java:119)\n        ... 5 more\nCaused by: java.lang.OutOfMemoryError: Map failed\n        at sun.nio.ch.FileChannelImpl.map0(Native Method)\n        ... 7 more\n INFO 23:23:02,122 Stop listening to thrift clients\n INFO 23:23:02,123 Waiting for messaging service to quiesce\n INFO 23:23:02,125 MessagingService shutting down server thread.\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "commitlog"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Preserve commitlog size cap when recycling segments at startup"
   },
   {
      "_id": "12553104",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-27 07:54:12",
      "description": "This ticket proposes to add a timeuuid type to CQL3. I know that the uuid type does support version 1 UUID (which is fine), but my rational is that time series is a very common use case for Cassandra. But when modeling time series, it seems to me that you'd almost always want to use time uuids rather than timestamps to avoid having to care about collision. In those case, using a timeuuid type would imo have the following advantages over simply uuid:\n# the type convey the idea that this is really a date (but need to avoid collision). In other words, the 'time' in timeuuid has a documentation purpose.\n# it validates that you do only insert a UUID v1. Inserting non-time based UUID when you really care about the time ordering is a important mistake, it's nice to validate this doesn't happen (it's one of the goal of the type after all)\n# it'll allow to parse date values (which TimeUUIDType already does). Since timeuuid is really a date, it's useful and convenient to allow '2012-04-27 11:32:02' as a value.\n\nI'll note that imho there really is no reason not to at least allow 3) and even if there is strong opposition to adding a new timeuuid type (though I don't see why that would be a big deal) we could add the parsing of date to uuid. But I do think personally that 1) and 2) are equally important and warrant the addition of timeuuid (and it'll feel less random to parse date as timeuuid than to do it for uuid).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: improve experience with time uuid"
   },
   {
      "_id": "12552933",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-04-26 19:11:06",
      "description": "tested in 1.1 and trunk branch on a single node:\n{panel}\ncqlsh:test> create table testcf_old ( username varchar , id int , name varchar , stuff varchar, primary key(username,id,name)) with compact storage;\ncqlsh:test> insert into testcf_old ( username , id , name , stuff ) values ('abc', 2, 'rst', 'some other bunch of craps');\ncqlsh:test> select * from testcf_old;\n username | id | name | stuff\n----------+----+------+---------------------------\n      abc |  2 |  rst | some other bunch of craps\n      abc |  4 |  xyz |          a bunch of craps\n\ncqlsh:test> delete from testcf_old where username = 'abc' and id =2;\ncqlsh:test> select * from testcf_old;\n username | id | name | stuff\n----------+----+------+---------------------------\n      abc |  2 |  rst | some other bunch of craps\n      abc |  4 |  xyz |          a bunch of craps\n{panel}\n\nsame also when not using compact:\n{panel}\ncqlsh:test> create table testcf ( username varchar , id int , name varchar , stuff varchar, primary key(username,id));\ncqlsh:test> select * from testcf;\n username | id | name                      | stuff\n----------+----+---------------------------+------------------\n      abc |  2 | some other bunch of craps |              rst\n      abc |  4 |                       xyz | a bunch of craps\n\ncqlsh:test> delete from testcf where username = 'abc' and id =2;\ncqlsh:test> select * from testcf;\n username | id | name                      | stuff\n----------+----+---------------------------+------------------\n      abc |  2 | some other bunch of craps |              rst\n      abc |  4 |                       xyz | a bunch of craps\n{panel}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cql delete does not delete"
   },
   {
      "_id": "12552832",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-26 10:35:43",
      "description": "This ticket proposes to fix two problems of CQL3 index handling:\n# DROP INDEX is broken (because the code forgot to clone the metadata before doing modification which break the schema update path)\n# If an index is created with a name (which CREATE INDEX allow), there is no way to drop the index (note that we will internally assign a name to the index ColumnFamilyStore, but we don't assign a name in the ColumnDefinition object, which is the only one checked by DROP INDEX).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: fix index dropping and assign default name if none provided at index creation"
   },
   {
      "_id": "12552706",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-04-25 19:01:16",
      "description": "Tested on a vanilla single-node cassandra 1.0.9 installation.\n\nWhen using super columns along with row caching via ConcurrentLinkedHashCacheProvider (default if no JNA available, or explicitly configured even if JNA available), there's what appears as transient data loss.\n\nGiven this script executed in cassandra-cli:\n{quote}\ncreate keyspace Test;\nuse Test;\n\ncreate column family Users with column_type='Super' and key_validation_class='UTF8Type' and comparator='UTF8Type' and subcomparator='UTF8Type' and default_validation_class='UTF8Type' and rows_cached=75000 and row_cache_provider='ConcurrentLinkedHashCacheProvider';\n\nset Users['mina']['attrs']['name'] = 'Mina';\nget Users['mina'];\n\nset Users['mina']['attrs']['country'] = 'Canada';\nget Users['mina'];\n\nset Users['mina']['attrs']['region'] = 'Quebec';\nget Users['mina'];\n{quote}\n\nThe output from the 3 gets above is as follows:\n\n{quote}\n=> (super_column=attrs,\n     (column=name, value=Mina, timestamp=1335377788441000))\nReturned 1 results.\n{quote}\n\n{quote}\n=> (super_column=attrs,\n     (column=name, value=Mina, timestamp=1335377788441000))\nReturned 1 results.\n{quote}\n\n{quote}\n=> (super_column=attrs,\n     (column=name, value=Mina, timestamp=1335377788441000))\nReturned 1 results.\n{quote}\n\nIt's clear that the second and third set commands (country, region) are missing in the returned results.\n\nIf the row cache is explicitly invalidated (in a second terminal, via `nodetool -h localhost invalidaterowcache Test Users`), the missing data springs to life on next 'get':\n{quote}\n[default@Test] get Users['mina'];\n=> (super_column=attrs,\n     (column=country, value=Canada, timestamp=1335377839592000)\n     (column=name, value=Mina, timestamp=1335377788441000)\n     (column=region, value=Quebec, timestamp=1335377871353000))\nReturned 1 results.\n{quote}\n\nFrom cursory checks, this does not to appear to happen with regular columns, nor with JNA enabled + SerializingCacheProvider.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ConcurrentLinkedHashCacheProvider",
         "cache",
         "supercolumns"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Apparent data loss using super columns and row cache via ConcurrentLinkedHashCacheProvider"
   },
   {
      "_id": "12552691",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-25 17:30:20",
      "description": "It makes way more sense to have min_compaction_threshold and max_compaction_threshold be parts of the compaction_strategy_options. They are not in thrift (and CQL2) only for historical reasons, but there is no reason not to fix it. Especially given that they don't make sense for all compaction strategy (Leveled compaction ignores them).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: move {max/min}_compaction_thresholds to compaction options"
   },
   {
      "_id": "12552685",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-25 16:01:48",
      "description": "CQL has quite a few keywords. Currently all of them are reserved, but this is not always necessary. PostreSQL for instance distinguish between reserved keywords and non-reserved ones, and allow things like {{key}}, {{timestamp}} or {{type}} as identifiers. I suggest we do the same as convenience for the user.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL3: make some keywords unreserved"
   },
   {
      "_id": "12552645",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-25 13:08:14",
      "description": "The goal of this ticket is to be the home for a number of minor fixes/improvements in CQL3 that I didn't felt warranted a ticket each. It includes 4 patches:\n* The first one fixes the grammar for float constants, so as to not recognize 3.-3, but to actually allow 3. (i.e, with radix point but with the fractional part left blank)\n* The second one correctly detect the (invalid) case where a table is created with COMPACT STORAGE but without any 'clustering keys'.\n* The third one fixes COUNT, first by making sure both COUNT(*) and COUNT(1) are correctly recognized and also by \"processing\" the internal row before counting, are there isn't a 1-to-1 correspondence between internal rows and CQL rows in CQL3. The grammar change in this patch actually rely on CASSANDRA-4184\n* The fourth and last patch disallows the counter type for keys (i.e. any column part of the PRIMARY KEY) as it is completely non-sensical and will only led to confusion.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Minor CQL3 fixes"
   },
   {
      "_id": "12552639",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-25 12:46:27",
      "description": "The current grammar for CQL3 allows:\n# uuid and integer constants as identifiers\n# identifier as value (aka term in the grammar)\n\nI think both of those should be removed.\n\nFor 1, mostly because this feels useless and slightly complicates the grammar which is annoying for the documentation of CQL3 for instance (note that this doesn't mean forbidding integer or uuid as identifier, but means they have to be double-quoted when used as such).\nFor 2, I think that allowing identifier as value is actually misleading, typically if you write things like {{SELECT foo WHERE foo=foo}}. It suggests we support JOIN when we do not.\n\nAlso, if both are done, then one will always be able to distinguish between identifier and value even without any context, which is a nice property.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Make identifier and value grammar for CQL3 stricter"
   },
   {
      "_id": "12551799",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-04-20 15:00:36",
      "description": "LazilyCompactedRow reads all data twice to compact a row which is obviously inefficient. The main reason we do that is to compute the row header. However, CASSANDRA-2319 have removed the main part of that row header. What remains is the size in bytes and the number of columns, but it should be relatively simple to remove those, which would then remove the need for the two-phase compaction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Single-pass compaction for LCR"
   },
   {
      "_id": "12551750",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-20 09:02:08",
      "description": "Currently CQL3 have a nice syntax for using composites in the column name (it's more than that in fact, it creates a whole new abstraction but let's say I'm talking implementation here). There is however 2 other place where composites could be used (again implementation wise): the row key and the column value. This ticket proposes to explore which of those make sense for CQL3 and how.\n\nFor the row key, I really think that CQL support makes sense. It's very common (and useful) to want to stuff composite information in a row key. Sharding a time serie (CASSANDRA-4176) is probably the best example but there is other.\n\nFor the column value it is less clear. CQL3 makes it very transparent and convenient to store multiple related values into multiple columns so maybe composites in a column value is much less needed. I do still see two cases for which it could be handy:\n# to save some disk/memory space, if you do know it makes no sense to insert/read two value separatly.\n# if you want to enforce that two values should not be inserted separatly. I.e. to enforce a form of \"constraint\" to avoid programatic error.\n\nThose are not widely useful things, but my reasoning is that if whatever syntax we come up for \"grouping\" row key in a composite trivially extends to column values, why not support it.\n\n\nAs for syntax I have 3 suggestions (that are just that, suggestions):\n# If we only care about allowing grouping for row keys:\n{noformat}\nCREATE TABLE timeline (\n    name text,\n    month int,\n    ts timestamp,\n    value text,\n    PRIMARY KEY ((name, month), ts)\n)\n{noformat}\n# A syntax that could work for both grouping in row key and colum value:\n{noformat}\nCREATE TABLE timeline (\n    name text,\n    month int,\n    ts timestamp,\n    value1 text,\n    value2 text,\n    GROUP (name, month) as key,\n    GROUP (value1, value2),\n    PRIMARY KEY (key, ts)\n)\n{noformat}\n# An alternative to the preceding one:\n{noformat}\nCREATE TABLE timeline (\n    name text,\n    month int,\n    ts timestamp,\n    value1 text,\n    value2 text,\n    GROUP (name, month) as key,\n    GROUP (value1, value2),\n    PRIMARY KEY (key, ts)\n) WITH GROUP (name, month) AS key\n   AND GROUP (value1, value2)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add more general support for composites (to row key, column value)"
   },
   {
      "_id": "12551531",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-18 21:01:39",
      "description": "running the following with cql3:\n\n{noformat}\nCREATE TABLE test (foo text PRIMARY KEY) WITH default_validation=timestamp;\nALTER TABLE test WITH default_validation=int;\n{noformat}\n\ndoes not actually change the default validation type of the CF. It does under cql2.\n\nNo error is thrown. Some properties *can* be successfully changed using ALTER WITH, such as comment and gc_grace_seconds, but I haven't tested all of them. It seems probable that default_validation is the only problematic one, since it's the only (changeable) property which accepts CQL typenames.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cql3 ALTER TABLE foo WITH default_validation=int has no effect"
   },
   {
      "_id": "12551529",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-18 20:57:07",
      "description": "running the following with cql3:\n\n{noformat}\nCREATE TABLE test (foo text PRIMARY KEY, bar int);\nALTER TABLE test ALTER bar TYPE float;\n{noformat}\n\ndoes not actually change the column type of bar. It does under cql2.\n\nNote that on the current cassandra-1.1.0 HEAD, this causes an NPE, fixed by CASSANDRA-4163. But even with that applied, the ALTER shown here has no effect.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cql3 ALTER TABLE ALTER TYPE has no effect"
   },
   {
      "_id": "12551356",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-04-18 06:18:04",
      "description": "We use the generated *Digest.sha1-files to verify backups, would be nice if they were generated for compressed sstables as well.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Generate Digest file for compressed SSTables"
   },
   {
      "_id": "12551206",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-04-17 12:06:49",
      "description": "When issuing a cql select statement with an ORDER BY ... DESC clause the comparison predicates in the WHERE clause gets reversed. \n\nExample: (see also attached)\n\nSELECT number FROM test WHERE number < 3 ORDER BY number DESC\n\nreturns the results expected of WHERE number > 3",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "ORDER BY ... DESC reverses comparrison predicates in WHERE"
   },
   {
      "_id": "12550633",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-04-12 07:26:11",
      "description": "We encountered an OOM Exception on 2 nodes during repair session.\nOur CF are set up to use LeveledCompactionStrategy and SnappyCompressor.\nThese two options used together maybe the key to the problem.\n\nDespite of setting XX:+HeapDumpOnOutOfMemoryError, no dump have been generated.\nNonetheless a memory analysis on a live node doing a repair reveals an hotspot: an ArrayList of SSTableBoundedScanner which appears to contain as many objects as there are SSTables on disk. \nThis ArrayList consumes 786 MB of the heap space for 5757 objects. Therefore each object is about 140 KB.\n\nEclipse Memory Analyzer's denominator tree shows that 99% of a SSTableBoundedScanner object's memory is consumed by a CompressedRandomAccessReader which contains two big byte arrays.\n\nCluster information:\n9 nodes\nEach node handles 35 GB (RandomPartitioner)\n\nThis JIRA was created following this discussion:\nhttp://cassandra-user-incubator-apache-org.3065146.n2.nabble.com/Why-so-many-SSTables-td7453033.html\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "OOM Exception during repair session with LeveledCompactionStrategy"
   },
   {
      "_id": "12549262",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-04-03 00:18:48",
      "description": "We just recently started using version 1.0.9, previously we were using tiered compaction because of a bug in 1.0.8 (not letting us use leveled compaction) and now since moving to 1.0.9 we have started using leveled compaction.\n\nTrying to do a cleanup we are getting the following exception:\n\nroot@test:~# nodetool -h localhost cleanup \nError occured during cleanup\njava.util.concurrent.ExecutionException: java.util.NoSuchElementException\n        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)\n        at java.util.concurrent.FutureTask.get(FutureTask.java:111)\n        at org.apache.cassandra.db.compaction.CompactionManager.performAllSSTableOperation(CompactionManager.java:204)\n        at org.apache.cassandra.db.compaction.CompactionManager.performCleanup(CompactionManager.java:240)\n        at org.apache.cassandra.db.ColumnFamilyStore.forceCleanup(ColumnFamilyStore.java:988)\n        at org.apache.cassandra.service.StorageService.forceTableCleanup(StorageService.java:1639)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:616)\n        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:111)\n        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:45)\n        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:226)\n        at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)\n        at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:251)\n        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:857)\n        at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:795)\n        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1450)\n        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:90)\n        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1285)\n        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1383)\n        at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:807)\n        at sun.reflect.GeneratedMethodAccessor31.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:616)\n        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)\n        at sun.rmi.transport.Transport$1.run(Transport.java:177)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at sun.rmi.transport.Transport.serviceCall(Transport.java:173)\n        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:553)\n        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:808)\n        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:667)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:636)\nCaused by: java.util.NoSuchElementException\n        at java.util.ArrayList$Itr.next(ArrayList.java:757)\n        at org.apache.cassandra.db.compaction.LeveledManifest.replace(LeveledManifest.java:196)\n        at org.apache.cassandra.db.compaction.LeveledCompactionStrategy.handleNotification(LeveledCompactionStrategy.java:147)\n        at org.apache.cassandra.db.DataTracker.notifySSTablesChanged(DataTracker.java:495)\n        at org.apache.cassandra.db.DataTracker.replaceCompactedSSTables(DataTracker.java:235)\n        at org.apache.cassandra.db.ColumnFamilyStore.replaceCompactedSSTables(ColumnFamilyStore.java:1010)\n        at org.apache.cassandra.db.compaction.CompactionManager.doCleanupCompaction(CompactionManager.java:802)\n        at org.apache.cassandra.db.compaction.CompactionManager.access$300(CompactionManager.java:64)\n        at org.apache.cassandra.db.compaction.CompactionManager$5.perform(CompactionManager.java:244)\n        at org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:183)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n\ncheers,\nShoaib",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "nodetool cleanup giving exception"
   },
   {
      "_id": "12548428",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-03-28 03:13:43",
      "description": "We log that mlockall() was successful only based on the lack of an assertion failure, so for anyone running w/o {{-ea}} we are lying about mlockall() succeeding.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "jna"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "mlockall() returned code is ignored w/o assertions"
   },
   {
      "_id": "12547849",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-03-23 18:15:29",
      "description": "shouldPurge in particular is still a performance sore point with LCS.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Cut down on the comparisons needed during shouldPurge and needDeserialize"
   },
   {
      "_id": "12547839",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-03-23 17:31:33",
      "description": "Before running a cleanup compaction on an SSTable we should check the range to see if the SSTable falls into the range we want to remove. If it doesn't we can just mark the SSTable as compacted and be done with it, if it does, we can no-op.\n\nWill not help with STCS, but for LCS, and perhaps some others we may see a benefit here after topology changes.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Check SSTable range before running cleanup"
   },
   {
      "_id": "12546471",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328221",
            "id": "12328221",
            "name": "Legacy/Local Write-Read Paths",
            "description": "Memtables, Commitlog, SSTables, CDC, Key and Row Caches, Low-Level Disk I/O"
         }
      ],
      "created": "2012-03-14 20:22:30",
      "description": "On Windows w/older java I/O libraries the files are not opened with FILE_SHARE_DELETE.  This causes problems as hard-links cannot be deleted while the original file is opened - our snapshots are a big problem in particular.  The nio library and FileChannels open with FILE_SHARE_DELETE which should help remedy this problem.\n\nOriginal text:\nI'm using Cassandra 1.0.8, on Windows 7.  When I take a snapshot of the database, I find that I am unable to delete the snapshot directory (i.e., dir named \"{datadir}\\{keyspacename}\\snapshots\\{snapshottag}\") while Cassandra is running:  \"The action can't be completed because the folder or a file in it is open in another program.  Close the folder or file and try again\" [in Windows Explorer].  If I terminate Cassandra, then I can delete the directory with no problem.\n\nI expect to be able to move or delete the snapshotted files while Cassandra is running, as this should not affect the runtime operation of Cassandra.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Rewrite RandomAccessReader to use FileChannel / nio to address Windows file access violations"
   },
   {
      "_id": "12545902",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-03-09 20:33:47",
      "description": "The first section in the help is in alphabetical order, but not the second part:\n\n{code}\nMiscellaneous help topics:\n==========================\nDROP_INDEX                 CREATE                       DELETE_WHERE       \nALTER_DROP                 DROP_KEYSPACE                UPDATE_USING       \nSELECT_EXPR                ALTER_ALTER                  UPDATE_WHERE       \nUUID_INPUT                 TYPES                        TIMESTAMP_OUTPUT   \nDELETE_COLUMNS             SELECT_COLUMNFAMILY          CONSISTENCYLEVEL   \nALTER_ADD                  CREATE_COLUMNFAMILY_OPTIONS  CREATE_INDEX       \nALTER_WITH                 BEGIN                        CREATE_KEYSPACE    \nAPPLY                      UPDATE_SET                   ASCII_OUTPUT       \nDELETE_USING               UPDATE_COUNTERS              DROP               \nCREATE_COLUMNFAMILY_TYPES  TRUNCATE                     TIMESTAMP_INPUT    \nDROP_COLUMNFAMILY          INSERT                       ALTER              \nBLOB_INPUT                 TEXT_OUTPUT                  CREATE_COLUMNFAMILY\nSELECT_WHERE               UPDATE                       DELETE             \nBOOLEAN_INPUT              SELECT_LIMIT\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql",
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh: Alphabetize the \"Miscellaneous Help Topics\" section"
   },
   {
      "_id": "12544881",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-03-02 03:21:57",
      "description": "1.0.7 + LeveledCompactionStrategy\nIf you run nodetool cleanup, scrub, or upgradesstables, Cassandra execute compaction for each sstable. During the compaction, it put the new sstable to next level of the original sstable. If you run cleanup many times, sstables will reached to the highest level, and CASSANDRA-3608 will happens at next cleanup.\n\nReproduce procedure:\n# create column family CF1 with compaction_strategy=LeveledCompactionStrategy and compaction_strategy_options={sstable_size_in_mb: 5};\n# Insert some data into CF1.\n# nodetool flush\n# Verify the sstable is created at L1 in CF1.json\n# nodetool cleanup\n# Verify sstable in L1 is removed and new sstable is created at L2 in CF1.json\n# repeat nodetool cleanup some times",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "nodetool cleanup/scrub/upgradesstables promotes all sstables to next level (LeveledCompaction)"
   },
   {
      "_id": "12544647",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-02-29 17:27:37",
      "description": "This ticket proposes to remove range ghosts in CQL3.\nThe basic argument is that range ghosts confuses users a lot and don't add any value since range ghost don't allow to distinguish between the two following case:\n* the row is deleted\n* the row is not deleted but don't have data for the provided filter",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Explore not returning range ghosts"
   },
   {
      "_id": "12544643",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-02-29 16:33:11",
      "description": "In CreateColumnFamilyStatement, we do\n{noformat}\ncatch (ConfigurationException e)\n{\n    throw new InvalidRequestException(e.toString());\n}\n{noformat}\n\nThis result in having the exception message looking like:\n{noformat}\njava.sql.SQLSyntaxErrorException: org.apache.cassandra.config.ConfigurationException: Cf1 already exists in keyspace Keyspace1\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't include original exception class name in CQL message"
   },
   {
      "_id": "12544623",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-02-29 14:15:51",
      "description": "It could be a good idea to assign documented error code for the different exception raised. Currently, one may have to parse the exception string (say if one wants to know if its 'create keyspace' failed because the keyspace already exists versus other kind of exception), but it means we cannot improve the error message at the risk of breaking client code. Adding documented error codes with the message would avoid this.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Consider providing error code with exceptions (and documenting them)"
   },
   {
      "_id": "12544447",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-02-28 16:51:15",
      "description": "If hints have accumulated for a CF that has been deleted, Hinted Handoff repeatedly fails until manual intervention removes those hints. For 1.0.7, UnserializableColumnFamilyException is thrown only when a CFid is unknown on the sending node. As discussed on #cassandra-dev, if the schema is in agreement, the affected hint(s) should be deleted to avoid indefinite repeat failures.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "datastax_qa"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Hints Should Be Dropped When Missing CFid Implies Deleted ColumnFamily"
   },
   {
      "_id": "12544067",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-02-24 22:39:21",
      "description": "{code}\n.       // sleep a random amount to stagger handoff delivery from different replicas.\n        // (if we had to wait, then gossiper randomness took care of that for us already.)\n        if (waited == 0)\n        {\n            // use a 'rounded' sleep interval because of a strange bug with windows: CASSANDRA-3375\n            int sleep = FBUtilities.threadLocalRandom().nextInt(2000) * 30;\n            logger_.debug(\"Sleeping {}ms to stagger hint delivery\", sleep);\n            Thread.sleep(sleep);\n        }\n{code}\n\nThis is obsolete now that we have the per-hint configurable delay.  And large hint loads (which are the ones that matter most) are going to overlap anyway even with the maximum 60s difference.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "hintedhandoff"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Remove random HH delay"
   },
   {
      "_id": "12544061",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-02-24 21:51:28",
      "description": "As reported at http://mail-archives.apache.org/mod_mbox/cassandra-user/201202.mbox/%3CCADJL=w5kH5TEQXOwhTn5Jm3cmR4Rj=NfjcqLryXV7pLyASi95A@mail.gmail.com%3E,\n\n{noformat}\nERROR 10:51:44,282 Fatal exception in thread\nThread[COMMIT-LOG-WRITER,5,main]\njava.lang.AssertionError: Final buffer length 4690 to accomodate data size\nof 2347 (predicted 2344) for RowMutation(keyspace='Player',\nkey='36336138643338652d366162302d343334392d383466302d356166643863353133356465',\nmodifications=[ColumnFamily(PlayerCity [SuperColumn(owneditem_1019\n[]),SuperColumn(owneditem_1024 []),SuperColumn(owneditem_1026\n[]),SuperColumn(owneditem_1074 []),SuperColumn(owneditem_1077\n[]),SuperColumn(owneditem_1084 []),SuperColumn(owneditem_1094\n[]),SuperColumn(owneditem_1130 []),SuperColumn(owneditem_1136\n[]),SuperColumn(owneditem_1141 []),SuperColumn(owneditem_1142\n[]),SuperColumn(owneditem_1145 []),SuperColumn(owneditem_1218\n[636f6e6e6563746564:false:5@1329648704269002\n,63757272656e744865616c7468:false:3@1329648704269006\n,656e64436f6e737472756374696f6e54696d65:false:13@1329648704269007\n,6964:false:4@1329648704269000,6974656d4964:false:15@1329648704269001\n,6c61737444657374726f79656454696d65:false:1@1329648704269008\n,6c61737454696d65436f6c6c6563746564:false:13@1329648704269005\n,736b696e4964:false:7@1329648704269009,78:false:4@1329648704269003\n,79:false:3@1329648704269004,]),SuperColumn(owneditem_133\n[]),SuperColumn(owneditem_134 []),SuperColumn(owneditem_135\n[]),SuperColumn(owneditem_141 []),SuperColumn(owneditem_147\n[]),SuperColumn(owneditem_154 []),SuperColumn(owneditem_159\n[]),SuperColumn(owneditem_171 []),SuperColumn(owneditem_253\n[]),SuperColumn(owneditem_422 []),SuperColumn(owneditem_438\n[]),SuperColumn(owneditem_515 []),SuperColumn(owneditem_521\n[]),SuperColumn(owneditem_523 []),SuperColumn(owneditem_525\n[]),SuperColumn(owneditem_562 []),SuperColumn(owneditem_61\n[]),SuperColumn(owneditem_634 []),SuperColumn(owneditem_636\n[]),SuperColumn(owneditem_71 []),SuperColumn(owneditem_712\n[]),SuperColumn(owneditem_720 []),SuperColumn(owneditem_728\n[]),SuperColumn(owneditem_787 []),SuperColumn(owneditem_797\n[]),SuperColumn(owneditem_798 []),SuperColumn(owneditem_838\n[]),SuperColumn(owneditem_842 []),SuperColumn(owneditem_847\n[]),SuperColumn(owneditem_849 []),SuperColumn(owneditem_851\n[]),SuperColumn(owneditem_852 []),SuperColumn(owneditem_853\n[]),SuperColumn(owneditem_854 []),SuperColumn(owneditem_857\n[]),SuperColumn(owneditem_858 []),SuperColumn(owneditem_874\n[]),SuperColumn(owneditem_884 []),SuperColumn(owneditem_886\n[]),SuperColumn(owneditem_908 []),SuperColumn(owneditem_91\n[]),SuperColumn(owneditem_911 []),SuperColumn(owneditem_930\n[]),SuperColumn(owneditem_934 []),SuperColumn(owneditem_937\n[]),SuperColumn(owneditem_944 []),SuperColumn(owneditem_945\n[]),SuperColumn(owneditem_962 []),SuperColumn(owneditem_963\n[]),SuperColumn(owneditem_964 []),])])\n        at org.apache.cassandra.utils.FBUtilities.serialize(FBUtilities.java:682)\n        at org.apache.cassandra.db.RowMutation.getSerializedBuffer(RowMutation.java:279)\n        at org.apache.cassandra.db.commitlog.CommitLogSegment.write(CommitLogSegment.java:122)\n        at org.apache.cassandra.db.commitlog.CommitLog$LogRecordAdder.run(CommitLog.java:599)\n        at org.apache.cassandra.db.commitlog.PeriodicCommitLogExecutorService$1.runMayThrow(PeriodicCommitLogExecutorService.java:49)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        at java.lang.Thread.run(Thread.java:662)\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "datastax_qa"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Supercolumn serialization assertion failure"
   },
   {
      "_id": "12543576",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-02-21 22:00:15",
      "description": "Or at least it should be marked deprecated somehow.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "thrift_protocol"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "mergeShardsChance deprecated; remove from thrift?"
   },
   {
      "_id": "12542719",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2012-02-15 17:28:53",
      "description": "Dropping a column should:\n\n- immediately make it unavailable for {{SELECT}}, including {{SELECT *}}\n- eventually (i.e., post-compaction) reclaim the space formerly used by that column\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "compaction",
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Dropping a column should do more than just remove the definition"
   },
   {
      "_id": "12540203",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-01-27 22:04:26",
      "description": "Should only snapshot the CF being compacted",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "snapshot-before-compaction snapshots entire keyspace"
   },
   {
      "_id": "12540197",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-01-27 21:30:57",
      "description": "cqlsh's ASSUME command currently only changes how query *return* values are deserialized, and never transforms user CQL text before sending to Cassandra.\n\nApparently cassandra-cli also changes how values are interpreted and marshaled for Cassandra, so user expectation is that cqlsh should also do this.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh: ASSUME should also change how values are sent to cassandra"
   },
   {
      "_id": "12539978",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-01-26 23:47:29",
      "description": "KsDef.replication_factor is superceded by KsDef.strategy_options, but we've been keeping special-case code around to populate the old r_f field for SimpleStrategy so that pre-0.8 clients can still create and introspect the schema.  Time to clean that up.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "thrift"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "remove deprecated KsDef.replication_factor field"
   },
   {
      "_id": "12539918",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-01-26 15:57:01",
      "description": "Current code don't allow doing a query by names on wide rows (compact CF). I.e. with:\n{noformat}\nCREATE TABLE test1 (\n    k int,\n    c int,\n    v int,\n    PRIMARY KEY (k, c)\n) WITH COMPACT STORAGE;\n{noformat}\nyou cannot do:\n{noformat}\nSELECT v FROM test1 WHERE k = 0 AND c IN (5, 2, 8)\n{noformat}\neven though this is a simple name query.\n\nThis ticket proposes to allow it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Support query by names for compact CF"
   },
   {
      "_id": "12539808",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-01-25 18:54:21",
      "description": "Currently, slices are always start and end inclusive. However, for CQL 3.0, we already differenciate between inclusivity/exclusivity for the row key and for the component of composite columns. It would be nice to always support that distinction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Support slice with exclusive start and stop"
   },
   {
      "_id": "12539699",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-01-25 00:17:56",
      "description": "There is currently no way to alter the key_validation_class from CQL. jbellis suggested that this could be done by being able to ALTER the type of the KEY alias.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL support for changing row key type in ALTER TABLE"
   },
   {
      "_id": "12539666",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-01-24 20:47:47",
      "description": "The language doc ({{doc/cql/CQL.textile}}) needs to be forked for CQLv3 and updated accordingly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "need forked language document"
   },
   {
      "_id": "12539665",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-01-24 20:45:27",
      "description": "{{...KEY IN (...)}} queries fail due to faulty validation.  A pull request for cassandra-dtest was opened that demonstrates this: https://github.com/riptano/cassandra-dtest/pull/2",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "KEY IN (...) queries do not work"
   },
   {
      "_id": "12539478",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-01-23 14:33:42",
      "description": "CQL < 3 silently turns a \"key >= X\" into \"token(key) >= token(X)\".  This is not what users will expect, since many of the rows returned will not in fact satisfy the requested key inequality.  We should add syntax that makes the difference between keys and tokens explicit, possibly with a token() \"function\" as imagined here.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow paging through non-ordered partitioner results in CQL3"
   },
   {
      "_id": "12539274",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-01-21 06:05:16",
      "description": "{noformat}\n12/01/21 06:03:16 WARN mapred.LocalJobRunner: job_local_0001\njava.lang.NullPointerException\n        at org.apache.cassandra.utils.FBUtilities.newPartitioner(FBUtilities.java:407)\n        at org.apache.cassandra.hadoop.ConfigHelper.getOutputPartitioner(ConfigHelper.java:384)\n        at org.apache.cassandra.client.RingCache.<init>(RingCache.java:58)\n        at org.apache.cassandra.hadoop.ColumnFamilyRecordWriter.<init>(ColumnFamilyRecordWriter.java:99)\n        at org.apache.cassandra.hadoop.ColumnFamilyRecordWriter.<init>(ColumnFamilyRecordWriter.java:93)\n        at org.apache.cassandra.hadoop.ColumnFamilyOutputFormat.getRecordWriter(ColumnFamilyOutputFormat.java:132)\n        at org.apache.cassandra.hadoop.ColumnFamilyOutputFormat.getRecordWriter(ColumnFamilyOutputFormat.java:62)\n        at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:553)\n        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:408)\n{noformat}\n\n(Output to filesystem still works.)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hadoop"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "hadoop word count example is unable to output to cassandra with default settings"
   },
   {
      "_id": "12539160",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-01-20 16:14:28",
      "description": "This ticket is a reformulation/generalization of CASSANDRA-2474. The core change of CQL 3.0 is to introduce the new syntaxes that were discussed in CASSANDRA-2474 that allow to:\n# Provide a better/more native support for wide rows, using the idea of transposed vie.\n# The generalization to composite columns.\n\nThe attached text file create_cf_syntaxes.txt recall the new syntaxes introduced.\n\nThe changes proposed above allow (and strongly suggest in some cases) a number of other changes to the language that this ticket proposes to explore/implement (more details coming in the comments).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL 3.0"
   },
   {
      "_id": "12539040",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-01-19 21:15:06",
      "description": "With CASSANDRA-3726, cqlsh now formats some types of query result data to be more human-readable, such as timestamps and hex data. The format of timestamps and the precision of floating point values should be configurable by cqlshrc and/or command line.\n\nsee the {{Shell.display_time_format}} and {{Shell.display_float_precision}} attributes.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh: allow configuration of value display formats"
   },
   {
      "_id": "12538863",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2012-01-18 19:02:19",
      "description": "As discussed on CASSANDRA-3634, adding type information to a prepared statement would allow more client-side error checking.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Update CqlPreparedResult to provide type information"
   },
   {
      "_id": "12538739",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-01-18 05:19:30",
      "description": "In CommitLog.recover, there seems to be the possibility of concurrent inserts to tablesRecovered (a HashSet) in the Runnables instantiated a bit below (line 323 in 1.0.7). This apparently happened during a commit log playback during startup of a node that had not shut down cleanly (the cluster was under heavy load previously and there were several gigabytes of commit logs), resulting in two threads running in perpetuity (2 cores were at 100% from running these threads), preventing the node from coming up. The relevant portion of the stack trace is:\n\n{noformat}\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \"MutationStage:25\" prio=10 tid=0x00002aaad01e0800 nid=0x6f62 runnable [0x0000000044d54000]\nINFO   | jvm 1    | 2012/01/16 16:54:42 |    java.lang.Thread.State: RUNNABLE\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.HashMap.put(HashMap.java:374)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.HashSet.add(HashSet.java:200)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat org.apache.cassandra.db.commitlog.CommitLog$2.runMayThrow(CommitLog.java:338)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.lang.Thread.run(Thread.java:662)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \nINFO   | jvm 1    | 2012/01/16 16:54:42 | \"MutationStage:21\" prio=10 tid=0x00002aaad00a2800 nid=0x6f5e runnable [0x0000000044950000]\nINFO   | jvm 1    | 2012/01/16 16:54:42 |    java.lang.Thread.State: RUNNABLE\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.HashMap.put(HashMap.java:374)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.HashSet.add(HashSet.java:200)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat org.apache.cassandra.db.commitlog.CommitLog$2.runMayThrow(CommitLog.java:338)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\nINFO   | jvm 1    | 2012/01/16 16:54:42 | \tat java.lang.Thread.run(Thread.java:662)\n\n{noformat}\n\nThe most recently modified file in the commit log directory was this entry:\n{noformat}\n-rw-r----- 1 <redacted> <redacted>    0 Jan 16 16:03 CommitLog-1326758622599.log\n{noformat}\nthough I'm not sure if this was related or not. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "commitlog"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Possible livelock during commit log playback"
   },
   {
      "_id": "12537925",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-01-10 17:36:49",
      "description": "As explained in CASSANDRA-3579, isMarkedForDelete() depends on the current system clock so it can change during a two-pass compaction.  Suggested fix is to replace iMFD + gLDT with a getExpirationTime method, so comparison with the compaction's gcBefore will remain constant.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Clean up isMarkedForDelete / getLocalDeletionTime"
   },
   {
      "_id": "12537700",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-01-08 23:46:40",
      "description": "With multithreaded compaction enabled, it looks like Reducer creates a new thread pool for every compaction.  These pools seem to just sit around - i.e. \"executor.shutdown()\" never gets called and the Threads live forever waiting for tasks that will never come.  For instance...\n\n\nName: CompactionReducer:1\nState: TIMED_WAITING on java.util.concurrent.SynchronousQueue$TransferStack@72938aea\nTotal blocked: 0  Total waited: 1\n\nStack trace: \n sun.misc.Unsafe.park(Native Method)\njava.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\njava.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)\njava.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:359)\njava.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:942)\njava.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\njava.lang.Thread.run(Thread.java:722)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "memory_leak",
         "threading",
         "threads"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Unsustainable Thread Accumulation in ParallelCompactionIterable.Reducer ThreadPoolExecutor"
   },
   {
      "_id": "12537433",
      "assignee": "jbellis",
      "components": [],
      "created": "2012-01-05 22:43:06",
      "description": "currently StatusLogger log:\n{noformat}\nlogger.info(String.format(\"%-25s%10s%10s\",\n                                  \"CompactionManager\", \"n/a\", CompactionManager.instance.getPendingTasks()));\n{noformat}\n\nIt'd be great if it could actually log the number of active tasks being processed. Without looking into the code, I thought there was no compaction running when reading the log.\n\n\n{code: title=CompactionManager.java}\n    public int getActiveCompactions()\n    {\n        return CompactionExecutor.compactions.size();\n    }\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "log Compaction Active tasks in StatusLogger instead of n/a"
   },
   {
      "_id": "12537183",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2012-01-04 12:53:28",
      "description": "during scrub:\n\nEvery 2.0s: for i in 1 2 3; do nodetool -h 192.168.2.$i compactionstats; done                                                                                                                                     Wed Jan  4 13:48:13 2012\n\npending tasks: 2147483646\n          compaction type        keyspace   column family bytes compacted     bytes total  progress\n               Compaction         Archive        Messages     28034971475     72393139120    38.73%\npending tasks: -2147483647\n          compaction type        keyspace   column family bytes compacted     bytes total  progress\n               Compaction         Archive        Messages     24575687282     72385305067    33.95%\npending tasks: 0\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "strange values of pending tasks with compactionstats (below 0)"
   },
   {
      "_id": "12537079",
      "assignee": "slebresne",
      "components": [],
      "created": "2012-01-03 17:01:44",
      "description": "LeveledManifest constructor has the following code:\n\n{code}\nfor (int i = 0; i < generations.length; i++)\n{\n    generations[i] = new ArrayList<SSTableReader>();\n    lastCompactedKeys[i] = new DecoratedKey(cfs.partitioner.getMinimumToken(), null);\n}\n{code}\n\nBut in the DecoratedKey constructor we have:\n\n{code}\nassert token != null && key != null && key.remaining() > 0;\n{code}\n\nso when you tried to create a CF with LeveledCompressionStrategy that will result in \n\n{noformat}\njava.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n\tat org.apache.cassandra.thrift.CassandraServer.applyMigrationOnStage(CassandraServer.java:865)\n\tat org.apache.cassandra.thrift.CassandraServer.system_add_keyspace(CassandraServer.java:953)\n\tat org.apache.cassandra.thrift.Cassandra$Processor$system_add_keyspace.process(Cassandra.java:4103)\n\tat org.apache.cassandra.thrift.Cassandra$Processor.process(Cassandra.java:3078)\n\tat org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:188)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:680)\nCaused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n\tat java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:83)\n\tat org.apache.cassandra.thrift.CassandraServer.applyMigrationOnStage(CassandraServer.java:857)\n\t... 7 more\nCaused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n\tat org.apache.cassandra.config.CFMetaData.createCompactionStrategyInstance(CFMetaData.java:770)\n\tat org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:209)\n\tat org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:300)\n\tat org.apache.cassandra.db.ColumnFamilyStore.createColumnFamilyStore(ColumnFamilyStore.java:281)\n\tat org.apache.cassandra.db.Table.initCf(Table.java:339)\n\tat org.apache.cassandra.db.Table.<init>(Table.java:288)\n\tat org.apache.cassandra.db.Table.open(Table.java:117)\n\tat org.apache.cassandra.db.migration.AddKeyspace.applyModels(AddKeyspace.java:72)\n\tat org.apache.cassandra.db.migration.Migration.apply(Migration.java:156)\n\tat org.apache.cassandra.thrift.CassandraServer$2.call(CassandraServer.java:850)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\t... 3 more\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n\tat org.apache.cassandra.config.CFMetaData.createCompactionStrategyInstance(CFMetaData.java:752)\n\t... 14 more\nCaused by: java.lang.AssertionError\n\tat org.apache.cassandra.db.DecoratedKey.<init>(DecoratedKey.java:55)\n\tat org.apache.cassandra.db.compaction.LeveledManifest.<init>(LeveledManifest.java:79)\n\tat org.apache.cassandra.db.compaction.LeveledManifest.create(LeveledManifest.java:85)\n\tat org.apache.cassandra.db.compaction.LeveledCompactionStrategy.<init>(LeveledCompactionStrategy.java:74)\n\t... 19 more\nERROR 19:52:44,029 Fatal exception in thread Thread[MigrationStage:1,5,main]\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "LeveledCompactionStrategy is broken because of generation pre-allocation in LeveledManifest."
   },
   {
      "_id": "12536553",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-12-29 03:03:36",
      "description": "HintedHandOffManager attempts to prevent multiple threads sending hints to the same target with the queuedDeliveries set, but the code is buggy.  If two handoffs *do* occur concurrently, the second thread can use an arbitrarily large amount of memory skipping tombstones when it starts paging from the beginning of the hint row, looking for the first live hint.  (This is not a problem with a single thread, since it always pages starting with the last-seen hint column name, effectively skipping the tombstones.  Then it compacts when it's done.)\n\nTechnically this bug is present in all older Cassandra releases, but it only causes problems in 1.0.x since the hint rows tend to be much larger (since there is one hint per write containing the entire mutation, instead of just one per row consisting of just the key).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hintedhandoff"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Multiple threads can attempt hint handoff to the same target"
   },
   {
      "_id": "12536532",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2011-12-28 21:20:53",
      "description": "CASSANDRA-2474 and CASSANDRA-3647 add the ability to transpose wide rows differently, for efficiency and functionality secondary index api needs to be altered to allow composite indexes.  \n\nI think this will require the IndexManager api to have a maybeIndex(ByteBuffer column) method that SS can call and implement a PerRowSecondaryIndex per column, break the composite into parts and index specific bits, also including the base rowkey.\n\nThen a search against a TRANSPOSED row or DOCUMENT will be possible.\n\n ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql3",
         "secondary_index"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Add Support for Composite Secondary Indexes"
   },
   {
      "_id": "12536306",
      "assignee": "joshuamckenzie",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2011-12-23 19:16:39",
      "description": "One of my colleague had reported the bug regarding the degraded performance of the sstable generator and sstable loader.\nISSUE :- https://issues.apache.org/jira/browse/CASSANDRA-3589 \nAs stated in above issue generator performance is rectified but performance of the sstableloader is still an issue.\n\n3589 is marked as duplicate of 3618.Both issues shows resolved status.But the problem with sstableloader still exists.\n\nSo opening other issue so that sstbleloader problem should not go unnoticed.\n\nFYI : We have tested the generator part with the patch given in 3589.Its Working fine.\n\nPlease let us know if you guys require further inputs from our side.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "streaming"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Parallel streaming for sstableloader"
   },
   {
      "_id": "12536283",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-12-23 13:09:42",
      "description": "When column family compaction strategy is changed from Leveled to SizeTiered and there're Leveled compaction tasks pending, Cassandra starting to flood in logs with thousands per sec messages:\n\nNothing to compact in ColumnFamily1.  Use forceUserDefinedCompaction if you wish to force compaction of single sstables (e.g. for tombstone collection)\n\nAs a result, log disk is full and system is down.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Changing compaction strategy from Leveled to SizeTiered logs millions of messages about nothing to compact"
   },
   {
      "_id": "12536150",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-12-22 11:28:52",
      "description": "I've just run (the newly released) FindBugs 2 out of curiosity. Attaching a number of patches related to issue raised by it. There is nothing major at all so all patches are against trunk.\n\nI've tried keep each issue to it's own patch with a self describing title. It far from covers all FindBugs alerts, but it's a picky tool so I've tried to address only what felt at least vaguely useful. Those are still mostly nits (only patch 2 is probably an actual bug).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "fingbugs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix smallish problems find by FindBugs"
   },
   {
      "_id": "12535918",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-12-20 22:33:10",
      "description": "Running a test upgrade from 0.7(version f sstables) to 1.0.\nupgradesstables runs for about 40 minutes and then NPE's when trying to retrieve a key.\n\nNo files have been succesfully upgraded. Likely related is that scrub (without having run upgrade) consumes all RAM and OOMs.\n\nPossible theory is that a lot of paths call IPartitioner's decorateKey, and, at least in the randompartitioner's implementation, if any of those callers pass a null ByteBuffer, they key will be null in the stack trace below.\n\n\njava.util.concurrent.ExecutionException: java.lang.NullPointerException\n\tat java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:83)\n\tat org.apache.cassandra.db.compaction.CompactionManager.performAllSSTableOperation(CompactionManager.java:203)\n\tat org.apache.cassandra.db.compaction.CompactionManager.performSSTableRewrite(CompactionManager.java:219)\n\tat org.apache.cassandra.db.ColumnFamilyStore.sstablesRewrite(ColumnFamilyStore.java:970)\n\tat org.apache.cassandra.service.StorageService.upgradeSSTables(StorageService.java:1540)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)\n\tat com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)\n\tat com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)\n\tat com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:120)\n\tat com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:262)\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:836)\n\tat com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:761)\n\tat javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1427)\n\tat javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)\n\tat javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265)\n\tat javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360)\n\tat javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:788)\n\tat sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:159)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.Transport.serviceCall(Transport.java:155)\n\tat sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\nCaused by: java.lang.NullPointerException\n\tat org.apache.cassandra.db.compaction.PrecompactedRow.removeDeletedAndOldShards(PrecompactedRow.java:65)\n\tat org.apache.cassandra.db.compaction.PrecompactedRow.<init>(PrecompactedRow.java:92)\n\tat org.apache.cassandra.db.compaction.CompactionController.getCompactedRow(CompactionController.java:137)\n\tat org.apache.cassandra.db.compaction.CompactionIterable$Reducer.getReduced(CompactionIterable.java:102)\n\tat org.apache.cassandra.db.compaction.CompactionIterable$Reducer.getReduced(CompactionIterable.java:87)\n\tat org.apache.cassandra.utils.MergeIterator$OneToOne.computeNext(MergeIterator.java:200)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:140)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:135)\n\tat com.google.common.collect.Iterators$7.computeNext(Iterators.java:614)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:140)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:135)\n\tat org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:172)\n\tat org.apache.cassandra.db.compaction.CompactionManager$4.perform(CompactionManager.java:229)\n\tat org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:182)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\t... 3 more\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "NPE when running upgradesstables"
   },
   {
      "_id": "12535723",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2011-12-19 17:29:28",
      "description": "Composite columns introduce the ability to have arbitrarily nested data in a Cassandra row.  We should expose this through CQL.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Support collection (list, set, and map) value types in CQL"
   },
   {
      "_id": "12535015",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-12-13 20:34:48",
      "description": "One of our nodes had collected alot of hints for another node, so when the dead node came back and the row mutations were read back from disk, the node died with an OOM-exception (and kept dying after restart, even with increased heap (from 8G to 12G)). The heap dump contained alot of SuperColumns and our application does not use those (but HH does). \n\nI'm guessing that each mutation is big so that PAGE_SIZE*<mutation_size> does not fit in memory (will check this tomorrow)\n\nA simple fix (if my assumption above is correct) would be to reduce the PAGE_SIZE in HintedHandOffManager.java to something like 10 (or even 1?) to reduce the memory pressure. The performance hit would be small since we are doing the hinted handoff throttle delay sleep before sending every *mutation* anyway (not every page), thoughts?\n\nIf anyone runs in to the same problem, I got the node started again by simply removing the HintsColumnFamily* files.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hintedhandoff"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Hinted Handoff - related OOM"
   },
   {
      "_id": "12534935",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2011-12-13 11:51:01",
      "description": "Proposal for an improved system for handling distributed deletes, which removes the requirement to regularly run repair processes to maintain performance and data integrity. \n\nh2. The Problem\n\nThere are various issues with repair:\n\n* Repair is expensive to run\n* Repair jobs are often made more expensive than they should be by other issues (nodes dropping requests, hinted handoff not working, downtime etc)\n* Repair processes can often fail and need restarting, for example in cloud environments where network issues make a node disappear from the ring for a brief moment\n* When you fail to run repair within GCSeconds, either by error or because of issues with Cassandra, data written to a node that did not see a later delete can reappear (and a node might miss a delete for several reasons including being down or simply dropping requests during load shedding)\n* If you cannot run repair and have to increase GCSeconds to prevent deleted data reappearing, in some cases the growing tombstone overhead can significantly degrade performance\n\nBecause of the foregoing, in high throughput environments it can be very difficult to make repair a cron job. It can be preferable to keep a terminal open and run repair jobs one by one, making sure they succeed and keeping and eye on overall load to reduce system impact. This isn't desirable, and problems are exacerbated when there are lots of column families in a database or it is necessary to run a column family with a low GCSeconds to reduce tombstone load (because there are many write/deletes to that column family). The database owner must run repair within the GCSeconds window, or increase GCSeconds, to avoid potentially losing delete operations. \n\nIt would be much better if there was no ongoing requirement to run repair to ensure deletes aren't lost, and no GCSeconds window. Ideally repair would be an optional maintenance utility used in special cases, or to ensure ONE reads get consistent data. \n\nh2. \"Reaper Model\" Proposal\n\n# Tombstones do not expire, and there is no GCSeconds\n# Tombstones have associated ACK lists, which record the replicas that have acknowledged them\n# Tombstones are deleted (or marked for compaction) when they have been acknowledged by all replicas\n# When a tombstone is deleted, it is added to a \"relic\" index. The relic index makes it possible for a reaper to acknowledge a tombstone after it is deleted\n# The ACK lists and relic index are held in memory for speed\n# Background \"reaper\" threads constantly stream ACK requests to other nodes, and stream back ACK responses back to requests they have received (throttling their usage of CPU and bandwidth so as not to affect performance)\n# If a reaper receives a request to ACK a tombstone that does not exist, it creates the tombstone and adds an ACK for the requestor, and replies with an ACK. This is the worst that can happen, and does not cause data corruption. \n\nADDENDUM\n\nThe proposal to hold the ACK and relic lists in memory was added after the first posting. Please see comments for full reasons. Furthermore, a proposal for enhancements to repair was posted to comments, which would cause tombstones to be scavenged when repair completes (the author had assumed this was the case anyway, but it seems at time of writing they are only scavenged during compaction on GCSeconds timeout). The proposals are not exclusive and this proposal is extended to include the possible enhancements to repair described.\n\nNOTES\n\n* If a node goes down for a prolonged period, the worst that can happen is that some tombstones are recreated across the cluster when it restarts, which does not corrupt data (and this will only occur with a very small number of tombstones)\n* The system is simple to implement and predictable \n* With the reaper model, repair would become an optional process for optimizing the database to increase the consistency seen by ConsistencyLevel.ONE reads, and for fixing up nodes, for example after an sstable was lost\n\nh3. Planned Benefits\n\n* Reaper threads can utilize \"spare\" cycles to constantly scavenge tombstones in the background thereby greatly reducing tombstone load, improving query performance, reducing the system resources needed by processes such as compaction, and making performance generally more predictable \n* The reaper model means that GCSeconds is no longer necessary, which removes the threat of data corruption if repair can't be run successfully within that period (for example if repair can't be run because of a new adopter's lack of Cassandra expertise, a cron script failing, or Cassandra bugs or other technical issues)\n* Reaper threads are fully automatic, work in the background and perform finely grained operations where interruption has little effect. This is much better for database administrators than having to manually run and manage repair, whether for the purposes of preventing data corruption or for optimizing performance, which in addition to wasting operator time also often creates load spikes and has to be restarted after failure.  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "GCSeconds,",
         "deletes,",
         "distributed_deletes,",
         "merkle_trees",
         "repair,"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Proposal for distributed deletes - fully automatic \"Reaper Model\" rather than GCSeconds and manual repairs"
   },
   {
      "_id": "12534402",
      "assignee": "iamaleksey",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2011-12-08 21:14:57",
      "description": "Cqlsh provides context-sensitive tab-completion functionality, but it's only available when the readline library is available, and this is not the case where readline's GPL license proves problematic. [libedit|http://www.thrysoee.dk/editline/] is a common replacement, which would be available to Mac OS X-bundled Python users, and the Python readline module makes libedit almost a drop-in replacement.\n\nIf possible, fallback to libedit functionality when providing tab completion.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cqlsh"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "cqlsh: use libedit when readline isn't available, if possible"
   },
   {
      "_id": "12533701",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-12-02 23:26:07",
      "description": "CASSANDRA-1740 broke cache saving on Windows.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Cache saving broken on windows"
   },
   {
      "_id": "12533699",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2011-12-02 23:08:30",
      "description": "Most validation is done by ThriftValidation.validateCfDef, which we call from QP when creating an index but not on CF creation.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL CF creation skips most of the validation code"
   },
   {
      "_id": "12533605",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-12-02 12:14:13",
      "description": "In other word, it would probably be a good idea to have:\n{noformat}\n  cfm == CFMetadata.fromThrift(cfm.toThrift())\n  cfm == CFMetadata.fromSchema(cfm.toSchema())\n{noformat}\nIn particular, we could have unit tests to check that, which would avoid things like CASSANDRA-3558.\n\nIt is not the case today for thrift because of the keyAlias. For some reason, if the keyAlias is not set, we return with toThrift() the default alias. I don't think this serves any purpose though.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "avro",
         "thrift"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CFMetaData conversions to Thrift/Native schema should be inverse one of the other"
   },
   {
      "_id": "12533603",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-12-02 11:59:41",
      "description": "CASSANDRA-3492 fixed the interpretation of chunk_length_kb as a size in bytes but infortunately forgot to convert it back to kb when returning it for thrift/avro. In particular, this means that a {{describe cf}} would return things like {{chunk_length_kb: 65535}}.\n\nI'm afraid that because migration uses Avro this is kind of a problem. One may have to issue an 'update column family' with the right chunk_length_kb to be sure to be in a safe place.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Compression chunk_length_kb is not correctly returned for thrift/avro"
   },
   {
      "_id": "12533568",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-12-02 05:46:15",
      "description": "If B drops a write from A because it is overwhelmed (but not dead), A will hint the write.  But it will never get notified that B is back up (since it was never down), so it will never attempt hint delivery.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hintedhandoff",
         "jmx"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Hints are not replayed unless node was marked down"
   },
   {
      "_id": "12532941",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-11-28 17:44:23",
      "description": " I have a 3 node cassandra cluster. I have RF set to 3 and do reads\nand writes using QUORUM.\n\nHere is my initial ring configuration\n\n[root@CAP4-CNode1 ~]# /root/cassandra/bin/nodetool -h localhost ring\nAddress         DC          Rack        Status State   Load\nOwns    Token\n\n       113427455640312821154458202477256070484\n10.19.104.11    datacenter1 rack1       Up     Normal  1.66 GB\n33.33%  0\n10.19.104.12    datacenter1 rack1       Up     Normal  1.06 GB\n33.33%  56713727820156410577229101238628035242\n10.19.104.13    datacenter1 rack1       Up     Normal  1.61 GB\n33.33%  113427455640312821154458202477256070484\n\nI want to add 10.19.104.14 to the cluster.\n\nI edited the 10.19.104.14 cassandra.yaml file and set the token to\n127605887595351923798765477786913079296 and set auto_bootstrap to\ntrue.\n\nWhen I started cassandra I am getting Assertion Error.  \n\nthanks\nRamesh\n\n\n\n\n[root@CAP4-CNode4 cassandra]#  INFO 10:29:46,093 Logging initialized\n INFO 10:29:46,099 JVM vendor/version: Java HotSpot(TM) 64-Bit Server\nVM/1.6.0_25\n INFO 10:29:46,100 Heap size: 8304721920/8304721920\n INFO 10:29:46,100 Classpath:\nbin/../conf:bin/../build/classes/main:bin/../build/classes/thrift:bin/../lib/antlr-3.2.jar:bin/../lib/apache-cassandra-1.0.2.jar:bin/../lib/apache-cassandra-clientutil-1.0.2.jar:bin/../lib/apache-cassandra-thrift-1.0.2.jar:bin/../lib/avro-1.4.0-fixes.jar:bin/../lib/avro-1.4.0-sources-fixes.jar:bin/../lib/commons-cli-1.1.jar:bin/../lib/commons-codec-1.2.jar:bin/../lib/commons-lang-2.4.jar:bin/../lib/compress-lzf-0.8.4.jar:bin/../lib/concurrentlinkedhashmap-lru-1.2.jar:bin/../lib/guava-r08.jar:bin/../lib/high-scale-lib-1.1.2.jar:bin/../lib/jackson-core-asl-1.4.0.jar:bin/../lib/jackson-mapper-asl-1.4.0.jar:bin/../lib/jamm-0.2.5.jar:bin/../lib/jline-0.9.94.jar:bin/../lib/jna.jar:bin/../lib/json-simple-1.1.jar:bin/../lib/libthrift-0.6.jar:bin/../lib/log4j-1.2.16.jar:bin/../lib/mx4j-examples.jar:bin/../lib/mx4j-impl.jar:bin/../lib/mx4j.jar:bin/../lib/mx4j-jmx.jar:bin/../lib/mx4j-remote.jar:bin/../lib/mx4j-rimpl.jar:bin/../lib/mx4j-rjmx.jar:bin/../lib/mx4j-tools.jar:bin/../lib/servlet-api-2.5-20081211.jar:bin/../lib/slf4j-api-1.6.1.jar:bin/../lib/slf4j-log4j12-1.6.1.jar:bin/../lib/snakeyaml-1.6.jar:bin/../lib/snappy-java-1.0.4.1.jar:bin/../lib/jamm-0.2.5.jar\n INFO 10:29:48,713 JNA mlockall successful\n INFO 10:29:48,726 Loading settings from\nfile:/root/apache-cassandra-1.0.2/conf/cassandra.yaml\n INFO 10:29:48,883 DiskAccessMode 'auto' determined to be mmap,\nindexAccessMode is mmap\n INFO 10:29:48,898 Global memtable threshold is enabled at 2640MB\n INFO 10:29:49,203 Couldn't detect any schema definitions in local storage.\n INFO 10:29:49,204 Found table data in data directories. Consider\nusing the CLI to define your schema.\n INFO 10:29:49,220 Creating new commitlog segment\n/var/lib/cassandra/commitlog/CommitLog-1321979389220.log\n INFO 10:29:49,227 No commitlog files found; skipping replay\n INFO 10:29:49,230 Cassandra version: 1.0.2\n INFO 10:29:49,230 Thrift API version: 19.18.0\n INFO 10:29:49,230 Loading persisted ring state\n INFO 10:29:49,235 Starting up server gossip\n INFO 10:29:49,259 Enqueuing flush of\nMemtable-LocationInfo@122130810(192/240 serialized/live bytes, 4 ops)\n INFO 10:29:49,260 Writing Memtable-LocationInfo@122130810(192/240\nserialized/live bytes, 4 ops)\n INFO 10:29:49,317 Completed flushing\n/var/lib/cassandra/data/system/LocationInfo-h-1-Data.db (300 bytes)\n INFO 10:29:49,340 Starting Messaging Service on port 7000\n INFO 10:29:49,349 JOINING: waiting for ring and schema information\n INFO 10:29:50,759 Applying migration\n4b0e20f0-1511-11e1-0000-c11bc95834d7 Add keyspace: MSA, rep\nstrategy:SimpleStrategy{}, durable_writes: true\n INFO 10:29:50,761 Enqueuing flush of\nMemtable-Migrations@1507565381(6744/8430 serialized/live bytes, 1 ops)\n INFO 10:29:50,761 Writing Memtable-Migrations@1507565381(6744/8430\nserialized/live bytes, 1 ops)\n INFO 10:29:50,761 Enqueuing flush of\nMemtable-Schema@1498835564(2889/3611 serialized/live bytes, 3 ops)\n INFO 10:29:50,776 Completed flushing\n/var/lib/cassandra/data/system/Migrations-h-1-Data.db (6808 bytes)\n INFO 10:29:50,777 Writing Memtable-Schema@1498835564(2889/3611\nserialized/live bytes, 3 ops)\n INFO 10:29:50,797 Completed flushing\n/var/lib/cassandra/data/system/Schema-h-1-Data.db (3039 bytes)\n INFO 10:29:50,814 Applying migration\n4b6f2cb0-1511-11e1-0000-c11bc95834d7 Add column family:\norg.apache.cassandra.config.CFMetaData@1639d811[cfId=1000,ksName=MSA,cfName=modseq,cfType=Standard,comparator=org.apache.cassandra.db.marshal.ReversedType(org.apache.cassandra.db.marshal.BytesType),subcolumncomparator=<null>,comment=,rowCacheSize=0.0,keyCacheSize=5000000.0,readRepairChance=1.0,replicateOnWrite=true,gcGraceSeconds=3600,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.BytesType,minCompactionThreshold=4,maxCompactionThreshold=32,rowCacheSavePeriodInSeconds=0,keyCacheSavePeriodInSeconds=14400,rowCacheKeysToSave=2147483647,rowCacheProvider=org.apache.cassandra.cache.SerializingCacheProvider@2f984f7d,mergeShardsChance=0.1,keyAlias=<null>,column_metadata={},compactionStrategyClass=class\norg.apache.cassandra.db.compaction.LeveledCompactionStrategy,compactionStrategyOptions={sstable_size_in_mb=10},compressionOptions={}]\n INFO 10:29:50,815 Enqueuing flush of\nMemtable-Migrations@948613108(7482/9352 serialized/live bytes, 1 ops)\n INFO 10:29:50,816 Writing Memtable-Migrations@948613108(7482/9352\nserialized/live bytes, 1 ops)\n INFO 10:29:50,816 Enqueuing flush of\nMemtable-Schema@421910828(3294/4117 serialized/live bytes, 3 ops)\n INFO 10:29:50,831 Completed flushing\n/var/lib/cassandra/data/system/Migrations-h-2-Data.db (7546 bytes)\n INFO 10:29:50,832 Writing Memtable-Schema@421910828(3294/4117\nserialized/live bytes, 3 ops)\n INFO 10:29:50,846 Completed flushing\n/var/lib/cassandra/data/system/Schema-h-2-Data.db (3444 bytes)\n INFO 10:29:50,854 Applying migration\n4b8c9fc0-1511-11e1-0000-c11bc95834d7 Add column family:\norg.apache.cassandra.config.CFMetaData@1bd97d0d[cfId=1001,ksName=MSA,cfName=msgid,cfType=Standard,comparator=org.apache.cassandra.db.marshal.BytesType,subcolumncomparator=<null>,comment=,rowCacheSize=0.0,keyCacheSize=1000000.0,readRepairChance=1.0,replicateOnWrite=true,gcGraceSeconds=3600,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.BytesType,minCompactionThreshold=4,maxCompactionThreshold=32,rowCacheSavePeriodInSeconds=0,keyCacheSavePeriodInSeconds=14400,rowCacheKeysToSave=2147483647,rowCacheProvider=org.apache.cassandra.cache.SerializingCacheProvider@63a0eec3,mergeShardsChance=0.1,keyAlias=<null>,column_metadata={},compactionStrategyClass=class\norg.apache.cassandra.db.compaction.SizeTieredCompactionStrategy,compactionStrategyOptions={},compressionOptions={}]\n INFO 10:29:50,855 Enqueuing flush of\nMemtable-Migrations@1520138062(7750/9687 serialized/live bytes, 1 ops)\n INFO 10:29:50,856 Writing Memtable-Migrations@1520138062(7750/9687\nserialized/live bytes, 1 ops)\n INFO 10:29:50,856 Enqueuing flush of\nMemtable-Schema@347459675(3630/4537 serialized/live bytes, 3 ops)\n INFO 10:29:50,878 Completed flushing\n/var/lib/cassandra/data/system/Migrations-h-3-Data.db (7814 bytes)\n INFO 10:29:50,879 Writing Memtable-Schema@347459675(3630/4537\nserialized/live bytes, 3 ops)\n INFO 10:29:50,894 Completed flushing\n/var/lib/cassandra/data/system/Schema-h-3-Data.db (3780 bytes)\n INFO 10:29:50,900 Applying migration\n4ba1ae60-1511-11e1-0000-c11bc95834d7 Add column family:\norg.apache.cassandra.config.CFMetaData@6a095b8a[cfId=1002,ksName=MSA,cfName=participants,cfType=Standard,comparator=org.apache.cassandra.db.marshal.ReversedType(org.apache.cassandra.db.marshal.BytesType),subcolumncomparator=<null>,comment=,rowCacheSize=0.0,keyCacheSize=1000000.0,readRepairChance=1.0,replicateOnWrite=true,gcGraceSeconds=3600,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.BytesType,minCompactionThreshold=4,maxCompactionThreshold=32,rowCacheSavePeriodInSeconds=0,keyCacheSavePeriodInSeconds=14400,rowCacheKeysToSave=2147483647,rowCacheProvider=org.apache.cassandra.cache.SerializingCacheProvider@c58f769,mergeShardsChance=0.1,keyAlias=<null>,column_metadata={},compactionStrategyClass=class\norg.apache.cassandra.db.compaction.SizeTieredCompactionStrategy,compactionStrategyOptions={},compressionOptions={}]\n INFO 10:29:50,900 Enqueuing flush of\nMemtable-Migrations@618337492(8194/10242 serialized/live bytes, 1 ops)\n INFO 10:29:50,901 Writing Memtable-Migrations@618337492(8194/10242\nserialized/live bytes, 1 ops)\n INFO 10:29:50,902 Enqueuing flush of\nMemtable-Schema@724860211(4020/5025 serialized/live bytes, 3 ops)\n INFO 10:29:50,917 Completed flushing\n/var/lib/cassandra/data/system/Migrations-h-4-Data.db (8258 bytes)\n INFO 10:29:50,918 Writing Memtable-Schema@724860211(4020/5025\nserialized/live bytes, 3 ops)\n INFO 10:29:50,925 Compacting\n[SSTableReader(path='/var/lib/cassandra/data/system/Migrations-h-1-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Migrations-h-2-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Migrations-h-4-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Migrations-h-3-Data.db')]\n INFO 10:29:50,934 Completed flushing\n/var/lib/cassandra/data/system/Schema-h-4-Data.db (4170 bytes)\n INFO 10:29:50,935 Compacting\n[SSTableReader(path='/var/lib/cassandra/data/system/Schema-h-2-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Schema-h-1-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Schema-h-4-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Schema-h-3-Data.db')]\n INFO 10:29:50,940 Applying migration\n4bb4e840-1511-11e1-0000-c11bc95834d7 Add column family:\norg.apache.cassandra.config.CFMetaData@318c69a9[cfId=1003,ksName=MSA,cfName=subinfo,cfType=Standard,comparator=org.apache.cassandra.db.marshal.ReversedType(org.apache.cassandra.db.marshal.BytesType),subcolumncomparator=<null>,comment=,rowCacheSize=5000.0,keyCacheSize=5000000.0,readRepairChance=1.0,replicateOnWrite=true,gcGraceSeconds=3600,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.BytesType,minCompactionThreshold=4,maxCompactionThreshold=32,rowCacheSavePeriodInSeconds=14400,keyCacheSavePeriodInSeconds=14400,rowCacheKeysToSave=2147483647,rowCacheProvider=org.apache.cassandra.cache.SerializingCacheProvider@796cefa8,mergeShardsChance=0.1,keyAlias=<null>,column_metadata={},compactionStrategyClass=class\norg.apache.cassandra.db.compaction.LeveledCompactionStrategy,compactionStrategyOptions={sstable_size_in_mb=10},compressionOptions={}]\n INFO 10:29:50,941 Enqueuing flush of\nMemtable-Migrations@1682081063(8618/10772 serialized/live bytes, 1\nops)\n INFO 10:29:50,941 Writing Memtable-Migrations@1682081063(8618/10772\nserialized/live bytes, 1 ops)\n INFO 10:29:50,941 Enqueuing flush of\nMemtable-Schema@1083461053(4427/5533 serialized/live bytes, 3 ops)\n INFO 10:29:50,977 Completed flushing\n/var/lib/cassandra/data/system/Migrations-h-5-Data.db (8682 bytes)\n INFO 10:29:50,978 Writing Memtable-Schema@1083461053(4427/5533\nserialized/live bytes, 3 ops)\n INFO 10:29:50,991 Compacted to\n[/var/lib/cassandra/data/system/Schema-h-5-Data.db,].  14,433 to\n14,106 (~97% of original) bytes for 5 keys at 0.269051MB/s.  Time:\n50ms.\n INFO 10:29:50,995 Completed flushing\n/var/lib/cassandra/data/system/Schema-h-7-Data.db (4577 bytes)\n INFO 10:29:51,000 Applying migration\n4bc6e9a0-1511-11e1-0000-c11bc95834d7 Add column family:\norg.apache.cassandra.config.CFMetaData@20b00ec2[cfId=1004,ksName=MSA,cfName=transactions,cfType=Standard,comparator=org.apache.cassandra.db.marshal.ReversedType(org.apache.cassandra.db.marshal.BytesType),subcolumncomparator=<null>,comment=,rowCacheSize=0.0,keyCacheSize=0.0,readRepairChance=1.0,replicateOnWrite=true,gcGraceSeconds=3600,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.BytesType,minCompactionThreshold=4,maxCompactionThreshold=32,rowCacheSavePeriodInSeconds=0,keyCacheSavePeriodInSeconds=0,rowCacheKeysToSave=2147483647,rowCacheProvider=org.apache.cassandra.cache.SerializingCacheProvider@698f352,mergeShardsChance=0.1,keyAlias=<null>,column_metadata={},compactionStrategyClass=class\norg.apache.cassandra.db.compaction.LeveledCompactionStrategy,compactionStrategyOptions={sstable_size_in_mb=10},compressionOptions={}]\n INFO 10:29:51,001 Enqueuing flush of\nMemtable-Migrations@596545504(9027/11283 serialized/live bytes, 1 ops)\n INFO 10:29:51,002 Writing Memtable-Migrations@596545504(9027/11283\nserialized/live bytes, 1 ops)\n INFO 10:29:51,003 Enqueuing flush of\nMemtable-Schema@1686621532(4835/6043 serialized/live bytes, 3 ops)\n INFO 10:29:51,029 Completed flushing\n/var/lib/cassandra/data/system/Migrations-h-7-Data.db (9091 bytes)\n INFO 10:29:51,029 Writing Memtable-Schema@1686621532(4835/6043\nserialized/live bytes, 3 ops)\n INFO 10:29:51,031 Compacted to\n[/var/lib/cassandra/data/system/Migrations-h-6-Data.db,].  30,426 to\n30,234 (~99% of original) bytes for 1 keys at 0.272013MB/s.  Time:\n106ms.\n INFO 10:29:51,044 Completed flushing\n/var/lib/cassandra/data/system/Schema-h-8-Data.db (4985 bytes)\n INFO 10:29:51,049 Applying migration\n4bd76460-1511-11e1-0000-c11bc95834d7 Add column family:\norg.apache.cassandra.config.CFMetaData@4ab4faeb[cfId=1005,ksName=MSA,cfName=uid,cfType=Standard,comparator=org.apache.cassandra.db.marshal.ReversedType(org.apache.cassandra.db.marshal.BytesType),subcolumncomparator=<null>,comment=,rowCacheSize=0.0,keyCacheSize=1500000.0,readRepairChance=1.0,replicateOnWrite=true,gcGraceSeconds=3600,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.BytesType,minCompactionThreshold=4,maxCompactionThreshold=32,rowCacheSavePeriodInSeconds=0,keyCacheSavePeriodInSeconds=14400,rowCacheKeysToSave=2147483647,rowCacheProvider=org.apache.cassandra.cache.SerializingCacheProvider@2fc5809e,mergeShardsChance=0.1,keyAlias=<null>,column_metadata={},compactionStrategyClass=class\norg.apache.cassandra.db.compaction.LeveledCompactionStrategy,compactionStrategyOptions={sstable_size_in_mb=10},compressionOptions={}]\n INFO 10:29:51,050 Enqueuing flush of\nMemtable-Migrations@1333730706(9421/11776 serialized/live bytes, 1\nops)\n INFO 10:29:51,050 Writing Memtable-Migrations@1333730706(9421/11776\nserialized/live bytes, 1 ops)\n INFO 10:29:51,051 Enqueuing flush of\nMemtable-Schema@577668356(5236/6545 serialized/live bytes, 3 ops)\n INFO 10:29:51,065 Completed flushing\n/var/lib/cassandra/data/system/Migrations-h-9-Data.db (9485 bytes)\n INFO 10:29:51,066 Compacting\n[SSTableReader(path='/var/lib/cassandra/data/system/Migrations-h-6-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Migrations-h-9-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Migrations-h-7-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Migrations-h-5-Data.db')]\n INFO 10:29:51,066 Writing Memtable-Schema@577668356(5236/6545\nserialized/live bytes, 3 ops)\n INFO 10:29:51,081 Completed flushing\n/var/lib/cassandra/data/system/Schema-h-9-Data.db (5386 bytes)\n INFO 10:29:51,083 Compacting\n[SSTableReader(path='/var/lib/cassandra/data/system/Schema-h-5-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Schema-h-9-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Schema-h-8-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/Schema-h-7-Data.db')]\n INFO 10:29:51,114 Compacted to\n[/var/lib/cassandra/data/system/Schema-h-10-Data.db,].  29,054 to\n28,727 (~98% of original) bytes for 8 keys at 0.913207MB/s.  Time:\n30ms.\n INFO 10:29:51,144 Compacted to\n[/var/lib/cassandra/data/system/Migrations-h-10-Data.db,].  57,492 to\n57,300 (~99% of original) bytes for 1 keys at 0.700584MB/s.  Time:\n78ms.\n INFO 10:29:51,410 Node /10.19.104.13 is now part of the cluster\n INFO 10:29:51,412 InetAddress /10.19.104.13 is now UP\n INFO 10:29:51,414 Enqueuing flush of\nMemtable-LocationInfo@709342045(35/43 serialized/live bytes, 1 ops)\n INFO 10:29:51,415 Writing Memtable-LocationInfo@709342045(35/43\nserialized/live bytes, 1 ops)\n INFO 10:29:51,428 Completed flushing\n/var/lib/cassandra/data/system/LocationInfo-h-2-Data.db (89 bytes)\n INFO 10:29:51,439 Node /10.19.104.12 is now part of the cluster\n INFO 10:29:51,439 InetAddress /10.19.104.12 is now UP\n INFO 10:29:51,441 Enqueuing flush of\nMemtable-LocationInfo@1292444743(35/43 serialized/live bytes, 1 ops)\n INFO 10:29:51,441 Writing Memtable-LocationInfo@1292444743(35/43\nserialized/live bytes, 1 ops)\n INFO 10:29:51,455 Completed flushing\n/var/lib/cassandra/data/system/LocationInfo-h-3-Data.db (89 bytes)\n INFO 10:29:51,456 Node /10.19.104.11 is now part of the cluster\n INFO 10:29:51,457 InetAddress /10.19.104.11 is now UP\n INFO 10:29:51,459 Enqueuing flush of\nMemtable-LocationInfo@1891328597(20/25 serialized/live bytes, 1 ops)\n INFO 10:29:51,459 Writing Memtable-LocationInfo@1891328597(20/25\nserialized/live bytes, 1 ops)\n INFO 10:29:51,471 Completed flushing\n/var/lib/cassandra/data/system/LocationInfo-h-4-Data.db (74 bytes)\n INFO 10:29:51,473 Compacting\n[SSTableReader(path='/var/lib/cassandra/data/system/LocationInfo-h-2-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/LocationInfo-h-4-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/LocationInfo-h-1-Data.db'),\nSSTableReader(path='/var/lib/cassandra/data/system/LocationInfo-h-3-Data.db')]\n INFO 10:29:51,497 Compacted to\n[/var/lib/cassandra/data/system/LocationInfo-h-5-Data.db,].  552 to\n444 (~80% of original) bytes for 3 keys at 0.018410MB/s.  Time: 23ms.\n INFO 10:30:19,349 JOINING: getting bootstrap token\n INFO 10:30:19,352 Enqueuing flush of\nMemtable-LocationInfo@225265367(36/45 serialized/live bytes, 1 ops)\n INFO 10:30:19,353 Writing Memtable-LocationInfo@225265367(36/45\nserialized/live bytes, 1 ops)\n INFO 10:30:19,364 Completed flushing\n/var/lib/cassandra/data/system/LocationInfo-h-7-Data.db (87 bytes)\n INFO 10:30:19,374 JOINING: sleeping 30000 ms for pending range setup\n INFO 10:30:49,375 JOINING: Starting to bootstrap...\nERROR 10:31:13,444 Fatal exception in thread Thread[Thread-49,5,main]\njava.lang.AssertionError\n       at org.apache.cassandra.db.compaction.LeveledManifest.promote(LeveledManifest.java:178)\n       at org.apache.cassandra.db.compaction.LeveledCompactionStrategy.handleNotification(LeveledCompactionStrategy.java:141)\n       at org.apache.cassandra.db.DataTracker.notifySSTablesChanged(DataTracker.java:466)\n       at org.apache.cassandra.db.DataTracker.replace(DataTracker.java:275)\n       at org.apache.cassandra.db.DataTracker.addSSTables(DataTracker.java:237)\n       at org.apache.cassandra.db.DataTracker.addStreamedSSTable(DataTracker.java:242)\n       at org.apache.cassandra.db.ColumnFamilyStore.addSSTable(ColumnFamilyStore.java:922)\n       at org.apache.cassandra.streaming.StreamInSession.closeIfFinished(StreamInSession.java:141)\n       at org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:102)\n       at org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:184)\n       at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:81)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Assertion error during bootstraping cassandra"
   },
   {
      "_id": "12532195",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-11-21 19:13:35",
      "description": "On a single node, I'm seeing the following error when trying to compact a CounterColumnFamily. This appears to have started with version 1.0.3.\n\nnodetool -h localhost compact TRProd MetricsAllTime\nError occured during compaction\njava.util.concurrent.ExecutionException: java.lang.ArrayIndexOutOfBoundsException\n\tat java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:83)\n\tat org.apache.cassandra.db.compaction.CompactionManager.performMaximal(CompactionManager.java:250)\n\tat org.apache.cassandra.db.ColumnFamilyStore.forceMajorCompaction(ColumnFamilyStore.java:1471)\n\tat org.apache.cassandra.service.StorageService.forceTableCompaction(StorageService.java:1523)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)\n\tat com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)\n\tat com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)\n\tat com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:120)\n\tat com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:262)\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:836)\n\tat com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:761)\n\tat javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1427)\n\tat javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)\n\tat javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265)\n\tat javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360)\n\tat javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:788)\n\tat sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:159)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.Transport.serviceCall(Transport.java:155)\n\tat sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:619)\nCaused by: java.lang.ArrayIndexOutOfBoundsException\n\tat org.apache.cassandra.utils.ByteBufferUtil.arrayCopy(ByteBufferUtil.java:292)\n\tat org.apache.cassandra.db.context.CounterContext$ContextState.copyTo(CounterContext.java:792)\n\tat org.apache.cassandra.db.context.CounterContext.removeOldShards(CounterContext.java:709)\n\tat org.apache.cassandra.db.CounterColumn.removeOldShards(CounterColumn.java:260)\n\tat org.apache.cassandra.db.CounterColumn.mergeAndRemoveOldShards(CounterColumn.java:306)\n\tat org.apache.cassandra.db.CounterColumn.mergeAndRemoveOldShards(CounterColumn.java:271)\n\tat org.apache.cassandra.db.compaction.PrecompactedRow.removeDeletedAndOldShards(PrecompactedRow.java:86)\n\tat org.apache.cassandra.db.compaction.PrecompactedRow.<init>(PrecompactedRow.java:102)\n\tat org.apache.cassandra.db.compaction.CompactionController.getCompactedRow(CompactionController.java:133)\n\tat org.apache.cassandra.db.compaction.CompactionIterable$Reducer.getReduced(CompactionIterable.java:102)\n\tat org.apache.cassandra.db.compaction.CompactionIterable$Reducer.getReduced(CompactionIterable.java:87)\n\tat org.apache.cassandra.utils.MergeIterator$ManyToOne.consume(MergeIterator.java:116)\n\tat org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:99)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:140)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:135)\n\tat com.google.common.collect.Iterators$7.computeNext(Iterators.java:614)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:140)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:135)\n\tat org.apache.cassandra.db.compaction.CompactionTask.execute(CompactionTask.java:172)\n\tat org.apache.cassandra.db.compaction.CompactionManager$4.call(CompactionManager.java:277)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\t... 3 more",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CounterColumnFamily Compaction error (ArrayIndexOutOfBoundsException)"
   },
   {
      "_id": "12530929",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-11-09 21:31:56",
      "description": "This has been happening since 1.0.2. I wasn't on 1.0 for very long but I'm fairly certain repair was working ok. Repair worked decently for me in 0.8 (data bloat sucked). All my SSTables are version h.\n\nOn one node:\n\njava.lang.AssertionError: incorrect row data size 596045 written to /mnt/cassandra/data/TRProd/Metrics1m-tmp-h-25036-Data.db; correct is 586675\n\tat org.apache.cassandra.io.sstable.SSTableWriter.appendFromStream(SSTableWriter.java:253)\n\tat org.apache.cassandra.streaming.IncomingStreamReader.streamIn(IncomingStreamReader.java:146)\n\tat org.apache.cassandra.streaming.IncomingStreamReader.read(IncomingStreamReader.java:87)\n\tat org.apache.cassandra.net.IncomingTcpConnection.stream(IncomingTcpConnection.java:184)\n\tat org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:81)\n\nOn the other node:\n\n4999 - 0%, /mnt/cassandra/data/TRProd/Metrics1m-h-24953-Data.db sections=1707 progress=0/1513497639 - 0%, /mnt/cassandra/data/TRProd/Metrics1m-h-25000-Data.db sections=635 progress=0/53400713 - 0%, /mnt/cassandra/data/TRProd/Metrics1m-h-25002-Data.db sections=570 progress=0/709993 - 0%, /mnt/cassandra/data/TRProd/Metrics1m-h-25003-Data.db sections=550 progress=0/449498 - 0%, /mnt/cassandra/data/TRProd/Metrics1m-h-25005-Data.db sections=516 progress=0/316301 - 0%], 6 sstables.\n INFO [StreamStage:1] 2011-11-09 19:45:22,795 StreamOutSession.java (line 203) Streaming to /10.38.69.192\nERROR [Streaming:1] 2011-11-09 19:47:47,964 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread[Streaming:1,1,main]\njava.lang.RuntimeException: java.net.SocketException: Connection reset\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:619)\nCaused by: java.net.SocketException: Connection reset\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:96)\n\tat java.net.SocketOutputStream.write(SocketOutputStream.java:136)\n\tat com.ning.compress.lzf.ChunkEncoder.encodeAndWriteChunk(ChunkEncoder.java:133)\n\tat com.ning.compress.lzf.LZFOutputStream.writeCompressedBlock(LZFOutputStream.java:203)\n\tat com.ning.compress.lzf.LZFOutputStream.write(LZFOutputStream.java:97)\n\tat org.apache.cassandra.streaming.FileStreamTask.write(FileStreamTask.java:181)\n\tat org.apache.cassandra.streaming.FileStreamTask.stream(FileStreamTask.java:145)\n\tat org.apache.cassandra.streaming.FileStreamTask.runMayThrow(FileStreamTask.java:91)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n\t... 3 more\nERROR [Streaming:1] 2011-11-09 19:47:47,970 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread[Streaming:1,1,main]\njava.lang.RuntimeException: java.net.SocketException: Connection reset\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:619)\nCaused by: java.net.SocketException: Connection reset\n\tat java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:96)\n\tat java.net.SocketOutputStream.write(SocketOutputStream.java:136)\n\tat com.ning.compress.lzf.ChunkEncoder.encodeAndWriteChunk(ChunkEncoder.java:133)\n\tat com.ning.compress.lzf.LZFOutputStream.writeCompressedBlock(LZFOutputStream.java:203)\n\tat com.ning.compress.lzf.LZFOutputStream.write(LZFOutputStream.java:97)\n\tat org.apache.cassandra.streaming.FileStreamTask.write(FileStreamTask.java:181)\n\tat org.apache.cassandra.streaming.FileStreamTask.stream(FileStreamTask.java:145)\n\tat org.apache.cassandra.streaming.FileStreamTask.runMayThrow(FileStreamTask.java:91)\n\tat org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n\t... 3 more\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "connection",
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "During repair, \"incorrect data size\" & \"Connection reset\" errors. Repair unable to complete."
   },
   {
      "_id": "12530617",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-11-07 19:16:31",
      "description": "While testing rolling upgrades from 0.8.7 to 1.0.2 on a test cluster I've noticed that hinted hand-off didn't always work properly. Hints generated on an upgraded node does not seem to be delivered to other newly upgraded nodes once they rejoin the ring. They only way I've found to get a node to deliver its hints is to restart it.\n\nHere's some steps to reproduce this issue:\n\n1. Install cassandra 0.8.7 on node1 and node2 using default settings.\n2. Create keyspace foo with {replication_factor: 2}. Create column family bar\n3. Shutdown node2 \n4. Insert data into bar and verify that HintsColumnFamily on node2 contains hints\n5. Start node2 and verify that hinted handoff is performed and HintsColumnFamily becomes empty again.\n\n6. Upgrade and restart node1\n7. Shutdown node2 \n8. Insert data into bar and verify that HintsColumnFamily on node2 contains hints\n9. Upgrade and start node2\n10. Notice that hinted handoff is *not* performed when \"node2\" comes back. (Only if node1 is restarted)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hintedhandoff"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Hinted handoff not working after rolling upgrade from 0.8.7 to 1.0.2"
   },
   {
      "_id": "12529885",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-11-02 16:15:25",
      "description": "I'm having a problem with doing a multiget_slice on a super column family\nafter its first flush. Updates to the column values work properly, but\ntrying to retrieve the updated values using a multiget_slice operation fail\nto get the updated values. Instead they return the values from before the\nflush. The problem is not apparent with standard column families.\n\nI've seen this problem in Cassandra v1.0.0 and v1.0.1. The problem\nis not present in Cassandra v0.7.6.\n\nSteps to reproduce:\n\n   1. Create one or more super column entries\n   2. Verify the sub column values can be updated and that you can retrieve\n   the new values\n   3. Use nodetool to flush the column family or restart cassandra\n   4. Update the sub column values\n   5. Verify they have been updated using cassandra-cli\n   6. Verify you *DO NOT* get the updated values when doing a\n   multiget_slice; instead you get the old values from before the flush\n\nYou can get the most recent value by doing a flush followed by a major\ncompaction. However, future updates are not retrieved properly either.\n\nWith debug turned on, it looks like the multiget_slice query uses the\nfollowing command/consistency level:\nSliceByNamesReadCommand(table='test_cassandra', key=666f6f,\ncolumnParent='QueryPath(columnFamilyName='test', superColumnName='null',\ncolumnName='null')', columns=[foo,])/QUORUM.\n\nCassandra-cli uses the following command/consistency level for a get_slice:\nSliceFromReadCommand(table='test_cassandra', key='666f6f',\ncolumn_parent='QueryPath(columnFamilyName='test', superColumnName='null',\ncolumnName='null')', start='', finish='', reversed=false,\ncount=1000000)/QUORUM\n\nNotice the test program gets 'bar2' for the column values and cassandra-cli\ngets 'bar3' for the column values:\n\ntcpdump from test program using hector-core:1.0-1\n\n16:46:07.424562 IP iam.47158 > iam.9160: Flags [P.], seq 55:138, ack 30,\nwin 257, options [nop,nop,TS val 27474096 ecr 27474095], length 83\nE....#@.@.PK.........6#.....].8......{.....\n..8...8.........multiget_slice................foo..........test................foo.........\n16:46:07.424575 IP iam.9160 > iam.47158: Flags [.], ack 138, win 256,\noptions [nop,nop,TS val 27474096 ecr 27474096], length 0\nE..4..@.@.<.........#..6].8..........(.....\n..8...8.\n16:46:07.428771 IP iam.9160 > iam.47158: Flags [P.], seq 30:173, ack 138,\nwin 256, options [nop,nop,TS val 27474097 ecr 27474096], length 143\n@.@.<&........#..6].8................\n............foo...............foo...............foo1.......bar2\n........6h........foo2.......bar2\n........I.....\n\n\ntcpdump of cassandra-cli:\n\n16:30:55.945123 IP iam.47134 > iam.9160: Flags [P.], seq 370:479, ack 5310,\nwin 387, options [nop,nop,TS val 27246226 ecr 27241207], length 109\nE.....@.@.9q..........#..n.X\\\n.............\n................get_range_slices..............test.........................................................d.........\n16:30:55.945152 IP iam.9160 > iam.47134: Flags [.], ack 479, win 256,\noptions [nop,nop,TS val 27246226 ecr 27246226], length 0\nE..4..@.@.\".........#...\\\n...n.......(.....\n........\n16:30:55.949245 IP iam.9160 > iam.47134: Flags [P.], seq 5310:5461, ack\n479, win 256, options [nop,nop,TS val 27246227 ecr 27246226], length 151\nE.....@.@.\"V........#...\\\n...n.............\n....................get_range_slices...................foo..................foo...............foo1.......bar3\n........&.........foo2.......bar3\n........: .....",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "supercolumns"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Problem SliceByNamesReadCommand on super column family after flush operation"
   },
   {
      "_id": "12529794",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-11-02 02:11:02",
      "description": "As reported by Ramash Natarajan on the mailing list:\n\n{noformat}\nWe have a 8 node cassandra cluster running 1.0.1. After running a load\ntest for a day we are seeing this exception in system.log file.\n\nERROR [EXPIRING-MAP-TIMER-1] 2011-11-01 13:20:45,350\nAbstractCassandraDaemon.java (line 133) Fatal exception in thread\nThread[EXPIRING-MAP-TIMER-1,5,main]\njava.lang.AssertionError: /10.19.102.12\n       at org.apache.cassandra.service.StorageProxy.scheduleLocalHint(StorageProxy.java:339)\n       at org.apache.cassandra.net.MessagingService.scheduleMutationHint(MessagingService.java:201)\n       at org.apache.cassandra.net.MessagingService.access$500(MessagingService.java:64)\n       at org.apache.cassandra.net.MessagingService$2.apply(MessagingService.java:175)\n       at org.apache.cassandra.net.MessagingService$2.apply(MessagingService.java:152)\n       at org.apache.cassandra.utils.ExpiringMap$1.run(ExpiringMap.java:89)\n       at java.util.TimerThread.mainLoop(Timer.java:512)\n       at java.util.TimerThread.run(Timer.java:462)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hintedhandoff"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "local writes timing out cause attempt to hint to self"
   },
   {
      "_id": "12529618",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-11-01 04:07:39",
      "description": "invalidate doesn't call unregisterSSTables, and vice versa, making it easy to get yourself into a situation that \"shouldn't happen.\"  This is causing test failures post-CASSANDRA-3116.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "invalidate / unregisterSSTables is confused"
   },
   {
      "_id": "12529565",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-31 21:43:17",
      "description": "The dumped object below shows that the default_name_type and the default_value_type are referenced inconsistently .. default_name_type should probably use the shortened version like everything else.\n\n--- !ruby/object:CassandraCQL::Thrift::CqlResult \nrows: \n- !ruby/object:CassandraCQL::Thrift::CqlRow \n  columns: \n  - !ruby/object:CassandraCQL::Thrift::Column \n    name: id\n    timestamp: -1\n    value: test string\n  - !ruby/object:CassandraCQL::Thrift::Column \n    name: test_column\n    timestamp: 1320097088551000\n    value: test\n  key: test string\nschema: !ruby/object:CassandraCQL::Thrift::CqlMetadata \n  default_name_type: org.apache.cassandra.db.marshal.UTF8Type\n  default_value_type: UTF8Type\n  name_types: \n    id: AsciiType\n  value_types: \n    id: AsciiType\n    test_column: UTF8Type\ntype: 1",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL Metadata has inconsistent schema nomenclature"
   },
   {
      "_id": "12529516",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-10-31 17:28:13",
      "description": "For each compressed file we keep the chunk offsets in memory (a long[]). The size of this array is directly proportional to the sstable file and the chunk_length_kb used, but say for a 64GB sstable, we're talking ~8MB in memory by default.\n\nWithout being absolutely huge, this probably makes the life of the GC harder than necessary for the same reasons than CASSANDRA-2466, and this ticket proposes the same solution, i.e. to break down those big array into smaller ones to ease fragmentation.\n\nNote that this is only a concern for size tiered compaction. But until leveled compaction is battle tested, the default and we know nobody uses size tiered anymore, it's probably worth making the optimization.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Avoid large array allocation for compressed chunk offsets"
   },
   {
      "_id": "12529483",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-10-31 13:57:36",
      "description": "The CompressionMetada holds the compressed block offsets in memory. Without being absolutely huge, this is still of non-negligible size as soon as you have a bit of data in the DB. Reallocating this for each read is a very bad idea.\n\nNote that this only affect range queries, since \"normal\" queries uses CompressedSegmentedFile that does reuse a unique CompressionMetadata instance.\n\n( Background: http://thread.gmane.org/gmane.comp.db.cassandra.user/21362 )",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CompressionMetadata is not shared across threads, we create a new one for each read"
   },
   {
      "_id": "12529403",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-30 12:22:41",
      "description": "CREATE KEYSPACE CassandraCQLTestKeyspace WITH strategy_class='org.apache.cassandra.locator.SimpleStrategy' AND strategy_options:replication_factor=1\nUSE CassandraCQLTestKeyspace\nCREATE COLUMNFAMILY row_key_validation_cf_ascii (id ascii PRIMARY KEY, test_column text)\nINSERT INTO row_key_validation_cf_ascii (id, test_column) VALUES ('test string', 'test')\n\n# Works as expected\nSELECT * FROM row_key_validation_cf_ascii WHERE id = 'test string'\n\n# Returns an empty result, unexpected\nSELECT id FROM row_key_validation_cf_ascii WHERE id = 'test string'\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Selecting just the row_key returns nil instead of just the row_key"
   },
   {
      "_id": "12527792",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-19 17:44:53",
      "description": "I'm using the current HEAD of 1.0.0 github branch, and I'm still seeing this error, not sure if it's  this bug or another one.\n\n\n\n INFO [HintedHandoff:1] 2011-10-19 12:43:17,674 HintedHandOffManager.java (line 263) Started hinted handoff for token: 11342745564\n0312821154458202477256070484 with IP: /10.39.85.140\nERROR [HintedHandoff:1] 2011-10-19 12:43:17,885 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread[HintedHan\ndoff:1,1,main]\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)\nCaused by: java.lang.NullPointerException\n        at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:289)\n        at org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81)\n        at org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:337)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        ... 3 more\nERROR [HintedHandoff:1] 2011-10-19 12:43:17,886 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread[HintedHandoff:1,1,main]\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)\nCaused by: java.lang.NullPointerException\n        at org.apache.cassandra.db.HintedHandOffManager.deliverHintsToEndpoint(HintedHandOffManager.java:289)\n        at org.apache.cassandra.db.HintedHandOffManager.access$100(HintedHandOffManager.java:81)\n        at org.apache.cassandra.db.HintedHandOffManager$2.runMayThrow(HintedHandOffManager.java:337)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        ... 3 more\n\n\nthis could possibly be related to #3291\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hintedhandoff"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "NPE in hinted handoff"
   },
   {
      "_id": "12527620",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-18 17:02:52",
      "description": "CASSANDRA-3004 switched MessagingService back to logging only \"recent\" dropped messages instead of server lifetime totals, but the log message was not updated.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "logging"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "correct dropped messages logging"
   },
   {
      "_id": "12527375",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-10-16 23:04:01",
      "description": "Hi,\n\nit seems that the Deflate Compressor corrupts the SSTables. 3 out of 3 Installations were corrupt. Snappy works fine.\n\nHere is what I did:\n\n1. Start a single cassandra node (I was using ByteOrderedPartitioner)\n2. Write data into cf that uses deflate compression - I think it has to be enough data so that the data folder contains some files.\n3. When I now try to read (I did a range scan) from my application, it fails and the logs show corruptions:\n\nCaused by: org.apache.cassandra.io.compress.CorruptedBlockException: (/home/cspriegel/Development/cassandra1/data/Test/Response-h-2-Data.db): corruption detected, chunk at 0 of length 65536.\n\nregards,\nChristian",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Deflate Compression corrupts SSTables"
   },
   {
      "_id": "12527269",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-14 22:55:35",
      "description": "Leveled compaction wants to prevent multiple tasks from running at once, but this check also defeats the \"kick off another compaction if there is more work to do\" code in CompactionTask.  So currently LCS relies completely on the every-five-minutes compaction check, which is not enough to keep up with heavy insert load.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow one leveled compaction task to kick off another"
   },
   {
      "_id": "12526654",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-10-11 13:07:45",
      "description": "Through rebases, CASSANDRA-2610 unfortunately got committed with the use of the wrong streaming method, the one that stream all the sstables of the keyspace.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Repair still streams unnecessary sstables"
   },
   {
      "_id": "12526414",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-10-10 08:30:43",
      "description": "We are using the uncompressed data size when estimating if we have enough to compact sstables. This means we can easily refuse compaction when there is clearly enough room to compact.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Uncompressed sizes are used to estimate space for compaction of compressed sstables"
   },
   {
      "_id": "12526275",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-07 21:20:13",
      "description": "dropping index causes some inflight mutations to fail. hector on client side didnt throw any exception\n\n INFO [MigrationStage:1] 2011-10-07 23:11:53,742 Migration.java (line 119) Applying migration fb1a8540-f128-11e0-0000-23b38323f4da Update column family to org.apache.cassandra.config.CFMetaData@786669[cfId=1000,ksName=test,cfName=sipdb,cfType=Standard,comparator=org.apache.cassandra.db.marshal.AsciiType,subcolumncomparator=<null>,comment=phone calls routing information,rowCacheSize=0.0,keyCacheSize=0.0,readRepairChance=0.0,replicateOnWrite=false,gcGraceSeconds=0,defaultValidator=org.apache.cassandra.db.marshal.BytesType,keyValidator=org.apache.cassandra.db.marshal.Int32Type,minCompactionThreshold=4,maxCompactionThreshold=32,rowCacheSavePeriodInSeconds=0,keyCacheSavePeriodInSeconds=0,rowCacheKeysToSave=2147483647,rowCacheProvider=org.apache.cassandra.cache.ConcurrentLinkedHashCacheProvider@8bb33c,mergeShardsChance=0.1,keyAlias=java.nio.HeapByteBuffer[pos=461 lim=464 cap=466],column_metadata={java.nio.HeapByteBuffer[pos=0 lim=3 cap=3]=ColumnDefinition{name=6b616d, validator=org.apache.cassandra.db.marshal.AsciiType, index_type=null, index_name='null'}},compactionStrategyClass=class org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy,compactionStrategyOptions={},compressionOptions={}]\n INFO [MigrationStage:1] 2011-10-07 23:11:53,805 ColumnFamilyStore.java (line 664) Enqueuing flush of Memtable-Migrations@27537043(7860/9825 serialized/live bytes, 1 ops)\n INFO [MigrationStage:1] 2011-10-07 23:11:53,820 ColumnFamilyStore.java (line 664) Enqueuing flush of Memtable-Schema@8340427(3320/4150 serialized/live bytes, 3 ops)\n INFO [FlushWriter:3] 2011-10-07 23:11:53,820 Memtable.java (line 237) Writing Memtable-Migrations@27537043(7860/9825 serialized/live bytes, 1 ops)\n INFO [FlushWriter:3] 2011-10-07 23:11:55,008 Memtable.java (line 273) Completed flushing \\var\\lib\\cassandra\\data\\system\\Migrations-h-14-Data.db (7924 bytes)\n INFO [FlushWriter:3] 2011-10-07 23:11:55,008 Memtable.java (line 237) Writing Memtable-Schema@8340427(3320/4150 serialized/live bytes, 3 ops)\n INFO [CompactionExecutor:4] 2011-10-07 23:11:55,008 CompactionTask.java (line 119) Compacting [SSTableReader(path='\\var\\lib\\cassandra\\data\\system\\Migrations-h-13-Data.db'), SSTableReader(path='\\var\\lib\\cassandra\\data\\system\\Migrations-h-14-Data.db'), SSTableReader(path='\\var\\lib\\cassandra\\data\\system\\Migrations-h-11-Data.db'), SSTableReader(path='\\var\\lib\\cassandra\\data\\system\\Migrations-h-12-Data.db')]\n INFO [FlushWriter:3] 2011-10-07 23:11:56,430 Memtable.java (line 273) Completed flushing \\var\\lib\\cassandra\\data\\system\\Schema-h-14-Data.db (3470 bytes)\n INFO [CompactionExecutor:3] 2011-10-07 23:11:56,446 CompactionTask.java (line 119) Compacting [SSTableReader(path='\\var\\lib\\cassandra\\data\\system\\Schema-h-13-Data.db'), SSTableReader(path='\\var\\lib\\cassandra\\data\\system\\Schema-h-14-Data.db'), SSTableReader(path='\\var\\lib\\cassandra\\data\\system\\Schema-h-12-Data.db'), SSTableReader(path='\\var\\lib\\cassandra\\data\\system\\Schema-h-11-Data.db')]\nERROR [MutationStage:56] 2011-10-07 23:11:56,508 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread[MutationStage:56,5,main]\njava.lang.AssertionError\n\tat org.apache.cassandra.db.index.SecondaryIndexManager.applyIndexUpdates(SecondaryIndexManager.java:369)\n\tat org.apache.cassandra.db.Table.apply(Table.java:457)\n\tat org.apache.cassandra.db.RowMutation.apply(RowMutation.java:253)\n\tat org.apache.cassandra.service.StorageProxy$5.runMayThrow(StorageProxy.java:436)\n\tat org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1263)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\nERROR [MutationStage:51] 2011-10-07 23:11:56,539 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread[MutationStage:51,5,main]\njava.lang.AssertionError\n\tat org.apache.cassandra.db.index.SecondaryIndexManager.applyIndexUpdates(SecondaryIndexManager.java:369)\n\tat org.apache.cassandra.db.Table.apply(Table.java:457)\n\tat org.apache.cassandra.db.RowMutation.apply(RowMutation.java:253)\n\tat org.apache.cassandra.service.StorageProxy$5.runMayThrow(StorageProxy.java:436)\n\tat org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1263)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\nERROR [MutationStage:38] 2011-10-07 23:11:56,633 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread[MutationStage:38,5,main]\njava.lang.AssertionError\n\tat org.apache.cassandra.db.index.SecondaryIndexManager.applyIndexUpdates(SecondaryIndexManager.java:369)\n\tat org.apache.cassandra.db.Table.apply(Table.java:457)\n\tat org.apache.cassandra.db.RowMutation.apply(RowMutation.java:253)\n\tat org.apache.cassandra.service.StorageProxy$5.runMayThrow(StorageProxy.java:436)\n\tat org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1263)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\nERROR [MutationStage:57] 2011-10-07 23:11:56,664 AbstractCassandraDaemon.java (line 133) Fatal exception in thread Thread[MutationStage:57,5,main]\njava.lang.AssertionError\n\tat org.apache.cassandra.db.index.SecondaryIndexManager.applyIndexUpdates(SecondaryIndexManager.java:369)\n\tat org.apache.cassandra.db.Table.apply(Table.java:457)\n\tat org.apache.cassandra.db.RowMutation.apply(RowMutation.java:253)\n\tat org.apache.cassandra.service.StorageProxy$5.runMayThrow(StorageProxy.java:436)\n\tat org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:1263)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "dropping index causes some inflight mutations to fail"
   },
   {
      "_id": "12526261",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-07 19:16:20",
      "description": "RowMutation.serializedBuffer and ReadVerbHandler both do an extra copy of the serialized data. We can avoid this be pre-computing the serialized size and allocating an appropriate buffer.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "network"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "remove more copies from read/write network path"
   },
   {
      "_id": "12526215",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-07 14:34:30",
      "description": "CompactionTask is still fairly coupled to SizeTieredCompaction, including some ugly casting.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve CompactionTask extensibility"
   },
   {
      "_id": "12525770",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-05 07:31:53",
      "description": "If there is index building in progress, following errors are thrown if cassandra is trying to delete *-Index.db files. There is no problem with deleting -Data or -Filter.. files. CF is using leveled compaction but it is probably not related.\n\nERROR [NonPeriodicTasks:1] 2011-10-05 09:13:03,702 AbstractCassandraDaemon.java\n(line 133) Fatal exception in thread Thread[NonPeriodicTasks:1,5,main]\njava.lang.RuntimeException: java.io.IOException: Failed to delete C:\\var\\lib\\cas\nsandra\\data\\test\\sipdb-h-772-Index.db\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:3\n4)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:44\n1)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.\naccess$301(ScheduledThreadPoolExecutor.java:98)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.\nrun(ScheduledThreadPoolExecutor.java:206)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExec\nutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor\n.java:908)\n        at java.lang.Thread.run(Thread.java:662)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "indexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Fail to delete -Index files if index is currently building"
   },
   {
      "_id": "12525766",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-05 06:58:15",
      "description": "Canceling index build throws this, but checking log there was no compaction running in background.\n\nINFO 08:46:41,343 Writing Memtable-IndexInfo@9480253(34/42 serialized/live byte\ns, 1 ops)\nERROR 08:46:41,343 Fatal exception in thread Thread[CompactionExecutor:3,5,main]\n\njava.lang.AssertionError\n        at org.apache.cassandra.db.index.SecondaryIndexManager.applyIndexUpdates\n(SecondaryIndexManager.java:397)\n        at org.apache.cassandra.db.Table.indexRow(Table.java:534)\n        at org.apache.cassandra.db.index.SecondaryIndexBuilder.build(SecondaryIn\ndexBuilder.java:64)\n        at org.apache.cassandra.db.compaction.CompactionManager$7.run(Compaction\nManager.java:856)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:44\n1)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExec\nutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor\n.java:908)\n        at java.lang.Thread.run(Thread.java:662)\n INFO 08:46:41,531 Completed flushing \\var\\lib\\cassandra\\data\\system\\IndexInfo-h\n-1-Data.db (88 bytes)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Cancelling index build throws assert error"
   },
   {
      "_id": "12525723",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-04 19:44:44",
      "description": "In CASSANDRA-3104, this was removed with the following reasoning:\n\nbq. compaction_throughput_mb_per_sec is a more effective throttle on compaction.\n\nThis turns out to be false in the majority of deployments.  In many (if not most) situations, compaction is actually CPU bound, not IO bound, so multithreaded compaction is generally helpful, but the priority needs to be lowered in order to prevent it from stealing CPU used for reads/writes.\n\nCompaction is always CPU bound on both real hardware (sw raid0 with two SATA disks) and on a rackspace cloud server (though my understanding is they are back by a raid10 array underneath) however I suspect even a single drive is fast enough to handle the ~20MB/s that compaction is currently performing when unthrottled.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add compaction_thread_priority back"
   },
   {
      "_id": "12525557",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-03 18:02:05",
      "description": "Our first stab at fixing this was CASSANDRA-2950.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "commitlog"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "truncate can still result in data being replayed after a restart"
   },
   {
      "_id": "12525396",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-10-01 07:00:16",
      "description": "[default@rapidshare] describe keyspace rapidshare;\nKeyspace: rapidshare:\n  Replication Strategy: org.apache.cassandra.locator.NetworkTopologyStrategy\n  Durable Writes: *false*\n    Options: [datacenter1:1]\n  Column Families:\n[default@rapidshare] create column family t1;\n1ba19300-ebfa-11e0-0000-34912694d0bf\nWaiting for schema agreement...\n... schemas agree across the cluster\n[default@rapidshare] describe keyspace rapidshare;\nKeyspace: rapidshare:\n  Replication Strategy: org.apache.cassandra.locator.NetworkTopologyStrategy\n  Durable Writes: *true*\n    Options: [datacenter1:1]\n  Column Families:\n    ColumnFamily: t1\n      Key Validation Class: org.apache.cassandra.db.marshal.BytesType\n      Default column value validator: org.apache.cassandra.db.marshal.BytesType\n      Columns sorted by: org.apache.cassandra.db.marshal.BytesType\n      Row cache size / save period in seconds: 0.0/0\n      Key cache size / save period in seconds: 200000.0/14400\n      Memtable thresholds: 0.028124999999999997/1440/6 (millions of ops/minutes/MB)\n      GC grace seconds: 864000\n      Compaction min/max thresholds: 4/32\n      Read repair chance: 1.0\n      Replicate on write: true\n      Built indexes: []",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "schema"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "creating column family sets durable_writes to true"
   },
   {
      "_id": "12525291",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-09-30 10:53:06",
      "description": "The commit of #3219 introduced two bugs: the condition to bootstrap is that there *are* non-system tables instead, a _not_ is missing, and the setToken() was wrongly push up into the \"I'm not bootstrapping\" block so a boostrapping node was left in the joining state.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "bootstrap"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Bootstrap is broken in 1.0.0-rc1"
   },
   {
      "_id": "12525107",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-28 21:40:20",
      "description": "I'm running 0.8.6 plus the multi-threaded compaction patch in issue 2901.  I'm getting an error compacting last night:\n\n\nError occured during compaction\njava.util.concurrent.ExecutionException: java.lang.ClassCastException: java.util.concurrent.ThreadPoolExecutor cannot be cast to org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor\n        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:222)\n        at java.util.concurrent.FutureTask.get(FutureTask.java:83)\n        at org.apache.cassandra.db.compaction.CompactionManager.performMajor(CompactionManager.java:278)\n        at org.apache.cassandra.db.ColumnFamilyStore.forceMajorCompaction(ColumnFamilyStore.java:1856)\n        at org.apache.cassandra.service.StorageService.forceTableCompaction(StorageService.java:1447)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)\n        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)\n        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)\n        at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:120)\n        at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:262)\n        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:836)\n        at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:761)\n        at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1427)\n        at javax.management.remote.rmi.RMIConnectionImpl.access$200(RMIConnectionImpl.java:72)\n        at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1265)\n        at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1360)\n        at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:788)\n        at sun.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:305)\n        at sun.rmi.transport.Transport$1.run(Transport.java:159)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at sun.rmi.transport.Transport.serviceCall(Transport.java:155)\n        at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:535)\n        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:790)\n        at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:649)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:619)\nCaused by: java.lang.ClassCastException: java.util.concurrent.ThreadPoolExecutor cannot be cast to org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor\n        at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:53)\n        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:767)\n        at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:658)\n        at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:92)\n        at org.apache.cassandra.db.compaction.ParallelCompactionIterable$Reducer.getCompactedRow(ParallelCompactionIterable.java:211)\n        at org.apache.cassandra.db.compaction.ParallelCompactionIterable$Reducer.getReduced(ParallelCompactionIterable.java:185)\n        at org.apache.cassandra.db.compaction.ParallelCompactionIterable$Reducer.getReduced(ParallelCompactionIterable.java:146)\n        at org.apache.cassandra.utils.ReducingIterator.computeNext(ReducingIterator.java:74)\n        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:140)\n        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:135)\n        at org.apache.cassandra.db.compaction.ParallelCompactionIterable$Unwrapper.computeNext(ParallelCompactionIterable.java:105)\n        at org.apache.cassandra.db.compaction.ParallelCompactionIterable$Unwrapper.computeNext(ParallelCompactionIterable.java:92)\n        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:140)\n        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:135)\n        at org.apache.commons.collections.iterators.FilterIterator.setNextObject(FilterIterator.java:183)\n        at org.apache.commons.collections.iterators.FilterIterator.hasNext(FilterIterator.java:94)\n        at org.apache.cassandra.db.compaction.CompactionManager.doCompactionWithoutSizeEstimation(CompactionManager.java:573)\n        at org.apache.cassandra.db.compaction.CompactionManager.doCompaction(CompactionManager.java:507)\n        at org.apache.cassandra.db.compaction.CompactionManager$4.call(CompactionManager.java:320)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n        ... 3 more\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Error during multi-threaded compaction in 0.8"
   },
   {
      "_id": "12524866",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-27 13:53:07",
      "description": "Hadoop input/output formats currently can OOM on wide rows.\n\nWe can add a new option to the ConfigHelper like columnPagingSize with a default of Integer.MAX_VALUE.\nThe input format would page the row internally rather than pull it over at once.\nThe output format could also use this to avoid sending huge rows over at once.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "hadoop"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Add wide row paging for ColumnFamilyInputFormat and ColumnFamilyOutputFormat"
   },
   {
      "_id": "12524504",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-09-24 06:10:36",
      "description": "When repairing a node, the following exception was thrown two times:\n\n{code}\nERROR [AntiEntropyStage:2] 2011-09-23 23:00:24,016 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[AntiEntropyStage:2,5,main]\njava.lang.AssertionError\n        at org.apache.cassandra.service.AntiEntropyService.rendezvous(AntiEntropyService.java:170)\n        at org.apache.cassandra.service.AntiEntropyService.access$100(AntiEntropyService.java:90)\n        at org.apache.cassandra.service.AntiEntropyService$TreeResponseVerbHandler.doVerb(AntiEntropyService.java:518)\n        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:59)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)\n{code}\n\nNo other errors occurred on the node. From peeking at the code, this assertion appears to simply check if an existing repair session could be found. Interestingly, the repair did continue to run after this as evidenced by several other AntiEntropyService entires in the log.\n\n8 node ring with an RF of 3, if that matters at all. No other nodes in the ring threw exceptions.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "AssertionError when repairing a node"
   },
   {
      "_id": "12524448",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-23 17:53:14",
      "description": "after my system ran for a while, it consitently goes into frozen state where all the mutations stage threads are waiting\non the switchlock,\n\nthe reason is that the switchlock is held by commit log, as shown by the following thread dump:\n\n\n\n\"COMMIT-LOG-WRITER\" prio=10 tid=0x00000000010df000 nid=0x32d3 waiting on condition [0x00007f2d81557000]\n   java.lang.Thread.State: WAITING (parking)\n        at sun.misc.Unsafe.park(Native Method)\n        - parking to wait for  <0x00007f3579eec060> (a java.util.concurrent.FutureTask$Sync)\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:838)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\n        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:248)\n        at java.util.concurrent.FutureTask.get(FutureTask.java:111)\n        at org.apache.cassandra.db.commitlog.CommitLog.getContext(CommitLog.java:386)\n        at org.apache.cassandra.db.ColumnFamilyStore.maybeSwitchMemtable(ColumnFamilyStore.java:650)\n        at org.apache.cassandra.db.ColumnFamilyStore.forceFlush(ColumnFamilyStore.java:722)\n        at org.apache.cassandra.db.commitlog.CommitLog.createNewSegment(CommitLog.java:573)\n        at org.apache.cassandra.db.commitlog.CommitLog.access$300(CommitLog.java:81)\n        at org.apache.cassandra.db.commitlog.CommitLog$LogRecordAdder.run(CommitLog.java:596)\n        at org.apache.cassandra.db.commitlog.PeriodicCommitLogExecutorService$1.runMayThrow(PeriodicCommitLogExecutorService.java:49)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        at java.lang.Thread.run(Thread.java:679)\n\n\nwe can clearly see that the COMMIT-LOG-WRITER thread is running the regular appender , but the appender itself calls getContext(), which again submits a new Callable to be executed, and waits on the Callable. but the new Callable is never going to be executed since the executor has only *one* thread.\n\n\nI believe this is a deterministic bug.\n\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "commitlog"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "inherent deadlock situation in commitLog flush?"
   },
   {
      "_id": "12524396",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-09-23 09:07:56",
      "description": "The --ignores option is supposed to take an argument but it doesn't.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "bulkloader"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "sstableloader ignores option doesn't work correctly"
   },
   {
      "_id": "12523921",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-09-21 21:09:59",
      "description": "super columns are annoying.  composite columns offer a better API and performance.  people should use composites over super columns.  some people are already using super columns.  C* should implement the super column API in terms of composites to reduce code, complexity and testing as well as increase performance.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "ponies"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "refactor super column implmentation to use composite column names instead"
   },
   {
      "_id": "12523796",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-20 23:47:56",
      "description": "Two main problems:\n\n- BF size calculation doesn't take into account LCS breaking the output apart into \"bite sized\" sstables, so memory use is much higher than predicted\n- ManyToMany merging is slow.  At least part of this is from running the full reducer machinery against single input sources, which can be optimized away.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "LeveledCompaction has several performance problems"
   },
   {
      "_id": "12523482",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2011-09-18 15:55:13",
      "description": "cassandra-cli set micro second timestamp by FBUtilities.timestampMicros. But CQL insert or update operation set milli second timestamp by AbstractModification.getTimestamp.\n\nIf you register data by cassandra-cli, you can't update data by CQL. Because CQL timestamp is judged as past time.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "cassandra-cli use micro second timestamp, but CQL use milli second"
   },
   {
      "_id": "12523442",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-17 18:10:17",
      "description": "As the title says, it barely does anything.  I inserted 50G worth of data with 1G heap and 99% overwrite ratio, and it only compacted twice:\n\n{noformat}\n INFO [CompactionExecutor:1] 2011-09-16 22:29:54,572 CompactionTask.java (line 118) Compacting [SSTableReader(path='/var/lib/cassandra/data/Keyspace1/Standard1-h-1-Data.db')]\n INFO [CompactionExecutor:1] 2011-09-16 22:29:58,606 CompactionTask.java (line 220) Compacted to [/var/lib/cassandra/data/Keyspace1/Standard1-h-2-Data.db,/var/lib/cassandra/data/Keyspace1/Standard1-h-4-Data.db,/var/lib/cassandra/data/Keyspace1/Standard1-h-5-Data.db,].  12,595,811 to 12,595,811 (~100% of original) bytes for 40,501 keys at 3.058122MBPS.  Time: 3,928ms.\n INFO [CompactionExecutor:1] 2011-09-16 22:29:58,607 CompactionTask.java (line 222) CF Total Bytes Compacted: 12,595,811\n INFO [CompactionExecutor:3] 2011-09-16 22:29:58,889 CompactionTask.java (line 118) Compacting [SSTableReader(path='/var/lib/cassandra/data/Keyspace1/Standard1-h-4-Data.db'), SSTableReader(path='/var/lib/cassandra/data/Keyspace1/Standard1-h-2-Data.db'), SSTableReader(path='/var/lib/cassandra/data/Keyspace1/Standard1-h-5-Data.db'), SSTableReader(path='/var/lib/cassandra/data/Keyspace1/Standard1-h-3-Data.db')]\n INFO [CompactionExecutor:3] 2011-09-16 22:30:06,900 CompactionTask.java (line 220) Compacted to [/var/lib/cassandra/data/Keyspace1/Standard1-h-7-Data.db,/var/lib/cassandra/data/Keyspace1/Standard1-h-9-Data.db,/var/lib/cassandra/data/Keyspace1/Standard1-h-11-Data.db,/var/lib/cassandra/data/Keyspace1/Standard1-h-12-Data.db,/var/lib/cassandra/data/Keyspace1/Standard1-h-14-Data.db,/var/lib/cassandra/data/Keyspace1/Standard1-h-15-Data.db,].  28,374,396 to 28,374,396 (~100% of original) bytes for 91,236 keys at 3.380379MBPS.  Time: 8,005ms.\n INFO [CompactionExecutor:3] 2011-09-16 22:30:06,901 CompactionTask.java (line 222) CF Total Bytes Compacted: 40,970,207\n{noformat}\n\nResulting in the following levels:\n\n{noformat}\nL0: 4965\nL1: 6\nL2: 0\nL3: 0\nL4: 0\nL5: 0\nL6: 0\nL7: 0\n{noformat}\n\nThis is obviously going to result in extremely poor read performance.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "LeveledCompactionStrategy is too complacent"
   },
   {
      "_id": "12523364",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-09-16 17:39:55",
      "description": "Since autoboostrap is defaulted to on when you start a cluster at once (http://screenr.com/5G6) you can end up with nodes being assigned the same token.\n\n{code}\nINFO 17:34:55,688 Node /67.23.43.14 is now part of the cluster\n INFO 17:34:55,698 InetAddress /67.23.43.14 is now UP\n INFO 17:34:55,698 Nodes /67.23.43.14 and tjake2/67.23.43.15 have the same token 8823900603000512634329811229926543166.  Ignoring /67.23.43.14\n INFO 17:34:55,698 Node /98.129.220.182 is now part of the cluster\n INFO 17:34:55,698 InetAddress /98.129.220.182 is now UP\n INFO 17:34:55,698 Nodes /98.129.220.182 and tjake2/67.23.43.15 have the same token 8823900603000512634329811229926543166.  Ignoring /98.129.220.182\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "bootstrap"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Nodes started at the same time end up with the same token"
   },
   {
      "_id": "12523332",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-09-16 13:36:46",
      "description": "A streamOutSession acquire a reference on the sstable it will stream and release them as soon as each sstable has been fully streamed. However, since a stream session has currently no means to know when it failed, we'll keep references indefinitely (meaning until next restart) if their is a failure. One way a stream session could very easily fail is if the remote end dies. We must make sure we correctly release sstable references when that happens.\n\nNote that it won't be bulletproof, there is probably other means by which a streaming could fail: a bug in the code throwing an exception, no space left on the receiving end, etc... But those are unlikely enough that I propose to care only for the case of a node dying for now and leave the bullet-proofing to CASSANDRA-3112. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "streaming"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "A streamOutSession keeps sstables references forever if the remote end dies"
   },
   {
      "_id": "12523081",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-09-14 18:05:18",
      "description": "If JMX times out it's difficult to tell when repair completes.Right now we log at DEBUG for each column family but we need a way to tell when the repair operation completes as a whole.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "logging",
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Log message at INFO when a global or keyspace level repair operation completes"
   },
   {
      "_id": "12522905",
      "assignee": "krummas",
      "components": [],
      "created": "2011-09-13 14:58:03",
      "description": "Currently, repair compare merkle trees by pair, in isolation of any other tree. What that means concretely is that if I have three node A, B and C (RF=3) with A and B in sync, but C having some range r inconsitent with both A and B (since those are consistent), we will do the following transfer of r: A -> C, C -> A, B -> C, C -> B.\n\nThe fact that we do both A -> C and C -> A is fine, because we cannot know which one is more to date from A or C. However, the transfer B -> C is useless provided we do A -> C if A and B are in sync. Not doing that transfer will be a 25% improvement in that case. With RF=5 and only one node inconsistent with all the others, that almost a 40% improvement, etc...\n\nGiven that this situation of one node not in sync while the others are is probably fairly common (one node died so it is behind), this could be a fair improvement over what is transferred. In the case where we use repair to rebuild completely a node, this will be a dramatic improvement, because it will avoid the rebuilded node to get RF times the data it should get.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Repair: compare all trees together (for a given range/cf) instead of by pair in isolation"
   },
   {
      "_id": "12522820",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-12 22:34:56",
      "description": "Removed memtable_flush_after_mins in CASSANDRA-2183 instead of making it a no-op.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix backwards compatibilty for cql memtable properties"
   },
   {
      "_id": "12522760",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-12 16:01:51",
      "description": "With CASSANDRA-3171 fixed we don't need to be scared of large numbers of compaction candidates anymore.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Remove special-cased maximum on sstables-to-compact for leveled strategy"
   },
   {
      "_id": "12522759",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-12 15:51:23",
      "description": "Compaction just stops running at some point.  To repro, insert like 20M rows with a 1G heap and you'll get around 1k sstables.  Restarting doesn't help, you have to invoke a major to get anything to happen.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Compaction fails to occur"
   },
   {
      "_id": "12522749",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-09-12 14:58:17",
      "description": "The first part of the counter shard merging process is done during counter replication. This was done there because it requires that all replica are made aware of the merging (we could only rely on nodetool repair for that but that seems much too fragile, it's better as just a safety net). However this part isn't thread safe as multiple threads can do the merging for the same shard at the same time (which shouldn't really \"corrupt\" the counter value per se, but result in an incorrect context).\n\nSynchronizing that part of the code would be very costly in term of performance, so instance I propose to move the part of the shard merging done during replication to compaction. It's a better place anyway. The only downside is that it means compaction will sometime send mutations to other node as a side effect, which doesn't feel very clean but is probably not a big deal either.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Counter shard merging is not thread safe"
   },
   {
      "_id": "12522664",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-10 23:20:47",
      "description": "In order to test a theory, we tried to disable hinted handoff on our cluster.  We updated all of the yaml files and then restarted all the nodes in our cluster.  However we continue to get messages such as this in the logs after restarting:\n{quote}\nINFO [HintedHandoff:1] 2011-09-10 22:41:40,813 HintedHandOffManager.java (line 323) Started hinted handoff for endpoint /10.1.2.3\nINFO [HintedHandoff:1] 2011-09-10 22:41:40,813 HintedHandOffManager.java (line 379) Finished hinted handoff of 0 rows to endpoint /10.1.2.3\nINFO [HintedHandoff:1] 2011-09-10 22:41:45,025 HintedHandOffManager.java (line 323) Started hinted handoff for endpoint /10.2.3.4\nINFO [HintedHandoff:1] 2011-09-10 22:41:45,026 HintedHandOffManager.java (line 379) Finished hinted handoff of 0 rows to endpoint /10.2.3.4\nINFO [HintedHandoff:1] 2011-09-10 22:42:10,017 HintedHandOffManager.java (line 323) Started hinted handoff for endpoint /10.3.4.5\nINFO [HintedHandoff:1] 2011-09-10 22:42:10,017 HintedHandOffManager.java (line 379) Finished hinted handoff of 0 rows to endpoint /10.3.4.5\n{quote}\n\nAlso looking at the System.HintsColumnFamily in jmx there is activity there such as pending tasks that come and go.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "HintedHandoff"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Disabling hinted handoff counterintuitively continues to log handoff messages"
   },
   {
      "_id": "12522420",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2011-09-09 13:10:54",
      "description": "Per previous discussions, the drivers should be removed from the newly created 1.x branches.  The attached patch (to follow shortly) removes build and test from build.xml.  The remaining bit would be to perform the actual svn rm, and the merge or merges, complete with whatever magic arguments are necessary to ensure that doesn't propagate upward to trunk (yet).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "remove drivers/ from new branches"
   },
   {
      "_id": "12522322",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-08 20:59:38",
      "description": "This is because Long objects need to be compared with .equals, not ==.\n\nCASSANDRA-3076 is the original issue but we should use a new ticket for this since 0.7.9 and 0.8.5 are both released already.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "thistimeforsure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "GCInspector still not avoiding divide by zero"
   },
   {
      "_id": "12521621",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-07 16:49:12",
      "description": "As discussed in CASSANDRA-3031, we should make the following changes:\n\n- rename bytea to blob\n- rename date to timestamp\n- remove int, pending addition of CASSANDRA-3031 (bigint and varint will be unchanged)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Update CQL type names to match expected (SQL) behavor"
   },
   {
      "_id": "12521381",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-05 19:29:53",
      "description": "Need to expose the CQL api version; might as well include the server version while we're at it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Expose server, api versions to CQL"
   },
   {
      "_id": "12521007",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-09-01 02:42:09",
      "description": "A compaction lock is acquired when dropping keyspaces or column families which will cause the schema migration to block if a compaction is in progress.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Compactions can (seriously) delay schema migrations"
   },
   {
      "_id": "12520595",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332923",
            "id": "12332923",
            "name": "Feature/2i Index"
         }
      ],
      "created": "2011-08-29 15:41:32",
      "description": "We deleted all of our secondary indexes.  A couple of days later I was watching compactionstats on one of the nodes and it was in the process of minor compacting one of the deleted secondary indexes.  I double checked the keyspace definitions on the CLI and there were no secondary indexes defined.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Secondary index still does minor compacting after deleting index"
   },
   {
      "_id": "12520318",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-08-26 22:54:08",
      "description": "CASSANDRA-1608 attempts to restrict itself to one compaction task per CF (see discussion there for why this is necessary) by synchronizing LCS.getBackgroundTasks but this is not sufficient.  Consider this sequence of events:\n\n1. getBackgroundTasks returns a Task for compacting some L0 sstables.  this Task is scheduled.\n2. Another SSTable for this CF is flushed, so CompactionManager.submitBackground is called.  getBT is not currently in-progress so the synchronization does not stop another Task from being returned and scheduled.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lcs"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Leveled compaction allows multiple simultaneous compaction Tasks"
   },
   {
      "_id": "12519731",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2011-08-22 19:52:52",
      "description": "count() has been broken since it was introduced in CASSANDRA-1704.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix count()"
   },
   {
      "_id": "12519038",
      "assignee": "iamaleksey",
      "components": [],
      "created": "2011-08-16 19:33:33",
      "description": "Using already existing options for authentication in ConfigHelper, and adding a call to client#login just before client#set_keyspace to in CassandraStorage#initSchema",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "authentication",
         "pig"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Implement authentication in Pig loadFunc"
   },
   {
      "_id": "12518911",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-08-15 19:18:47",
      "description": "While doing a cleanup I got the following AssertionError, I have tried a scrub and a major compaction before the cleanup which has not helped.\n\nST:\n\n INFO 18:49:58,540 Scrubbing SSTableReader(path='/vol/cassandra/data/system/LocationInfo-g-93-Data.db')\n INFO 18:49:58,834 Scrub of SSTableReader(path='/vol/cassandra/data/system/LocationInfo-g-93-Data.db') complete: 4 rows in new sstable and 0 empty (tombstoned) rows dropped\n INFO 18:49:58,913 Scrubbing SSTableReader(path='/vol/cassandra/data/system/Migrations-g-56-Data.db')\n INFO 18:49:59,218 Scrub of SSTableReader(path='/vol/cassandra/data/system/Migrations-g-56-Data.db') complete: 1 rows in new sstable and 0 empty (tombstoned) rows dropped\n INFO 18:49:59,256 Scrubbing SSTableReader(path='/vol/cassandra/data/system/Schema-g-58-Data.db')\n INFO 18:49:59,323 Scrub of SSTableReader(path='/vol/cassandra/data/system/Schema-g-58-Data.db') complete: 34 rows in new sstable and 0 empty (tombstoned) rows dropped\n INFO 18:49:59,416 Scrubbing SSTableReader(path='/vol/cassandra/data/SpiderServices/Content2-g-5074-Data.db')\n INFO 18:50:50,137 Scrub of SSTableReader(path='/vol/cassandra/data/SpiderServices/Content2-g-5074-Data.db') complete: 91735 rows in new sstable and 32 empty (tombstoned) rows dropped\n INFO 18:50:50,137 Scrubbing SSTableReader(path='/vol/cassandra/data/SpiderServices/Content2-g-5075-Data.db')\n INFO 18:50:53,075 Scrub of SSTableReader(path='/vol/cassandra/data/SpiderServices/Content2-g-5075-Data.db') complete: 27940 rows in new sstable and 0 empty (tombstoned) rows dropped\n INFO 18:50:53,089 Scrubbing SSTableReader(path='/vol/cassandra/data/SpiderServices/Content-g-238-Data.db')\n\n INFO 18:51:10,302 Scrub of SSTableReader(path='/vol/cassandra/data/SpiderServices/Content-g-238-Data.db') complete: 70815 rows in new sstable and 0 empty (tombstoned) rows dropped\n INFO 18:53:05,420 Cleaning up SSTableReader(path='/vol/cassandra/data/SpiderServices/Content2-g-5078-Data.db')\n INFO 18:53:13,266 Cleaned up to /vol/cassandra/data/SpiderServices/Content2-tmp-g-5079-Data.db.  198,705,176 to 198,705,176 (~100% of original) bytes for 27,940 keys.  Time: 7,846ms.\n INFO 18:53:13,267 Cleaning up SSTableReader(path='/vol/cassandra/data/SpiderServices/Content2-g-5077-Data.db')\nERROR 18:53:33,913 Fatal exception in thread Thread[CompactionExecutor:21,1,RMI Runtime]\njava.lang.AssertionError\n\tat org.apache.cassandra.db.compaction.PrecompactedRow.write(PrecompactedRow.java:107)\n\tat org.apache.cassandra.io.sstable.SSTableWriter.append(SSTableWriter.java:132)\n\tat org.apache.cassandra.db.compaction.CompactionManager.doCleanupCompaction(CompactionManager.java:866)\n\tat org.apache.cassandra.db.compaction.CompactionManager.access$500(CompactionManager.java:65)\n\tat org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:204)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "exception",
         "nodetool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "AssertionError on nodetool cleanup"
   },
   {
      "_id": "12518303",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-08-09 10:22:23",
      "description": "I'm getting large quantity of exceptions during streaming. It is always in MessagingService.java:420. The streaming appears to be blocked.\n\n INFO 10:11:14,734 Streaming to /10.235.77.27\nERROR 10:11:14,734 Fatal exception in thread Thread[StreamStage:2,5,main]\njava.lang.NullPointerException\n        at org.apache.cassandra.net.MessagingService.stream(MessagingService.java:420)\n        at org.apache.cassandra.streaming.StreamOutSession.begin(StreamOutSession.java:176)\n        at org.apache.cassandra.streaming.StreamOut.transferRangesForRequest(StreamOut.java:148)\n        at org.apache.cassandra.streaming.StreamRequestVerbHandler.doVerb(StreamRequestVerbHandler.java:54)\n        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:59)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:636)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "nullpointerexception",
         "streaming"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "NullPointerException in MessagingService.java:420"
   },
   {
      "_id": "12517821",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-08-03 18:10:50",
      "description": "We currently do not reject writes for counters at CL.ANY, even though this is not supported (and rightly so).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "We should refuse query for counters at CL.ANY"
   },
   {
      "_id": "12515424",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-07-26 16:19:51",
      "description": "Steps to reproduce:\n* Perform a batch mutation of more than one counter in more than one super-column in the same column-family.\n* The following exception is thrown during replication:\n\nDEBUG [MutationStage:63] 2011-07-26 17:05:12,653 CounterMutationVerbHandler.java (line 52) Applying forwarded CounterMutation(RowMutation(keyspace='ks1', key='4ae71336e44bf9bf', modifications=[ColumnFamily(cf1 [SuperColumn(302c7375706572636f6c30 [302c636f6c30:false:8@1311696312648,]),SuperColumn(302c7375706572636f6c31 [302c636f6c30:false:8@1311696312648,]),])]), QUORUM)\nDEBUG [MutationStage:63] 2011-07-26 17:05:12,653 StorageProxy.java (line 432) insert writing local & replicate CounterMutation(RowMutation(keyspace='ks1', key='4ae71336e44bf9bf', modifications=[cf1]), QUORUM)\nDEBUG [MutationStage:63] 2011-07-26 17:05:12,654 Table.java (line 398) applying mutation of row 4ae71336e44bf9bf\nERROR [ReplicateOnWriteStage:125] 2011-07-26 17:05:12,655 AbstractCassandraDaemon.java (line 139) Fatal exception in thread Thread[ReplicateOnWriteStage:125,5,main]\njava.lang.RuntimeException: java.lang.IllegalArgumentException: ColumnFamily ColumnFamily(cf1 [SuperColumn(302c7375706572636f6c31 [302c636f6c30:false:[{cad93dc0-b7a0-11e0-0000-123f813dd5df, 3, 3}*]@1311696312648!-9223372036854775808,]),]) already has modifications in this mutation: ColumnFamily(cf1 [SuperColumn(302c7375706572636f6c30 [302c636f6c30:false:[{cad93dc0-b7a0-11e0-0000-123f813dd5df, 3, 3}*]@1311696312648!-9223372036854775808,]),])\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:34)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:636)\nCaused by: java.lang.IllegalArgumentException: ColumnFamily ColumnFamily(cf1 [SuperColumn(302c7375706572636f6c31 [302c636f6c30:false:[{cad93dc0-b7a0-11e0-0000-123f813dd5df, 3, 3}*]@1311696312648!-9223372036854775808,]),]) already has modifications in this mutation: ColumnFamily(cf1 [SuperColumn(302c7375706572636f6c30 [302c636f6c30:false:[{cad93dc0-b7a0-11e0-0000-123f813dd5df, 3, 3}*]@1311696312648!-9223372036854775808,]),])\n        at org.apache.cassandra.db.RowMutation.add(RowMutation.java:123)\n        at org.apache.cassandra.db.CounterMutation.makeReplicationMutation(CounterMutation.java:120)\n        at org.apache.cassandra.service.StorageProxy$5$1.runMayThrow(StorageProxy.java:455)\n        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n        ... 3 more\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "batch_mutate",
         "counters",
         "supercolumns"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Batch mutation of counters in multiple supercolumns throws an exception during replication."
   },
   {
      "_id": "12514422",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-07-18 11:32:32",
      "description": "sstableloader only stream existing sstables. If you need to load data existing in another form (json, csv, whatnot), you need to first write the sstable(s) to load. The recommended way to do this is either to use json2sstable or to modify it if your input is not json. Modifying json2sstable is however more involved than it needs to be, you'll need at least some basic understanding of a bunch of internal classes (DecoratedKey, ColumnFamily, SuperColumn, ...). Even for json input, you can use json2sstable only if your json actually conform to what is expected and even then, good luck to someone that want to add counters.\n\nThis ticket proposes to add a simple interface to write sstables. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "bulkloader"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Simplified classes to write SSTables (for bulk loading usage)"
   },
   {
      "_id": "12514405",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-07-18 07:33:16",
      "description": "The bulk loader needs both the data file and the index file. This ticket proposes to make it rebuild the index part if it is not present (it would still be faster to have the index file around, but it is annoying to not be able to bulk load a sstable just because you happen to have deleted the index file).\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bulkloader"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Have the bulkloader rebuild the index file if necessary"
   },
   {
      "_id": "12514404",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-07-18 07:23:01",
      "description": "The bulkload JMX call is supposed to simplify bulkloading when done from a Cassandra node (so you don't have to configure the bulkloading client to not conflict with the node itself), but that call doesn't work (it forgets to add the ranges to stream).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "bulkloader"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix bulkload JMX call"
   },
   {
      "_id": "12513859",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-07-12 22:04:36",
      "description": "For counters with RF=1, we still do a read to replicate, even though there is nothing to replicate it too.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Don't \"replicate_on_write\" with RF=1"
   },
   {
      "_id": "12513838",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-07-12 19:28:38",
      "description": "Right now, we choose the first replica for a counter increments based solely on what the snitch returns. If the clients requests are well balanced over the cluster and the snitch not ill configured, this should not be a problem, but this is probably too strong an assumption to make.\n\nThe goal of this ticket is to change this to choose a random replica in the current data center instead.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Randomize (to some extend) the choice of the first replica for counter increment"
   },
   {
      "_id": "12513837",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-07-12 19:14:31",
      "description": "The counter design involves a read on the first replica during a write. At CL.ONE, this read is not involved in the latency of the operation (the write is acknowledged before). This means it is fairly easy to insert too quickly at CL.ONE and have the replicate on write tasks falling behind. The goal of this ticket is to protect against that.\n\nAn option could be to bound the replicate on write task queue so that write start to block once we have too much of those in the queue. Another option could be to drop the oldest tasks when they are too old, but it's probably a more unsafe option.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Avoids having replicate on write tasks stacking up at CL.ONE"
   },
   {
      "_id": "12513477",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-07-10 21:39:00",
      "description": "Currently, when running a MapReduce job against data in a Cassandra data store, it reads through all the data for a particular ColumnFamily.  This could be optimized to only read through those rows that have to do with the query.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "hadoop"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Allow map/reduce to use server-side query filters"
   },
   {
      "_id": "12513118",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-07-07 10:20:03",
      "description": "After upgrading the binaries to 0.8.1 I get an exception when starting cassandra:\n\n{noformat}\n[root@bserv2 local]#  INFO 12:51:04,512 Logging initialized\n INFO 12:51:04,523 Heap size: 8329887744/8329887744\n INFO 12:51:04,524 JNA not found. Native methods will be disabled.\n INFO 12:51:04,531 Loading settings from file:/usr/local/apache-cassandra-0.8.1/conf/cassandra.yaml\n INFO 12:51:04,621 DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap\n INFO 12:51:04,707 Global memtable threshold is enabled at 2648MB\n INFO 12:51:04,708 Removing compacted SSTable files (see http://wiki.apache.org/cassandra/MemtableSSTable)\n INFO 12:51:04,713 Removing compacted SSTable files (see http://wiki.apache.org/cassandra/MemtableSSTable)\n INFO 12:51:04,714 Removing compacted SSTable files (see http://wiki.apache.org/cassandra/MemtableSSTable)\n INFO 12:51:04,716 Removing compacted SSTable files (see http://wiki.apache.org/cassandra/MemtableSSTable)\n INFO 12:51:04,717 Removing compacted SSTable files (see http://wiki.apache.org/cassandra/MemtableSSTable)\n INFO 12:51:04,719 Removing compacted SSTable files (see http://wiki.apache.org/cassandra/MemtableSSTable)\n INFO 12:51:04,770 reading saved cache /vm1/cassandraDB/saved_caches/system-IndexInfo-KeyCache\n INFO 12:51:04,776 Opening /vm1/cassandraDB/data/system/IndexInfo-f-9\n INFO 12:51:04,792 reading saved cache /vm1/cassandraDB/saved_caches/system-Schema-KeyCache\n INFO 12:51:04,794 Opening /vm1/cassandraDB/data/system/Schema-f-194\n INFO 12:51:04,797 Opening /vm1/cassandraDB/data/system/Schema-f-195\n INFO 12:51:04,802 Opening /vm1/cassandraDB/data/system/Schema-f-193\n INFO 12:51:04,811 Opening /vm1/cassandraDB/data/system/Migrations-f-193\n INFO 12:51:04,814 reading saved cache /vm1/cassandraDB/saved_caches/system-LocationInfo-KeyCache\n INFO 12:51:04,815 Opening /vm1/cassandraDB/data/system/LocationInfo-f-292\n INFO 12:51:04,843 Loading schema version 586e70fd-a332-11e0-828e-34b74a661156\nERROR 12:51:04,996 Exception encountered during startup.\norg.apache.cassandra.db.marshal.MarshalException: A long is exactly 8 bytes: 15\n        at org.apache.cassandra.db.marshal.LongType.getString(LongType.java:72)\n        at org.apache.cassandra.config.CFMetaData.getDefaultIndexName(CFMetaData.java:971)\n        at org.apache.cassandra.config.CFMetaData.inflate(CFMetaData.java:381)\n        at org.apache.cassandra.config.KSMetaData.inflate(KSMetaData.java:172)\n        at org.apache.cassandra.db.DefsTable.loadFromStorage(DefsTable.java:99)\n        at org.apache.cassandra.config.DatabaseDescriptor.loadSchemas(DatabaseDescriptor.java:479)\n        at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:139)\n        at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:315)\n        at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:80)\nException encountered during startup.\norg.apache.cassandra.db.marshal.MarshalException: A long is exactly 8 bytes: 15\n        at org.apache.cassandra.db.marshal.LongType.getString(LongType.java:72)\n        at org.apache.cassandra.config.CFMetaData.getDefaultIndexName(CFMetaData.java:971)\n        at org.apache.cassandra.config.CFMetaData.inflate(CFMetaData.java:381)\n        at org.apache.cassandra.config.KSMetaData.inflate(KSMetaData.java:172)\n        at org.apache.cassandra.db.DefsTable.loadFromStorage(DefsTable.java:99)\n        at org.apache.cassandra.config.DatabaseDescriptor.loadSchemas(DatabaseDescriptor.java:479)\n        at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:139)\n        at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:315)\n        at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:80)\n{noformat}\n\nIt seems this has something to do with indexes, and I do have a CF with an index on it, but it is not used.\nI can try and remove the index with 0.7.x binaries, but I will wait a bit to see if anyone needs it to reproduce the bug.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "exception",
         "index",
         "starting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Starting 0.8.1 after upgrade from 0.7.6-2 fails"
   },
   {
      "_id": "12512248",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-06-29 19:03:27",
      "description": "When creating the initial merkle tree, repair tries to be (too) smart and use the key samples to \"guide\" the tree splitting. While this is a good idea for OPP where there is a good change the data distribution is uneven, you can't beat an even distribution for the RandomPartitionner. And a quick experiment even shows that the method used is significantly less efficient than an even distribution for the ranges of the merkle tree (that is, an even distribution gives a much better of distribution of the number of keys by range of the tree).\n\nThus let's switch to an even distribution for RandomPartitionner. That 3 lines change alone amounts for a significant improvement of repair's precision.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Always use even distribution for merkle tree with RandomPartitionner"
   },
   {
      "_id": "12511983",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-06-28 12:47:19",
      "description": "Replicate_on_write *must* default to true (defaulting to false is very dangerous and imho, the option of setting it to false shouldn't exist in the first place) and CFMetadata.DEFAULT_REPLICATE_ON_WRITE is correctly true. But it doesn't get set correctly. Instead, the code force the value of the cf_def even if it wasn't defined, resulting in setting it to false since that is the default value for a boolean in JAVA.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CFMetadata don't set the default for Replicate_on_write correctly"
   },
   {
      "_id": "12511479",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-06-24 14:46:04",
      "description": "I'm getting NullPointerException on a node upgraded from 0.7 to 0.8.0 (Debian package). The exception is thrown quickly several times after start. Then the Cassandra node is unresponsive. The Stack trace is:\n\nERROR 14:36:49,712 Fatal exception in thread Thread[WRITE-/10.228.243.191,5,main]\njava.lang.NullPointerException\n        at org.apache.cassandra.net.OutboundTcpConnection.connect(OutboundTcpConnection.java:168)\n        at org.apache.cassandra.net.OutboundTcpConnection.run(OutboundTcpConnection.java:89)\n\nERROR 14:36:49,758 Fatal exception in thread Thread[WRITE-/10.227.101.171,5,main]\njava.lang.NullPointerException\n        at org.apache.cassandra.net.OutboundTcpConnection.connect(OutboundTcpConnection.java:168)\n        at org.apache.cassandra.net.OutboundTcpConnection.run(OutboundTcpConnection.java:89)\n\nERROR 14:36:49,797 Fatal exception in thread Thread[WRITE-/10.228.243.191,5,main]\njava.lang.NullPointerException\n        at org.apache.cassandra.net.OutboundTcpConnection.connect(OutboundTcpConnection.java:168)\n        at org.apache.cassandra.net.OutboundTcpConnection.run(OutboundTcpConnection.java:89)\n\nERROR 14:36:50,756 Fatal exception in thread Thread[WRITE-/10.226.194.239,5,main]\njava.lang.NullPointerException\n        at org.apache.cassandra.net.OutboundTcpConnection.connect(OutboundTcpConnection.java:168)\n        at org.apache.cassandra.net.OutboundTcpConnection.run(OutboundTcpConnection.java:89)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "nullpointerexception"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "NullPointerException after upgrade to 0.8.0"
   },
   {
      "_id": "12511343",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-06-23 11:35:30",
      "description": "Being a little slow, I just realized after having opened CASSANDRA-2811 and CASSANDRA-2815 that there is a more general problem with repair.\n\nWhen a repair is started, it will send a number of merkle tree to its neighbor as well as himself and assume for correction that the building of those trees will be started on every node roughly at the same time (if not, we end up comparing data snapshot at different time and will thus mistakenly repair a lot of useless data). This is bogus for many reasons:\n* Because validation compaction runs on the same executor that other compaction, the start of the validation on the different node is subject to other compactions. 0.8 mitigates this in a way by being multi-threaded (and thus there is less change to be blocked a long time by a long running compaction), but the compaction executor being bounded, its still a problem)\n* if you run a nodetool repair without arguments, it will repair every CFs. As a consequence it will generate lots of merkle tree requests and all of those requests will be issued at the same time. Because even in 0.8 the compaction executor is bounded, some of those validations will end up being queued behind the first ones. Even assuming that the different validation are submitted in the same order on each node (which isn't guaranteed either), there is no guarantee that on all nodes, the first validation will take the same time, hence desynchronizing the queued ones.\n\nOverall, it is important for the precision of repair that for a given CF and range (which is the unit at which trees are computed), we make sure that all node will start the validation at the same time (or, since we can't do magic, as close as possible).\n\nOne (reasonably simple) proposition to fix this would be to have repair schedule validation compactions across nodes one by one (i.e, one CF/range at a time), waiting for all nodes to return their tree before submitting the next request. Then on each node, we should make sure that the node will start the validation compaction as soon as requested. For that, we probably want to have a specific executor for validation compaction and:\n* either we fail the whole repair whenever one node is not able to execute the validation compaction right away (because no thread are available right away).\n* we simply tell the user that if he start too many repairs in parallel, he may start seeing some of those repairing more data than it should.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Repair doesn't synchronize merkle tree creation properly"
   },
   {
      "_id": "12511327",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-06-23 07:53:05",
      "description": "The core of the problem is that the sstables used to construct a merkle tree are not necessarily the same than the ones for which streaming is initiated. This is usually not a big deal: newly compacted sstables don't matter since data hasn't change. Newly flushed data (between the start of the validation compaction and the start of the streaming) are a little bit more problematic, even though one could argue that on average this won't be not too much data.\n\nBut there can be more problematic scenario: suppose a 3 nodes cluster with RF=3, all the data on node3 is removed and then repair is started on node3.  Also suppose the cluster havs two CFs, cf1 and cf2, sharing evenly the data.\nNode3 will request the usual merkle trees and let's pretend validation compaction is mono-threaded to simplify.\nWhat can happen is the following:\n  # node3 computes its merkle trees for all requests very quickly, having no data. It will thus wait on the other nodes trees (his own trees saying \"I have no data\").\n  # node1 starts computing its tree for say cf1 (queuing the computation for cf2). In the meantime, node2 may start computing the tree for cf2 (queuing the one for cf1).\n  # when node1 completes his first tree, it sends it to node3. Node3 receives it, compare to his own tree and initiate transfer of all the data for cf1 from node1 to him.\n  # not too long after that, node2 completes it's first tree, the one for cf2 and send it to node3. Based on it, transfer of all the data for cf2 from node2 to node3 starts.\n  # An arbitrary long time after that (compaction validation can take time), node2 will finish his second tree (for cf1 that is and send it back to node3. Node3 will compare to his own (empty) tree and decide that all the ranges should be repaired with node2 for cf1. The problem is that when that happens, the transfer of cf1 from node1 may have been done already, or at least partly done. For that reason, node3 will start streaming all this data to node2.\n  # For the same reasons, node3 may end up transfering all or part of cf2 to node1.\n\nSo the problem is, even though at the beginning node1 and node2 may be perfectly consistent, we will end up streaming potentially huge amount of data to them.\n\nI think this affects both 0.7 and 0.8, though differently because compaction multi-threading and the fact that 0.8 differentiates the ranges make the timing different.\n\nOne solution (in a way, the theoretically right solution) would be to grab references to the sstables we use for the validation compaction, and only initiate streaming on these sstables. However, in 0.8 where compaction is multi-threaded, this would mean retaining compacted sstables longer that necessary. This is also a bit complicated and in particular would require a network protocol change (because a streaming request message would have to contain some information allowing to decide what set of sstables to use).\n\nA maybe simpler solution could be to have the node coordinating the repair wait for the tree of all the remotes (in this obviously only for a given column family and range) before starting streaming.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Bad timing in repair can transfer data it is not suppose to "
   },
   {
      "_id": "12510951",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-06-20 12:33:54",
      "description": "This is actually a streaming problem. If a StreamOutSession has nothing to transfer (i.e, no sstables have the requested ranges), it will not even initiate the transfer and simply close the session right away. The problem is that if the session was initiated by a remote end (through a StreamRequestMessage), the remote end will never be notified and never run his callback.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair",
         "streaming"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Repair hangs if a neighbor has nothing to send "
   },
   {
      "_id": "12510664",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-06-17 14:39:01",
      "description": "If an sstable of a counter column family is corrupted, the only safe solution a user have right now is to:\n# Remove the NodeId System table to force the node to regenerate a new NodeId (and thus stop incrementing on it's previous, corrupted, subcount)\n# Remove all the sstables for that column family on that node (this is important because otherwise the node will never get \"repaired\" for it's previous subcount)\n\nThis is far from being ideal, but I think this is the price we pay for avoiding the read-before-write. In any case, the first step (remove the NodeId system table) happens to remove the list of the old NodeId this node has, which could prevent us for merging the other potential previous nodeId. This is ok but sub-optimal. This ticket proposes to add a new startup flag to make the node renew it's NodeId, thus replacing this first.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add startup option renew the NodeId (for counters)"
   },
   {
      "_id": "12510655",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-06-17 12:42:37",
      "description": "After a minor compaction, deleted key-slices are visible again.\n\nSteps to reproduce:\n\n1) Insert a row named \"test\".\n2) Insert 500000 rows. During this step, row \"test\" is included in a major compaction:\n   file-1, file-2, file-3 and file-4 compacted to file-5 (includes \"test\").\n3) Delete row named \"test\".\n4) Insert 500000 rows. During this step, row \"test\" is included in a minor compaction:\n   file-6, file-7, file-8 and file-9 compacted to file-10 (should include tombstoned \"test\").\nAfter step 4, row \"test\" is live again.\n\nTest environment:\n\nSingle node with empty database.\n\nStandard configured super-column-family (I see this behavior with several gc_grace settings (big and small values):\ncreate column family Customers with column_type = 'Super' and comparator = 'BytesType;\n\nIn Cassandra 0.7.6 I observe the expected behavior, i.e. after step 4, the row is still deleted.\n\nI've included a .NET program to reproduce the problem. I will add a Java version later on.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "After a minor compaction, deleted key-slices are visible again"
   },
   {
      "_id": "12509845",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-06-10 16:20:55",
      "description": "If scrub cannot 'repair' a corrupted row, it will skip it. On node A, if the row contains some sub-count for A id, those will be lost forever since A is the source of truth on it's current id. We should thus renew node A id when that happens to avoid this (not unlike we do in cleanup).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Scrub could lose increments and replicate that loss"
   },
   {
      "_id": "12509041",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2011-06-02 00:12:16",
      "description": "*The following statement fails when used with a Statement or PreparedStatement*\n{code}\nres = stmt.executeQuery(\"SELECT bar FROM users\");  \nres.next();\n{code}\n\n*Error Message*\n{code}\n    [junit] Testcase: simpleSelect(com.datastax.cql.reproBugTest):\tCaused an ERROR\n    [junit] null\n    [junit] java.lang.NullPointerException\n    [junit] \tat org.apache.cassandra.cql.jdbc.ColumnDecoder.makeKeyColumn(ColumnDecoder.java:136)\n    [junit] \tat org.apache.cassandra.cql.jdbc.CResultSet.next(CResultSet.java:388)\n    [junit] \tat com.datastax.cql.reproBugTest.simpleSelect(reproBugTest.java:57)\n    [junit] \n    [junit] \n    [junit] Test com.datastax.cql.reproBugTest FAILED\n{code}\n\n\n*Here is a quick repro.  Showing that res.next() works with other statements but not select.*\n_Also notice that ResultSet.getMetaData().getColumnCount() always returns zero._  \n_I noticed in the existing driver tests similar test cases, so not sure the issue._\n\n*Steps to run script*\n* you will need to drop this in your test directory\n* change the package declaration\n* ant test -Dtest.name=reproBugTest\n\n{code}\npackage com.datastax.cql;\n\nimport java.sql.DriverManager;\nimport java.sql.Connection;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\n\nimport org.junit.Test;\n\npublic class reproBugTest {\n    \n    @Test\n    public void simpleSelect() throws Exception {   \n        Connection connection = null;\n        ResultSet res;\n        Statement stmt;\n        int colCount = 0;\n        \n        try {\n            Class.forName(\"org.apache.cassandra.cql.jdbc.CassandraDriver\");\n            \n            // Check create keyspace\n            connection = DriverManager.getConnection(\"jdbc:cassandra:root/root@127.0.0.1:9160/default\");     \n            stmt = connection.createStatement();\n\n            try {\n              System.out.println(\"Running DROP KS Statement\");  \n              res = stmt.executeQuery(\"DROP KEYSPACE ks1\");  \n              res.next();\n              \n              System.out.println(\"Running CREATE KS Statement\");\n              res = stmt.executeQuery(\"CREATE KEYSPACE ks1 with strategy_class =  'org.apache.cassandra.locator.SimpleStrategy' and strategy_options:replication_factor=1\");  \n              res.next();\n\n            } catch (SQLException e) {\n                if (e.getMessage().startsWith(\"Keyspace does not exist\")) \n                {\n                    res = stmt.executeQuery(\"CREATE KEYSPACE ks1 with strategy_class =  'org.apache.cassandra.locator.SimpleStrategy' and strategy_options:replication_factor=1\");  \n                } \n            }   \n            connection.close();    \n            \n            // Run Test\n            connection = DriverManager.getConnection(\"jdbc:cassandra:root/root@127.0.0.1:9160/ks1\");     \n            stmt = connection.createStatement();\n\n            System.out.print(\"Running CREATE CF Statement\");\n            res = stmt.executeQuery(\"CREATE COLUMNFAMILY users (KEY varchar PRIMARY KEY, password varchar, gender varchar, session_token varchar, state varchar, birth_year bigint)\");    \n            colCount = res.getMetaData().getColumnCount();\n            System.out.println(\" -- Column Count: \" + colCount); \n            res.next();\n            \n            System.out.print(\"Running INSERT Statement\");\n            res = stmt.executeQuery(\"INSERT INTO users (KEY, password) VALUES ('user1', 'ch@nge')\");  \n            colCount = res.getMetaData().getColumnCount();\n            System.out.println(\" -- Column Count: \" + colCount); \n            res.next();\n            \n            System.out.print(\"Running SELECT Statement\");\n            res = stmt.executeQuery(\"SELECT bar FROM users\");  \n            colCount = res.getMetaData().getColumnCount();\n            System.out.println(\" -- Column Count: \" + colCount); \n            res.getRow();\n            res.next();\n                \n            connection.close();               \n\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n    }\n       \n}\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL protocol does not include schema information"
   },
   {
      "_id": "12507136",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2011-05-13 14:40:30",
      "description": "The cli doesn't allow\n{noformat}\nget cf['k'] limit 5;\n{noformat}\nbut should. Actually it should probably allow\n{noformat}\nget cf['k']['c':'g'] limit 10;\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cli"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Cli should be able to specify a limit for get_slice"
   },
   {
      "_id": "12506191",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-05-04 16:51:52",
      "description": "CASSANDRA-2324 introduces the ability to do a repair only on a given range. This ticket proposes to add a nodetool repairPrimaryRange to trigger the repair of only the primary range of a node. This allows to repair a full cluster without any work duplication (or at least make it much simpler). This also introdude a global_repair command to clustertool to trigger the primary range repair on each node of the cluster one after another (we could do all in parallel, but that's probably not nice on the cluster).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Expose through JMX the ability to repair only the primary range"
   },
   {
      "_id": "12504969",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-04-22 11:37:02",
      "description": "Repair uses the sstable sampled keys to split the merkle tree. This means the 'precision' of the tree will be index_interval (so 128 by default). This is probably fine when you have lots of skinny rows. But when you have less fat rows, this is probably unnecessary imprecise.\n\nAdded to that the fact that each node will not have the same set of samples, you may not always end up using the more precise range in the trees when computing differences, which could make the imprecision worst (to be fair, it is quite possible this happens very rarely).\n\nAnyway, this ticket proposes to add an additional 'split_factor' (can be fixed, can be configurable (by the user or based on metrics on how fat the rows are)) that makes use re-split 'split_factor' times each ranges after the initial sample-based split of the tree.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve the precision of the repair merkle trees"
   },
   {
      "_id": "12504840",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-04-21 01:35:08",
      "description": "I ran the following SQL in cqlsh and immediately received a socket closed error.  After that point, I couldn't run nodetool, and then got an exception starting up the cluster.\n\nPlease Note:  The following syntax is valid in 0.74 but invalid in 0.8.\nThe 0.8 cassandra-cli errors on the following statement, so the resolution of the bug is to have cqlsh block this incorrect syntax.\n\n{code}\ncreate keyspace testcli with replication_factor=1\nand placement_strategy = 'org.apache.cassandra.locator.SimpleStrategy';\n{code}\n\n{code}\nCREATE KEYSPACE testcql with replication_factor = 1 and strategy_class = 'org.apache.cassandra.locator.SimpleStrategy';\t\n{code}\n\n\n{code}\nERROR 01:29:26,989 Exception encountered during startup.\njava.lang.RuntimeException: org.apache.cassandra.config.ConfigurationException: SimpleStrategy requires a replication_factor strategy option.\n\tat org.apache.cassandra.db.Table.<init>(Table.java:278)\n\tat org.apache.cassandra.db.Table.open(Table.java:110)\n\tat org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:160)\n\tat org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:314)\n\tat org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:80)\nCaused by: org.apache.cassandra.config.ConfigurationException: SimpleStrategy requires a replication_factor strategy option.\n\tat org.apache.cassandra.locator.SimpleStrategy.validateOptions(SimpleStrategy.java:79)\n\tat org.apache.cassandra.locator.AbstractReplicationStrategy.createReplicationStrategy(AbstractReplicationStrategy.java:262)\n\tat org.apache.cassandra.db.Table.createReplicationStrategy(Table.java:328)\n\tat org.apache.cassandra.db.Table.<init>(Table.java:274)\n\t... 4 more\nException encountered during startup.\njava.lang.RuntimeException: org.apache.cassandra.config.ConfigurationException: SimpleStrategy requires a replication_factor strategy option.\n\tat org.apache.cassandra.db.Table.<init>(Table.java:278)\n\tat org.apache.cassandra.db.Table.open(Table.java:110)\n\tat org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:160)\n\tat org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:314)\n\tat org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:80)\nCaused by: org.apache.cassandra.config.ConfigurationException: SimpleStrategy requires a replication_factor strategy option.\n\tat org.apache.cassandra.locator.SimpleStrategy.validateOptions(SimpleStrategy.java:79)\n\tat org.apache.cassandra.locator.AbstractReplicationStrategy.createReplicationStrategy(AbstractReplicationStrategy.java:262)\n\tat org.apache.cassandra.db.Table.createReplicationStrategy(Table.java:328)\n\tat org.apache.cassandra.db.Table.<init>(Table.java:274)\n\t... 4 more\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "CQL: create keyspace does not the replication factor argument and allows invalid sql to pass thru"
   },
   {
      "_id": "12504694",
      "assignee": "jbellis",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12312979",
            "id": "12312979",
            "name": "Legacy/Tools",
            "description": "stress, nodetool, cqlsh, various (sstableloader, sstablescrub, sstablerepairedset, etc)"
         }
      ],
      "created": "2011-04-19 17:44:05",
      "description": "Try:\n\nbq. cd drivers/py && python -c 'from cql import DateFromTicks; DateFromTicks(1)'\n\nAlso:\n{{cql.connection}} is missing an import of {{AuthenticationRequest}} from {{ttypes}}, and the exceptions {{NotSupportedError}}, and {{InternalError}}.\n\nAlso:\n{{marshal.unmarshal_long}} has a NameError waiting to happen in the form of \"unpack\"",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "missing imports in CQL Python driver"
   },
   {
      "_id": "12504618",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-04-19 02:16:01",
      "description": "Oncdsed. This basic approach would improve read performance considerably, but would cause a lot of duplicate data to be written, and would make compaction's work more necessary.\r\n\r\nAugmenting the basic idea, if when we superseded data in a file we marked it as superseded somehow, the next compaction that touched that file could remove the data. Since our file format is immutable, the values that a particular sstable superseded could be recorded in a component of that sstable. If we always supersede at the \"block\" level (as defined by CASSANDRA-674 or CASSANDRA-47), then the list of superseded blocks could be represented using a generation number and a bitmap of block numbers. Since 2498 would already allow for sstables to be eliminated due to timestamps, this information would probably only be used at compaction time (by loading all superseding information in the system for the sstables that are being compacted).\r\n\r\nInitially described on [1608|https://issues.apache.org/jira/secure/EditComment!default.jspa?id=12477095&commentId=12920353].",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Eagerly re-write data at read time (\"superseding / defragmenting\")"
   },
   {
      "_id": "12504612",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-04-18 22:51:39",
      "description": "*Error when running cqlsh*\n{code}\n[cassandra@cdaw-qa1 cql-1.0.0]$ cqlsh cdaw-qa1\nTraceback (most recent call last):\n  File \"/usr/bin/cqlsh\", line 212, in <module>\n    password=options.password)\n  File \"/usr/bin/cqlsh\", line 55, in __init__\n    self.conn = cql.connect(hostname, port, user=username, password=password)\n  File \"/usr/lib/python2.6/site-packages/cql/__init__.py\", line 51, in connect\n    return connection.Connection(host, port, keyspace, user, password)\n  File \"/usr/lib/python2.6/site-packages/cql/connection.py\", line 53, in __init__\n    c.execute('USE %s;' % keyspace)\n  File \"/usr/lib/python2.6/site-packages/cql/cursor.py\", line 126, in execute\n    except SchemaDisagreementException, sde:\nNameError: global name 'SchemaDisagreementException' is not defined\n{code}\n\n\n*Build*\n* Install the cassandra binary from the nightly build\nwget https://builds.apache.org/hudson/job/Cassandra/lastSuccessfulBuild/artifact/cassandra/build/apache-cassandra-2011-04-18_11-02-29-bin.tar.gz\n\n* Install cql from .tar file on nightly build\nwget https://builds.apache.org/hudson/job/Cassandra/lastSuccessfulBuild/artifact/cassandra/build/cql-1.0.0.tar.gz\n\n*CQL Install Output*\n{code}\n[cassandra@cdaw-qa1 cql-1.0.0]$ sudo python2.6 ./setup.py install\n[sudo] password for cassandra: \nrunning install\nrunning build\nrunning build_py\nrunning build_scripts\ncreating build/scripts-2.6\ncopying and adjusting cqlsh -> build/scripts-2.6\nchanging mode of build/scripts-2.6/cqlsh from 644 to 755\nrunning install_lib\ncreating /usr/lib/python2.6/site-packages/cql\ncopying build/lib/cql/results.py -> /usr/lib/python2.6/site-packages/cql\ncopying build/lib/cql/marshal.py -> /usr/lib/python2.6/site-packages/cql\ncopying build/lib/cql/connection.py -> /usr/lib/python2.6/site-packages/cql\ncopying build/lib/cql/cursor.py -> /usr/lib/python2.6/site-packages/cql\ncreating /usr/lib/python2.6/site-packages/cql/cassandra\ncopying build/lib/cql/cassandra/__init__.py -> /usr/lib/python2.6/site-packages/cql/cassandra\ncopying build/lib/cql/cassandra/Cassandra.py -> /usr/lib/python2.6/site-packages/cql/cassandra\ncopying build/lib/cql/cassandra/constants.py -> /usr/lib/python2.6/site-packages/cql/cassandra\ncopying build/lib/cql/cassandra/ttypes.py -> /usr/lib/python2.6/site-packages/cql/cassandra\ncopying build/lib/cql/decoders.py -> /usr/lib/python2.6/site-packages/cql\ncopying build/lib/cql/__init__.py -> /usr/lib/python2.6/site-packages/cql\ncopying build/lib/cql/errors.py -> /usr/lib/python2.6/site-packages/cql\ncopying build/lib/cql/connection_pool.py -> /usr/lib/python2.6/site-packages/cql\nbyte-compiling /usr/lib/python2.6/site-packages/cql/results.py to results.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/marshal.py to marshal.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/connection.py to connection.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/cursor.py to cursor.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/cassandra/__init__.py to __init__.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/cassandra/Cassandra.py to Cassandra.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/cassandra/constants.py to constants.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/cassandra/ttypes.py to ttypes.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/decoders.py to decoders.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/__init__.py to __init__.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/errors.py to errors.pyc\nbyte-compiling /usr/lib/python2.6/site-packages/cql/connection_pool.py to connection_pool.pyc\nrunning install_scripts\ncopying build/scripts-2.6/cqlsh -> /usr/bin\nchanging mode of /usr/bin/cqlsh to 755\nrunning install_egg_info\nWriting /usr/lib/python2.6/site-packages/cql-1.0.0-py2.6.egg-info\n\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Error running cqlsh from .tar file -- global name 'SchemaDisagreementException' is not defined"
   },
   {
      "_id": "12504590",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-04-18 20:00:04",
      "description": "Read performance in an update-heavy environment relies heavily on compaction to maintain good throughput. (This is not the case for workloads where rows are only inserted once, because the bloom filter keeps us from having to check sstables unnecessarily.)\n\nVery early versions of Cassandra attempted to mitigate this by checking sstables in descending generation order (mostly equivalent to descending mtime): once all the requested columns were found, it would not check any older sstables.\n\nThis was incorrect, because data timestamp will not correspond to sstable timestamp, both because compaction has the side effect of \"refreshing\" data to a newer sstable, and because hintead handoff may send us data older than what we already have.\n\nInstead, we could create a per-sstable piece of metadata containing the most recent (client-specified) timestamp for any column in the sstable.  We could then sort sstables by this timestamp instead, and perform a similar optimization (if the remaining sstable client-timestamps are older than the oldest column found in the desired result set so far, we don't need to look further). Since under almost every workload, client timestamps of data in a given sstable will tend to be similar, we expect this to cut the number of sstables down proportionally to how frequently each column in the row is updated. (If each column is updated with each write, we only have to check a single sstable.)\n\nThis may also be useful information when deciding which SSTables to compact.\n\n(Note that this optimization is only appropriate for named-column queries, not slice queries, since we don't know what non-overlapping columns may exist in older sstables.)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "ponies"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Improve read performance in update-intensive workload"
   },
   {
      "_id": "12504294",
      "assignee": "slebresne",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328220",
            "id": "12328220",
            "name": "Legacy/CQL",
            "description": "Grammar, Statements, Native Protocol, UDFs/UDAs, JSON"
         }
      ],
      "created": "2011-04-14 16:56:40",
      "description": "A custom wire protocol would give us the flexibility to optimize for our specific use-cases, and eliminate a troublesome dependency (I'm referring to Thrift, but none of the others would be significantly better).  Additionally, RPC is bad fit here, and we'd do better to move in the direction of something that natively supports streaming.\n\nI don't think this is as daunting as it might seem initially.  Utilizing an existing server framework like Netty, combined with some copy-and-paste of bits from other FLOSS projects would probably get us 80% of the way there.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "cql"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Custom CQL protocol/transport"
   },
   {
      "_id": "12503646",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-04-07 15:40:10",
      "description": "Running repair in cases where a stream fails we are seeing multiple problems.\n\n1. Although retry is initiated and completes, the old stream doesn't seem to clean itself up and repair hangs.\n2. The temp files are left behind and multiple failures can end up filling up the data partition.\n\nThese issues together are making repair very difficult for nearly everyone running repair on a non-trivial sized data set.\n\nThis issue is also being worked on w.r.t CASSANDRA-2088, however that was moved to 0.8 for a few reasons. This ticket is to fix the immediate issues that we are seeing in 0.7.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Failed Streams Break Repair"
   },
   {
      "_id": "12503450",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-04-05 20:49:22",
      "description": "When a memtable was flush, there is a small delay before the commit log replay position gets updated. If the node fails during this delay, all the updates of this memtable will be replay during commit log recovery and will end-up being over-counts.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Risk of counter over-count when recovering commit log"
   },
   {
      "_id": "12502977",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-03-31 05:29:09",
      "description": "As suggested by Aaron Morton [(1)|https://issues.apache.org/jira/browse/CASSANDRA-2191?focusedCommentId=13010077&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13010077], a compaction thread should attempt to empty a bucket before moving on to a larger bucket. This would change the submitMinorIfNeeded {{for}} loop into a while loop that regenerated the buckets and started from the bottom after each successful compaction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Compaction thread should try to empty a bucket before moving on"
   },
   {
      "_id": "12501263",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-03-12 19:44:43",
      "description": "The row index contains entries for configurably sized blocks of a wide row. For a row of appreciable size, the row index ends up directing the third seek (1. index, 2. row index, 3. content) to nearby the first column of a scan.\n\nSince the row index is always used for wide rows, and since it contains information that tells us whether or not the 3rd seek is necessary (the column range or name we are trying to slice may not exist in a given sstable), promoting the row index into the sstable index would allow us to drop the maximum number of seeks for wide rows back to 2, and, more importantly, would allow sstables to be eliminated using only the index.\n\nAn example usecase that benefits greatly from this change is time series data in wide rows, where data is appended to the beginning or end of the row. Our existing compaction strategy gets lucky and clusters the oldest data in the oldest sstables: for queries to recently appended data, we would be able to eliminate wide rows using only the sstable index, rather than needing to seek into the data file to determine that it isn't interesting. For narrow rows, this change would have no effect, as they will not reach the threshold for indexing anyway.\n\nA first cut design for this change would look very similar to the file format design proposed on #674: http://wiki.apache.org/cassandra/FileFormatDesignDoc: row keys clustered, column names clustered, and offsets clustered and delta encoded.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "index",
         "timeseries"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Promote row index"
   },
   {
      "_id": "12501231",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-03-12 07:12:22",
      "description": "Running latest SVN snapshot of 0.7.\n\nWhen I ran a repair on a node, that node's neighbor threw the following exception. Let me know what other info could be helpful.\n\n{code}\n INFO 23:43:44,358 Streaming to /10.251.166.15\nERROR 23:50:21,321 Fatal exception in thread Thread[CompactionExecutor:1,1,main]\njava.util.NoSuchElementException\n        at com.google.common.collect.AbstractIterator.next(AbstractIterator.java:146)\n        at org.apache.cassandra.service.AntiEntropyService$Validator.add(AntiEntropyService.java:366)\n        at org.apache.cassandra.db.CompactionManager.doValidationCompaction(CompactionManager.java:825)\n        at org.apache.cassandra.db.CompactionManager.access$800(CompactionManager.java:56)\n        at org.apache.cassandra.db.CompactionManager$6.call(CompactionManager.java:358)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:636)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "repair"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "NoSuchElement exception on node which is streaming a repair"
   },
   {
      "_id": "12499332",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-02-22 12:17:19",
      "description": "While compaction, if for a row we have only 1 sstable holding data, we echo this data. This breaks when we change the data format, creating mixed (corrupted) sstable.\n\n(I suspect this is the cause of CASSANDRA-2195, but opening a new ticket until we can confirm that hunch)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10000",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Urgent",
         "id": "10000"
      },
      "projectname": "CASSANDRA",
      "summary": "Compaction can echo data which breaks upon sstable format changes"
   },
   {
      "_id": "12498670",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-02-15 18:11:20",
      "description": "As reported by Jonas Borgstrom on the mailing list:\n\n{quote}\nWhile testing the new 0.7.1 release I got the following exception:\n\nERROR [ReadStage:11] 2011-02-15 16:39:18,105\nDebuggableThreadPoolExecutor.java (line 103) Error in ThreadPoolExecutor\njava.io.IOError: java.io.EOFException\n       at\norg.apache.cassandra.db.columniterator.SSTableNamesIterator.<init>(SSTableNamesIterator.java:75)\n       at\norg.apache.cassandra.db.filter.NamesQueryFilter.getSSTableColumnIterator(NamesQueryFilter.java:59)\n       at\norg.apache.cassandra.db.filter.QueryFilter.getSSTableColumnIterator(QueryFilter.java:80)\n       at\norg.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:1274)\n       at\norg.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1166)\n       at\norg.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1095)\n       at org.apache.cassandra.db.Table.getRow(Table.java:384)\n       at\norg.apache.cassandra.db.SliceByNamesReadCommand.getRow(SliceByNamesReadCommand.java:60)\n       at\norg.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:473)\n       at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30)\n       at\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n       at\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n       at java.lang.Thread.run(Thread.java:636)\nCaused by: java.io.EOFException\n       at java.io.DataInputStream.readInt(DataInputStream.java:392)\n       at\norg.apache.cassandra.utils.BloomFilterSerializer.deserialize(BloomFilterSerializer.java:48)\n       at\norg.apache.cassandra.utils.BloomFilterSerializer.deserialize(BloomFilterSerializer.java:30)\n       at\norg.apache.cassandra.io.sstable.IndexHelper.defreezeBloomFilter(IndexHelper.java:108)\n       at\norg.apache.cassandra.db.columniterator.SSTableNamesIterator.read(SSTableNamesIterator.java:106)\n       at\norg.apache.cassandra.db.columniterator.SSTableNamesIterator.<init>(SSTableNamesIterator.java:71)\n       ... 12 more\n\n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "EOF"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "EOFException during name query"
   },
   {
      "_id": "12498027",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-02-08 20:35:01",
      "description": "Users frequently create too many columnfamilies, set the memtable thresholds too high (or adjust throughput while ignoring operations), and/or set caching thresholds too high.  Then their server OOMs and they tell their friends Cassandra sucks.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "ponies"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add \"reduce memory usage because I tuned things poorly\" feature"
   },
   {
      "_id": "12497624",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-02-03 22:00:39",
      "description": "When read repair is completely disabled, the dynamic snitch will never adjust.\n\nOptions:\n# Explicitly disallow running with RR==0 + des\n# Implicitly enable RR at some low fraction when des is in use\n# Log warnings",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "des"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Warn or fail when read repair is disabled with the dynamic snitch"
   },
   {
      "_id": "12497550",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-02-03 10:51:07",
      "description": "There is a (known) race condition during counter read. Indeed, for standard\ncolumn family there is a small time during which a memtable is both active and\npending flush and similarly a small time during which a 'memtable' is both\npending flush and an active sstable. For counters that would imply sometime\nreconciling twice during a read the same counterColumn and thus over-counting.\n\nCurrent code changes this slightly by trading the possibility to count twice a\ngiven counterColumn by the possibility to miss a counterColumn. Thus it trades\nover-counts for under-counts.\n\nBut this is no fix and there is no hope to offer clients any kind of guarantee\non reads unless we fix this.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "counters"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "Fix the read race condition in CFStore for counters "
   },
   {
      "_id": "12497480",
      "assignee": "slebresne",
      "components": [],
      "created": "2011-02-02 17:15:35",
      "description": "The help of nodetool is not very pretty, in particular there is no description of proposed commands",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "nodetool"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Add description to nodetool commands"
   },
   {
      "_id": "12497179",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-01-31 07:40:22",
      "description": "Despite the singleton status of each AbstractType, we end up creating at least one new comparator per query. By making more of the \"wrapper\" comparators that exist in the codebase members of AbstractType, we could cut down on the \"new Comparator\" spam.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "abstract_types",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10003",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Low",
         "id": "10003"
      },
      "projectname": "CASSANDRA",
      "summary": "Eliminate excess comparator creation"
   },
   {
      "_id": "12495682",
      "assignee": "jbellis",
      "components": [],
      "created": "2011-01-15 18:29:43",
      "description": "While investigate CASSANDRA-1955 I realized I was seeing very poor latencies for reasons that had nothing to do with flush_writers, even when using periodic commit log mode (and flush writers set ridiculously high, 500).\n\nIt turns out writes blocked were slow because Table.apply() was spending lots of time (I can easily trigger seconds on moderate work-load) trying to acquire a flusher lock read lock (\"flush lock millis\" log printout in the logging patch I'll attach).\n\nThat in turns is caused by CFS.maybeSwitchMemtable() which acquires the flusher lock write lock.\n\nBisecting further revealed that the offending line of code that blocked was:\n\n                    final CommitLogSegment.CommitLogContext ctx = writeCommitLog ? CommitLog.instance.getContext() : null;\n\nIndeed, CommitLog.getContext() simply returns currentSegment().getContext(), but does so by submitting a callable on the service executor. So independently of flush writers, this can block all (global, for all cf:s) writes very easily, and does.\n\nI'll attach a file that is an independent Python script that triggers it on my macos laptop (with an intel SSD, which is why I was particularly surprised) (it assumes CPython, out-of-the-box-or-almost Cassandra on localhost that isn't in a cluster, and it will drop/recreate a keyspace called '1955').\n\nI'm also attaching, just FYI, the patch with log entries that I used while tracking it down.\n\nFinally, I'll attach a patch with a suggested solution of keeping track of the latest commit log with an AtomicReference (as an alternative to synchronizing all access to segments). With that patch applied, latencies are not affected by my trigger case like they were before. There are some sub-optimal > 100 ms cases on my test machine, but for other reasons. I'm no longer able to trigger the extremes.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "commitlog"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "CFS.maybeSwitchMemtable() calls CommitLog.instance.getContext(), which may block, under flusher lock write lock"
   },
   {
      "_id": "12463494",
      "assignee": "jbellis",
      "components": [],
      "created": "2010-05-01 16:18:02",
      "description": "There's a bug in ColumnFamilyRecordReader that appears when processing a single split (which happens in most tests that have small number of rows), and potentially in other cases.  When the start and end tokens of the split are equal, duplicate rows can be returned.\n\nExample with 5 rows:\ntoken (start and end) = 53193025635115934196771903670925341736\n\nTokens returned by first get_range_slices iteration (all 5 rows):\n 16955237001963240173058271559858726497\n 40670782773005619916245995581909898190\n 99079589977253916124855502156832923443\n 144992942750327304334463589818972416113\n 166860289390734216023086131251507064403\n\nTokens returned by next iteration (first token is last token from\nprevious, end token is unchanged)\n 16955237001963240173058271559858726497\n 40670782773005619916245995581909898190\n\nTokens returned by final iteration  (first token is last token from\nprevious, end token is unchanged)\n [] (empty)\n\nIn this example, the mapper has processed 7 rows in total, 2 of which\nwere duplicates.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "hadoop",
         "mapreduce"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/10002",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Normal",
         "id": "10002"
      },
      "projectname": "CASSANDRA",
      "summary": "ColumnFamilyRecordReader returns duplicate rows"
   }
]