[
   {
      "_id": "13391377",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2021-07-22 15:05:19",
      "description": "the security related Delegator classes in _org.apache.jackrabbit.oak.jcr.delegate_ deserve a bit of housekeeping.\r\nwhile doing so i spotted that the param validation in the {{UserManagerDelegator}} constructor throws {{IllegalStateException}} instead of {{IllegalArgumentException}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improvements to security related Delegators in org.apache.jackrabbit.oak.jcr.delegate"
   },
   {
      "_id": "13391165",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2021-07-21 16:46:32",
      "description": "today _jacoco-maven-plugin_ is skipped in _oak-jcr_ and thus doesn't record line/branch coverage. i would suggest to enable it by default. as of now line coverage is 72%, branch coverage is 60%.\r\n\r\n[~mreutegg], unless you have any concerns i would go ahead and add the 2 properties to the pom.xml:\r\n{code}\r\n    <skip.coverage>false</skip.coverage>\r\n    <minimum.coverage>0.72</minimum.coverage>\r\n    <minimum.branch.coverage>0.60</minimum.branch.coverage>\r\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable minimum line and branch test coverage for oak-jcr"
   },
   {
      "_id": "13391157",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12335369",
            "id": "12335369",
            "name": "authorization-principalbased"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333543",
            "id": "12333543",
            "name": "security-spi",
            "description": "Oak Security SPI"
         }
      ],
      "created": "2021-07-21 15:41:56",
      "description": "there area  few duplicate code blocks across oak authorization modules.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Duplicate code blocks in authorization modules"
   },
   {
      "_id": "13391102",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2021-07-21 09:36:01",
      "description": "on https://jackrabbit.apache.org/oak/docs/security/principal/differences.html the link to the {{PrincipalProvider}} points to the {{PrincipalManager}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "link to PrincipalProvider points to wrong resource"
   },
   {
      "_id": "13391100",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2021-07-21 09:32:54",
      "description": "with OAK-8339 the Jackrabbit API has been moved to the Oak source but the links to security related interfaces still point to svn.apache.org. instead they are now generated with the oak javadoc and links should be adjusted such that they capture the latest state of the API.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak Security Documentation : links to Jackrabbit-API point to svn"
   },
   {
      "_id": "13389668",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2021-07-14 16:33:03",
      "description": "the description of the 'principalName' index definition stored in the 'info' property is IMHO misleading. \r\n[~thomasm], do you recall what your intention was when stating _if it was constructed manually_? that sounds a bit odd as the rep:principalName property is always defined when a new user/group is created through the API. on JCR level users/groups cannot be created manually using regular write operations due to the protected nature some properties.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "UserInitializer: info property of 'principalName' index not accurate"
   },
   {
      "_id": "13389392",
      "assignee": "dulceanu",
      "components": [],
      "created": "2021-07-13 13:15:55",
      "description": "{noformat}\r\nOne or more dependencies were identified with known vulnerabilities in Jackrabbit Oak:aggs-matrix-stats-client-7.1.1.jar (pkg:maven/org.elasticsearch.plugin/aggs-matrix-stats-client@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\nbcprov-jdk15on-1.65.jar (pkg:maven/org.bouncycastle/bcprov-jdk15on@1.65, cpe:2.3:a:bouncycastle:legion-of-the-bouncy-castle-java-crytography-api:1.65:*:*:*:*:*:*:*) : CVE-2020-28052\r\ncommons-io-2.6.jar (pkg:maven/commons-io/commons-io@2.6, cpe:2.3:a:apache:commons_io:2.6:*:*:*:*:*:*:*) : CVE-2021-29425\r\ncxf-core-3.3.6.jar (pkg:maven/org.apache.cxf/cxf-core@3.3.6, cpe:2.3:a:apache:cxf:3.3.6:*:*:*:*:*:*:*) : CVE-2020-13954, CVE-2021-22696, CVE-2021-30468\r\nelasticsearch-core-7.1.1.jar (pkg:maven/org.elasticsearch/elasticsearch-core@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\nfluent-hc-4.5.12.jar (pkg:maven/org.apache.httpcomponents/fluent-hc@4.5.12, cpe:2.3:a:apache:httpclient:4.5.12:*:*:*:*:*:*:*) : CVE-2020-13956\r\ngroovy-2.5.2.jar (pkg:maven/org.codehaus.groovy/groovy@2.5.2, cpe:2.3:a:apache:groovy:2.5.2:*:*:*:*:*:*:*) : CVE-2020-17521\r\ngroovy-all-2.4.17.jar (pkg:maven/org.codehaus.groovy/groovy-all@2.4.17, cpe:2.3:a:apache:groovy:2.4.17:*:*:*:*:*:*:*) : CVE-2020-17521\r\nguava-15.0.jar (pkg:maven/com.google.guava/guava@15.0, cpe:2.3:a:google:guava:15.0:*:*:*:*:*:*:*) : CVE-2018-10237, CVE-2020-8908\r\nguava-18.0.jar (pkg:maven/com.google.guava/guava@18.0, cpe:2.3:a:google:guava:18.0:*:*:*:*:*:*:*) : CVE-2018-10237, CVE-2020-8908\r\nhibernate-validator-5.3.6.Final.jar (pkg:maven/org.hibernate/hibernate-validator@5.3.6.Final, cpe:2.3:a:hibernate:hibernate-validator:5.3.6:*:*:*:*:*:*:*, cpe:2.3:a:redhat:hibernate_validator:5.3.6:*:*:*:*:*:*:*) : CVE-2020-10693\r\nhttp2-client-9.4.27.v20200227.jar (pkg:maven/org.eclipse.jetty.http2/http2-client@9.4.27.v20200227, cpe:2.3:a:eclipse:jetty:9.4.27:20200227:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.27:20200227:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.27:20200227:*:*:*:*:*:*) : CVE-2019-17638, CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\nhttpclient-4.5.12.jar (pkg:maven/org.apache.httpcomponents/httpclient@4.5.12, cpe:2.3:a:apache:httpclient:4.5.12:*:*:*:*:*:*:*) : CVE-2020-13956\r\nhttpclient-osgi-4.5.12.jar/META-INF/maven/org.apache.httpcomponents/httpclient-cache/pom.xml (pkg:maven/org.apache.httpcomponents/httpclient-cache@4.5.12, cpe:2.3:a:apache:httpclient:4.5.12:*:*:*:*:*:*:*) : CVE-2020-13956\r\njackson-databind-2.10.3.jar (pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.10.3, cpe:2.3:a:fasterxml:jackson-databind:2.10.3:*:*:*:*:*:*:*) : CVE-2020-25649\r\njava-xmlbuilder-1.1.jar (pkg:maven/com.jamesmurty.utils/java-xmlbuilder@1.1) : CWE-611: Improper Restriction of XML External Entity Reference ('XXE')\r\njavax-websocket-server-impl-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty.websocket/javax-websocket-server-impl@9.4.18.v20190429, cpe:2.3:a:eclipse:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:java-websocket_project:java-websocket:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*) : CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njavax.servlet-3.0.0.v201112011016.jar (pkg:maven/org.eclipse.jetty.orbit/javax.servlet@3.0.0.v201112011016, cpe:2.3:a:eclipse:jetty:3.0.0:201112011016:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:3.0.0:201112011016:*:*:*:*:*:*) : CVE-2009-5045, CVE-2009-5046, CVE-2017-7656, CVE-2017-7657, CVE-2017-7658, CVE-2020-27216, CVE-2021-28169, CVE-2021-34428\r\njavax.websocket-api-1.0.jar (pkg:maven/javax.websocket/javax.websocket-api@1.0, cpe:2.3:a:java-websocket_project:java-websocket:1.0:*:*:*:*:*:*:*) : CVE-2020-11050\r\njdom2-2.0.6.jar (pkg:maven/org.jdom/jdom2@2.0.6, cpe:2.3:a:jdom:jdom:2.0.6:*:*:*:*:*:*:*) : CVE-2021-33813\r\njetty-http-9.4.27.v20200227.jar (pkg:maven/org.eclipse.jetty/jetty-http@9.4.27.v20200227, cpe:2.3:a:eclipse:jetty:9.4.27:20200227:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.27:20200227:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.27:20200227:*:*:*:*:*:*) : CVE-2019-17638, CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njetty-io-8.2.0.v20160908.jar (pkg:maven/org.eclipse.jetty/jetty-io@8.2.0.v20160908, cpe:2.3:a:mortbay_jetty:jetty:8.2.0:20160908:*:*:*:*:*:*) : CVE-2021-28165\r\njetty-io-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty/jetty-io@9.4.18.v20190429, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*) : CVE-2021-28165\r\njetty-io-9.4.27.v20200227.jar (pkg:maven/org.eclipse.jetty/jetty-io@9.4.27.v20200227, cpe:2.3:a:mortbay_jetty:jetty:9.4.27:20200227:*:*:*:*:*:*) : CVE-2021-28165\r\njetty-server-8.2.0.v20160908.jar (pkg:maven/org.eclipse.jetty/jetty-server@8.2.0.v20160908, cpe:2.3:a:eclipse:jetty:8.2.0:20160908:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:8.2.0:20160908:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:8.2.0:20160908:*:*:*:*:*:*) : CVE-2017-7656, CVE-2017-7657, CVE-2017-7658, CVE-2017-9735, CVE-2019-10241, CVE-2019-10247, CVE-2020-27216, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njetty-server-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty/jetty-server@9.4.18.v20190429, cpe:2.3:a:eclipse:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*) : CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njetty-util-8.2.0.v20160908.jar (pkg:maven/org.eclipse.jetty/jetty-util@8.2.0.v20160908, cpe:2.3:a:eclipse:jetty:8.2.0:20160908:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:8.2.0:20160908:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:8.2.0:20160908:*:*:*:*:*:*) : CVE-2017-7656, CVE-2017-7657, CVE-2017-7658, CVE-2019-10247, CVE-2020-27216, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njunit-4.12.jar (pkg:maven/junit/junit@4.12) : CVE-2020-15250\r\nlang-mustache-client-7.1.1.jar (pkg:maven/org.elasticsearch.plugin/lang-mustache-client@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\nlog4j-1.2.16.jar (pkg:maven/log4j/log4j@1.2.16, cpe:2.3:a:apache:log4j:1.2.16:*:*:*:*:*:*:*) : CVE-2019-17571, CVE-2020-9488\r\nlog4j-1.2.17.jar (pkg:maven/log4j/log4j@1.2.17, cpe:2.3:a:apache:log4j:1.2.17:*:*:*:*:*:*:*) : CVE-2019-17571, CVE-2020-9488\r\nlog4j-api-2.11.1.jar (pkg:maven/org.apache.logging.log4j/log4j-api@2.11.1, cpe:2.3:a:apache:log4j:2.11.1:*:*:*:*:*:*:*) : CVE-2020-9488\r\nlog4j-over-slf4j-1.7.30.jar (pkg:maven/org.slf4j/log4j-over-slf4j@1.7.30, cpe:2.3:a:apache:log4j:1.7.30:*:*:*:*:*:*:*) : CVE-2020-9488\r\nmongo-java-driver-3.12.7.jar (pkg:maven/org.mongodb/mongo-java-driver@3.12.7, cpe:2.3:a:mongodb:java_driver:3.12.7:*:*:*:*:*:*:*) : CVE-2021-20328\r\nnetty-3.7.0.Final.jar (pkg:maven/io.netty/netty@3.7.0.Final, cpe:2.3:a:netty:netty:3.7.0:*:*:*:*:*:*:*) : CVE-2014-0193, CVE-2014-3488, CVE-2015-2156, CVE-2019-16869, CVE-2019-20444, CVE-2019-20445, CVE-2021-21290, CVE-2021-21295, CVE-2021-21409, POODLE vulnerability in SSLv3.0 support\r\nnetty-transport-4.1.47.Final.jar (pkg:maven/io.netty/netty-transport@4.1.47.Final, cpe:2.3:a:netty:netty:4.1.47:*:*:*:*:*:*:*) : CVE-2021-21290, CVE-2021-21295, CVE-2021-21409\r\nnetty-transport-4.1.52.Final.jar (pkg:maven/io.netty/netty-transport@4.1.52.Final, cpe:2.3:a:netty:netty:4.1.52:*:*:*:*:*:*:*) : CVE-2021-21290, CVE-2021-21295, CVE-2021-21409\r\noak-jackrabbit-api-1.34.0.jar (pkg:maven/org.apache.jackrabbit/oak-jackrabbit-api@1.34.0, cpe:2.3:a:apache:jackrabbit:1.34.0:*:*:*:*:*:*:*, cpe:2.3:a:apache:jackrabbit_oak:1.34.0:*:*:*:*:*:*:*) : CVE-2015-1833\r\noak-segment-1.6.0.jar (pkg:maven/org.apache.jackrabbit/oak-segment@1.6.0, cpe:2.3:a:apache:jackrabbit:1.6.0:*:*:*:*:*:*:*, cpe:2.3:a:apache:jackrabbit_oak:1.6.0:*:*:*:*:*:*:*) : CVE-2015-1833, CVE-2020-1940\r\norg.apache.felix.webconsole-4.2.10-all.jar: jquery-1.8.3.js (pkg:javascript/jquery@1.8.3) : CVE-2012-6708, CVE-2015-9251, CVE-2019-11358, CVE-2020-11022, CVE-2020-11023\r\norg.apache.felix.webconsole-4.2.10-all.jar: jquery-ui-1.9.2.js (pkg:javascript/jquery-ui-dialog@1.9.2, pkg:javascript/jquery-ui-tooltip@1.9.2) : CVE-2010-5312, CVE-2012-6662, CVE-2016-7103\r\npom.xml (pkg:maven/org.apache.jackrabbit/oak-jackrabbit-api@1.22.8-SNAPSHOT, cpe:2.3:a:apache:jackrabbit:1.22.8:snapshot:*:*:*:*:*:*, cpe:2.3:a:apache:jackrabbit_oak:1.22.8:snapshot:*:*:*:*:*:*) : CVE-2015-1833\r\npom.xml (pkg:maven/org.apache.jackrabbit/oak-solr-core@1.22.8-SNAPSHOT, cpe:2.3:a:apache:jackrabbit_oak:1.22.8:snapshot:*:*:*:*:*:*, cpe:2.3:a:apache:solr:1.22.8:snapshot:*:*:*:*:*:*) : CVE-2012-6612, CVE-2013-6397, CVE-2013-6407, CVE-2013-6408, CVE-2015-8795, CVE-2015-8796, CVE-2015-8797, CVE-2017-3163, CVE-2017-3164, CVE-2018-11802, CVE-2018-1308, CVE-2019-0193, CVE-2020-13941, CVE-2021-27905, CVE-2021-29262, CVE-2021-29943\r\norg.apache.servicemix.bundles.dom4j-2.1.1_1.jar (pkg:maven/org.apache.servicemix.bundles/org.apache.servicemix.bundles.dom4j@2.1.1_1, cpe:2.3:a:dom4j_project:dom4j:2.1.1.1:*:*:*:*:*:*:*) : CVE-2020-10683\r\norg.apache.sling.commons.logservice-1.0.4.jar (pkg:maven/org.apache.sling/org.apache.sling.commons.logservice@1.0.4, cpe:2.3:a:apache:sling:1.0.4:*:*:*:*:*:*:*) : CVE-2016-5394, CVE-2016-6798\r\nparent-join-client-7.1.1.jar (pkg:maven/org.elasticsearch.plugin/parent-join-client@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\npdfbox-2.0.19.jar (pkg:maven/org.apache.pdfbox/pdfbox@2.0.19, cpe:2.3:a:apache:pdfbox:2.0.19:*:*:*:*:*:*:*) : CVE-2021-27807, CVE-2021-27906, CVE-2021-31811, CVE-2021-31812\r\npreflight-2.0.19.jar (pkg:maven/org.apache.pdfbox/preflight@2.0.19, cpe:2.3:a:apache:pdfbox:2.0.19:*:*:*:*:*:*:*) : CVE-2021-27807, CVE-2021-27906, CVE-2021-31811, CVE-2021-31812\r\nrank-eval-client-7.1.1.jar (pkg:maven/org.elasticsearch.plugin/rank-eval-client@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\nsentiment-analysis-parser-0.1.jar (pkg:maven/edu.usc.ir/sentiment-analysis-parser@0.1, cpe:2.3:a:data_tools_project:data_tools:0.1:*:*:*:*:*:*:*) : CVE-2018-18749\r\nsis-netcdf-1.0.jar (pkg:maven/org.apache.sis.storage/sis-netcdf@1.0, cpe:2.3:a:storage_project:storage:1.0:*:*:*:*:*:*:*) : CVE-2021-20291\r\nsnakeyaml-1.17.jar (pkg:maven/org.yaml/snakeyaml@1.17, cpe:2.3:a:snakeyaml_project:snakeyaml:1.17:*:*:*:*:*:*:*) : CVE-2017-18640\r\nsolr-solrj-8.6.3.jar (pkg:maven/org.apache.solr/solr-solrj@8.6.3, cpe:2.3:a:apache:solr:8.6.3:*:*:*:*:*:*:*) : CVE-2021-27905, CVE-2021-29262, CVE-2021-29943\r\nspring-core-4.3.24.RELEASE.jar (pkg:maven/org.springframework/spring-core@4.3.24.RELEASE, cpe:2.3:a:pivotal_software:spring_framework:4.3.24:release:*:*:*:*:*:*, cpe:2.3:a:springsource:spring_framework:4.3.24:release:*:*:*:*:*:*, cpe:2.3:a:vmware:spring_framework:4.3.24:release:*:*:*:*:*:*, cpe:2.3:a:vmware:springsource_spring_framework:4.3.24:release:*:*:*:*:*:*) : CVE-2020-5421\r\ntagsoup-1.2.1.jar (pkg:maven/org.ccil.cowan.tagsoup/tagsoup@1.2.1, cpe:2.3:a:tag_project:tag:1.2.1:*:*:*:*:*:*:*) : CVE-2020-29242, CVE-2020-29243, CVE-2020-29244, CVE-2020-29245\r\ntika-core-1.24.1.jar (pkg:maven/org.apache.tika/tika-core@1.24.1, cpe:2.3:a:apache:tika:1.24.1:*:*:*:*:*:*:*) : CVE-2021-28657\r\nvorbis-java-tika-0.8.jar (pkg:maven/org.gagravarr/vorbis-java-tika@0.8, cpe:2.3:a:flac_project:flac:0.8:*:*:*:*:*:*:*) : CVE-2017-6888\r\nwebsocket-common-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty.websocket/websocket-common@9.4.18.v20190429, cpe:2.3:a:eclipse:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:java-websocket_project:java-websocket:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:websocket-extensions_project:websocket-extensions:9.4.18:20190429:*:*:*:*:*:*) : CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\nwebsocket-server-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty.websocket/websocket-server@9.4.18.v20190429, cpe:2.3:a:eclipse:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:java-websocket_project:java-websocket:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*) : CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\nxmpbox-2.0.19.jar (pkg:maven/org.apache.pdfbox/xmpbox@2.0.19, cpe:2.3:a:apache:pdfbox:2.0.19:*:*:*:*:*:*:*) : CVE-2021-27807, CVE-2021-27906, CVE-2021-31811, CVE-2021-31812\r\nzookeeper-3.4.6.jar (pkg:maven/org.apache.zookeeper/zookeeper@3.4.6, cpe:2.3:a:apache:zookeeper:3.4.6:*:*:*:*:*:*:*) : CVE-2016-5017, CVE-2017-5637, CVE-2018-8012, CVE-2019-0201, CVE-2021-21409\r\nzookeeper-3.5.7.jar (pkg:maven/org.apache.zookeeper/zookeeper@3.5.7, cpe:2.3:a:apache:zookeeper:3.5.7:*:*:*:*:*:*:*) : CVE-2021-21409\r\n-1,548 {noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_22"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Address vulnerabilities found by dependency checker plugin"
   },
   {
      "_id": "13385676",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2021-06-24 16:10:07",
      "description": "while reviewing the proposed changes for OAK-9462 [~kpauls] noticed that {{SyncConfigTracker#hasDynamicMembership}} could be simplified by introducing a filter to the service tracking. consequently only synchandler-references that have dynamic-membership enabled would be tracked.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use Filter for SyncConfigTracker to limit respected references "
   },
   {
      "_id": "13381686",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2021-06-02 12:03:13",
      "description": "The cold standby is able to do SSL connections to the primary, but currently only using on-the-fly generated certificates. This means that data is transferred over an encrypted connection but there is no protection against a man in the middle yet.\r\n\r\nWith this issue we want to:\r\n* make server and client certificates configurable\r\n* optionally validate the client certificate\r\n* optionally only allow matching subjects in client and server certificates ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cold Standby SSL certificates should be configurable"
   },
   {
      "_id": "13380389",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2021-05-25 16:50:29",
      "description": "The test fails consistently on Jenkins but succeeds on Travis and when running locally.\r\n{noformat}org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: Configured cluster node id 1 already in use: leaseEnd 1621945215196 > 1621945095197 - 119999ms in the future\r\n\tat org.apache.jackrabbit.oak.plugins.document.ClusterNodeInfo.createInstance(ClusterNodeInfo.java:628)\r\n\tat org.apache.jackrabbit.oak.plugins.document.ClusterNodeInfo.getInstance(ClusterNodeInfo.java:471)\r\n\tat org.apache.jackrabbit.oak.plugins.document.ClusterNodeInfo.getInstance(ClusterNodeInfo.java:440)\r\n\tat org.apache.jackrabbit.oak.plugins.document.mongo.LeaseUpdateSocketTimeoutIT.newClusterNodeInfo(LeaseUpdateSocketTimeoutIT.java:153)\r\n\tat org.apache.jackrabbit.oak.plugins.document.mongo.LeaseUpdateSocketTimeoutIT.leaseUpdateFailureOnSocketTimeout(LeaseUpdateSocketTimeoutIT.java:107)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n\tat org.testcontainers.containers.FailureDetectingExternalResource$1.evaluate(FailureDetectingExternalResource.java:30)\r\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)\r\n\tat org.testcontainers.containers.FailureDetectingExternalResource$1.evaluate(FailureDetectingExternalResource.java:30)\r\n\tat org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)\r\n\tat org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\r\n\tat org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:413)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "continuous_integration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failure: LeaseUpdateSocketTimeoutIT.leaseUpdateFailureOnSocketTimeout"
   },
   {
      "_id": "13375867",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2021-04-29 15:16:25",
      "description": "In <https://github.com/apache/jackrabbit-oak/blob/cde907088a5c460178fd714cb4edc141cd45e23d/oak-store-document/src/main/java/org/apache/jackrabbit/oak/plugins/document/JournalEntry.java#L387-L395>:\r\n\r\n- Exception should be created with message \"call stack\" instead of null\r\n- replace \"would\" with \"will\"",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_22"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "slightly misleading debug message in JournalEntry"
   },
   {
      "_id": "13375040",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2021-04-26 10:45:42",
      "description": "Currently {{oak-run compact}} for Azure Segment Store always compacts the source container in place. It should be better to allow compacting the source container to a different container, allowing thus to skip source container cleanup. Moreover, in order to speed up compaction, Azure compaction should always employ a persistent disk cache, whose path for storing the segments and size should be configurable.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve oak-run compact to better support Azure compaction"
   },
   {
      "_id": "13372660",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2021-04-15 14:31:01",
      "description": "there are a couple of minor improvements for oak-auth-external code base \r\n- private fields could be final\r\n- unused imports\r\n- unused log fields\r\n- trivial code simplifications",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Minor improvements to oak-auth-external"
   },
   {
      "_id": "13372233",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2021-04-14 08:06:02",
      "description": "There won't be a leaseEndTime when the recovering clusterId, the one referred to in\u00a0{{recoveryBy}}, is not active anymore. The implementation of\u00a0{{RecoveryLock.tryBreakRecoveryLock()}}\u00a0should only call\u00a0{{getLeaseEndTime()}}\u00a0when\u00a0{{recovering.isActive()}}\u00a0is true.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_22",
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Breaking recovery lock issue"
   },
   {
      "_id": "13358367",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2021-02-12 15:06:46",
      "description": "Log state of lease update thread.\r\n\r\nOptionally log stack trace of thread (log level depending on whether lease has expired).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_22",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore: in dispose(), improve lease update diagnostics"
   },
   {
      "_id": "13357932",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2021-02-10 13:01:58",
      "description": "The async index update uses checkpoints to ensure consistency: it\r\n* 1. creates checkpoint2\r\n* 2. indexes everything between checkpoint1 and checkpoint2\r\n* 3. update the indexing lane to checkpoint2\r\nIf there is s a problem before step 3, the checkpoint2 is removed. That's fine.\r\n\r\nHowever, if there is a problem after step 3 is complete, in some cases it also removes checkpoint2. This is incorrect, as checkpoint2 is needed.\r\n\r\nWe have seen this is the case if the node store is closed, but dispose works. See OAK-9300. So fixing that should resolve most issues. However, the current code is still not correct.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "index"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Index update: release the correct checkpoint"
   },
   {
      "_id": "13345098",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         }
      ],
      "created": "2020-12-09 14:49:38",
      "description": "From 1.24.0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update Tika dependency to 1.24.1 (backport)"
   },
   {
      "_id": "13329558",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2020-09-26 21:14:22",
      "description": "{{oak-run explore}}\u00a0should accept Azure URIs for the segment store in order to\u00a0be able to browse azure segments.\u00a0\r\n\r\nThe Azure URI will be taken as argument and will have the following format:\u00a0{{az:[https://myaccount.blob.core.windows.net/container/repo]}}, where\u00a0_az_\u00a0identifies the cloud provider. The last missing piece is the secret key which will be supplied as an environment variable, i.e.\u00a0_AZURE_SECRET_KEY._",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run explore should support Azure Segment Store"
   },
   {
      "_id": "13328580",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2020-09-21 14:41:38",
      "description": "After netty update in OAK-9210,  {{OSGiIT}} fails with the following exception:\r\n\r\n{code}\r\nERROR: Bundle org.apache.jackrabbit.oak-segment-tar [41] Error starting file:/var/folders/jh/rvxkcm515dl3bksp1zlzdws80000gn/T/1600699057212-0/bundles/org.apache.jackrabbit.oak-segment-tar_1.35.0.SNAPSHOT.jar (org.osgi.framework.BundleException: Unable to resolve org.apache.jackrabbit.oak-segment-tar [41](R 41.0): missing requirement [org.apache.jackrabbit.oak-segment-tar [41](R 41.0)] osgi.wiring.package; (osgi.wiring.package=com.oracle.svm.core.annotate) Unresolved requirements: [[org.apache.jackrabbit.oak-segment-tar [41](R 41.0)] osgi.wiring.package; (osgi.wiring.package=com.oracle.svm.core.annotate)])\r\norg.osgi.framework.BundleException: Unable to resolve org.apache.jackrabbit.oak-segment-tar [41](R 41.0): missing requirement [org.apache.jackrabbit.oak-segment-tar [41](R 41.0)] osgi.wiring.package; (osgi.wiring.package=com.oracle.svm.core.annotate) Unresolved requirements: [[org.apache.jackrabbit.oak-segment-tar [41](R 41.0)] osgi.wiring.package; (osgi.wiring.package=com.oracle.svm.core.annotate)]\r\n\tat org.apache.felix.framework.Felix.resolveBundleRevision(Felix.java:4368)\r\n\tat org.apache.felix.framework.Felix.startBundle(Felix.java:2281)\r\n\tat org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1539)\r\n\tat org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:308)\r\n\tat java.base/java.lang.Thread.run(Thread.java:835)\r\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix OSGi wiring after netty update to 4.1.52.Final"
   },
   {
      "_id": "13327862",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2020-09-16 12:56:31",
      "description": "The current version presents several vulnerability issues:\u00a0\r\n\r\nBDSA-2018-4022,BDSA-2018-4482,BDSA-2019-2642,BDSA-2019-2643.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bump netty dependency from 4.1.17.Final to 4.1.52.Final"
   },
   {
      "_id": "13326424",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         }
      ],
      "created": "2020-09-08 09:23:23",
      "description": "Failure to write a segment to the redis cache results in an error level log message with a stack trace. However, this is expected behaviour: socket timeouts prevent the cache from effectively slowing down a request. OTOH too many socket timeouts make the cache ineffective, so it's good to have a way to log such errors when debugging. My suggestion is therefore to change the log level to \"debug\" and avoid the stack trace.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "patch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "PersistentRedisCache: failure to write segment is not an error"
   },
   {
      "_id": "13324427",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2020-08-25 09:40:23",
      "description": "since {{AbstractAccessControlManager}} does not have access to the {{RefreshStrategy}} present in _oak-jcr_, it currently eagerly refresh the {{PermissionProvider}} used internally. [~asanso] reported that this may lead to performance issues, when item read operations are combined with frequent calls to {{AccessControlManager.hasPrivileges}} or {{AccessControlManager.getPrivileges}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "AbstractAccessControlManager: improve refresh strategy of PermissionProvider"
   },
   {
      "_id": "13318203",
      "assignee": "fortino",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2020-07-20 09:00:44",
      "description": "I believe\u00a0OakAnalyzer applies LowerCaseFilter and WordDelimiterFilter in the wrong order.\u00a0 WordDelimiterFilter is invoked with the\u00a0GENERATE_WORD_PARTS flag, which splits camelCase/PascalCase into multiple terms, but since the LowerCaseFilter is applied first, the mixed-case is lost and the terms can't be split.\r\n\r\nSearching for savings, the damAssetLucene index (which uses the default OakAnalyzer) does not find an asset named savingsAccount.svg.\r\n\r\nUpon configuring the index's analyzers (/oak:index/damAssetLucene/analyzers) to apply WordDelimiterFilter before LowerCaseFilter, the correct behaviour was seen.\r\n\r\n{noformat}\r\n{\r\n  \"jcr:primaryType\": \"nt:unstructured\",\r\n  \"default\": {\r\n    \"jcr:primaryType\": \"nt:unstructured\",\r\n    \"tokenizer\": {\r\n      \"jcr:primaryType\": \"nt:unstructured\",\r\n      \"name\": \"Standard\"\r\n    },\r\n    \"filters\": {\r\n      \"jcr:primaryType\": \"nt:unstructured\",\r\n      \"WordDelimiter\": {\"jcr:primaryType\": \"nt:unstructured\"},\r\n      \"LowerCase\": {\"jcr:primaryType\": \"nt:unstructured\"}\r\n    }\r\n  }\r\n}\r\n{noformat}\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "easyfix",
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "OakAnalyzer applies LowerCaseFilter and WordDelimiterFilter in wrong order"
   },
   {
      "_id": "13315609",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2020-07-08 11:04:39",
      "description": "There is a support for reading osgi configs from file using felix interpolation plugin -\u00a0\r\n[https://github.com/apache/felix-dev/tree/9bd66812f21944925268bfd5551218c436886d30/configadmin-plugins/interpolation]\r\n\r\nWe already support reading ES host using this technique. We need to be able to read port number as well.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "amrit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow elasticsearch port to be read from secrets"
   },
   {
      "_id": "13315105",
      "assignee": "corderob",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2020-07-06 08:38:08",
      "description": "One of the changes between JCR 1.0 and JCR 2.0 is the definition of nt:frozenNode. In JCR 1.0 the node type extends from mix:referenceable, while in JCR 2.0 it does [not anymore|https://docs.adobe.com/docs/en/spec/jcr/2.0/3_Repository_Model.html#3.13.4.1%20nt:frozenNode].\r\n\r\nOak currently uses a nt:frozenNode definition that extends from mix:referenceable. This adds quite a bit of overhead because each node written under a JCR version gets a jcr:uuid, which is indexed by default.\r\n\r\nThe proposal is to remove the supertype \"mix:referenceable\" from nt:frozenNode.\r\n\r\nRemoving this supertype, the frozenNodes wouldn't have a \"jcr:uuid\" field, which at the end is not used, and allows to reduce the size of the index.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "patch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove mix:referenceable from nt:frozenNode definition"
   },
   {
      "_id": "13310571",
      "assignee": "tmueller",
      "components": [],
      "created": "2020-06-10 07:13:47",
      "description": "Currently, async indexes (Lucene) are marked corrupt if they couldn't be updated for some time. I think the default delay of 30 minutes is far too low. In the past, we have seen the following cases where async indexing is delayed:\r\n\r\n* Topology problems (no leader)\r\n* High load prevents updating them\r\n\r\nFor cases where index update is run, but failing, include:\r\n\r\n* Restart of Oak with inconsistent data in the /repository/index directory\r\n* Out-of-disk-space\r\n\r\nFor these cases, it's better to stop Oak, clean the index directory, and restart. This might anyway be happening regularly (e.g. daily). Marking the index corrupt, so that reindexing is needed, doesn't seem to be needed or helping.\r\n\r\nThis setting is already configurable in org.apache.jackrabbit.oak.plugins.index.AsyncIndexerService: failingIndexTimeoutSeconds. But instead of changing the configuration everywhere, it's probably better to change the default value for failingIndexTimeoutSeconds in Oak, to 604800L = 60L * 60 * 24 * 7 (one week).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "index"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Change default timeout to mark indexes corrupt"
   },
   {
      "_id": "13308651",
      "assignee": "vholani",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2020-06-01 07:25:57",
      "description": "Getting below exception on RDBMK setup with MSSQL 2019 using jdbc version 8.2.2\r\n\r\n\u00a0\r\n\r\nCaused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakOak0001: Update for path failedCaused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakOak0001: Update for path failed at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.mergeFailed(DocumentNodeStoreBranch.java:334) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.access$600(DocumentNodeStoreBranch.java:55) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch$InMemory.merge(DocumentNodeStoreBranch.java:539) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:194) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:119) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:170) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1869) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.core.MutableRoot.commit(MutableRoot.java:250) [org.apache.jackrabbit.oak-core:1.10.8] at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:346) [org.apache.jackrabbit.oak-jcr:1.10.8] at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:493) [org.apache.jackrabbit.oak-jcr:1.10.8] ... 14 common frames omittedCaused by: org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: Update for path failed at org.apache.jackrabbit.oak.plugins.document.rdb.RDBJDBCTools.asDocumentStoreException(RDBJDBCTools.java:434) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.handleException(RDBDocumentStore.java:2377) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.handleException(RDBDocumentStore.java:2382) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.updateDocument(RDBDocumentStore.java:2108) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.internalUpdate(RDBDocumentStore.java:1670) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.internalCreateOrUpdate(RDBDocumentStore.java:1637) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.findAndUpdate(RDBDocumentStore.java:603) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.util.LeaseCheckDocumentStoreWrapper.findAndUpdate(LeaseCheckDocumentStoreWrapper.java:141) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.updateCommitRoot(DocumentNodeStore.java:1540) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.Commit.conditionalCommit(Commit.java:440) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:329) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:252) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.Commit.applyInternal(Commit.java:220) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.Commit.apply(Commit.java:208) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:310) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:275) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.access$500(DocumentNodeStoreBranch.java:55) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch$InMemory.merge(DocumentNodeStoreBranch.java:531) [org.apache.jackrabbit.oak-store-document:1.10.8] ... 21 common frames omittedCaused by: com.microsoft.sqlserver.jdbc.SQLServerException: String or binary data would be truncated in table 'NODES', column 'DATA'. Truncated value: '\\{\"_deleted\":{\"r171a9e9bdfa-0-1\":\"false\"},\"jcr:created\":{\"r171a9e9bdfa-0-1\":\"\\\"dat:2020-04-24T02:00:0'. at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:262) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at com.microsoft.sqlserver.jdbc.SQLServerStatement.getNextResult(SQLServerStatement.java:1632) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.doExecutePreparedStatement(SQLServerPreparedStatement.java:600) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement$PrepStmtExecCmd.doExecute(SQLServerPreparedStatement.java:522) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7225) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3053) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at com.microsoft.sqlserver.jdbc.SQLServerStatement.executeCommand(SQLServerStatement.java:247) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at com.microsoft.sqlserver.jdbc.SQLServerStatement.executeStatement(SQLServerStatement.java:222) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at com.microsoft.sqlserver.jdbc.SQLServerPreparedStatement.executeUpdate(SQLServerPreparedStatement.java:471) [com.microsoft.sqlserver.mssql-jdbc:8.2.2] at sun.reflect.GeneratedMethodAccessor48.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.tomcat.jdbc.pool.interceptor.AbstractQueryReport$StatementProxy.invoke(AbstractQueryReport.java:212) [org.apache.sling.datasource:1.0.4] at com.sun.proxy.$Proxy19.executeUpdate(Unknown Source) at sun.reflect.GeneratedMethodAccessor48.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.tomcat.jdbc.pool.interceptor.StatementDecoratorInterceptor$StatementProxy.invoke(StatementDecoratorInterceptor.java:237) [org.apache.sling.datasource:1.0.4] at com.sun.proxy.$Proxy19.executeUpdate(Unknown Source) at sun.reflect.GeneratedMethodAccessor48.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.tomcat.jdbc.pool.StatementFacade$StatementProxy.invoke(StatementFacade.java:114) [org.apache.sling.datasource:1.0.4] at com.sun.proxy.$Proxy19.executeUpdate(Unknown Source) at org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStoreJDBC.appendingUpdate(RDBDocumentStoreJDBC.java:132) [org.apache.jackrabbit.oak-store-document:1.10.8] at org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.updateDocument(RDBDocumentStore.java:2074) [org.apache.jackrabbit.oak-store-document:1.10.8] ... 35 common frames omitted",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "RDBDocumentStore: Update error code for MSSQL 2019"
   },
   {
      "_id": "13301237",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2020-04-27 11:21:56",
      "description": "During repository startup if archive directory is not closed properly, recovery will be performed. During that procedure, segents are copied to the backup directory and deleted from the source direcory, one by one.\r\n\r\nIt can create problems and negativelly impact other ongoing actiivties, which are accessing the same archive. This activity, for example, can be repository cloning in order to create new environment.\u00a0\r\n\r\nProposed patch, after creating backup is not deleting all segments from archive, but only segments which could not be recovered.\u00a0\r\n\r\n[^proposal.patch]\r\n\r\n\u00a0\r\n\r\n+API change+\r\n\r\nProposed patch is changing major version of exported SPI package, org.apache.jackrabbit.oak.segment.spi.persistence.split.\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Patch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve azure archive recovery during startup"
   },
   {
      "_id": "13300281",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333401",
            "id": "12333401",
            "name": "search-mt"
         }
      ],
      "created": "2020-04-22 14:13:59",
      "description": "...this seems to be caused by the fact that the project's pom lists slf4j-api as \"provided\" (what for?), and joshua-incubating pulls in a reference to slf4j-log4j12.\r\n\r\nRemoving the provided dependency to slf4j-api seems to fix this.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_22"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-search-mt imports org.slf4j.impl"
   },
   {
      "_id": "13299938",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         }
      ],
      "created": "2020-04-21 09:29:23",
      "description": "Needed f\u00fcr certain mocking features to work with Java 14.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_22"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "upgrade to mockito-core 3.3.3"
   },
   {
      "_id": "13298551",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2020-04-15 12:26:15",
      "description": "I'd like to somewhat standardize getting system properties, with respect to:\r\n\r\n- default handling\r\n- parsing\r\n- logging\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_22"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Standardize handling of system properties"
   },
   {
      "_id": "13293445",
      "assignee": "mkataria",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334700",
            "id": "12334700",
            "name": "search"
         }
      ],
      "created": "2020-03-24 05:27:17",
      "description": "A query with Or and having order by along with limit Don't reproduce results as per order mentioned.\u00a0\r\n\r\ne.g.\u00a0\r\n\r\nLet content be:\r\n\r\n\"/UnionQueryTest1/node0\",\r\n\"/UnionQueryTest/node0\",\r\n\"/UnionQueryTest1/node0/node1\",\r\n\"/UnionQueryTest/node0/node1\",\r\n\"/UnionQueryTest1/node0/node1/node2\",\r\n\"/UnionQueryTest/node0/node1/node2\",\r\n\"/UnionQueryTest1/node0/node1/node2/node3\",\r\n\"/UnionQueryTest/node0/node1/node2/node3\"\r\n\r\neach node having x = number in node name.\r\n\r\nSELECT idn1.* FROM [nt:base] as idn1 WHERE ISDESCENDANTNODE([/UnionQueryTest]) OR\u00a0 ISDESCENDANTNODE([/UnionQueryTest1]) ORDER BY idn1.[x] ASC\r\n\r\n\u00a0\r\n\r\nresult should be\u00a0 same as above mentioned where as current result come out to be\r\n\r\n/UnionQueryTest1/node0\r\n/UnionQueryTest1/node0/node1\r\n/UnionQueryTest1/node0/node1/node2\r\n/UnionQueryTest1/node0/node1/node2/node3\r\n/UnionQueryTest1/node0/node1/node2/node3/node4\r\n/UnionQueryTest/node0\r\n/UnionQueryTest/node0/node1\r\n/UnionQueryTest/node0/node1/node2\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "OR  query with ORDER BY don't work as expected"
   },
   {
      "_id": "13291031",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2020-03-11 09:31:47",
      "description": "While registering a resource change listener, we encountered the following exception :\u00a0\r\n\r\n\u00a0\r\n{code:java}\r\n05.03.2020 23:39:00.728 *ERROR* [FelixDispatchQueue] org.apache.sling.resourceresolver FrameworkEvent ERROR (java.lang.NullPointerException)\r\njava.lang.NullPointerException: null\r\nat org.apache.jackrabbit.oak.commons.PathUtils.unifyInExcludes(PathUtils.java:501) [org.apache.jackrabbit.oak-commons:1.8.17]\r\nat org.apache.jackrabbit.oak.jcr.observation.ObservationManagerImpl.addEventListener(ObservationManagerImpl.java:240) [org.apache.jackrabbit.oak-jcr:1.8.17]\r\nat org.apache.sling.jcr.resource.internal.JcrListenerBaseConfig.register(JcrListenerBaseConfig.java:136) [org.apache.sling.jcr.resource:3.0.16.1]\r\n{code}\r\n\u00a0\r\n\r\nOn further debugging, we found that issues lies in this snippet :\u00a0\r\n{code:java}\r\nif (exclude.equals(include) || isAncestor(exclude, include)) {\r\n includesRemoved.add(include);{code}\r\n'exclude' can be null if the getOakPath() method returns a null. This NPE causes listeners(ResourceChangeListener in our case) to fail at registration.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ObservationManager.addEventListener() throws NPE with invalid paths in filter"
   },
   {
      "_id": "13289743",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2020-03-05 09:03:15",
      "description": "When running oak run jar in recovery mode on a mongo replica set with auth enabled. it fails to pass the auth data for a findOne command called in\u00a0*GetRootRevisionsCallable*\r\n\r\n\u00a0\r\n{code:java}\r\nDBObject root = collection.findOne(new BasicDBObject(Document.ID, \"0:/\"));{code}\r\nStack Trace as below\r\n 07:07:27.790 [MongoDocumentStore replica set info provider] ERROR o.a.j.o.p.d.m.replica.ReplicaSetInfo - Can't connect to the Mongo instance07:07:27.790 [MongoDocumentStore replica set info provider] ERROR o.a.j.o.p.d.m.replica.ReplicaSetInfo - Can't connect to the Mongo instancejava.util.concurrent.ExecutionException: com.mongodb.MongoQueryException: Query failed with error code 13 and error message 'not authorized on dampro64tmp to execute command { find: \"nodes\", filter:\r\n\r\n{ _id: \"0:/\" }\r\n\r\n, limit: 1, singleBatch: true }' on server at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.getRootRevisions(ReplicaSetInfo.java:346) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.updateRevisions(ReplicaSetInfo.java:269) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.updateReplicaStatus(ReplicaSetInfo.java:181) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.updateLoop(ReplicaSetInfo.java:144) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.run(ReplicaSetInfo.java:133) at java.lang.Thread.run(Thread.java:745)Caused by: com.mongodb.MongoQueryException: Query failed with error code 13 and error message 'not authorized on DB to execute command { find: \"nodes\", filter:\r\n\r\n{ _id: \"0:/\" }\r\n\r\n, limit: 1, singleBatch: true }' on server at com.mongodb.operation.FindOperation$1.call(FindOperation.java:722) at com.mongodb.operation.FindOperation$1.call(FindOperation.java:711) at com.mongodb.operation.OperationHelper.withConnectionSource(OperationHelper.java:471) at com.mongodb.operation.OperationHelper.withConnection(OperationHelper.java:415) at com.mongodb.operation.FindOperation.execute(FindOperation.java:711) at com.mongodb.operation.FindOperation.execute(FindOperation.java:83) at com.mongodb.Mongo$3.execute(Mongo.java:826) at com.mongodb.Mongo$3.execute(Mongo.java:813) at com.mongodb.DBCursor.initializeCursor(DBCursor.java:877) at com.mongodb.DBCursor.hasNext(DBCursor.java:144) at com.mongodb.DBCursor.one(DBCursor.java:683) at com.mongodb.DBCollection.findOne(DBCollection.java:829) at com.mongodb.DBCollection.findOne(DBCollection.java:792) at com.mongodb.DBCollection.findOne(DBCollection.java:739) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.GetRootRevisionsCallable.call(GetRootRevisionsCallable.java:58) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.GetRootRevisionsCallable.call(GetRootRevisionsCallable.java:34) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.getRootRevisions(ReplicaSetInfo.java:340) ... 5 common frames omitted",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Oak run recovery fails when running on mongo replicaSet with auth enabled"
   },
   {
      "_id": "13289303",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2020-03-03 17:37:37",
      "description": "ClusterNodeInfo is taking the lowest MAC address found in the machine. When the machine has \"docker0\" bridge, it takes that MAC address (which may change) and uses it. Resulting in errors like this one:\r\nConfigured cluster node id 123 already in use: needs recovery and machineId/instanceId do not match: mac:02421b0c73d3//home/ec2-user != mac:0242a5c0c5e5//home/ec2-user\u00a0 \u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve ClusterNodeInfo MAC address detection "
   },
   {
      "_id": "13289151",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2020-03-03 09:03:11",
      "description": "We should provide a way to filter the index using a regular expression. For example, only index nodes that contain a reference to another node. (Not a JCR reference, but a reference within the value itself). For example, index a node if one of the properties contains:\r\n\r\n* /content/abc\r\n* <html...> <a href=\"/content/abc\">\r\n* and so on\r\n\r\nThis will allow to run a query to find if /content/abc is referenced. The index and the query will probably need to use a tag, and the cost of the index needs to be high. Otherwise the query engine can't know when this index should be used.\r\n\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "amrit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Indexing: filter entries with a regular expression"
   },
   {
      "_id": "13288550",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2020-03-01 14:01:25",
      "description": "The current (new) algorithm (introduced in OAK-5855) may cause SELECT and DELETE statements to run concurrently, which might cause problems on certain DBs, such as SQL Server.\r\n\r\nAdded a fallback (triggered by a system property) to the older (but slower) algorithm. Select it by setting system property like that:\r\n{noformat}\r\n-Dorg.apache.jackrabbit.oak.plugins.document.rdb.RDBVersionGCSupport.MODE=1 {noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RDBDocumentStore: allow RDBVersionGC support fallback to simpler algorithm"
   },
   {
      "_id": "13285694",
      "assignee": "tmueller",
      "components": [],
      "created": "2020-02-17 07:44:33",
      "description": "Improve\u00a0[http://jackrabbit.apache.org/oak/docs/query/lucene.html]\u00a0with the following:\r\n * Extend the\u00a0*analyzers*\u00a0section including a reference on how to support\u00a0*stemming*\u00a0([http://jackrabbit.apache.org/oak/docs/query/lucene.html])\r\n * *supersedes*\u00a0- does not seem to be documented**\r\n * *functionName (string)*\u00a0&\u00a0*useIfExists (string)*\u00a0are not listed in the canonical\u00a0*Index Definition*\u00a0structure.\r\n * *function (string)*\u00a0is not listed in the canonical\u00a0*Property Definitions*\u00a0structure\r\n * *weight*\u00a0- in the canonical structure the default value is -1, but the actual default is 5",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "amrit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve OAK Lucene Index Documentation"
   },
   {
      "_id": "13282907",
      "assignee": "tmueller",
      "components": [],
      "created": "2020-02-03 06:14:29",
      "description": "Add javadoc to package-info files in all packages of {{oak-lucene}} , {{oak-query-spi}} and {{oak-search}} .",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "amrit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add javadoc to package-info files"
   },
   {
      "_id": "13281598",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2020-01-26 16:32:49",
      "description": "...offering JDK 8 Predicate API in addition.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_22"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "deprecate use of Guava Predicate class in oak-core API"
   },
   {
      "_id": "13281162",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         }
      ],
      "created": "2020-01-23 10:52:52",
      "description": "We use azcopy to copy segments from one azure blob container to another for testing. There is a bug in the current version of azcopy (10.3.3), which makes all metadata keys start with a capital letter -\u00a0\"type\" becomes \"Type\". As a consequence, the current implementation can not find the segments in the azure blob storage.\u00a0\r\n\u00a0\r\nThe azcopy\u00a0issue was already reported [1] in 2018.\u00a0I have little hope that azcopy will be fixed soon.\r\n\u00a0\r\nTherefore I suggest a patch to oak-segment-azure, that would be backward compatible and ignore the case of the keys when reading metadata.\u00a0We should be strict in what we write and tolerant in what we read.\u00a0\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "azureblob"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Access azure segments metadata in a case-insensitive way"
   },
   {
      "_id": "13274106",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-12-12 10:54:40",
      "description": "We are probably not affected by the CVE though...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-store-document: update org.quartz-scheduler dependency to 2.3.2"
   },
   {
      "_id": "13273865",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2019-12-11 12:21:12",
      "description": "oak-solr-osgi embeds jackson-core and jackson-dataformat-smile, currently at 2.9.10.\r\n\r\nOnce we update the project's jackson dependency to 2.10.1, oak-solr-osgi will break because the in jackson, dependencies and packaging changed.\r\n\r\nTo make oak-solr-osgi work with 2.9.10, we'll have to also include -databind and -annotations, increasing the bundle size by ~1.4M.\r\n\r\nFor now and instead, I'll hardwire the 2.9.10 dependency and let the indexing team (cc [~thomasm], [~teofili]) decide how to proceed with the general question about what to embed in the bundle.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-solr-osgi: decouple jackson dependency from project dependency"
   },
   {
      "_id": "13272238",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2019-12-04 13:46:52",
      "description": "See <https://issues.apache.org/jira/browse/OAK-8798?focusedCommentId=16987186&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16987186>",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-solr-osgi: adjust Import-Package declaration for upgrade of maven-bundle-plugin to 4.2.1"
   },
   {
      "_id": "13271259",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2019-11-28 16:01:30",
      "description": "See https://issues.apache.org/jira/browse/OAK-8798?focusedCommentId=16984471&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16984471",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-lucene: adjust Import-Package declaration for upgrade of maven-bundle-plugin to 4.2.1"
   },
   {
      "_id": "13270725",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333546",
            "id": "12333546",
            "name": "oak-http"
         }
      ],
      "created": "2019-11-26 13:43:32",
      "description": "The bare \"*\" causes run time exceptions in newer versions of the bundle plugin, see OAK-8798.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-http: broken Export-Package statement"
   },
   {
      "_id": "13267750",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-11-12 15:44:47",
      "description": "...which is not thread-safe.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ClusterViewDocument uses static instance of SimpleDateFormat"
   },
   {
      "_id": "13265315",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2019-10-30 14:29:17",
      "description": "{noformat}\r\n            // 3. deal with locked nodes\r\n            boolean wasLockable = isNodeType(MIX_LOCKABLE);\r\n            boolean isLockable = isNodeType(MIX_LOCKABLE);\r\n            if (wasLockable && !isLockable && holdsLock(false)) {\r\n                // TODO: This should probably be done in a commit hook\r\n                unlock();\r\n                sessionDelegate.refresh(true);\r\n            }\r\n{noformat}\r\n\r\nAFAICT, this code block will never be executed. Clean up, [~angela]?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "dead locking related code in NodeDelegate.updateMixins"
   },
   {
      "_id": "13264800",
      "assignee": "dulceanu",
      "components": [],
      "created": "2019-10-28 11:32:37",
      "description": "Currently the consistency check reports only if the command runs successfully (return code 0) or fails (return code 1).\r\nInto this logic will also add the status of repository consistency:\r\n- checking only the last revision: will return 0 if the revision is consistent and the command runs successfully OR will return 1 if the revision is inconsistent or job did not run successfully (some errors/exception were encountered during the run)\r\n- checking multiple revisions: will return 0 if at least one revision is consistent and the job runs successfully OR will return 1 if none of the revisions are consistent or the command did not run successfully (some errors/exception were encounter during the run) ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "oak-run",
         "segment-tar"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak run check command must return the status of repository consistency check"
   },
   {
      "_id": "13263811",
      "assignee": "nitigup",
      "components": [],
      "created": "2019-10-22 13:56:56",
      "description": "Consider a scenario where a query is there with facets and the traversal cost is less than the index cost that serves the facet query . This would be problematic.\r\n\r\n\u00a0\r\n\r\nIn this case we should maybe set the traversal cost to infinity so that traversal is not an option for queries with facets.\r\n\r\n\u00a0\r\n\r\nIn case there is no index available to serve this faceted query we can probably throw an exception with a meaningful message .",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "amrit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Queries with facets should not use traversal"
   },
   {
      "_id": "13262887",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2019-10-17 15:12:17",
      "description": "The INTERMEDIATE value (30) in the documentmk docs does not align with the one in SplitDocType enum (40).\r\n\r\n[https://github.com/apache/jackrabbit-oak/blob/jackrabbit-oak-1.12.0/oak-store-document/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java#L299]\r\n\r\ncc [~mreutegg] [~reschke]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "fabriziofortino"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "DocumentMK documentation: fix INTERMEDIATE SplitDocType value"
   },
   {
      "_id": "13262099",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333401",
            "id": "12333401",
            "name": "search-mt"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12335337",
            "id": "12335337",
            "name": "test"
         }
      ],
      "created": "2019-10-14 08:06:17",
      "description": "The test runs fine through\u00a0{{mvn clean install}}\u00a0or when\u00a0{{mvn clean test}}\u00a0is run inside\u00a0{{oak-search-mt}}\u00a0folder.\r\n\r\nHowever, running {{mvn clean test}} from trunk throws the following exception:\r\n{code:java}\r\n[INFO] Running org.apache.jackrabbit.oak.plugins.index.mt.MTFulltextQueryTermsProviderTest\r\n [ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.57 s <<< FAILURE! - in org.apache.jackrabbit.oak.plugins.index.mt.MTFulltextQueryTermsProviderTest\r\n [ERROR] testGetQueryTermWithPhraseTranslation(org.apache.jackrabbit.oak.plugins.index.mt.MTFulltextQueryTermsProviderTest) \u00a0Time elapsed: 0.527 s \u00a0<<< ERROR!\r\n java.lang.NoClassDefFoundError: org/apache/lucene/analysis/standard/StandardTokenizer\r\n \u00a0 \u00a0at org.apache.jackrabbit.oak.plugins.index.mt.MTFulltextQueryTermsProviderTest.testGetQueryTermWithPhraseTranslation(MTFulltextQueryTermsProviderTest.java:57)\r\n Caused by: java.lang.ClassNotFoundException: org.apache.lucene.analysis.standard.StandardTokenizer\r\n \u00a0 \u00a0at org.apache.jackrabbit.oak.plugins.index.mt.MTFulltextQueryTermsProviderTest.testGetQueryTermWithPhraseTranslation(MTFulltextQueryTermsProviderTest.java:57){code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "fabriziofortino"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NoClassDefFound running tests in oak-search-mt"
   },
   {
      "_id": "13261807",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-10-11 13:39:56",
      "description": "...this would make it easier to find the relevant part in the system log.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "state time of start of LeaseFailure in exception/log entry"
   },
   {
      "_id": "13260246",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-10-03 07:16:14",
      "description": "Changing and merging descendant nodes of a bundled node fails when the commit root of the changes is located on a bundled node. The merge tries to apply the final commit changes on a document that does not exist (because the bundled node is located on an ancestor document).\r\n\r\nThe exception is misleading but looks like this:\r\n{noformat}\r\nCaused by: org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: Conflicting concurrent change. Update operation failed: key: 3:/foo/bar/baz update {_revisions.r16d8bf18282-0-1=SET_MAP_ENTRY c, _modified=MAX 1570010920}\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:398) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStoreWithTiming(Commit.java:278) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:262) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyInternal(Commit.java:230) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.apply(Commit.java:218) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:320) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:282) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.access$500(DocumentNodeStoreBranch.java:56) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch$InMemory.merge(DocumentNodeStoreBranch.java:548) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Merge may fail when commit root is a bundled node"
   },
   {
      "_id": "13259835",
      "assignee": "nitigup",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333864",
            "id": "12333864",
            "name": "oak-search"
         }
      ],
      "created": "2019-10-01 08:07:51",
      "description": "The custom scorer exposes the Lucene API directly. This needs to be removed in order to support remote index services (solr, elasticsearch). Since this feature does not seem to be used, we can safely remove it.\r\n\r\n\u00a0\r\n\r\n[https://github.com/apache/jackrabbit-oak/tree/trunk/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/score]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "fabriziofortino"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Deprecate support for lucene custom scorer"
   },
   {
      "_id": "13257936",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332467",
            "id": "12332467",
            "name": "composite",
            "description": "Oak Composite Node Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12335337",
            "id": "12335337",
            "name": "test"
         }
      ],
      "created": "2019-09-20 12:24:51",
      "description": "CompositeNodeStore tests using document store (h2, document memory) are currently disabled because the index creation does not work.\u00a0\r\n\r\n[https://svn.apache.org/repos/asf/jackrabbit/oak/trunk/oak-lucene/src/test/java/org/apache/jackrabbit/oak/composite/CompositeNodeStoreQueryTestBase.java]\u00a0\r\n\r\nThe below assertion fails because the lucene index is not found. This does not happen with segment and memory stores.\r\n\r\n\u00a0\r\n{noformat}\r\njava.lang.AssertionError: java.lang.AssertionError: Expected: a string containing \"/* traverse \\\"//*\\\" where ([a].[foo] = 'bar'\"     but: was \"plan: [nt:base] as [a] /* lucene:luceneTest(/oak:index/luceneTest) foo:bar where ([a].[foo] = 'bar') and (isdescendantnode([a], [/])) */ \"Expected :a string containing \"/* traverse \\\"//*\\\" where ([a].[foo] = 'bar'\"Actual   :\"plan: [nt:base] as [a] /* lucene:luceneTest(/oak:index/luceneTest) foo:bar where ([a].[foo] = 'bar') and (isdescendantnode([a], [/])) */ \"<Click to see difference>\r\nat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20) \r\nat org.junit.Assert.assertThat(Assert.java:956) \r\nat org.junit.Assert.assertThat(Assert.java:923) \r\nat org.apache.jackrabbit.oak.composite.CompositeNodeStoreLuceneIndexTest.removeLuceneIndex(CompositeNodeStoreLuceneIndexTest.java:169) \r\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) \r\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) \r\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) \r\nat java.lang.reflect.Method.invoke(Method.java:498) \r\nat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) \r\nat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) \r\nat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) \r\nat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) \r\nat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) \r\nat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) \r\nat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) \r\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) \r\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) \r\nat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) \r\nat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) \r\nat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) \r\nat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) \r\nat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) \r\nat org.junit.runners.ParentRunner.run(ParentRunner.java:363) \r\nat org.junit.runners.Suite.runChild(Suite.java:128) \r\nat org.junit.runners.Suite.runChild(Suite.java:27) \r\nat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) \r\nat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) \r\nat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) \r\nat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) \r\nat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) \r\nat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48) \r\nat org.junit.rules.RunRules.evaluate(RunRules.java:20) \r\nat org.junit.runners.ParentRunner.run(ParentRunner.java:363) \r\nat org.junit.runner.JUnitCore.run(JUnitCore.java:137) \r\nat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) \r\nat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) \r\nat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) \r\nat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "fabriziofortino",
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Composite node store tests with document store"
   },
   {
      "_id": "13257125",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-09-17 13:53:52",
      "description": "The DocumentNodeStore node bundling feature may expose a hidden internal property when a bundled node structure is deleted and re-created with a non-bundling nodetype.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Node bundling exposes hidden properties"
   },
   {
      "_id": "13255224",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332467",
            "id": "12332467",
            "name": "composite",
            "description": "Oak Composite Node Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2019-09-06 10:15:11",
      "description": "When using the composite node store with a read-only portion of the repository, the counter index does not allow to index from scratch / reindex.\r\n\r\nIndex from scratch is needed in case the async checkpoint is lost. Reindex is started by setting the \"reindex\" flag to true.\r\n\r\nCurrently the failure is:\r\n\r\n{noformat}\r\n05.09.2019 09:29:21.892 *WARN* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate [async] The index update is still failing\r\njava.lang.UnsupportedOperationException: This builder is read-only.\r\n\tat org.apache.jackrabbit.oak.spi.state.ReadOnlyBuilder.unsupported(ReadOnlyBuilder.java:44) [org.apache.jackrabbit.oak-store-spi:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.spi.state.ReadOnlyBuilder.child(ReadOnlyBuilder.java:189) [org.apache.jackrabbit.oak-store-spi:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.spi.state.ReadOnlyBuilder.child(ReadOnlyBuilder.java:34) [org.apache.jackrabbit.oak-store-spi:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.getBuilder(NodeCounterEditor.java:184) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.leaveNew(NodeCounterEditor.java:162) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.index.counter.NodeCounterEditor.leave(NodeCounterEditor.java:114) [org.apache.jackrabbit.oak-core:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.spi.commit.CompositeEditor.leave(CompositeEditor.java:73) [org.apache.jackrabbit.oak-store-spi:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:59) [org.apache.jackrabbit.oak-store-spi:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeAdded(EditorDiff.java:129) [org.apache.jackrabbit.oak-store-spi:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160) [org.apache.jackrabbit.oak-store-spi:1.16.0.R1866113]\r\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:504) [org.apache.jackrabbit.oak-segment-tar:1.16.0.R1866113]\r\n\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "fabriziofortino"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Composite Node Store + Counter Index: allow indexing from scratch / reindex"
   },
   {
      "_id": "13251784",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-08-20 08:50:59",
      "description": "Backport OAK-8066 to 1.10 and 1.8.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Backport OAK-8066 to 1.10 and 1.8"
   },
   {
      "_id": "13242886",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332557",
            "id": "12332557",
            "name": "store-spi",
            "description": "Oak NodeStore and Commit SPI"
         }
      ],
      "created": "2019-07-03 03:35:55",
      "description": "As per the api doc here [https://github.com/apache/jackrabbit-oak/blob/trunk/oak-api/src/main/java/org/apache/jackrabbit/oak/api/PropertyState.java#L67#L69] for PropertyState the getValue method should throw an IllegalStateException if the actual Property stored is multivalued and the code calling getValue(Type type) expects it to be single valued i.e type.isArray() == false .\r\n\r\n\u00a0\r\n\r\nIn SegmentStore implementation , this is followed and the getValue method throws an IllegalStateException in this scenario .\r\n\r\n\u00a0\r\n\r\nHowever in case of MemoryNodeStore , the code here throws an IllegalArgumentException [https://github.com/apache/jackrabbit-oak/blob/trunk/oak-store-spi/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MultiPropertyState.java#L151#L154] instead of IllegalStateException .\r\n\r\nSince MemoryNodeStore is primarily used in testing , this difference in implementation can lead to false or incomplete testing .\r\n\r\n\u00a0\r\n\r\nFor example , the fix for https://issues.apache.org/jira/browse/OAK-8328 required to catch IllegalStateException in a use case where the property was configured to be multi valued in the repository but the code expected it to be single valued . Now the fix works fine on SegmentStore , but due to the difference in implementation in MemoryNodeStore , a test written with memorynode store fails .\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Memory Node store implementation of PropertyState throws Exception that is not in line with the API documentation"
   },
   {
      "_id": "13240824",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-06-21 09:53:54",
      "description": "{{oak-run check}} should expose the head node and property counts for the last good revision. Currently these are only logged at the end of the check operation as\r\n{noformat}\r\nChecked X nodes and Y properties.{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run check should expose repository statistics for the last good revision"
   },
   {
      "_id": "13236196",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         }
      ],
      "created": "2019-05-29 09:11:13",
      "description": "Add remote store monitoring\r\nImplement the remote store monitoring for Azure Store.\u00a0This should include:\r\n- request_count : number of request to azure store\r\n- error_count : number of failed requests to azure store\r\n- duration : duration of a request to azure store in nanoseconds ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add remote store monitoring  for Azure"
   },
   {
      "_id": "13235965",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-05-28 10:16:13",
      "description": "{{oak-run check}}\u00a0currently uses memory mapping by default when building the {{FileStore}}. This setting should be configurable, to allow switching memory mapping off.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run check should have an option for specifying memory mapping"
   },
   {
      "_id": "13235311",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2019-05-24 07:50:43",
      "description": "We need to expose the local index directory size a metric that can later be consumed for monitor and alerting purposes .\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose local index directory size as a metric"
   },
   {
      "_id": "13233909",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2019-05-17 07:28:24",
      "description": "If we\u00a0 set \"/oak:index/indexName/entryCount\" to a Long multi-valued property. That will cause the system to reindex in a loop... You only see the root cause if debug level logging is enabled. There are likely other such problems. Oak should log a proper meaningful exception for config errors, and if possible not get into this loop. It also blocks other indexes to be updated I think.\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n{code:java}\r\n29.03.2019 11:58:55.688 *INFO* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.IndexUpdate Reindexing will be performed for following indexes: [/oak:index/unifiedCreatedLucene]\r\n29.03.2019 11:59:00.691 *INFO* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.IndexUpdate Reindexing will be performed for following indexes: [/oak:index/unifiedCreatedLucene]\r\n29.03.2019 11:59:05.685 *INFO* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.IndexUpdate Reindexing will be performed for following indexes: [/oak:index/unifiedCreatedLucene]\r\n29.03.2019 11:59:10.687 *INFO* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.IndexUpdate Reindexing will be performed for following indexes: [/oak:index/unifiedCreatedLucene]\r\n29.03.2019 11:59:15.685 *INFO* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.IndexUpdate Reindexing will be performed for following indexes: [/oak:index/unifiedCreatedLucene]\r\n29.03.2019 11:59:20.688 *INFO* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.IndexUpdate Reindexing will be performed for following indexes: [/oak:index/unifiedCreatedLucene]\r\n\r\n29.03.2019 12:13:50.692 *DEBUG* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate [async] The index update is still failing\r\njava.lang.IllegalStateException: null\r\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:134)\r\n\tat org.apache.jackrabbit.oak.segment.SegmentPropertyState.getValue(SegmentPropertyState.java:145)\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition.<init>(IndexDefinition.java:358)\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition.<init>(IndexDefinition.java:95)\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition$Builder.build(IndexDefinition.java:314)\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorContext.enableReindexMode(LuceneIndexEditorContext.java:184)\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.enter(LuceneIndexEditor.java:118)\r\n\tat org.apache.jackrabbit.oak.spi.commit.ProgressNotificationEditor.enter(ProgressNotificationEditor.java:71)\r\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bug in index definition can block indexing / cause indexing in a loop"
   },
   {
      "_id": "13232448",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2019-05-09 11:27:07",
      "description": "The metrics added should show slow query count but the count is not getting updated for each query.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": " SLOW_QUERY_COUNT don't get updated for each slow query."
   },
   {
      "_id": "13230882",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2019-04-30 11:10:39",
      "description": "{noformat}\r\nWARNING: An illegal reflective access operation has occurred\r\nWARNING: Illegal reflective access by org.apache.felix.framework.URLHandlers (file:/C:/Users/jre/.m2/repository/org/apache/felix/org.apache.felix.framework/5.6.10/org.apache.felix.framework-5.6.10.jar) to constructor sun.net.www.protocol.file.Handler()\r\nWARNING: Please consider reporting this to the maintainers of org.apache.felix.framework.URLHandlers\r\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\nWARNING: All illegal access operations will be denied in a future release\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Creating bundle watcher with scanner [org.ops4j.pax.swissbox.extender.BundleManifestScanner@2834f898]...\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.apache.felix.framework]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.exam]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.exam.inject]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.exam.extender.service]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [osgi.cmpn]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.base]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.swissbox.core]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.swissbox.extender]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.swissbox.framework]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.swissbox.lifecycle]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.swissbox.tracker]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.apache.geronimo.specs.geronimo-atinject_1.0_spec]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.tipi.junit]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.tipi.hamcrest.core]\r\n[org.ops4j.pax.swissbox.extender.BundleWatcher] : Scanning bundle [org.ops4j.pax.exam.invoker.junit]\r\nERROR: org.apache.felix.scr (15): Exception starting during restart\r\njava.lang.IllegalStateException: Stream handler unavailable.\r\n        at org.apache.felix.framework.URLHandlersStreamHandlerProxy.getDefaultPort(URLHandlersStreamHandlerProxy.java:180)\r\n        at java.base/java.net.URL.getDefaultPort(URL.java:885)\r\n        at java.base/sun.net.util.URLUtil.urlNoFragString(URLUtil.java:68)\r\n        at java.base/java.security.CodeSource.<init>(CodeSource.java:120)\r\n        at java.base/jdk.internal.loader.BuiltinClassLoader.defineClass(BuiltinClassLoader.java:779)\r\n        at java.base/jdk.internal.loader.BuiltinClassLoader.findClassInModuleOrNull(BuiltinClassLoader.java:703)\r\n        at java.base/jdk.internal.loader.BuiltinClassLoader.findClass(BuiltinClassLoader.java:584)\r\n        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:633)\r\n        at java.base/java.lang.Class.forName(Class.java:492)\r\n        at java.base/java.util.ServiceLoader.loadProvider(ServiceLoader.java:853)\r\n        at java.base/java.util.ServiceLoader$ModuleServicesLookupIterator.hasNext(ServiceLoader.java:1077)\r\n        at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)\r\n        at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)\r\n        at java.base/sun.util.cldr.CLDRLocaleProviderAdapter$1.run(CLDRLocaleProviderAdapter.java:89)\r\n        at java.base/sun.util.cldr.CLDRLocaleProviderAdapter$1.run(CLDRLocaleProviderAdapter.java:86)\r\n        at java.base/java.security.AccessController.doPrivileged(AccessController.java:553)\r\n        at java.base/sun.util.cldr.CLDRLocaleProviderAdapter.<init>(CLDRLocaleProviderAdapter.java:86)\r\n        at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n        at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n        at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n        at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)\r\n        at java.base/java.lang.reflect.ReflectAccess.newInstance(ReflectAccess.java:166)\r\n        at java.base/jdk.internal.reflect.ReflectionFactory.newInstance(ReflectionFactory.java:404)\r\n        at java.base/java.lang.Class.newInstance(Class.java:591)\r\n        at java.base/sun.util.locale.provider.LocaleProviderAdapter.forType(LocaleProviderAdapter.java:176)\r\n        at java.base/sun.util.locale.provider.LocaleProviderAdapter.findAdapter(LocaleProviderAdapter.java:279)\r\n        at java.base/sun.util.locale.provider.LocaleProviderAdapter.getAdapter(LocaleProviderAdapter.java:250)\r\n        at java.base/java.text.NumberFormat.getInstance(NumberFormat.java:951)\r\n        at java.base/java.text.NumberFormat.getInstance(NumberFormat.java:491)\r\n        at java.base/java.text.MessageFormat.subformat(MessageFormat.java:1293)\r\n        at java.base/java.text.MessageFormat.format(MessageFormat.java:885)\r\n        at java.base/java.text.Format.format(Format.java:158)\r\n        at java.base/java.text.MessageFormat.format(MessageFormat.java:860)\r\n        at org.apache.felix.scr.impl.Activator.warn(Activator.java:460)\r\n        at org.apache.felix.utils.extender.AbstractExtender.createExtension(AbstractExtender.java:268)\r\n        at org.apache.felix.utils.extender.AbstractExtender.modifiedBundle(AbstractExtender.java:227)\r\n        at org.apache.felix.utils.extender.AbstractExtender.addingBundle(AbstractExtender.java:187)\r\n        at org.osgi.util.tracker.BundleTracker$Tracked.customizerAdding(BundleTracker.java:469)\r\n        at org.osgi.util.tracker.BundleTracker$Tracked.customizerAdding(BundleTracker.java:415)\r\n        at org.osgi.util.tracker.AbstractTracked.trackAdding(AbstractTracked.java:256)\r\n        at org.osgi.util.tracker.AbstractTracked.trackInitial(AbstractTracked.java:183)\r\n        at org.osgi.util.tracker.BundleTracker.open(BundleTracker.java:156)\r\n        at org.apache.felix.utils.extender.AbstractExtender.startTracking(AbstractExtender.java:150)\r\n        at org.apache.felix.utils.extender.AbstractExtender.doStart(AbstractExtender.java:142)\r\n        at org.apache.felix.scr.impl.Activator.doStart(Activator.java:172)\r\n        at org.apache.felix.utils.extender.AbstractExtender.start(AbstractExtender.java:114)\r\n        at org.apache.felix.scr.impl.Activator.restart(Activator.java:142)\r\n        at org.apache.felix.scr.impl.config.ScrConfigurationImpl.configure(ScrConfigurationImpl.java:196)\r\n        at org.apache.felix.scr.impl.config.ScrConfigurationImpl.start(ScrConfigurationImpl.java:117)\r\n        at org.apache.felix.scr.impl.Activator.start(Activator.java:110)\r\n        at org.apache.felix.framework.util.SecureAction.startActivator(SecureAction.java:697)\r\n        at org.apache.felix.framework.Felix.activateBundle(Felix.java:2240)\r\n        at org.apache.felix.framework.Felix.startBundle(Felix.java:2146)\r\n        at org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1373)\r\n        at org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:308)\r\n        at java.base/java.lang.Thread.run(Thread.java:835)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "jdk13"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update org.apache.felix.framework for jdk13"
   },
   {
      "_id": "13229853",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-04-24 12:06:17",
      "description": "The DocumentNodeStore does not clean up orphaned branch commit entries ({{_bc}}) after a restart. Cleanup for those entries happens while the DocumentNodeStore is running as well, but only when the branch is not referenceable anymore. In some cases it may happen that a branch is referenced right until the DocumentNodeStore is disposed and the cleanup must happen on startup.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Orphaned branch commit entries after restart"
   },
   {
      "_id": "13229537",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2019-04-23 08:22:02",
      "description": "Steps to reproduce issue:\r\n\r\nDelete blob filesystem(in case of tarmk) from repository/datastore and empty repository/index folder.\r\n\r\nNow asyncIndexUpdate will run periodically and fail but index won't get marked as corrupt.\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Indexing lane failing but the index is not marked corrupt"
   },
   {
      "_id": "13228157",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2019-04-15 16:32:34",
      "description": "No description is provided\r\n\r\nThe build Jackrabbit Oak #2091 has failed.\r\nFirst failed run: [Jackrabbit Oak #2091|https://builds.apache.org/job/Jackrabbit%20Oak/2091/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/2091/console]\r\n\r\n{noformat}\r\n[ERROR] Tests run: 13, Failures: 0, Errors: 2, Skipped: 2, Time elapsed: 3.402 s <<< FAILURE! - in org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest\r\n[ERROR] org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest  Time elapsed: 3.08 s  <<< ERROR!\r\ncom.carrotsearch.randomizedtesting.ThreadLeakError: \r\n1 thread leaked from SUITE scope at org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest: \r\n   1) Thread[id=143, name=oak-scheduled-executor-61, state=TIMED_WAITING, group=main]\r\n        at sun.misc.Unsafe.park(Native Method)\r\n        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\r\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:1129)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:809)\r\n        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n\tat __randomizedtesting.SeedInfo.seed([7416B4EE1CED31C6]:0)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Build failure: ThreadLeakError"
   },
   {
      "_id": "13227519",
      "assignee": "baedke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2019-04-11 18:12:20",
      "description": "In contrast to Node#addNode(String, String), Node#setPrimaryType(String) does not create child nodes that are defined as autoCreated. See attached failing test case.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Node#setPrimaryType(String) does not create child nodes defined as autoCreated"
   },
   {
      "_id": "13225702",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2019-04-03 05:41:32",
      "description": "Log level warn is being used\u00a0 at [1]. In case an index can't be used because of some filter not supported by that index, a warning is being locked. Though is a normal scenario as that query may have been created keeping another index in mind.\r\n\r\ne.g.\u00a0\r\n select [jcr:path], [jcr:score], [rep:facet(jcr:content/metadata/x)], [rep:facet(jcr:content/metadata/y)] from [z] as\r\n a where isdescendantnode(a, '/content/p')\r\n Lets assume we have facets configured on index definition z on properties which are not indexed in nt:base leading to warning log.\u00a0\r\n\r\n[1]: [https://github.com/apache/jackrabbit-oak/blob/5deeea0055deb776fffbf268b66c4a97d096d124/oak-search/src/main/java/org/apache/jackrabbit/oak/plugins/index/search/spi/query/FulltextIndexPlanner.java#L224]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Getting warning message in error logs while trying to search using filters"
   },
   {
      "_id": "13224619",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332467",
            "id": "12332467",
            "name": "composite",
            "description": "Oak Composite Node Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2019-03-28 15:04:46",
      "description": "04.03.2019 06:42:46.956 *WARN* [sling-oak-3-org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate-async] org.apache.jackrabbit.oak.composite.CompositeNodeStore Checkpoint f7e6524d-62c4-4589-8137-ca873cec934b doesn't exist\r\n\r\n\r\nThe above warning was observed - but there are not enough logs around this to identify what's causing this .\r\n\r\n\u00a0\r\n\r\nWe need to add stack trace when this is logged and probably changed the message to make it unique.\r\n\r\n\u00a0\r\n\r\nAlso , Since this was logged from a flow in AsyncIndexUpdate - It would make sense to add some more info/ warn level logging there around the code that calls getReferenceCheckpoint()",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add logging around getReferenceCheckpoint method "
   },
   {
      "_id": "13224315",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2019-03-27 13:56:18",
      "description": "The {{ExternalGroupPrincipalProvider}} related changes for OAK-8131.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "principal-management-extensions"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ExternalGroupPrincipalProvider support for full text search"
   },
   {
      "_id": "13223920",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2019-03-26 01:44:55",
      "description": "With the statistical mode, facet count is\u00a0updated proportionally to the percentage of accessible samples, which works for secured contents scattered across different facets. For edge case where the whole facet (results) is not accessible, the count still shows a number after the sampling percent is applied. Even\u00a0if the number is small, user experience is misleading/inaccurate as nothing would\u00a0return when the facet is clicked (applied as a query condition).\r\n\r\nFor example,\u00a0a ACLs/CUGs guarded \"private\" folder, in which all the assets are tagged with the same facet value. Non authorized user may still see this facet with a count but gets nothing when clicking on the facet.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "vulnerability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "With uneven distribution of ACL restriction across facet labels statistical facet count become too inaccurate"
   },
   {
      "_id": "13223813",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2019-03-25 16:02:02",
      "description": "If an index definition contains the same orderable property with and without functions, it will fail to index any node which contains that property. The failure will be logged as [1].\r\n\r\nSteps to reproduce:\r\n* Configure index with the two property definitions shown at [2].\r\n* Refresh the index definition\r\n* Modify a node that falls under the definition - it will fail with the exception shown at [1]\r\n* Modify the 'non-function' index definition to not be orderable (orderable=false)\r\n* Refresh the index definition\r\n* Modify the same node - note there is no exception.\r\n\r\nThanks to [~catholicon] for assistance identifying root cause.\r\n\r\n\r\n[1]\r\n{code}\r\n25.03.2019 15:39:04.135 *WARN* [async-index-update-async] org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor Failed to index the node [/content/dam/Unknown-2.png]\r\njava.lang.IllegalArgumentException: DocValuesField \":dvjcr:content/metadata/dc:title\" appears more than once in this document (only one value is allowed per field)\r\n\tat org.apache.lucene.index.SortedDocValuesWriter.addValue(SortedDocValuesWriter.java:62) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.lucene.index.DocValuesProcessor.addSortedField(DocValuesProcessor.java:125) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.lucene.index.DocValuesProcessor.addField(DocValuesProcessor.java:59) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.lucene.index.TwoStoredFieldsConsumers.addField(TwoStoredFieldsConsumers.java:36) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.lucene.index.DocFieldProcessor.processDocument(DocFieldProcessor.java:236) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.lucene.index.DocumentsWriterPerThread.updateDocument(DocumentsWriterPerThread.java:253) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:455) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1534) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1507) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.writer.DefaultIndexWriter.updateDocument(DefaultIndexWriter.java:86) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.addOrUpdate(LuceneIndexEditor.java:258) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:140) [org.apache.jackrabbit.oak-lucene:1.8.9]\r\n\tat org.apache.jackrabbit.oak.spi.commit.CompositeEditor.leave(CompositeEditor.java:74) [org.apache.jackrabbit.oak-store-spi:1.8.9]\r\n{code}\r\n\r\n\r\n[2] \r\n{code}\r\n\"dcTitle\": {\r\n    \"jcr:primaryType\": \"nt:unstructured\",\r\n    \"nodeScopeIndex\": \"true\",\r\n    \"useInSuggest\": \"true\",\r\n    \"ordered\": \"true\",\r\n    \"propertyIndex\": \"true\",\r\n    \"useInSpellcheck\": \"true\",\r\n    \"name\": \"jcr:content/metadata/dc:title\",\r\n    \"boost\": \"2.0\"\r\n    },\r\n  \"dcTitleLowercase\": {\r\n    \"jcr:primaryType\": \"nt:unstructured\",\r\n    \"ordered\": \"true\",\r\n    \"propertyIndex\": \"true\",\r\n    \"function\": \"fn:lower-case(jcr:content/metadata/@dc:title)\"\r\n    }\r\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexingPatch",
         "nitin"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Index definition with orderable property definitions with and without functions breaks index"
   },
   {
      "_id": "13223359",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333543",
            "id": "12333543",
            "name": "security-spi",
            "description": "Oak Security SPI"
         }
      ],
      "created": "2019-03-22 14:23:44",
      "description": "[~stillalex], the new {{findPrincipals}} method added recent lacks NotNull and Overrides annotation in {{CompositePrincipalProvider}}. Hope you don't mind if I add it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "principal-management-extensions"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "CompositePrincipalProvider.findPrincipals lacks NotNull and Overrides annotation"
   },
   {
      "_id": "13222812",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2019-03-20 11:17:01",
      "description": "# We need a metric which calculates the number of slow queries compared to all run queries. The value should be a percentile for slow queries relative to all queries to prove 99% absence of slow product queries that traverse more than 100'000 nodes)\r\n # Add another metric showing total number of slow queries executed.\r\n\r\nSee:\u00a0[https://sling.apache.org/documentation/bundles/metrics.html]\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": " [Indexing] Implement sling metric to calculate number of slow queries(relative to all queries)"
   },
   {
      "_id": "13222600",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333543",
            "id": "12333543",
            "name": "security-spi",
            "description": "Oak Security SPI"
         }
      ],
      "created": "2019-03-19 14:38:22",
      "description": "The {{CompositePrincipalProvider}} related changes for OAK-8131.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "principal-management-extensions"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CompositePrincipalProvider support for full text search"
   },
   {
      "_id": "13222312",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2019-03-18 13:13:37",
      "description": "The {{UserPrincipalProvider}} related changes for OAK-8131.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "principal-management-extensions"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "UserPrincipalProvider support for full text search"
   },
   {
      "_id": "13222303",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-03-18 12:49:07",
      "description": "OAK-3492 silences log warns when it encounters an 1.0 or 1.2 oak version (in the case where there is an inactive cluster node that doesn't have lastWrittenRootRev set).\r\n\r\nThe silencing uses osgi Version to do the version comparison, however the actual version is stored in maven format. This breaks for eg the case where version is set to something like 1.0.10-SNAPSHOT where it expects 1.0.10.SNAPSHOT and the following exception would occur:\r\n{{org.apache.jackrabbit.oak.plugins.document.DocumentDiscoveryLiteService hasBacklog: couldn't parse version 1.0.10-SNAPSHOT : java.lang.IllegalArgumentException: invalid version \"1.0.10-SNAPSHOT\": non-numeric \"10-SNAPSHOT\"}}\r\n\r\nThe silencing should be fixed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentDiscoveryLiteService hasBacklog silencing must support maven version format"
   },
   {
      "_id": "13222202",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334700",
            "id": "12334700",
            "name": "search"
         }
      ],
      "created": "2019-03-18 03:14:28",
      "description": "In cases where search hit count is less than sample size defined for statistical mode for facets, secure mode should be used so that the counts are accurate for non-admin users.\r\n\r\n\u00a0\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_6",
         "candidate_oak_1_8",
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "facets: use secure mode when search hit count low"
   },
   {
      "_id": "13222184",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2019-03-17 23:50:13",
      "description": "Product index definitions are delivered using {{RepositoryInitializer}} (e.g. AEM and oak itself).\r\nOak run has tooling to dump index definitions as a json and also ability to create lucene indexes as defined by an index definition json.\r\n\r\nThat leaves a gap in tooling where we can dump current set of index definitions and prepare an index definition description to prepare of upgrades (thus saving time \"during\" upgrade). This step is currently done manually and hence is error prone. It'd be nice to have some automated tooling to assist in such a flow.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak run tooling to run a RepositoryInitializer on top a list index definitions"
   },
   {
      "_id": "13221854",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2019-03-15 09:29:47",
      "description": "\u00a0In cases an index is re-indexed, but indexing is stopped in between, the index copier mbean shows the partially created new index stats even though old indexes are still in use.\r\n\r\n1. Reindex by setting reindex= true\r\n\r\n2. stop reindexing using from jmx console (indexstats) as follows:\r\n * <host>:<port>/system/console/jmx\r\n * click on index's \"index stats\" whose reindexing is triggered.\r\n * call abortAndPause operation.\u00a0\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Index Copier Stats MBean shows stale info"
   },
   {
      "_id": "13221696",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333543",
            "id": "12333543",
            "name": "security-spi",
            "description": "Oak Security SPI"
         }
      ],
      "created": "2019-03-14 15:11:13",
      "description": "Followup of OAK-7994, there's another improvement I would like to add: the option to run a full text search instead the current {{jcr:like}} on the {{rep:principalName}} property.\r\nAs far as the apis go, this will be reflected in a new flag to be passed to the method: {{fullText}}, it would be a best-effort attempts, as for some of the existing impls this doesn't make sense (like the {{ExternalGroupPrincipalProvider}}).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "principal-management-extensions"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Principal Management APIs full text search support"
   },
   {
      "_id": "13221146",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2019-03-12 14:42:43",
      "description": "The {{PrincipalProviderImpl}} related changes for OAK-7994.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "principal-management-extensions"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "PrincipalProviderImpl support for range search"
   },
   {
      "_id": "13220126",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333864",
            "id": "12333864",
            "name": "oak-search"
         }
      ],
      "created": "2019-03-07 08:38:50",
      "description": "We want to expose Text extraction stats as sling metrics (time metrics).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose text extraction metrics as sling metrics"
   },
   {
      "_id": "13220021",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334700",
            "id": "12334700",
            "name": "search"
         }
      ],
      "created": "2019-03-06 20:29:39",
      "description": "{{IndexDefinitionBuilder}} currently sets reindex flag while building an index definition if there is a difference in existing def v/s what it builds.\r\n\r\nThe only place it acts smarter is while setting up nrt or sync flag. There are quite a few properties which only affect querying or cost-estimation and don't imply a change in indexed data. For such cases, simply setting {{refresh=true}} should suffice.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "indexingPatch",
         "nitin"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "IndexDefinitionBuilder should be smarter when to reindex while updating a definition"
   },
   {
      "_id": "13218575",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2019-02-28 09:13:13",
      "description": "If the standby client issues a request for a\u00a0binary ID larger than 8192 bytes, it will fail on the server side due to the current frame limitation, set to 8192 bytes:\r\n{noformat}\r\n28.02.2019 00:01:36.034 *WARN* [primary-32] org.apache.jackrabbit.oak.segment.standby.server.ExceptionHandler Exception caught on the server\r\nio.netty.handler.codec.TooLongFrameException: frame length (35029) exceeds the allowed maximum (8192)\r\n        at io.netty.handler.codec.LineBasedFrameDecoder.fail(LineBasedFrameDecoder.java:146) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.LineBasedFrameDecoder.fail(LineBasedFrameDecoder.java:142) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.LineBasedFrameDecoder.decode(LineBasedFrameDecoder.java:131) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.LineBasedFrameDecoder.decode(LineBasedFrameDecoder.java:75) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1342) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:934) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at java.base/java.lang.Thread.run(Thread.java:834)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "The cold standby server cannot handle blob requests for long blob IDs"
   },
   {
      "_id": "13218375",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-02-27 15:18:35",
      "description": "The problem is that {{dispose()}} let's the {{BackgroundLeaseUpdateThread}} run once.\r\n\r\nIf the duration of the remaining operations then exceeds the lease update interval, these operations will fail with a {{DocumentStoreException}}.\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore dispose can fail when duration of final background ops exceeds lease time"
   },
   {
      "_id": "13218371",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-02-27 15:12:39",
      "description": "The background update stats does not have timing information for refreshing the head revision.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add refresh head revision time to background update stats"
   },
   {
      "_id": "13218345",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         }
      ],
      "created": "2019-02-27 13:40:42",
      "description": "...due to a Java 11 incompatibility:\r\n\r\n{noformat}\r\n     [java] The following errors occurred during analysis:\r\n     [java]   Error scanning java/lang/Throwable for referenced classes\r\n     [java]     java.lang.UnsupportedOperationException\r\n     [java]       At org.objectweb.asm.ClassVisitor.visitNestMemberExperimental(ClassVisitor.java:248)\r\n     [java]       At org.objectweb.asm.ClassReader.accept(ClassReader.java:651)\r\n     [java]       At edu.umd.cs.findbugs.asm.FBClassReader.accept(FBClassReader.java:44)\r\n     [java]       At org.objectweb.asm.ClassReader.accept(ClassReader.java:391)\r\n     [java]       At edu.umd.cs.findbugs.classfile.engine.ClassParserUsingASM.parse(ClassParserUsingASM.java:519)\r\n     [java]       At edu.umd.cs.findbugs.classfile.engine.ClassParserUsingASM.parse(ClassParserUsingASM.java:703)\r\n     [java]       At edu.umd.cs.findbugs.classfile.engine.ClassInfoAnalysisEngine.analyze(ClassInfoAnalysisEngine.java:79)\r\n     [java]       At edu.umd.cs.findbugs.classfile.engine.ClassInfoAnalysisEngine.analyze(ClassInfoAnalysisEngine.java:38)\r\n     [java]       At edu.umd.cs.findbugs.classfile.impl.AnalysisCache.getClassAnalysis(AnalysisCache.java:262)\r\n     [java]       At edu.umd.cs.findbugs.FindBugs2.buildReferencedClassSet(FindBugs2.java:774)\r\n     [java]       At edu.umd.cs.findbugs.FindBugs2.execute(FindBugs2.java:220)\r\n     [java]       At edu.umd.cs.findbugs.FindBugs.runMain(FindBugs.java:401)\r\n     [java]       At edu.umd.cs.findbugs.FindBugs2.main(FindBugs2.java:1185)\r\n\r\n{noformat}\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "jdk11"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Upgrade spotbugs to 3.1.11"
   },
   {
      "_id": "13217859",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2019-02-25 15:27:36",
      "description": "The {{UserPrincipalProvider}} related changes for OAK-7994.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "principal-management-extensions"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "UserPrincipalProvider support for range search"
   },
   {
      "_id": "13217162",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-02-21 10:56:42",
      "description": "In a first step towards resolving OAK-8066, I want to add some logging regarding the number of transiently modified direct child nodes in {{DefaultSegmentWriter}} ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Log warning for too many transient modifications of direct child nodes"
   },
   {
      "_id": "13217128",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-02-21 08:35:49",
      "description": "{{DefaultSegmentWriter}} keeps a map of\u00a0[child nodes|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/DefaultSegmentWriter.java#L805] of a node being written. This can lead to high memory consumption in the case where many child nodes are added at the same time. The latter could happen in the case where a node needs to be rewritten because of an increase in the GC generation from a concurrently completed revision garbage collection.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Nodes with many direct children can lead to OOME when saving"
   },
   {
      "_id": "13216958",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2019-02-20 15:20:23",
      "description": "The logic from {{StandbyClientSyncExecution#copySegmentHierarchyFromPrimary}} has a flaw when it comes to \"backward references\". Suppose we have the following data segment graph to be transferred from primary: S1, which references \\{S2, S3} and S3 which references S2. Then, the correct transfer order should be S2, S3 and S1.\r\n\r\nGoing through the current logic employed by the method, here's what happens:\r\n{noformat}\r\nStep 0: batch={S1}\r\n\r\nStep 1: visited={S1}, data={S1}, batch={S2, S3}, queued={S2, S3}\r\n\r\nStep 2: visited={S1, S2}, data={S2, S1}, batch={S3}, queued={S2, S3}\r\n\r\nStep 3: visited={S1, S2, S3}, data={S3, S2, S1}, batch={}, queued={S2, S3}.{noformat}\r\nTherefore, at the end of the loop, the order of the segments to be transferred will be S3, S2, S1, which\u00a0might trigger a {{SegmentNotFoundException}} when S3 is further processed, because S2 is missing on standby (see OAK-8006).\r\n\r\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "The cold standby client doesn't correctly handle backward references"
   },
   {
      "_id": "13215267",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2019-02-12 15:00:49",
      "description": "while writing tests for OAK-8000 i noticed that {{AccessControlManagerImpl.getEffectivePolicies}} may return empty access control lists. this doesn't seem valuable to me as they have no real effect. since i am indecided about OAK-8000 i would suggest to fix that separately.\r\n\r\n[~stillalex], fyi",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "AccessControlManagerImpl.getEffectivePolicies returns empty ACLs"
   },
   {
      "_id": "13214937",
      "assignee": "mduerig",
      "components": [],
      "created": "2019-02-11 08:11:35",
      "description": "{{CompactionAndCleanupIT.testMixedSegments}} fails every 50-th build or so:\r\n{code:java}\r\n[ERROR] testMixedSegments(org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT)  Time elapsed: 1.064 s  <<< FAILURE!\r\njava.lang.AssertionError: Mixed segments found: 7395f14c-15dd-4224-ad53-ec981f46f5cd\r\n\tat org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT.testMixedSegments(CompactionAndCleanupIT.java:701)\r\n{code}\r\n\u00a0\r\n\r\nThis might have the same root cause as OAK-8033. But no causality found yet.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Intermittent test failure of CompactionAndCleanupIT.testMixedSegments"
   },
   {
      "_id": "13214560",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2019-02-08 09:17:28",
      "description": "Steps to reproduce -\r\n # You would need two index definitions of same query index type , let's say fullText index , having similar cost evaluations.\r\n # Now while the index plan is evaluated you will notice that there should have been a debug log saying that selected index has similar cost - this serves as an important warning to either change the index definitions or the query ([https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/query/QueryImpl.java#L1069#L1072)]\r\n\r\n\u00a0\r\n\r\nHowever If we have a look at this code block here - [https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/query/QueryImpl.java#L1017#L1041]\u00a0, there is no comparison for near best costs for index plans having same query index type .\r\n\r\n\u00a0\r\n\r\ncc : [~teofili]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "indexingPatch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Debug logging when two or more indices have same or very close cost amounts doesn't work in case both indices belong to the same type of Query Index"
   },
   {
      "_id": "13214414",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-02-07 16:09:53",
      "description": "Due to a regression introduced with OAK-7867 a full compaction can sometimes cause nodes that are written concurrently to reference segments from more than a single gc generation.\r\n\r\nThis happens when the {{borrowWriter}} method needs to [create a new writer|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentBufferWriterPool.java#L197-L201]. In this case the new writer will be of the generation of the current head state instead of the generation associated with the current write operation in progress.\r\n\r\n\u00a0\r\n\r\ncc [~frm], [~ahanikel]\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Node states sometimes refer to more than a single generation of segments after a full compaction"
   },
   {
      "_id": "13213866",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2019-02-05 10:41:17",
      "description": "[~stillalex], it seems that editing access control by principal in the default implementation doesn't allow for applying entries to the 'null' path.\r\n\r\ninitially i thought that we can use an empty string value instead for the {{rep:nodePath}}, but that doesn't work as it gets converted to \".\" for some reason. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "AccessControlManagerImpl can not handle repository level when editing policies by principal"
   },
   {
      "_id": "13212224",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2019-01-28 12:24:15",
      "description": "When persisting a segment transferred from master, among others, the cold standby needs to read the binary references from the segment. While this usually doesn't involve any additional reads from any other segments,\u00a0there is a special case concerning binary IDs larger than 4092 bytes. These can live in other segments (which got transferred prior to the current segment and are already on the standby), but it might also be the case that the binary ID is stored in the same segment.\u00a0If this happens, the call to\u00a0{{blobId.getSegment()}}[0],\u00a0triggers a new read of the current, un-persisted segment\u00a0. Thus, a {{SegmentNotFoundException}} is thrown:\r\n{noformat}\r\n22.01.2019 09:35:59.345 *ERROR* [standby-run-1] org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSync Failed synchronizing state.\r\norg.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment d40a9da6-06a2-4dc0-ab91-5554a33c02b0 not found\r\n        at org.apache.jackrabbit.oak.segment.file.AbstractFileStore.readSegmentUncached(AbstractFileStore.java:284) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.lambda$readSegment$10(FileStore.java:498) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.SegmentCache$NonEmptyCache.lambda$getSegment$0(SegmentCache.java:163) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache.get(LocalCache.java:3932) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at org.apache.jackrabbit.oak.segment.SegmentCache$NonEmptyCache.getSegment(SegmentCache.java:160) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:498) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:153) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.RecordId.getSegment(RecordId.java:98) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.SegmentBlob.readLongBlobId(SegmentBlob.java:206) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.SegmentBlob.readBlobId(SegmentBlob.java:163) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.AbstractFileStore$3.consume(AbstractFileStore.java:262) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.Segment.forEachRecord(Segment.java:601) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.AbstractFileStore.readBinaryReferences(AbstractFileStore.java:257) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.writeSegment(FileStore.java:533) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSyncExecution.copySegmentFromPrimary(StandbyClientSyncExecution.java:225) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSyncExecution.copySegmentHierarchyFromPrimary(StandbyClientSyncExecution.java:194) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSyncExecution.compareAgainstBaseState(StandbyClientSyncExecution.java:101) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSyncExecution.execute(StandbyClientSyncExecution.java:76) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSync.run(StandbyClientSync.java:165) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:347) [org.apache.sling.commons.scheduler:2.7.2]\r\n        at org.quartz.core.JobRunShell.run(JobRunShell.java:202) [org.apache.sling.commons.scheduler:2.7.2]\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n        at java.base/java.lang.Thread.run(Thread.java:834){noformat}\r\n\u00a0\r\n\r\n[0]\u00a0https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentBlob.java#L205",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentBlob#readLongBlobId might cause SegmentNotFoundException on standby"
   },
   {
      "_id": "13210334",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333543",
            "id": "12333543",
            "name": "security-spi",
            "description": "Oak Security SPI"
         }
      ],
      "created": "2019-01-18 09:02:45",
      "description": "Current apis are limited to passing a search token, I'd like to also add range (offset, limit).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "principal-management-extensions"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Principal Management APIs don't allow for search pagination"
   },
   {
      "_id": "13208546",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         }
      ],
      "created": "2019-01-09 13:36:03",
      "description": "The transfer of segments between different persistence types when using {{oak-run segment-copy}} can be\u00a0sped up by employing multiple threads in the transfer. The idea is to try to load {{n}} segments from the source, which are then consumed by the writer on the target, keeping the ordering of the segments in the process.\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add multi-threaded segment transfer to oak-run segment-copy"
   },
   {
      "_id": "13200222",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332467",
            "id": "12332467",
            "name": "composite",
            "description": "Oak Composite Node Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2018-11-23 10:34:07",
      "description": "OAK-7910 resolves the immediate problem, now it should be possible to creating a new Lucene index and reindex.\r\n\r\nHowever, there is no test case, and the general approach to resolve the issue is questionable.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "indexingPatch",
         "tech-debt",
         "tech-debt-test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Composite node store: technical debt for create index / reindex"
   },
   {
      "_id": "13193775",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332917",
            "id": "12332917",
            "name": "blob-cloud"
         }
      ],
      "created": "2018-10-24 07:36:20",
      "description": "Fixed a major bug in the S3 bucket iterator.\r\n\r\nWhen the returned queue of records is empty due to the fact that we get a full page of records starting with the META/ key, the iterator stops while there is still data available in the bucket.\r\n\r\nThis causes problems\u00a0with datastore GC, and datastore consistency checks (both online and offline), and possibly even more.\r\n\r\nA little explainer. But based on a batch size of 2 instead of 1000.\r\n\r\nSuppose your list of S3 keys looks as follows:\r\n * 1\r\n * 2\r\n * 3\r\n * 4\r\n * META/1\r\n * META/2\r\n * 5\r\n * 6\r\n\r\nloadBatch would first load [1, 2], filter out no META/ keys and pass [1, 2] to the caller.\r\nNext time, loadBatch would load [3, 4], filter out no META/ keys and pass [3, 4] to the caller.\r\nThan, loadBatch would load [META/1, META/2], filter out the META/ keys and pass [] to the caller.\r\n\r\nWhen that happens, traversing the bucket would stop, because the returned list is empty, even if there are many more batches to load.\r\n\r\nThe fix\u00a0checks\u00a0if the returned list is empty\u00a0and there are more batches available, it would load (a) new batch(es) until there is data in the batch or there is no more batch available.\r\n\r\nWe are currently running Oak 1.6.6 on AEM 6.3.1.2, but as the bug is still in trunk, all previous versions of Oak are affected as well.\r\n\r\nI provided 2 pull requests: one for trunk ([https://github.com/apache/jackrabbit-oak/pull/103)]\u00a0and one for the 1.6 branch ([https://github.com/apache/jackrabbit-oak/pull/104).]\r\n\r\nCI failed on [https://github.com/apache/jackrabbit-oak/pull/103,]\u00a0but I don't think it's related to my changes.\r\n\r\nFor the record, the patch works as I was able to successfully test this on our production repository using oak-run --id. With version 1.6.6 it reported 800k items, with my patched version, it reported 1.8m items. (As our META/ nodes are\u00a0listed somewhere half-way through.)\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "newbie",
         "pull-request-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "S3 Bucket iterator stops too early"
   },
   {
      "_id": "13193763",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332917",
            "id": "12332917",
            "name": "blob-cloud"
         }
      ],
      "created": "2018-10-24 05:52:40",
      "description": "S3#getAllIdentifiers can trim the listing once the whole batch contains only the metadata entries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "S3#getAllIdentifiers may trim listing when filtering out metadata objects"
   },
   {
      "_id": "13190670",
      "assignee": "mattvryan",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333300",
            "id": "12333300",
            "name": "blob-cloud-azure"
         }
      ],
      "created": "2018-10-10 15:44:36",
      "description": "In {{AzureBlobStoreBackend#completeHttpUpload()}}, the code catches {{StorageException}} and {{URISyntaxException}} as thrown by the Azure SDK, but this exception is not chained in the {{DataStoreException}} that is thrown if those exceptions are caught, which makes it more difficult to diagnose the real issue behind the {{DataStoreException}}.\r\n\r\nThis was just a simple oversight in the original implementation.\u00a0 We should also examine the other code related to direct binary access, both in the Azure and S3 implementations, to see if there are any other similar bugs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "easyfix"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "[DirectBinaryAccess] AzureDataStore not chaining exceptions on upload completion"
   },
   {
      "_id": "13186010",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         }
      ],
      "created": "2018-09-19 09:43:39",
      "description": "Note: requires Java 8, so can't be done for branches before Oak 1.8.\r\n\r\nCVEs: CVE-2018-8017, CVE-2018-11761, CVE-2018-11762",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "requires-java8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update tika dependency to 1.19"
   },
   {
      "_id": "13185131",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-09-14 12:25:29",
      "description": "We are getting the following deadlock. Please help! (Production environment)\r\n\r\nI have already annotated possible locks and synchronized blocks in between:\r\n\r\n{noformat}\r\n\"TarMK flush [/opt/condat/epet9/sling/repository/segmentstore]\":\r\n\u00a0 waiting to lock Monitor@0x00007fedfc00cc28 (Object@0x00000004795519a8, a org/apache/jackrabbit/oak/segment/SegmentId),\r\n\u00a0 which is held by \"oak-lucene-14\"\r\n\"oak-lucene-14\":\r\n\u00a0waiting for ownable synchronizer 0x00000003c13818c0, (a java/util/concurrent/locks/ReentrantReadWriteLock$NonfairSync),\r\n\u00a0which is held by \"TarMK flush [/opt/condat/epet9/sling/repository/segmentstore]\"\r\n\r\nThread 28883: (state = BLOCKED)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentId.getSegment() @bci=12, line=121 (Compiled frame)\r\n\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0synchronized (this) \r\n\u00a0- org.apache.jackrabbit.oak.segment.Record.getSegment() @bci=4, line=70 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.BlockRecord.read(int, byte[], int, int) @bci=49, line=57 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentStream.read(byte[], int, int) @bci=314, line=189 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.read(java.io.InputStream, byte[], int, int) @bci=43, line=828 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.readFully(java.io.InputStream, byte[], int, int) @bci=4, line=695 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.readFully(java.io.InputStream, byte[]) @bci=5, line=676 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentStream.getString() @bci=93, line=103 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.Segment.readString(int) @bci=189, line=524 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBlob.readLongBlobId(org.apache.jackrabbit.oak.segment.Segment, int) @bci=15, line=212 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBlob.readBlobId(org.apache.jackrabbit.oak.segment.Segment, int) @bci=37, line=167 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.AbstractFileStore$4.consume(int, org.apache.jackrabbit.oak.segment.RecordType, int) @bci=24, line=354 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.Segment.forEachRecord(org.apache.jackrabbit.oak.segment.Segment$RecordConsumer) @bci=48, line=716 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.AbstractFileStore.populateTarBinaryReferences(org.apache.jackrabbit.oak.segment.Segment, org.apache.jackrabbit.oak.segment.file.TarWriter) @bci=25, line=349 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore.writeSegment(org.apache.jackrabbit.oak.segment.SegmentId, byte[], int, int) @bci=136, line=657 (Compiled frame)\r\n\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0fileStoreLock.writeLock().lock(); Zeile 639\r\n\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0bis: populateTarBinaryReferences\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBufferWriter.flush() @bci=383, line=383 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBufferWriterPool.flush() @bci=165, line=148 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentWriter.flush() @bci=4, line=143 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$7.call() @bci=7, line=373 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$7.call() @bci=1, line=370 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.TarRevisions.doFlush(java.util.concurrent.Callable) @bci=25, line=224 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.TarRevisions.flush(java.util.concurrent.Callable) @bci=42, line=212 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore.flush() @bci=20, line=370 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$2.run() @bci=15, line=233 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.SafeRunnable.run() @bci=21, line=67 (Compiled frame)\r\n\u00a0- java.util.concurrent.Executors$RunnableAdapter.call() @bci=4, line=511 (Compiled frame)\r\n\u00a0- java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308 (Compiled frame)\r\n\u00a0- java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask) @bci=1, line=180 (Compiled frame)\r\n\u00a0- java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run() @bci=37, line=294 (Compiled frame)\r\n\u00a0- java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1142 (Compiled frame)\r\n\u00a0- java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=617 (Interpreted frame)\r\n\u00a0- java.lang.Thread.run() @bci=11, line=748 (Interpreted frame)\r\n\r\nLocked ownable synchronizers:\r\n\u00a0\u00a0\u00a0 - <0x00000003c1361228>, (a java/util/concurrent/locks/ReentrantLock$NonfairSync)\r\n\u00a0\u00a0\u00a0 - <0x00000003c13818c0>, (a java/util/concurrent/locks/ReentrantReadWriteLock$NonfairSync)\r\n\u00a0\u00a0\u00a0 - <0x00000003c1c3a0d8>, (a java/util/concurrent/ThreadPoolExecutor$Worker)\r\n\r\nThread 31035: (state = BLOCKED)\r\n\u00a0- sun.misc.Unsafe.park(boolean, long) @bci=0 (Compiled frame; information may be imprecise)\r\n\u00a0- java.util.concurrent.locks.LockSupport.park(java.lang.Object) @bci=14, line=175 (Compiled frame)\r\n\u00a0- java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt() @bci=1, line=836 (Compiled frame)\r\n\u00a0- java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(int) @bci=83, line=967 (Interpreted frame)\r\n\u00a0- java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(int) @bci=10, line=1283 (Compiled frame)\r\n\u00a0- java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock() @bci=5, line=727 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$8.call() @bci=158, line=567 (Compiled frame)\r\n\u00a0\u00a0 \u00a0fileStoreLock.readLock().lock();\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$8.call() @bci=1, line=542 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentCache.getSegment(org.apache.jackrabbit.oak.segment.SegmentId, java.util.concurrent.Callable) @bci=1, line=95 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(org.apache.jackrabbit.oak.segment.SegmentId) @bci=14, line=542 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentId.getSegment() @bci=38, line=125 (Compiled frame)\r\n\u00a0\u00a0 \u00a0synchronized (this) \r\n\u00a0- org.apache.jackrabbit.oak.segment.Record.getSegment() @bci=4, line=70 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.BlockRecord.read(int, byte[], int, int) @bci=49, line=57 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentStream.read(byte[], int, int) @bci=314, line=189 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.read(java.io.InputStream, byte[], int, int) @bci=64, line=833 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.readFully(java.io.InputStream, byte[], int, int) @bci=4, line=695 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.readFully(java.io.InputStream, byte[]) @bci=5, line=676 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentStream.getString() @bci=93, line=103 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.Segment.readString(int) @bci=189, line=524 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBlob.readLongBlobId(org.apache.jackrabbit.oak.segment.Segment, int) @bci=15, line=212 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBlob.length() @bci=124, line=115 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexFile.<init>(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeBuilder, java.lang.String, org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$BlobFactory) @bci=204, line=409 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.<init>(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeBuilder, java.lang.String, org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$BlobFactory) @bci=25, line=589 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory.fileLength(java.lang.String) @bci=64, line=176 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.directory.CopyOnReadDirectory.copyFilesToLocal(org.apache.jackrabbit.oak.plugins.index.lucene.directory.CopyOnReadDirectory$CORFileReference, boolean, boolean) @bci=195, line=214 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.directory.CopyOnReadDirectory.prefetchIndexFiles() @bci=96, line=170 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.directory.CopyOnReadDirectory.<init>(org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier, org.apache.lucene.store.Directory, org.apache.lucene.store.Directory, boolean, java.lang.String, java.util.concurrent.Executor) @bci=85, line=81 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier.wrapForRead(java.lang.String, org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition, org.apache.lucene.store.Directory, java.lang.String) @bci=35, line=122 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.reader.DefaultIndexReaderFactory.createReader(org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition, org.apache.jackrabbit.oak.spi.state.NodeState, java.lang.String, java.lang.String, java.lang.String) @bci=61, line=102 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.reader.DefaultIndexReaderFactory.createReaders(org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition, org.apache.jackrabbit.oak.spi.state.NodeState, java.lang.String) @bci=20, line=61 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexNode.open(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.plugins.index.lucene.reader.LuceneIndexReaderFactory, org.apache.jackrabbit.oak.plugins.index.lucene.hybrid.NRTIndexFactory) @bci=17, line=68 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker$1.leave(org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState) @bci=30, line=132 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeChanged(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState) @bci=66, line=153 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.MapRecord.compare(org.apache.jackrabbit.oak.segment.MapRecord, org.apache.jackrabbit.oak.spi.state.NodeStateDiff) @bci=197, line=415 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentNodeState.compareAgainstBaseState(org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeStateDiff) @bci=909, line=608 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeChanged(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState) @bci=43, line=148 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.MapRecord.compare(org.apache.jackrabbit.oak.segment.MapRecord, org.apache.jackrabbit.oak.spi.state.NodeStateDiff) @bci=400, line=457 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentNodeState.compareAgainstBaseState(org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeStateDiff) @bci=909, line=608 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(org.apache.jackrabbit.oak.spi.commit.Editor, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState) @bci=34, line=52 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker.diffAndUpdate(org.apache.jackrabbit.oak.spi.state.NodeState) @bci=140, line=142 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker.update(org.apache.jackrabbit.oak.spi.state.NodeState) @bci=36, line=113 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1$1.call() @bci=79, line=135 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1$1.call() @bci=1, line=128 (Compiled frame)\r\n\u00a0- java.util.concurrent.FutureTask.run() @bci=42, line=266 (Compiled frame)\r\n\u00a0- java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1142 (Compiled frame)\r\n\u00a0- java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=617 (Compiled frame)\r\n\u00a0- java.lang.Thread.run() @bci=11, line=748 (Compiled frame)\r\n\r\nLocked ownable synchronizers:\r\n\u00a0\u00a0\u00a0 - <0x0000000476194f30>, (a java/util/concurrent/ThreadPoolExecutor$Worker)\u00a0\u00a0\u00a0\r\n\r\n{noformat}\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "deadlock"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "deadlock TarMK flush, lucene"
   },
   {
      "_id": "13184064",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-09-10 14:12:44",
      "description": "It's not entirely clear to me what behavior we expect if:\r\n\u00a0\r\n * node 1 creates a document\r\n * node 2 deletes it\r\n * node 1 tries to update it\r\n\r\n(and, related to that, whether the behavior really matters in practice)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clarify update semantics on deleted nodes"
   },
   {
      "_id": "13182799",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2018-09-04 12:13:05",
      "description": "XPath union queries that contain \"order by @jcr:score descending\" actually do order by jcr:score, which is unexpected.\r\n\r\nThis is a bit related to OAK-7131.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "indexingPatch",
         "mohit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Order by jcr:score descending is not always ignored"
   },
   {
      "_id": "13181865",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-08-29 10:12:04",
      "description": "Callers of the {{check}} command can specify an alternative journal with the {{\\-\\-journal}} option. This option instructs the {{ConsistencyChecker}} to check the revisions stored in that file instead of the ones stored in the default {{journal.log}}.\r\n\r\nI spotted at least two problems while using {{\\-\\-journal}} on a repository with a corrupted {{journal.log}} that didn't contain any valid revision.\r\n\r\nFirst, the path to the {{FileStore}} is validated by {{FileStoreHelper#isValidFileStoreOrFail}}, which checks for the existence of a {{journal.log}} in the specified folder. But if a {{journal.log}} doesn't exist and the user specified a different journal on the command line this check should be ignored.\r\n\r\nSecond, when opening the {{FileStore}} the default {{journal.log}} is scanned to determine the initial revision of the head state. If a user specifies an alternative journal on the command line, that journal should be used instead of the default {{journal.log}}. It might be that the default journal contains no valid revision, which would force the system to crash when opening a new instance of {{FileStore}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CheckCommand should consistently use an alternative journal if specified"
   },
   {
      "_id": "13181405",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2018-08-27 16:38:04",
      "description": "In the opening paragraph of the documentation on Direct Binary Access, reference is made to S3DataStore and AzureDataStore as blob stores that support this feature, but is is not clear whether they are mentioned as examples or as an exhaustive list of supporting blob stores.  It is only on further examination of the documentation that you are able to determine that the list was specific and not as examples.\r\nWe should change the documentation so it is more clear up front which blob stores support the feature.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Documentation for direct binary access is unclear"
   },
   {
      "_id": "13180468",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2018-08-22 13:09:41",
      "description": "Some SecurityProviderRegistrationTest.testRequiredUserAuthenticationFactoryNotAvailable() fails every now and then. The last occurrence on travis-ci was here: https://travis-ci.org/apache/jackrabbit-oak/jobs/414016611 but I've also seen the same test fail on other infrastructure.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "continuous_integration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failure: SecurityProviderRegistrationTest.testRequiredUserAuthenticationFactoryNotAvailable()"
   },
   {
      "_id": "13179095",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-08-15 14:05:52",
      "description": "We have seen instances were offline compaction did not clean up all reclaimable tar files on the first run but would reclaim them on subsequent runs. Apparently this is caused by OAK-6648, which fixes an issue where the file reaper is invoked without a prior call to {{System.gc}} reclaiming potential references.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Backport OAK-6648 to Oak 1.6"
   },
   {
      "_id": "13177340",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333543",
            "id": "12333543",
            "name": "security-spi",
            "description": "Oak Security SPI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332557",
            "id": "12332557",
            "name": "store-spi",
            "description": "Oak NodeStore and Commit SPI"
         }
      ],
      "created": "2018-08-07 09:08:37",
      "description": "The ValueFactoryImpl has a few static methods that are used to create a {{Value}} from a {{PropertyState}} or {{PropertyValue}}. Those methods should be refactored to make it easier to  add a {{BlobAccessProvider}} for OAK-7569.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Replace usage of static ValueFactoryImpl methods"
   },
   {
      "_id": "13177087",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2018-08-06 12:01:27",
      "description": "Unfortunately, mocking varargs seems to work different in current mockito versions. With the 2:* default from the parent pom, I'm getting the test failure below:\r\n{noformat}\r\n[ERROR] Tests run: 12, Failures: 8, Errors: 0, Skipped: 0, Time elapsed: 0.828 s <<< FAILURE! - in org.apache.jackrabbit.oak.commons.PerfLoggerTest\r\n[ERROR] logAtDebugMessageStartWithInfoLog(org.apache.jackrabbit.oak.commons.PerfLoggerTest)  Time elapsed: 0.045 s  <<< FAILURE!\r\norg.mockito.exceptions.verification.junit.ArgumentsAreDifferent:\r\n\r\nArgument(s) are different! Wanted:\r\nlogger.debug(\r\n    <any string>,\r\n    <any java.lang.Object[]>\r\n);\r\n-> at org.apache.jackrabbit.oak.commons.PerfLoggerTest.verifyDebugInteractions(PerfLoggerTest.java:227)\r\nActual invocation has different arguments:\r\nlogger.debug(\r\n    \"message [took 0ms]\",\r\n    \"argument\"\r\n);\r\n-> at org.apache.jackrabbit.oak.commons.PerfLogger.end(PerfLogger.java:223)\r\n\r\n        at org.apache.jackrabbit.oak.commons.PerfLoggerTest.verifyDebugInteractions(PerfLoggerTest.java:227)\r\n        at org.apache.jackrabbit.oak.commons.PerfLoggerTest.logAtDebugMessageStartWithInfoLog(PerfLoggerTest.java:144)\r\n\r\n\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-commons: upgrade to project default mockito version"
   },
   {
      "_id": "13176090",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-08-01 11:34:04",
      "description": "Often there's the need to transform a type of {{SegmentStore}} (e.g. local TarMK) into *the exact same* counter-part, using another persistence type (e.g. Azure Segment Store). While {{oak-upgrade}} partially solves this through sidegrades (see OAK-7623), there's a gap in the final content because of the level at which {{oak-upgrade}} operates (node store level). Therefore, the resulting sidegraded repository doesn't contain all the (possibly stale, unreferenced) data from the original repository, but only the latest head state. A side effect of this is that the resulting repository is always compacted.\r\n\r\nIntroducing a new command in {{oak-run}}, namely {{segment-copy}}, would allow us to operate at a lower level (i.e. segment persistence), dealing only with constructs from {{org.apache.jackrabbit.oak.segment.spi.persistence}}: journal file, gc journal file, archives and archive entries. This way the only focus of this process would be to \"translate\" a segment between two persistence formats, without caring about the node logic stored inside (referenced/unreferenced node/property).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Introduce oak-run segment-copy for moving around segments in different storages"
   },
   {
      "_id": "13174984",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-07-26 20:31:35",
      "description": "{{AzureCompact}} in {{oak-segment-azure}} follows closely the structure and logic of {{Compact}} in {{oak-segment-tar}}. Since the only thing which differs is the underlying persistence used (remote in Azure vs. local in TAR files), the common logic should be extracted in a super-class, extended by both. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tech-debt",
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor AzureCompact and Compact"
   },
   {
      "_id": "13173120",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2018-07-19 07:26:21",
      "description": "OAK-3865 introduced a strategy to optimize reads from secondaries. This has been superseded by OAK-6087. This task is about removing the old strategy.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove strategy to optimize secondary reads"
   },
   {
      "_id": "13172835",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-07-18 06:05:59",
      "description": "With the changes from OAK-6770 applied, it seems that {{repository.home}} attribute is not correctly set, causing the repository to be written one level up in the directory hierarchy from where it was supposed to.\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Revert changes done by OAK-6770"
   },
   {
      "_id": "13172638",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         }
      ],
      "created": "2018-07-17 12:32:27",
      "description": "- org.apache.jackrabbit.oak.spi.cluster\r\n- org.apache.jackrabbit.oak.namepath.impl\r\n- org.apache.jackrabbit.oak.plugins.index.property.strategy\r\n- org.apache.jackrabbit.oak.plugins.migration.report",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "various internal APIs missing in package export filter"
   },
   {
      "_id": "13172627",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-07-17 11:49:32",
      "description": "This is similar to OAK-3883, but must prevent commits with revisions that are older than already present in the repository. At runtime, this is already taken care of with static fields in the Revision class, but on startup the clock may have jumped into the past since Oak was stopped.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Prevent commits in the past"
   },
   {
      "_id": "13172315",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-07-16 06:43:34",
      "description": "{{oak-run check}}\u00a0should accept Azure URIs for the segment store in order to\u00a0be able to check for data integrity. This will come handy in the light of remote compacted segment stores and/or sidegraded remote segment stores (see OAK-7623, OAK-7459).\r\n\r\nThe Azure URI will be taken as argument and will have the following format:\u00a0{{az:[https://myaccount.blob.core.windows.net/container/repo]}}, where\u00a0_az_\u00a0identifies the cloud provider. The last missing piece is the secret key which will be supplied as an environment variable, i.e.\u00a0_AZURE_SECRET_KEY._",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run check should support Azure Segment Store"
   },
   {
      "_id": "13171335",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2018-07-11 08:23:12",
      "description": "Azure support for segment-tar (OAK-6922) allowed us to plug another storage option for the segment store. Since sometimes there's the need to compare how local vs remote storage behaves, a sidegrade from local tar storage to remote azure storage must be implemented.\r\n\r\nThis would allow us to replicate the exact repository content, changing only the underlying storage mechanism. Analogous to OAK-7459, the Azure Segment Store\u00a0connection details\u00a0will be supplied in the following format:\r\n * an URI with the following format:\u00a0{{az:[https://myaccount.blob.core.windows.net/container/repo]}}, where\u00a0_az_\u00a0identifies the cloud provider\r\n * a secret key supplied as an environment variable, i.e.\u00a0_AZURE_SECRET_KEY._",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "azure",
         "migration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeStore - sidegrade support between TarPersistence and AzurePersistence"
   },
   {
      "_id": "13168004",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332555",
            "id": "12332555",
            "name": "blob-plugins",
            "description": "Oak Blob Plugins"
         }
      ],
      "created": "2018-06-25 09:57:51",
      "description": "To ascertain effectiveness of DataStore GC following metrics are quite useful:\r\n* Number of candidates identified\r\n* Number of blobs deleted\r\n* Total estimated size of the blobs deleted",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "maintenance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add stats for DataStore GC performance"
   },
   {
      "_id": "13167314",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332555",
            "id": "12332555",
            "name": "blob-plugins",
            "description": "Oak Blob Plugins"
         }
      ],
      "created": "2018-06-21 05:57:35",
      "description": "Minor renaming of the metrics to mimic what was done for OAK-7555",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "maintenance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Rename metrics for DataStore garbage collection"
   },
   {
      "_id": "13167181",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-06-20 14:43:15",
      "description": "OAK-3976 introduced a force push of of a journal entry during the commit when the accumulated changes reach 100'000 elements.\r\n\r\nCreating the journal entry however may fail with a DocumentStoreException and fail the commit even though all changes, including the one on the commit root, made it to the DocumentStore.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Commit fails when forced journal push throws exception"
   },
   {
      "_id": "13167093",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-06-20 07:36:41",
      "description": "The persistent cache has an async write mode enabled by default and the write queue is maintained by the CacheActionDispatcher. The queue has a fixed size of 16'384 and is not memory bound. It may happen that the queue retains a lot of memory (multiple GB of heap) when the pending write actions reference big cache values and cause OOME.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4",
         "candidate_oak_1_6",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CacheActionDispatcher not memory bound"
   },
   {
      "_id": "13166027",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2018-06-14 07:31:01",
      "description": "MissingLastRevSeekerTest actually does not run on MongoDB right now, but changing the test accordingly revealed an issue with the MongoDB specific implementation of MissingLastRevSeeker when running on a replica-set and secondary preferred read preference.\r\n\r\nThe class MongoMissingLastRevSeeker uses the configured read preference when checking for cluster node info entries that require recovery. This is inconsistent because the candidate nodes are read with primary read preference.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MissingLastRevSeekerTest fails on MongoDB with secondary preferred"
   },
   {
      "_id": "13163397",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332555",
            "id": "12332555",
            "name": "blob-plugins",
            "description": "Oak Blob Plugins"
         }
      ],
      "created": "2018-06-01 10:33:19",
      "description": "Enable collection of simple collection stats related to the DSGC:\r\n* Start counter\r\n* Finish success counter\r\n* Finish failure counter\r\n* Duration timer\r\nThis can later be enhanced to capture other performance metrics as well.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "maintenance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Enable collection of simple operation stats for DataStore garbage collection"
   },
   {
      "_id": "13162018",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2018-05-25 09:10:36",
      "description": "Currently the repository initializers (RepositoryInitializer and WorkspaceInitializer) run when the repo boots without any hooks [0] which means that current RepositoryInitializers need to setup custom Roots (roots with hardcoded editor providers like NamespaceEditorProvider and TypeEditorProvider) on top of the provided builders to be able to setup properly. I'm looking at the InitialContent [1] and the CugConfiguration [2] in the context of installing node types.\r\n\r\nI would like to look into removing the hardcoded providers and trying to run all existing editors over the content produced by the initializers.\r\n\r\nAs an added benefit this will allow decoupling of hard dependencies between components (see for example OAK-7499)\r\n\r\n\r\n\r\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/Oak.java#L687 \r\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/InitialContent.java#L134\r\n[2] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-authorization-cug/src/main/java/org/apache/jackrabbit/oak/spi/security/authorization/cug/impl/CugConfiguration.java#L162\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Run repository initializers with hooks"
   },
   {
      "_id": "13159633",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332556",
            "id": "12332556",
            "name": "core-spi",
            "description": "Oak Core SPI"
         }
      ],
      "created": "2018-05-16 07:30:12",
      "description": "for consistency with other JCR specific constants that have been copied to _oak-core-spi_, we should do the same for {{LockConstants}}. This will help to further reduce the dependency to _oak-core_ across the different modules.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "m12n"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Deprecate org.apache.jackrabbit.oak.plugins.lock.LockConstants in favor of corresponding SPI"
   },
   {
      "_id": "13158259",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2018-05-09 17:52:56",
      "description": "in order to cleanup troublesome dependencies within oak core, the {{VersionablePathHook}} associated with the default authorization model should be co-located with the latter instead of being placed inside _o.a.j.oak.plugins.version_.\r\n\r\n[~stillalex], fyi",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "m12n"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "VersionablePathHook should be located with authorization code"
   },
   {
      "_id": "13156818",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12327522",
            "id": "12327522",
            "name": "authorization-cug",
            "description": "Oak CUG Authorization"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333543",
            "id": "12333543",
            "name": "security-spi",
            "description": "Oak Security SPI"
         }
      ],
      "created": "2018-05-03 09:26:59",
      "description": "With a minor extension to {{TreeProvider}} we would be able to get rid of the direct casting to implementation details like {{ImmutableTree}} and {{AbstractTree}} altogether.\r\n\r\n[~stillalex], patch for review will follow right away.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "m12n"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove Usage of ImmutableTree and AbstractTree in Security Code"
   },
   {
      "_id": "13155694",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-27 12:22:01",
      "description": "{{oak-run compact}}\u00a0should accept Azure URIs for the segment store in order to enable OffRC for Azure Segment Store.\r\n\r\n-Proposed options to add:-\r\n * -{{azure-connection}}: connection URL to to connect to the Azure Storage-\r\n * -{{azure-container}}: name of the container to use-\r\n * -{{azure-root-path}}: segment store directory-\r\n\r\nThe Azure URI will be taken as argument and will have the following format: {{az:[https://myaccount.blob.core.windows.net/container/repo]}}, where *az*\u00a0identifies the cloud provider. The last missing piece is the secret key which will be supplied as an environment variable, i.e. _AZURE_SECRET_KEY._",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run compact should support Azure Segment Store"
   },
   {
      "_id": "13154803",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-24 13:29:05",
      "description": "The IO tracing facility introduced with OAK-5655 should also be available during normal operation. The idea is to log IO reads intercepted via an {{IOMonitor}} instance to a logger. If {{DEBUG}} logging is not enabled for that logger at the time when the {{FileStore}} is instantiated, then no tracing would take place.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "monitoring",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow collection of IOTraces during normal operation"
   },
   {
      "_id": "13154787",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-04-24 12:26:14",
      "description": "The module oak-store-document currently only uses a single utility method from commons-codec. It shouldn't be too difficult to remove this dependency.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove dependency to commons-codec"
   },
   {
      "_id": "13153315",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-18 10:46:59",
      "description": "It would be useful to expose\u00a0{{writerGroups}} in\u00a0{{SegmentNodeStoreStats}} through an OSGi config property. Since this is a low level configuration related to monitoring, it shouldn't be added to {{SegmentNodeStoreService}}, but to a newly created service, {{SegmentNodeStoreMonitorService}} that would handle exposing monitoring related stuff. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Introduce SegmentNodeStoreMonitorService for exposing writerGroups as an OSGi config property"
   },
   {
      "_id": "13152910",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-17 06:53:58",
      "description": "With guidance from [~mduerig], I recently developed a way to expose Segment Node Store's internal information through the NodeState API. \r\n\r\nThe concept is similar in spirit to the proc file system in Linux: the proc subtree exposes internal information in a straightforward manner, enabling consumers to rely on a well-understood API to access the data. This proc subtree shelters tooling from variations of the internal APIs of the Segment Store. As long as the data exported through the proc subtree is stable, the same tools are going to work across different versions of the Segment Store with minimal to no modifications.\r\n\r\nThe proc subtree has been developed in [this branch on GitHub|https://github.com/francescomari/jackrabbit-oak/tree/proc]. I created this issue in order to review the work done so far, and to track the contribution of the proc subtree in Oak.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Contribute a 'proc' subtree for the Segment Node Store"
   },
   {
      "_id": "13151579",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-11 08:05:29",
      "description": "[http://svn.apache.org/viewvc?view=revision&revision=1827841] introduced utility classes to collect IO traces. See e.g. https://issues.apache.org/jira/browse/OAK-5655?focusedCommentId=16415730&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16415730. Currently the only way to run such traces is via code or JUnit (see {{IOTracerRunner}}).\r\n\r\nGoing forward we should wire this functionality to {{oak-run}} to make it more generally useful. \r\n\r\n\u00a0\r\n\r\n[~frm], FYI.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose UI for collecting IO traces"
   },
   {
      "_id": "13151561",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-04-11 06:30:29",
      "description": "In some cases no persisted branch is created by the DocumentNodeStore when the number of changes hit the update limit. This happens when the current branch state is in-memory and the commit hook contributes changes that reach the update limit. The implementation keeps those changes in memory, which may lead to a commit way bigger than specified by the update limit.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Changes kept in memory when update limit is hit in commit hook"
   },
   {
      "_id": "13149438",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-02 08:55:03",
      "description": "The current \"CommitsCountPerWriter\" stats exposed by {{SegmentNodeStoreStats}} are hard to follow since there can be too many writers at a time. To improve this, a more coarse-grained version of this metric should be added, in which commits are recorded for groups of threads. The groups should be configurable and represent regexes to be matched by individual thread names. An additional group (i.e. \"other\") will group all threads not matching any of the defined group regexes. \r\n\r\nThe current behaviour will be split in two:\r\n* \"CommitsCountOtherThreads\" will expose a snapshot of threads currently in \"other\" group\r\n* \"CommitsCountPerGroup\" will expose an aggregate of commits count per thread group for the previous minute.\r\n\r\nBoth metrics will be reset each minute.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeStoreStats should expose stats for previous minute per thread group"
   },
   {
      "_id": "13148170",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2018-03-27 09:12:42",
      "description": "Currently, if a query has a property restriction of the form \"property = x\", and the property is indexed in a Lucene property index, the estimated cost is the index is the number of documents indexed for that property. This is a very conservative estimate, it means all documents have the same value. So the cost is relatively high for that index.\r\n\r\nIn almost all cases, there are many distinct values for a property. Rarely there are few values, or a skewed distribution where one value contains most documents. But in almost all cases there are more than 5 distinct values.\r\n\r\nI think it makes sense to use 5 as the default value. It is still conservative (cost of the index is high), but much better than now.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Lucene Index: per-column selectivity, assume 5 unique entries"
   },
   {
      "_id": "13146525",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2018-03-20 12:09:46",
      "description": "The {{MongoDocumentStore}} currently uses the old API in {{com.mongodb}}. Starting with MongoDB Java driver 3.0 a new client API was introduced in {{com.mongodb.client}}. New features like client sessions are only available in the new API and MongoDB may remove some deprecated methods/classes/interfaces in the future. The implementation should be migrated to the new client API.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Migrate to the MongoDB Java driver API 3.0"
   },
   {
      "_id": "13145333",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2018-03-15 10:39:06",
      "description": "Container issue to track potential improvements to {{PermissionEntryProviderImpl}} based on discussions with [~stillalex].",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improvements to PermissionEntryProviderImpl"
   },
   {
      "_id": "13145009",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2018-03-14 12:26:46",
      "description": "h4. Problem\r\n\r\nIn some edge cases when the binary under the same path (/content/asset1) is modified by 2 independent checkpoints: A & B the sidegrade without providing DataStore might fail with the following error:\r\n{noformat:title=An exception thrown by oak-upgrade tool}\r\nCaused by: java.lang.UnsupportedOperationException: null\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.upgrade.cli.blob.MissingBlobStore.getInputStream(MissingBlobStore.java:62)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.blob.BlobStoreBlob.getNewStream(BlobStoreBlob.java:47)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.getNewStream(SegmentBlob.java:276)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.getNewStream(SegmentBlob.java:86)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.memory.AbstractBlob$1.openStream(AbstractBlob.java:44)\r\n\u00a0\u00a0\u00a0 at com.google.common.io.ByteSource.contentEquals(ByteSource.java:344)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.memory.AbstractBlob.equal(AbstractBlob.java:67)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.equals(SegmentBlob.java:227)\r\n\u00a0\u00a0\u00a0 at com.google.common.base.Objects.equal(Objects.java:60)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.memory.AbstractPropertyState.equal(AbstractPropertyState.java:59)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.SegmentPropertyState.equals(SegmentPropertyState.java:242)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareProperties(SegmentNodeState.java:617)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:511)\r\n(the same nested methods)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:604)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.upgrade.PersistingDiff.diff(PersistingDiff.java:139)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.upgrade.PersistingDiff.childNodeChanged(PersistingDiff.java:191)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.MapRecord$3.childNodeChanged(MapRecord.java:440)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:483)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:432)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:604)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.upgrade.PersistingDiff.diff(PersistingDiff.java:139)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.upgrade.PersistingDiff.applyDiffOnNodeState(PersistingDiff.java:106)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.upgrade.RepositorySidegrade.copyDiffToTarget(RepositorySidegrade.java:403)\r\n\u00a0\u00a0\u00a0 at org.apache.jackrabbit.oak.upgrade.RepositorySidegrade.migrateWithCheckpoints(RepositorySidegrade.java:347)\r\n{noformat}\r\n\u00a0\r\nh4. Abstract of proposed solution\r\n\r\nThe idea for migration is simple: instead of failing on:\r\n{code:java}\r\npublic InputStream getInputStream(String blobId) throws IOException;\r\n{code}\r\nor\r\n{code:java}\r\npublic int readBlob(String blobId, long pos, byte[] buff, int off, int length) throws IOException;\r\n{code}\r\nlets introduce a BlobStore implementation that acts similarly as a *localhost* interface that what you sent it will resend back to this interface.\r\nh4. How it works\r\n\r\nIt works as a *localhost* interface, the same way: when *{{blobId}}* is requested... then *{{blobId}}* is served as a binary content instead *of throwing*: {{UnsupportedOperationException}}.\r\n\r\nThis allows to act quickly on migrations that requires to compare binaries in order to satisfy requirements for checkpoints to be rewritten, copied from scratch.\r\nh4. Pros\r\n * simplifies simple sidegrade migration use cases: you do not need anymore to include your DataStore (which slows that migration not necessary) on the command line when the migration is failing\r\n * speeds up the migration as it doesn't require to reference BlobStore implementation in cases where binary references are only copied together with NodeStore inlined binaries\r\n * you're always copying checkpoints which means (no need anymore for {{--skip-checkpoints}} option) that no full re-indexes are happening anymore after migration on migrated repository\r\n\r\nh4. Cons and risks\r\n * *Low risk:* not visible effect to user that for a specific migration a DataStore is needed (whether you are running into this specific edge case)\r\n * *Medium risk:* NodeStore storage overhead for checkpoints if compared binaries across checkpoints have different blob IDs (in example different algorithms SHA256 vs SHA512). *This we'll lead in comparison to not equal evaluation and the node will be rewritten for the checkpoint.*\r\n * *Low risk:* Currently we're accepting in\u00a0{{readBlob}} requests to copy smaller binaries whilst the caller expects higher length of binary (it might be the case if\u00a0{{getBlobLength}} is not used for some reasons apriori to the\u00a0{{readBlob}} and the original length of the binary (that is really placed in real DataStore) is kept somewhere in cache. The API here informs anyway how many bytes were read and it recommends to caller to check for that value.\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix all sidegrades breaking with UnsupportedOperationException on MissingBlobStore by introducing LoopbackBlobStore"
   },
   {
      "_id": "13144981",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-03-14 10:02:29",
      "description": "Due to duplicate registration of {{SegmentNodeStoreStats}} in both {{SegmentNodeStore}}  and {{LockBasedScheduler}}, we end up with two instances of this MBean. The former gets exposed via JMX and always returns empty tables for CommitsCountPerWriter and QueuedWriters, while the latter correctly tracks these data, but is not exposed. To address this, we should stick to only one instance of {{SegmentNodeStoreStats}}, used in both {{SegmentNodeStore}} and {{LockBasedScheduler}}.\r\n\r\nWhile at this, two additional points to be addressed:\r\n# {{CommitsTracker}} needs to be unit tested\r\n# commits count map size needs to be configurable via {{SegmentNodeStoreStats}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CommitsTracker data is always empty when exposed via JMX"
   },
   {
      "_id": "13144371",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-03-12 16:51:18",
      "description": "We should transform {{CacheWeightEstimator}} from a stand-alone utility into a unit test such that we can regularly run in on a CI.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Transform CacheWeightEstimator into a unit test"
   },
   {
      "_id": "13143850",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2018-03-09 09:49:13",
      "description": "Refactor exception handling in preparation for OAK-7286.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "RDBDocumentStore: Refactor exception handling"
   },
   {
      "_id": "13143234",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-03-07 14:40:04",
      "description": "Support for long ids of external blobs where introduces with OAK-3107.\u00a0{{SegmentParser.parseBlob()}} is still oblivious about them.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentParser#parseBlob does not long ids of external blobs"
   },
   {
      "_id": "13141749",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-03-01 10:00:43",
      "description": "OAK-4707 introduced logging at debug logging to the system console for sorting out test failures on Jenkins. Since we haveen't seen these failures for a while and that issue is fixed I would like to remove the extra logging again to avoid cluttering the console unnecessarily.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove debug logging to the console during tests"
   },
   {
      "_id": "13138487",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-02-14 13:39:57",
      "description": "Including invalid ones.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DocumentStore: add test coverage for various types of IDs"
   },
   {
      "_id": "13137875",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-02-12 14:22:03",
      "description": "When investigating the performance of\u00a0 {{segment-tar}}, the source of the writes (commits) is a very useful indicator of the cause.\r\n\r\nTo better understand which threads are currently writing in the repository and which are blocked on the semaphore, we need to improve {{SegmentNodeStoreStats}} to:\r\n * expose the number of commits executed per thread\r\n * expose threads currently waiting on the semaphore",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve SegmentNodeStoreStats to include number of commits per thread and threads currently waiting on the semaphore"
   },
   {
      "_id": "13137149",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2018-02-08 13:20:24",
      "description": "Queries that don't have a clear path restriction should not use indexes that have excludedPaths or includedPaths set, except in some exceptional cases (to be defined).\r\n\r\nFor example, if a query doesn't have a path restriction, say:\r\n\r\n{noformat}\r\n/jcr:root//element(*, nt:base)[@status='RUNNING']\r\n{noformat}\r\n\r\nThen an index that has excludedPaths set (for example to /etc) shouldn't be used, at least not if a different index is available. Currently it is used currently, actually in _favor_ of another index, if the property \"status\" is commonly used in /etc. Because of that, the index that doesn't have excludedPath has a higher cost (as it indexes the property \"status\" in /etc, and so has more entries for \"status\", than the index that doesn't index /etc).\r\n\r\nThe same for includedPaths, in case queryPaths isn't set to the same value(s).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "indexingPatch",
         "mohit"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Indexes with excludedPaths, or includedPaths should not be picked for queries without path"
   },
   {
      "_id": "13136571",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-02-06 14:14:57",
      "description": "With OAK-5595 we have enabled deep traversals by default when using the check command. At the same time we have deprecated the --{{deep}}\u00a0option.\r\n\r\nSince all these happened for {{1.8}}, the next logical step to do for {{1.10}} is to remove this option altogether.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove deprecated deep option from check command"
   },
   {
      "_id": "13135379",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-02-01 10:52:00",
      "description": "Analyze and further reduce calls to the DocumentStore when content is written to the repository. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce calls to DocumentStore"
   },
   {
      "_id": "13135038",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-31 10:29:01",
      "description": "{{oak-run check}}\u00a0does currently\u00a0*not*\u00a0check the checksums of the segments. As a consequence, there is no quick way of determining the\u00a0state of the repository (corrupt/valid), after corrupting some random node record, as we currently do in {{CheckRepositoryTestBase#corruptRecord}}. To determine that, there needs to be an attempt to read the corrupt record as part of a traversal.\r\n\r\nAn easier way would be to have a new dedicated option for this (i.e., {{--segments}}) which checks by default the content of segments against the checksums from all the tar files in the specified location. Additionally, it could accept as an argument a list of tar files, the segments of which to be checked.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run check should have an option to check the segments checksums"
   },
   {
      "_id": "13134479",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-01-29 15:46:48",
      "description": "The persistent cache currently stores binaries up to one MB by default. However most of the BlobStore implementations already provide some form of caching. E.g. for S3 a cache on the local filesystem is maintained and when using a Jackrabbit FileDataStore the persistent cache is actually unnecessary.\r\n\r\nSupport for documents in the persistent cache should also be removed. In contrast to other cache entries, documents are mutable and may cause consistency issues when enabled with the persistent cache. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove support for binaries and documents in persistent cache"
   },
   {
      "_id": "13134438",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-29 12:39:03",
      "description": "{{SegmentOverflowExceptionIT}} potentially consumes a lot of disk space. Running it for 10 minutes on a AWS m4.4xlarge instance with 900 / 3000 IOPS resulted in 80GB being taken up. \r\nCurrently the test can be time boxed but not size boxed. I suggest to add another option to cap the repository size in addition to the existing {{-Dtimeout}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add configurable repository size cap to SegmentOverflowExceptionIT"
   },
   {
      "_id": "13134388",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-01-29 08:48:43",
      "description": "When nodes are bundled in a document, the DocumentNodeStore keeps track of whether all children are included in a document. The presence of the hidden {{:doc-has-child-non-bundled}} property indicates there are non bundled child nodes. For the case when a document contains all children in the bundle, the DocumentNodeStore still does a find call on the DocumentStore when asked for an unknown child node.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bundling",
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Avoid call for child node when bundle contains all children"
   },
   {
      "_id": "13133748",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2018-01-25 16:46:07",
      "description": "Our node name check currently allow control characters other than CR, LF and TAB. This is a bug according to JCR, names being restricted to XML characters.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Various disallowed control characters are accepted in item names"
   },
   {
      "_id": "13133362",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2018-01-24 13:37:15",
      "description": "In some cases a call to {{Node.getMixinNodeTypes()}} may result in a check whether there is a child node named {{jcr:mixinTypes}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Node.getMixinNodeTypes() may check for child node named jcr:mixinTypes"
   },
   {
      "_id": "13132712",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-22 13:40:37",
      "description": "See https://google.github.io/guava/releases/19.0/api/docs/com/google/common/util/concurrent/Futures.html#transform(com.google.common.util.concurrent.ListenableFuture,%20com.google.common.util.concurrent.AsyncFunction)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "guava: ListenableFuture.transform() changes to transformAsync in version 20"
   },
   {
      "_id": "13131603",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-17 15:05:40",
      "description": "We should review and update the documentation of [{{oak-run check}}|http://jackrabbit.apache.org/oak/docs/nodestore/segment/overview.html#check]. E.g. to include the new options from OAK-6373.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Update documentation for oak-run check"
   },
   {
      "_id": "13131600",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-17 15:01:58",
      "description": "Currently the [TarMK documentation|http://jackrabbit.apache.org/oak/docs/nodestore/segment/overview.html#monitoring-via-jmx] only mentions {{SegmentRevisionGarbageCollection}}. We should review that paragraph and also include documentation for all other relevant JMX endpoints.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document TarMK specific MBeans"
   },
   {
      "_id": "13131220",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-16 12:17:50",
      "description": "There is a race condition on {{TarRevisions#head}} between a running compaction trying to set the new head [0] and the scheduler doing the same after executing a specific commit [1]. If the compaction thread is first, then the head assignment in the scheduler will fail and not be re-attempted. \r\n\r\nIMO, the simple if statement should be changed to a while loop in which the head is refreshed and the commit is re-applied against the new head, before attempting again to set a new head in {{TarRevisions}}. This is somehow similar to what we previously had [2], but without the unneeded optimistic/pessimistic strategies involving tokens.\r\n\r\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/FileStore.java#L764\r\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/scheduler/LockBasedScheduler.java#L253\r\n[2] https://github.com/apache/jackrabbit-oak/blob/1.6/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentNodeStore.java#L686",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Race condition on revisions head between compaction and scheduler could result in skipped commit"
   },
   {
      "_id": "13129793",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-10 09:44:03",
      "description": "In some cases we observed a {{SNFE}} right after a the cleanup following a full compaction:\r\n\r\n{noformat}\r\n31.12.2017 04:25:19.816 *ERROR* [pool-17-thread-22] org.apache.jackrabbit.oak.segment.SegmentNotFoundExceptionListener Segment not found: a82a99a3-f1e9-49b7-a1e0-55e7fec80c41. SegmentId age=609487478ms,segment-generation=GCGeneration{generation=4,fullGeneration=2,isCompacted=true}\r\norg.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment a82a99a3-f1e9-49b7-a1e0-55e7fec80c41 not found\r\n        at org.apache.jackrabbit.oak.segment.file.AbstractFileStore.readSegmentUncached(AbstractFileStore.java:276)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.lambda$readSegment$5(FileStore.java:478)\r\n        at org.apache.jackrabbit.oak.segment.SegmentCache.lambda$getSegment$0(SegmentCache.java:116)\r\n        at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724)\r\n        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522)\r\n        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315)\r\n        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278)\r\n        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193)\r\n        at com.google.common.cache.LocalCache.get(LocalCache.java:3932)\r\n        at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721)\r\n        at org.apache.jackrabbit.oak.segment.SegmentCache.getSegment(SegmentCache.java:113)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:478)\r\n        at org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:154)\r\n        at org.apache.jackrabbit.oak.segment.CachingSegmentReader$1.apply(CachingSegmentReader.java:94)\r\n        at org.apache.jackrabbit.oak.segment.CachingSegmentReader$1.apply(CachingSegmentReader.java:90)\r\n        at org.apache.jackrabbit.oak.segment.ReaderCache.get(ReaderCache.java:118)\r\n        at org.apache.jackrabbit.oak.segment.CachingSegmentReader.readString(CachingSegmentReader.java:90)\r\n        at org.apache.jackrabbit.oak.segment.MapRecord.getEntry(MapRecord.java:220)\r\n        at org.apache.jackrabbit.oak.segment.MapRecord.getEntry(MapRecord.java:173)\r\n        at org.apache.jackrabbit.oak.segment.SegmentNodeState.getChildNode(SegmentNodeState.java:423)\r\n        at org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.<init>(MemoryNodeBuilder.java:143)\r\n        at org.apache.jackrabbit.oak.segment.SegmentNodeBuilder.<init>(SegmentNodeBuilder.java:93)\r\n        at org.apache.jackrabbit.oak.segment.SegmentNodeBuilder.createChildBuilder(SegmentNodeBuilder.java:148)\r\n        at org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.getChildNode(MemoryNodeBuilder.java:331)\r\n        at org.apache.jackrabbit.oak.core.SecureNodeBuilder.<init>(SecureNodeBuilder.java:112)\r\n        at org.apache.jackrabbit.oak.core.SecureNodeBuilder.getChildNode(SecureNodeBuilder.java:329)\r\n        at org.apache.jackrabbit.oak.core.MutableTree.getTree(MutableTree.java:290)\r\n        at org.apache.jackrabbit.oak.core.MutableRoot.getTree(MutableRoot.java:220)\r\n        at org.apache.jackrabbit.oak.core.MutableRoot.getTree(MutableRoot.java:69)\r\n        at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.getItem(SessionDelegate.java:442)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl.getItemInternal(SessionImpl.java:167)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl.access$400(SessionImpl.java:82)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl$3.performNullable(SessionImpl.java:229)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl$3.performNullable(SessionImpl.java:226)\r\n        at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.performNullable(SessionDelegate.java:243)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl.getItemOrNull(SessionImpl.java:226)\r\n{noformat}\r\n\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "SNFE after full compaction"
   },
   {
      "_id": "13126821",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-12-22 14:17:46",
      "description": "Improve monitoring section of cold standby in {{oak-doc}} to include missing MBean screenshots.\r\n\r\n-[~mduerig], [~frm]: How about adding a *Benchmarking* section to the cold standby page covering a bit ways to use the new {{Oak-Segment-Tar-Cold}} fixture and also running {{ScalabilityStandbySuite}} on top of it?-",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Update documentation for cold standby"
   },
   {
      "_id": "13126227",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-20 09:24:53",
      "description": "When compaction starts it should also log the current gc generation and the new gc generation it is going to create. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Compaction should log generation info"
   },
   {
      "_id": "13125964",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-19 16:41:02",
      "description": "When starting on an Oak 1.6 repository and the {{gc.log}} file is present the TarMK fails with:\r\n{noformat}\r\njava.lang.ArrayIndexOutOfBoundsException: 5\r\n        at org.apache.jackrabbit.oak.segment.file.GCJournal$GCJournalEntry.parseString(GCJournal.java:217)\r\n        at org.apache.jackrabbit.oak.segment.file.GCJournal$GCJournalEntry.fromString(GCJournal.java:204)\r\n        at org.apache.jackrabbit.oak.segment.file.GCJournal.read(GCJournal.java:115)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.compact(FileStore.java:750)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.compactFull(FileStore.java:731)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.compactFull(FileStore.java:385)\r\n        at org.apache.jackrabbit.oak.segment.tool.Compact.run(Compact.java:273)\r\n        at org.apache.jackrabbit.oak.run.CompactCommand.execute(CompactCommand.java:72)\r\n        at org.apache.jackrabbit.oak.run.Main.main(Main.java:49)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "migration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "ArrayIndexOutOfBoundsException when upgrading from Oak 1.6"
   },
   {
      "_id": "13125830",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-12-19 09:07:54",
      "description": "The newly introduced {{Segment-Tar-Cold}} fixture should support secure communication between primary and standby via a {{--secure}} option. Moreover, the current implementation allows only for continuous sync between primary and standby. It should be possible to allow a \"one-shot run\" of the sync to easily measure and compare specific metrics ({{--oneShotRun}} option).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Segment-Tar-Cold fixture should have options for secure communication and one shot runs"
   },
   {
      "_id": "13125733",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-12-18 22:38:14",
      "description": "Running the following query {{select \\[rep:facet(simple/tags)] from \\[nt:base] where contains(\\[text], 'ipsum')}} with the following content \r\n\r\n{code}\r\n/content/foo\r\n - text = \"lorem lorem\"\r\n + simple/\r\n   - tags = [\"tag1\", \"tag2\"]\r\n/content/bar\r\n - text = \"lorem ipsum\"\r\n{code}\r\n\r\nruns in the following NPE\r\n\r\n{code}\r\njava.lang.NullPointerException\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.util.FilteredSortedSetDocValuesFacetCounts.getTopChildren(FilteredSortedSetDocValuesFacetCounts.java:63)\r\n\tat org.apache.lucene.facet.MultiFacets.getTopChildren(MultiFacets.java:52)\r\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LucenePropertyIndex$LucenePathCursor$2.getValue(LucenePropertyIndex.java:1646)\r\n\t... 38 more\r\n{code}\r\n\r\nThis is because the result set for the query only contains {{/content/bar}} and with that the count of the dimension {{simple/tag}} is 0. For that case [SortedSetDocValuesFacetCounts#getDim()|https://github.com/apache/lucene-solr/blob/releases/lucene-solr/4.7.1/lucene/facet/src/java/org/apache/lucene/facet/sortedset/SortedSetDocValuesFacetCounts.java#L108] returns {{null}} and so does {{getTopChildren}}.\r\n\r\nThis expected behaviour is properly handled in [LucenePropertyIndex.java#L1647|https://github.com/apache/jackrabbit-oak/blob/jackrabbit-oak-1.6.7/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java#L1647] but not in [FilteredSortedSetDocValuesFacetCounts.java#L63|https://github.com/apache/jackrabbit-oak/blob/jackrabbit-oak-1.6.7/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/util/FilteredSortedSetDocValuesFacetCounts.java#L63] where {{topChildren}} is dereferenced without null check.\r\n\r\nTo workaround that secure facets can be set to false, though the default value is true.\r\n ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "facet"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NullPointerException in FilteredSortedSetDocValuesFacetCounts during query evaluation"
   },
   {
      "_id": "13125593",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-18 10:47:03",
      "description": "Ensure {{oak-doc}} is up to date with the current version of {{oak-run compact}}, its current command line arguments and system properties. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document oak-run compact arguments and system properties"
   },
   {
      "_id": "13125455",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-12-17 09:41:15",
      "description": "The change made here:\r\nhttps://github.com/apache/jackrabbit-oak/commit/00c94b71293abcae6d76bb162c3f55c7d09b702e#diff-d4bdf443c61f24b634f33aab607e2114\r\n\r\nbreaks the logic in line 676:\r\n\r\n{{else if (oakPropertyName.equals(QueryConstants.REP_EXCERPT + \"(\"))}}\r\n\r\nThis statement doesn't make much sense considering a query like {{select \\[rep:excerpt] from \\[test:Page] as page where contains(\\*, 'term\\*')}} or even {{select \\[rep:excerpt(text)] from \\[test:Page] as page where contains(page.\\[text], 'term\\*')}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "excerpt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "rep:excerpt selector broken as regression of OAK-6750"
   },
   {
      "_id": "13124683",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-13 14:09:31",
      "description": "When {{oak-run compact}} gets cancelled because running out of disk space it will send a corresponding warning to the logs and bail out. However on the console it will still report success. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "production",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run compact reports success even when it was cancelled"
   },
   {
      "_id": "13124679",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-13 14:05:42",
      "description": "Currently the Segment dump created in {{Segment.toString}} includes a list of records with their offsets. However these offsets do no match the ones in the subsequent raw byte dump of the segment. We should add a raw offsets to the list of records so finding the actual data that belongs to a record doesn't involve manually fiddling with logical / physical offset translation. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Segment.toString: Record table should include an index into the hexdump"
   },
   {
      "_id": "13124359",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2017-12-12 13:02:53",
      "description": "{{oak-doc/src/site/markdown/command_line.md}} refers to the {{compress-interval}} system property, which does not exist any more. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove dangling reference to compress-interval system property from oak-run documentation"
   },
   {
      "_id": "13124338",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-12 11:00:34",
      "description": "Offline compaction can corrupt the repository in some cases: when offline compaction is cancelled by the {{CancelCompactionSupplier}} the corresponding return value is not correctly passed up the call chain resulting in a incomplete compacted head state being set as the compacted head state (instead of being discarded). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "corruption",
         "data-corruption"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Offline compaction corrupts repository"
   },
   {
      "_id": "13124118",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-12-11 12:26:32",
      "description": "\"For keys, the maximum length is 512 bytes in the UTF-8 representation (in the latest Unicode version).\"\r\n\r\nThat's a bit misleading, as the UTF-8 representation is independent of the Unicode version.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentStore API: clarify key length"
   },
   {
      "_id": "13122808",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-12-05 08:52:10",
      "description": "Seen on an internal Windows Jenkins node:\r\n\r\nh3. Regression\r\n\r\norg.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT.testSyncFailingDueToTooShortTimeout\r\n\r\nh3. Error Message\r\n\r\n{noformat}\r\nValues should be different. Actual: { root = { ... } }\r\n{noformat}\r\n\r\nh3. Stacktrace\r\n\r\n{noformat}\r\njava.lang.AssertionError: Values should be different. Actual: { root = { ... } }\r\n\tat org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT.testSyncFailingDueToTooShortTimeout(ExternalPrivateStoreIT.java:87)\r\n{noformat}\r\n\r\nh3. Standard Output\r\n\r\n{noformat}\r\n22:41:13.646 INFO  [main] FileStoreBuilder.java:340         Creating file store FileStoreBuilder{version=1.8-SNAPSHOT, directory=target\\junit2834122541179880349\\junit3041268421527563090, blobStore=DataStore backed BlobStore [org.apache.jackrabbit.core.data.FileDataStore], maxFileSize=1, segmentCacheSize=0, stringCacheSize=0, templateCacheSize=0, stringDeduplicationCacheSize=15000, templateDeduplicationCacheSize=3000, nodeDeduplicationCacheSize=1, memoryMapping=false, gcOptions=SegmentGCOptions{paused=false, estimationDisabled=false, gcSizeDeltaEstimation=1073741824, retryCount=5, forceTimeout=60, retainedGenerations=2, gcType=FULL}}\r\n22:41:13.646 INFO  [main] FileStore.java:241                TarMK opened at target\\junit2834122541179880349\\junit3041268421527563090, mmap=false, size=0 B (0 bytes)\r\n22:41:13.646 DEBUG [main] FileStore.java:247                TAR files: TarFiles{readers=[],writer=target\\junit2834122541179880349\\junit3041268421527563090\\data00000a.tar}\r\n22:41:13.646 DEBUG [main] TarWriter.java:185                Writing segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a to target\\junit2834122541179880349\\junit3041268421527563090\\data00000a.tar\r\n22:41:13.646 INFO  [main] FileStoreBuilder.java:340         Creating file store FileStoreBuilder{version=1.8-SNAPSHOT, directory=target\\junit2834122541179880349\\junit4470899745425503556, blobStore=DataStore backed BlobStore [org.apache.jackrabbit.core.data.FileDataStore], maxFileSize=1, segmentCacheSize=0, stringCacheSize=0, templateCacheSize=0, stringDeduplicationCacheSize=15000, templateDeduplicationCacheSize=3000, nodeDeduplicationCacheSize=1, memoryMapping=false, gcOptions=SegmentGCOptions{paused=false, estimationDisabled=false, gcSizeDeltaEstimation=1073741824, retryCount=5, forceTimeout=60, retainedGenerations=2, gcType=FULL}}\r\n22:41:13.646 INFO  [main] FileStore.java:241                TarMK opened at target\\junit2834122541179880349\\junit4470899745425503556, mmap=false, size=0 B (0 bytes)\r\n22:41:13.646 DEBUG [main] FileStore.java:247                TAR files: TarFiles{readers=[],writer=target\\junit2834122541179880349\\junit4470899745425503556\\data00000a.tar}\r\n22:41:13.646 DEBUG [main] TarWriter.java:185                Writing segment 8d19c7dc-8b48-4e10-a58d-31c15c93f2fe to target\\junit2834122541179880349\\junit4470899745425503556\\data00000a.tar\r\n22:41:13.646 INFO  [main] DataStoreTestBase.java:127        Test begin: testSyncFailingDueToTooShortTimeout\r\n22:41:13.646 INFO  [main] SegmentNodeStore.java:120         Creating segment node store SegmentNodeStoreBuilder{blobStore=DataStore backed BlobStore [org.apache.jackrabbit.core.data.FileDataStore]}\r\n22:41:13.646 INFO  [main] LockBasedScheduler.java:155       Initializing SegmentNodeStore with the commitFairLock option enabled.\r\n22:41:13.708 DEBUG [main] StandbyServer.java:248            Binding was successful\r\n22:41:13.708 DEBUG [main] TarWriter.java:185                Writing segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to target\\junit2834122541179880349\\junit3041268421527563090\\data00000a.tar\r\n22:41:13.739 DEBUG [main] TarRevisions.java:240             TarMK journal update null -> 4a5183bd-bcdf-41ab-a557-6f19143bbc91.0000000c\r\n22:41:13.755 DEBUG [standby-1] GetHeadRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for current head\r\n22:41:13.755 DEBUG [primary-1] ClientFilterHandler.java:53  Client /127.0.0.1:65480 is allowed\r\n22:41:13.755 DEBUG [primary-1] RequestDecoder.java:42       Parsed 'get head' message\r\n22:41:13.755 DEBUG [primary-1] CommunicationObserver.java:120 Message 'get head' received from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.755 DEBUG [primary-1] GetHeadRequestHandler.java:43 Reading head for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.755 DEBUG [primary-1] GetHeadResponseEncoder.java:36 Sending head 4a5183bd-bcdf-41ab-a557-6f19143bbc91.0000000c to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.755 DEBUG [standby-1] ResponseDecoder.java:82      Decoding 'get head' response\r\n22:41:13.755 DEBUG [standby-run-23] StandbyClientSyncExecution.java:103 Found missing segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91\r\n22:41:13.755 DEBUG [standby-run-23] StandbyClientSyncExecution.java:124 Inspecting segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91\r\n22:41:13.755 DEBUG [standby-1] GetReferencesRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for references of segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91\r\n22:41:13.755 DEBUG [primary-1] RequestDecoder.java:48       Parsed 'get references' message\r\n22:41:13.771 DEBUG [primary-1] GetReferencesRequestHandler.java:39 Reading references of segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetReferencesResponseEncoder.java:34 Sending references of segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [standby-1] ResponseDecoder.java:94      Decoding 'get references' response\r\n22:41:13.771 DEBUG [standby-run-23] StandbyClientSyncExecution.java:184 Found reference from 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to 4cea1684-ef05-44f5-a869-3ef2df6e0c9a\r\n22:41:13.771 DEBUG [standby-run-23] StandbyClientSyncExecution.java:124 Inspecting segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a\r\n22:41:13.771 DEBUG [standby-1] GetReferencesRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for references of segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a\r\n22:41:13.771 DEBUG [primary-1] RequestDecoder.java:48       Parsed 'get references' message\r\n22:41:13.771 DEBUG [primary-1] GetReferencesRequestHandler.java:39 Reading references of segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetReferencesResponseEncoder.java:34 Sending references of segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [standby-1] ResponseDecoder.java:94      Decoding 'get references' response\r\n22:41:13.771 INFO  [standby-run-23] StandbyClientSyncExecution.java:196 Copying data segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a from primary\r\n22:41:13.771 DEBUG [standby-1] GetSegmentRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a\r\n22:41:13.771 DEBUG [primary-1] RequestDecoder.java:45       Parsed 'get segment' message\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:120 Message 'get segment' received from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetSegmentRequestHandler.java:39 Reading segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:125 Segment with size 192 sent to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetSegmentResponseEncoder.java:43 Sending segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [standby-1] ResponseDecoder.java:86      Decoding 'get segment' response\r\n22:41:13.771 DEBUG [standby-run-23] TarWriter.java:185      Writing segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a to target\\junit2834122541179880349\\junit4470899745425503556\\data00000a.tar\r\n22:41:13.771 INFO  [standby-run-23] StandbyClientSyncExecution.java:196 Copying data segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 from primary\r\n22:41:13.771 DEBUG [standby-1] GetSegmentRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91\r\n22:41:13.771 DEBUG [primary-1] RequestDecoder.java:45       Parsed 'get segment' message\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:120 Message 'get segment' received from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetSegmentRequestHandler.java:39 Reading segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:125 Segment with size 448 sent to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetSegmentResponseEncoder.java:43 Sending segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [standby-1] ResponseDecoder.java:86      Decoding 'get segment' response\r\n22:41:13.771 DEBUG [standby-run-23] TarWriter.java:185      Writing segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to target\\junit2834122541179880349\\junit4470899745425503556\\data00000a.tar\r\n22:41:13.771 DEBUG [standby-1] GetBlobRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.771 DEBUG [primary-1] RequestDecoder.java:39       Parsed 'get blob' request\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:120 Message 'get blob id' received from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetBlobRequestHandler.java:41 Reading blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:130 Binary with size 5242880 sent to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetBlobResponseEncoder.java:41 Sending blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.786 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 1/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.802 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 2/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.802 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.802 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 1/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.802 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.802 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 3/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.802 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 2/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.818 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 4/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 3/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.818 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 5/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 4/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 5/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:167     Received entire blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.880 DEBUG [standby-run-23] ResponseDecoder.java:66 Processing input stream finished! Deleting file C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp\r\n22:41:13.896 DEBUG [standby-run-23] TarRevisions.java:240   TarMK journal update null -> 4a5183bd-bcdf-41ab-a557-6f19143bbc91.0000000c\r\n22:41:13.911 WARN  [standby-1] ExceptionHandler.java:37     Exception caught on client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\nio.netty.handler.timeout.ReadTimeoutException: null\r\n22:41:13.911 INFO  [standby-run-23] StandbyClientSyncExecution.java:82 updated head state successfully: true in 156ms.\r\n22:41:13.911 DEBUG [standby-run-23] StandbyClient.java:157  Channel closed\r\n22:41:16.137 DEBUG [main] StandbyClientSync.java:277        Group shut down\r\n22:41:16.137 DEBUG [main] StandbyServer.java:219            Channel disconnected\r\n22:41:16.137 DEBUG [main] StandbyServer.java:219            Channel disconnected\r\n22:41:16.137 DEBUG [main] StandbyServer.java:230            Boss group shut down\r\n22:41:16.137 DEBUG [main] StandbyServer.java:236            Worker group shut down\r\n22:41:16.137 INFO  [main] DataStoreTestBase.java:132        Test end: testSyncFailingDueToTooShortTimeout\r\n22:41:16.137 DEBUG [main] Scheduler.java:134                The scheduler FileStore background tasks was successfully shut down\r\n22:41:16.137 DEBUG [main] TarRevisions.java:236             Head state did not change, skipping flush\r\n22:41:16.184 INFO  [main] FileStore.java:480                TarMK closed: target\\junit2834122541179880349\\junit4470899745425503556\r\n22:41:16.184 DEBUG [main] Scheduler.java:134                The scheduler FileStore background tasks was successfully shut down\r\n22:41:16.184 DEBUG [main] TarRevisions.java:236             Head state did not change, skipping flush\r\n22:41:16.199 INFO  [main] FileStore.java:480                TarMK closed: target\\junit2834122541179880349\\junit3041268421527563090\r\n{noformat}\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ExternalPrivateStoreIT.testSyncFailingDueToTooShortTimeout"
   },
   {
      "_id": "13121939",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-30 15:23:28",
      "description": "Since OAK-6883, FULL estimation compares segmentstore size with the previous FULL. There can be cases where the current segmentstore is smaller than the previous FULL (i.e. due to TAIL cleaning up more). This leads to FULL being skipped for much more than anticipated.\r\n\r\nA case to illustrate this scenario:\r\n\r\n    Start Oak with a 10 GB repo\r\n    GC #1: run FULL results in segmenstore of 20GB\r\n    GC #2: run TAIL results in segmentstore of 11GB\r\n    GC #3: run FULL (saturday) - skipped because the reference is 20GB from the previous FULL\r\n\r\nFULL be executed again only when the segmentstore grows back above 20GB, which might be too late.\r\n\r\nEstimation should take this situation into account this and take a better decision.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Estimation for FULL can be off sometimes"
   },
   {
      "_id": "13120892",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-27 11:00:15",
      "description": "We have seen unusual high read IO in compaction retry cycles in our longevity tests at Adobe.\r\n\r\n!cpu.png|width=1000!\r\n\r\nAbove picture shows the CPU utilisation during an online compaction run, which starts at 03:00. At about 03:22 CPU user time drops and CPU waiting for IO time increases. This point in time coincides with the start of the first retry cycle of compaction. \r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "High read IO in compaction retry cycles"
   },
   {
      "_id": "13120406",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-23 08:10:31",
      "description": "{noformat}\r\nINFO] Running org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\r\n[WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file C:\\projects\\apache\\oak\\trunk\\oak-segment-tar\\target\\failsafe-reports\\2017-11-23T08-48-55_999-jvmRun1.dumpstream\r\n[ERROR] Tests run: 4, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 17.984 s <<< FAILURE! - in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\r\n[ERROR] offRCUpgradesSegments(org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT)  Time elapsed: 5.024 s  <<< FAILURE!\r\njava.lang.AssertionError: Segment version mismatch. Expected V_13, found V_12 expected:<V_13> but was:<V_12>\r\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.checkSegmentVersion(UpgradeIT.java:143)\r\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.offRCUpgradesSegments(UpgradeIT.java:108)\r\n\r\n{noformat}\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "test failure seen in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT"
   },
   {
      "_id": "13119685",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-20 15:17:59",
      "description": "We need to add documentation of tail compaction:\r\n* What is it, how does it work?\r\n* How is it configured and scheduled?\r\n* How can it be monitored, what are the related log entries?\r\n* What are its limitations?\r\n* What if it fails?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document tail compaction"
   },
   {
      "_id": "13117925",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-13 12:49:01",
      "description": "The {{-Dcache}} option currently has no effect when used in conjunction with the {{compact}} run mode of {{oak-run}}. However we should enable users to configure the segment cache size through this option if necessary. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Enable the -Dcache of offline compaction"
   },
   {
      "_id": "13116641",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-11-07 11:47:37",
      "description": "The changes to the segment cache introduced in r1793527 [0] introduced a performance regression on the primary for the case in which a standby is attached to it. Below a benchmark duration comparison between primary w/o and w/ standby for r1793527 (after the segment cache changes) and r1793526 (before the changes) :\r\n\r\n|Oak 1.6 r1793527 (20170502)|{noformat}\r\n# BasicWriteTest                   C     min     10%     50%     90%     max       N\r\nOak-Segment-Tar                    1      19      21      22      26     160    2491\r\nOak-Segment-Tar-DS                 1      56      59      63      70     181     919\r\nOak-Segment-Tar-Cold(Shared DS)    1      58      66     159     177     372     302\r\n{noformat}|\r\n|Oak 1.6 r1793526 (20170502)|{noformat}\r\n# BasicWriteTest                   C     min     10%     50%     90%     max       N\r\nOak-Segment-Tar                    1      19      21      22      25      52    2584\r\nOak-Segment-Tar-DS                 1      56      60      63      69     158     925\r\nOak-Segment-Tar-Cold(Shared DS)    1      57      60      64      70     122     915\r\n{noformat}|\r\n\r\n[0] https://github.com/apache/jackrabbit-oak/commit/efafa4e1710621b7f3b8e92d0b2681669185fcd4",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby",
         "performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cold standby performance regression due to segment caching"
   },
   {
      "_id": "13116579",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-07 04:55:40",
      "description": "SegmentNodeStore currently inlines binaries of size less that 16KB (Segment.MEDIUM_LIMIT) even if external BlobStore is configured. \r\n\r\nDue to this behaviour quite a bit of segment tar storage consist of blob data. In one setup out of 370 GB segmentstore size 290GB is due to inlined binary. If most of this binary content is moved to BlobStore then it would allow same repository to work better in lesser RAM\r\n\r\nSo it would be useful if some way is provided to disable this default behaviour and let BlobStore take control of inline size i.e. in presence of BlobStore no inlining is attempted by SegmentWriter.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide a way to tune inline size while storing binaries"
   },
   {
      "_id": "13116445",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-06 16:38:38",
      "description": "The offline compaction tool should do an effort to detect whether it is being run on windows and disable memory mapping if so. Rational: with memory mapping enabled it might fail to remove the old tar files (see OAK-4274 and [JDK-4724038|http://bugs.java.com/view_bug.do?bug_id=4724038]).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction should not use mmap on Windows"
   },
   {
      "_id": "13116443",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-06 16:32:51",
      "description": "When {{FileStore.compact()}} returns the {{journal.log}} does not necessarily contain the head created by the compactor. This can lead to problems downstream like e.g. in OAK-6894 where the compactor tool wrote the wrong (i.e. uncompacted) head to the {{journal.log}}. \r\n\r\nProposed fix is to call on of the {{FileStore.flush()}} methods after compaction and add a test case that verifies the {{journal.log}} contains the correct head state. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "FileStore.compact does not persist compacted head to journal"
   },
   {
      "_id": "13115677",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-11-02 16:58:12",
      "description": "After the netty upgrade in OAK-6564, there's a recurring warning appearing in the server thread:\r\n{noformat}\r\n18:54:44.691 [main] WARN  io.netty.bootstrap.ServerBootstrap - Unknown channel option 'TCP_NODELAY' for channel '[id: 0xa64bc5c4]'\r\n{noformat}\r\n\r\nWe need to see what's causing it (i.e. was that option removed in the latest version? if yes, is there a substitute/change needed?).\r\n\r\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Unknown channel option 'TCP_NODELAY' for channel warning in cold standby"
   },
   {
      "_id": "13115540",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-02 04:32:10",
      "description": "It would be useful if we can log the segmentstore size at time of startup. FileStore already computes the size to initialize the FileStoreStats so we just need to log it\r\n\r\nThis size often help when customer report issues and provide log files",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Log SegmentStore size at startup"
   },
   {
      "_id": "13115364",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-01 14:04:08",
      "description": "{noformat}\r\n[ERROR] offRCUpgradesSegments(org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT)  Time elapsed: 7.446 s  <<< FAILURE!\r\njava.lang.AssertionError: Segment version mismatch. Expected V_13, found V_12 expected:<V_13> but was:<V_12>\r\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.checkSegmentVersion(UpgradeIT.java:141)\r\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.offRCUpgradesSegments(UpgradeIT.java:107)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.offRCUpgradesSegments failing"
   },
   {
      "_id": "13113327",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-31 15:28:15",
      "description": "The background threads used in {{FileStore}} are implemented by wrapping {{Runnable}} instances in {{SafeRunnable}}, and by handing the {{SafeRunnable}} instances over to a {{ScheduledExecutorService}}. \r\n\r\nThe documentation of {{ScheduledExecutorService#scheduleAtFixedRate}} states that \"if any execution of a task takes longer than its period, then subsequent executions may start late, but will not concurrently execute\". This means that if an execution is delayed, the piled up executions might fire in rapid succession.\r\n\r\nThis way of running the periodic background threads might not be ideal. For example, it doesn't make much sense to flush the File Store five times in a row. On the other hand, if the background tasks are coded with this caveat in mind, this issue might not be a problem at all. For example, flushing the File Store five times in a row might not be a problem if many of those executions don't do much and return quickly.\r\n\r\nTasks piling up might be a problem when it comes to release the resource associated with the {{FileStore}} in a responsive way. Since the {{ScheduledExecutorService}} is gracefully shut down, it might take some time before all the scheduled background tasks are processed and the {{ScheduledExecutorService}} is ready to be terminated.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Executions of background threads might pile up"
   },
   {
      "_id": "13113323",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-31 15:13:59",
      "description": "The background threads used in {{FileStore}} are implemented by wrapping {{Runnable}} instances in {{SafeRunnable}}, and by handing the {{SafeRunnable}} instances over to a {{ScheduledExecutorService}}. \r\n\r\nThe documentation of {{ScheduledExecutorService#scheduleAtFixedRate}} states that \"if any execution of the task encounters an exception, subsequent executions are suppressed\". But a {{SafeRunnable}} always re-throws any {{Throwable}} that it catches, effectively preventing itself from executing again in the future.\r\n\r\nThere is more than one solution to this problem. One of these is to never re-throw any exception. Even if it doesn't always make sense, e.g. in case of an {{OutOfMemoryError}}, never re-throwing an exception would better fulfil the assumption that background threads should always be up and running even in case of error.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Background threads might not be automatically restarted"
   },
   {
      "_id": "13113277",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-31 10:57:49",
      "description": "After an offline compaction the {{gc.log}} always contains 0 for the number of compacted nodes. This is caused by {{org.apache.jackrabbit.oak.segment.tool.Compact.compact()}} instantiating a new {{FileStore}} to run cleanup. That file store has new {{GCMonitor}} instance, which did no see any of the nodes written by the compaction that was run on the previous {{FileStore}} instance. \r\n\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "OffRC always logs 0 for the number of compacted nodes in gc.log"
   },
   {
      "_id": "13113047",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-10-30 14:50:45",
      "description": "It seems that the disk space check is not properly synchronized with {{FileStore}} as I revealed a race condition while using oak-upgrade during migration to {{segment-tar}}.\r\n\r\nThe {{FileStore}} instance is closed while TarMK disk check tries to execute and it seems it is dependent on the state of segment ({{org.apache.jackrabbit.oak.segment.file.FileStore.checkDiskSpace(FileStore.java:541)}} that needs to be opened. \r\n\r\n{noformat}\r\n30.10.2017 11:26:05.834 WARN   o.a.j.o.s.f.Scheduler: The scheduler FileStore background tasks takes too long to shut down\r\n30.10.2017 11:26:11.674 INFO   o.a.j.o.s.f.FileStore: TarMK closed: /data/cq/crx-quickstart/repository-segment-tar-20171030-112401/segmentstore\r\n30.10.2017 11:26:11.676 ERROR  o.a.j.o.s.f.SafeRunnable: Uncaught exception in TarMK disk space check [/data/cq/crx-quickstart/repository-segment-tar-20171030-112401/segmentstore]\r\njava.lang.IllegalStateException: already shut down\r\n    at org.apache.jackrabbit.oak.segment.file.ShutDown.keepAlive(ShutDown.java:42)\r\n    at org.apache.jackrabbit.oak.segment.file.FileStore.size(FileStore.java:302)\r\n    at org.apache.jackrabbit.oak.segment.file.FileStore.checkDiskSpace(FileStore.java:541)\r\n    at org.apache.jackrabbit.oak.segment.file.FileStore.access$300(FileStore.java:102)\r\n    at org.apache.jackrabbit.oak.segment.file.FileStore$3.run(FileStore.java:237)\r\n    at org.apache.jackrabbit.oak.segment.file.SafeRunnable.run(SafeRunnable.java:67)\r\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n    at java.lang.Thread.run(Thread.java:745)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "TarMK disk space check is not synchronized with FileStore opened state"
   },
   {
      "_id": "13113043",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-30 14:46:56",
      "description": "Currently the compaction estimator unconditionally looks at the growth of the repository since the last compaction run. This turn out to be not optimal when interleaving tail and full compaction. It would be better to have the estimator look at the growth of the repository since last full compaction when running full compaction. \r\n\r\ncc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "The compaction estimator should take the compaction type (tail vs. full) into consideration"
   },
   {
      "_id": "13112267",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-10-26 12:27:31",
      "description": "When {{--shareDataStore}} option is used for {{Segment-Tar-Cold}}, the standby instance ends up without a blob store configured.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Segment-Tar-Cold fixture doesn't correctly set up standby blob store"
   },
   {
      "_id": "13110251",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332555",
            "id": "12332555",
            "name": "blob-plugins",
            "description": "Oak Blob Plugins"
         }
      ],
      "created": "2017-10-18 09:53:51",
      "description": "DataStore initialization logs the {{repository.home}} path ignoring the one specified with a {{path}} property which takes precedence which leads to confusion.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4",
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Log correct path while initializing the DataStore"
   },
   {
      "_id": "13110217",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-18 08:10:43",
      "description": "{{FileStore.close}} should take better advantage of the {{Closer}} instance to close its resources (including the file store lock). Also the order of the close calls should be aligned with their dependencies. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor FileStore.close"
   },
   {
      "_id": "13108896",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2017-10-12 11:59:08",
      "description": "For upgrade case in many applications older index type is set to {{disabled}} when new index is provisioned. If the new index is async then it would take some time for reindex and till then any query which used to make use of old index would end up traversing the repository\r\n\r\nTo avoid such a scenario we should only mark older index as \"disabled\" only if the newer index is reindex. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement support for disabling indexes which are replaced with newer index"
   },
   {
      "_id": "13107951",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-10-09 11:18:10",
      "description": "Currently persistent cache if enabled for nodes caches all nodes accessed on the system. It would be better if it can be configured to only cache those nodes which are not volatile so that caching can be effective\r\n\r\nPurpose of this issue is to\r\n* Provide an extension point in PersistentCache logic to check if a node is to be cached\r\n* Provide an impl which relies on some static OSGi config to determine that\r\n\r\nLater we can make this impl dynamic i.e. rely on access pattern to cache imp stuff",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Provide a way to for persistent cache to determine which all nodes can be cached"
   },
   {
      "_id": "13107238",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-05 14:16:27",
      "description": "Exceptions thrown by {{oak-run compact}} are inhibited so the exit code of the command is not correct in case of error. \n\nExample: \n{code}\n$ java -jar oak-run-1.7.8-R1809845.jar compact test-oak-run/\nApache Jackrabbit Oak 1.7.8-R1809845\nCompacting test-oak-run-6.3.0\nWith default access mode\n    before\n        Thu Oct 05 15:14:22 CEST 2017, journal.log\n        Thu Oct 05 15:14:23 CEST 2017, data00000a.tar\n        Thu Oct 05 15:14:23 CEST 2017, manifest\n        Thu Oct 05 15:14:23 CEST 2017, repo.lock\n    size 119.1 MB (119133142 bytes)\n    -> compacting\norg.apache.jackrabbit.oak.segment.file.InvalidFileStoreVersionException: Using a too recent version of oak-segment-tar\n\tat org.apache.jackrabbit.oak.segment.file.ManifestChecker.checkStoreVersion(ManifestChecker.java:81)\n\tat org.apache.jackrabbit.oak.segment.file.ManifestChecker.checkManifest(ManifestChecker.java:70)\n\tat org.apache.jackrabbit.oak.segment.file.ManifestChecker.checkAndUpdateManifest(ManifestChecker.java:51)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore.<init>(FileStore.java:191)\n\tat org.apache.jackrabbit.oak.segment.file.FileStoreBuilder.build(FileStoreBuilder.java:343)\n\tat org.apache.jackrabbit.oak.segment.tool.Compact.newFileStore(Compact.java:165)\n\tat org.apache.jackrabbit.oak.segment.tool.Compact.compact(Compact.java:135)\n\tat org.apache.jackrabbit.oak.segment.tool.Compact.run(Compact.java:128)\n\tat org.apache.jackrabbit.oak.run.SegmentTarUtils.compact(SegmentTarUtils.java:183)\n\tat org.apache.jackrabbit.oak.run.CompactCommand.execute(CompactCommand.java:93)\n\tat org.apache.jackrabbit.oak.run.Main.main(Main.java:49)\n    after\n        Thu Oct 05 15:14:22 CEST 2017, journal.log\n        Thu Oct 05 15:14:23 CEST 2017, data00000a.tar\n        Thu Oct 05 15:14:23 CEST 2017, manifest\n        Thu Oct 05 15:14:23 CEST 2017, repo.lock\n    size 119.1 MB (119133142 bytes)\n    removed files []\n    added files []\nCompaction succeeded in 211.9 ms (0s).\n{code}\n\nA quick fix would be to wrap the exception into a {{RuntimeException}}:\n{code}\n--- a/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/tool/Compact.java\n+++ b/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/tool/Compact.java\n@@ -127,7 +127,7 @@ public class Compact implements Runnable {\n         try {\n             compact();\n         } catch (Exception e) {\n-            e.printStackTrace();\n+            throw new RuntimeException(\"Failed to run compact\", e);\n         }\n     }\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Exceptions are inhibited in oak-run compact"
   },
   {
      "_id": "13105674",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-28 06:55:40",
      "description": "Currently all the {{GetXXXRequestHandler}} (where XXX stands for Blob, Head, References and Segment), on the server discard client requests which cannot be satisfied (i.e. the requested object does not exist (yet) on the server). A more transparent approach would be to timely respond to all client requests, clearly stating that the object was not found. This would improve a lot debugging for example, because all requests and their responses could be easily followed from the client log, without needing to know what actually happened on the server.\n\nBelow, a possible implementation for {{GetHeadRequestHandler}}, suggested by [~frm] in a comment on OAK-6678:\n\n{noformat}\nString id = reader.readHeadRecordId();\n\nif (id == null) {\n    ctx.writeAndFlush(new NotFoundGetHeadResponse(msg.getClientId(), id));\n    return;\n}\n\nctx.writeAndFlush(new GetHeadResponse(msg.getClientId(), id));\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Standby server should send timely responses to all client requests"
   },
   {
      "_id": "13105438",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2017-09-27 13:40:19",
      "description": "The cost estimation of the Lucene index is somewhat inaccurate because (by default) it just used the number of documents in the index (as of Oak 1.7.4 by default, due to OAK-6333).\n\nInstead, it should use the number of documents for the given fields (the minimum, if there are multiple fields with restrictions). \n\nPlus divided by the number of restrictions (as we do now already).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Lucene Index: improved cost estimation by using document count per field"
   },
   {
      "_id": "13104491",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-09-23 09:21:16",
      "description": "While running performance tests (internally) using latest unstable releases having {{CommitMitigatedTieredMergePolicy}} we observed significant drop in performance (OAK-6704).\nThe policy, although bad for performance, showed dramatic drop in churn created in data store size. So, clearly, OAK-5192 did what it intended to do.\n\nOpening this issue to factor in drop in performance and then set the default back to {{CommitMitigatedTieredMergePolicy}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CommitMitigated merge policy should not reduce performance significantly"
   },
   {
      "_id": "13104303",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-22 14:34:25",
      "description": "Invoking TarWriter.close() on an already closed writer throws an {{ISE}}. According to the general contract this is not allowed:\n\n{code}\n* Closes this stream and releases any system resources associated\n* with it. If the stream is already closed then invoking this\n* method has no effect.\n{code}\n\nWe should adjust the behvaviour of that method accordingly. \n\nFailing to comply with that general contract causes {{TarWriter}} instances to fail in try-resource statements when multiple wrapped streams are involved.\n\nConsider \n\n{code}\ntry (\n    StringWriter string = new StringWriter();\n    PrintWriter writer = new PrintWriter(string);\n    WriterOutputStream out = new WriterOutputStream(writer, Charsets.UTF_8))\n{\n    dumpHeader(out);\n    writer.println(\"----------------------------------------\");\n    dumpHex(out);\n    writer.println(\"----------------------------------------\");\n    return string.toString();\n}\n{code}\n\nThis code would cause exceptions to be thrown if e.g. the {{PrintWriter.close}} method would not be idempotent. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "TarWriter.close() must not throw an exception on subsequent invocations"
   },
   {
      "_id": "13104227",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-22 09:11:35",
      "description": "In order to correctly configure cold standby there are two OSGi configurations that need to be provided. Among other settings, {{org.apache.jackrabbit.oak.segment.SegmentNodeStoreService.config}} needs {{standby=B\"true\"}} and {{org.apache.jackrabbit.oak.segment.standby.store.StandbyStoreService.config}} needs {{mode=\"standby\"}}. The problem is that sometimes we have {{mode=\"standby\"}} in {{StandbyStoreService}} and {{standby=B\"false\"}} in {{SegmentNodeStoreService}} which leads to starting a problematic standby instance (with primary behaviour enabled, e.g. indexing, etc.). This problem stems from the fact that there are two components whose configuration should be coordinated. Proposals to mitigate this:\n\n# Keep the {{mode=\"standby\"}}, but merge the configuration of {{StandbyStoreService}} in the one for {{SegmentNodeStoreService}} and eliminate {{StandbyStoreService}} altogether\n# {{StandbyStoreService}} should derive {{mode=\"standby\"}} from {{\"standby=B\"true\"}} in {{SegmentNodeStoreService}}\n# {{SegmentNodeStoreService}} should derive {{\"standby=B\"true\"}} from {{mode=\"standby\"}} in {{StandbyStoreService}} even if this is backwards when compared to how the synchronization currently happens, with {{StandbyStoreService}} waiting for for a proper initialisation of {{SegmentNodeStoreService}}\n# Make {{StandbyStoreService}} configuration mandatory, but require a {{mode=\"off\"}} setting. This way the removal of {{standby=B\"true\"}} from {{SegmentNodeStoreService}} would be guaranteed and any synchronization between the two components would be avoided.\n\n/cc  [~frm], [~volteanu], [~mduerig]\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve cold standby resiliency to incoherent configs"
   },
   {
      "_id": "13103614",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-20 14:20:00",
      "description": "Started a server with Oak version 1.7.7 and tried to connect oak-run-1.7.7 to same setup. This resulted in following exception\n\n{noformat}\n2017-09-20 19:47:22,213 INFO  [main] o.a.j.o.segment.file.FileStore - Creating file store FileStoreBuilder{version=1.7.7, directory=/path/to/repository/segmentstore, blobStore=DataStore backed BlobStore [org.apache.jackrabbit.oak.plugins.blob.datastore.OakFileDataStore], maxFileSize=256, segmentCacheSize=256, stringCacheSize=256, templateCacheSize=64, stringDeduplicationCacheSize=15000, templateDeduplicationCacheSize=3000, nodeDeduplicationCacheSize=1048576, memoryMapping=true, gcOptions=SegmentGCOptions{paused=false, estimationDisabled=false, gcSizeDeltaEstimation=1073741824, retryCount=5, forceTimeout=60, retainedGenerations=2, gcType=FULL}} \n2017-09-20 19:47:22,243 WARN  [main] o.a.j.o.s.file.tar.TarReader - Unable to load index of file data00000a.tar: Unrecognized magic number \n2017-09-20 19:47:22,243 INFO  [main] o.a.j.o.s.file.tar.TarReader - No index found in tar file data00000a.tar, skipping... \n2017-09-20 19:47:22,243 WARN  [main] o.a.j.o.s.file.tar.TarReader - Could not find a valid tar index in /path/to/repository/segmentstore/data00000a.tar, recovering read-only \n2017-09-20 19:47:22,243 INFO  [main] o.a.j.o.s.file.tar.TarReader - Recovering segments from tar file /path/to/repository/segmentstore/data00000a.tar \n2017-09-20 19:47:22,315 INFO  [main] o.a.j.o.s.file.tar.TarReader - Regenerating tar file/path/to/repository/segmentstore/data00000a.tar.ro.bak \n2017-09-20 19:47:22,460 ERROR [main] o.a.j.oak.index.IndexCommand - Error occurred while performing index tasks \njava.lang.IllegalArgumentException: invalid segment buffer\n\tat org.apache.jackrabbit.oak.segment.data.SegmentDataLoader.newSegmentData(SegmentDataLoader.java:37) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.data.SegmentData.newSegmentData(SegmentData.java:66) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.AbstractFileStore.writeSegment(AbstractFileStore.java:212) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.AbstractFileStore.access$000(AbstractFileStore.java:66) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.AbstractFileStore$1.recoverEntry(AbstractFileStore.java:125) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarReader.generateTarFile(TarReader.java:213) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarReader.openRO(TarReader.java:162) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarFiles.<init>(TarFiles.java:298) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarFiles.<init>(TarFiles.java:58) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarFiles$Builder.build(TarFiles.java:167) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.ReadOnlyFileStore.<init>(ReadOnlyFileStore.java:74) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.FileStoreBuilder.buildReadOnly(FileStoreBuilder.java:383) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.run.cli.SegmentTarFixtureProvider.configureSegment(SegmentTarFixtureProvider.java:63) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.run.cli.NodeStoreFixtureProvider.create(NodeStoreFixtureProvider.java:71) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.run.cli.NodeStoreFixtureProvider.create(NodeStoreFixtureProvider.java:47) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.index.IndexCommand.execute(IndexCommand.java:98) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.run.Main.main(Main.java:49) [oak-run-1.7.7.jar:1.7.7]\n\n{noformat}\n\nPost restart of server oak-run was able to connect fine. So looks like issue with very fresh setup only\n\nCommand used for oak-run\n{noformat}\njava -jar oak-run-1.7.7.jar index --fds-path=/path/to/repository/datastore --checkpoint head --reindex --index-paths=/oak:index/lucene /path/to/repository/segmentstore --metrics\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ReadOnly connection to fresh SegmentNodeStore setup failing"
   },
   {
      "_id": "13102961",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-09-18 14:00:09",
      "description": "{{DocumentNodeStoreTest.disabledBranchesWithBackgroundWrite}} fails when I try a clean build on Windows, as per r1808698.\n\n{noformat}\n[ERROR] Failures:\n[ERROR]   DocumentNodeStoreTest.disabledBranchesWithBackgroundWrite:3199 expected:<1> but was:<0>\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: DocumentNodeStoreTest.disabledBranchesWithBackgroundWrite"
   },
   {
      "_id": "13102805",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-17 05:53:00",
      "description": "With changes for OAK-6653 in place, {{ExternalPrivateStoreIT#testSyncBigBlog}} and sometimes {{ExternalSharedStoreIT#testSyncBigBlob}} are failing on CI:\n\n{noformat}\norg.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT\ntestSyncBigBlob(org.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT)  Time elapsed: 96.82 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n...\ntestSyncBigBlob(org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT)  Time elapsed: 95.254 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n{noformat}\n\nPartial stacktrace:\n{noformat}\n14:09:08.355 DEBUG [main] StandbyServer.java:242            Binding was successful\n14:09:08.358 DEBUG [standby-1] GetHeadRequestEncoder.java:33 Sending request from client Bar for current head\n14:09:08.359 DEBUG [primary-1] ClientFilterHandler.java:53  Client /127.0.0.1:52988 is allowed\n14:09:08.360 DEBUG [primary-1] RequestDecoder.java:42       Parsed 'get head' message\n14:09:08.360 DEBUG [primary-1] CommunicationObserver.java:79 Message 'get head' received from client Bar\n14:09:08.362 DEBUG [primary-1] GetHeadRequestHandler.java:43 Reading head for client Bar\n14:09:08.363 WARN  [primary-1] ExceptionHandler.java:31     Exception caught on the server\njava.lang.NullPointerException: null\n\tat org.apache.jackrabbit.oak.segment.standby.server.DefaultStandbyHeadReader.readHeadRecordId(DefaultStandbyHeadReader.java:32) ~[oak-segment-tar-1.8-SNAPSHOT.jar:1.8-SNAPSHOT]\n\tat org.apache.jackrabbit.oak.segment.standby.server.GetHeadRequestHandler.channelRead0(GetHeadRequestHandler.java:45) ~[oak-segment-tar-1.8-SNAPSHOT.jar:1.8-SNAPSHOT]\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Syncing big blobs fails since StandbyServer sends persisted head"
   },
   {
      "_id": "13102497",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-15 08:10:43",
      "description": "At the moment all integration tests for cold standby are using the same scenario in their tests: some content is created on the server (including binaries), a standby sync cycle is started and then the content is checked on the client. The only twist here is using/not using a data store for storing binaries.\n\nAlthough good, this model could be extended to cover many more cases. For example, {{StandbyDiff}} covers the following 6 cases node/property added/changed/deleted. From these, with the scenario described, the removal part is never tested (and the change part is covered in only one test). \n\nIt would be nice to have an IT which would add content on the server, do a sync, remove some of the content, do a sync and then call OnRC. This way all cases will be covered, including if cleanup works as expected on the client.\n\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby",
         "technical_debt",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Create a more complex IT for cold standby"
   },
   {
      "_id": "13102494",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-15 08:00:45",
      "description": "With the new feature which allows chunking in blob transfer between server and client, there are various places in which more meaningful log messages could be used. For example, on the server, there's a tally of the no. of chunks sent/total no. of chunks, but this part is missing on the client, i.e. no. of chunks received/total no. of chunks. \n\nAnother case which would benefit from improved logging is when a big blob can't be sent fully from the server to the client in {{readTimeoutMs}}. The current exception message is a bit scarce in details (e.g. {{\"Unable to load remote blob \" + blobId + \" at \" + path + \"#\" + pName}}). This could also mean that the remote blob doesn't exist on the server in the first place. A better option would be to advise about increasing {{readTimeoutMs}}.\n\nFinally, the same log level should be used everywhere, since currently {{DEBUG}} and {{INFO}} are  interchangeably mixed.\n\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve cold standby logging"
   },
   {
      "_id": "13102284",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-14 15:14:12",
      "description": "{{StandbyDiff}} still makes use of the {{logOnly}} property for deciding when to act upon node/property changes. The official documentation of {{logOnly}} states that it helps for\n\n{quote}\n/**\n     * read-only traversal of the diff that has 2 properties: one is to log all\n     * the content changes, second is to drill down to properly level, so that\n     * missing binaries can be sync'ed if needed\n     */\n{quote}\n\nbut it's use is a bit misleading. The first call to {{StandbyDiff}} is always with {{logOnly==false}}, while subsequent calls are done with {{logOnly==true}}. Implementing {{StandbyDiff}} without this mechanism would result in better clarity and maintainability.\n\nAnother minor improvement is to rename {{#binaryCheck}} methods and {{#readBinary}} to {{#fetchBinary}} and {{#fetchAndStoreBlob}} which is more appropriate to their purpose.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Refactor StandbyDiff for better clarity and understandability"
   },
   {
      "_id": "13102249",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-09-14 13:06:16",
      "description": "Move the DocumentNodeStore implementation and the two backends (MongoDB, RDB) into its own bundle. This will make it possible to release oak-core and the NodeStore implementation independently.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move DocumentNodeStore into its own bundle"
   },
   {
      "_id": "13101964",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-13 13:40:25",
      "description": "As already explained in OAK-6659, there can be cases in which deleting the previous spool file fails (Windows) and new (duplicate) content is added under the hood to the old file. This way the persisted blob doesn't match in content and id with the original sent by the server.\n\nA first improvement here is to not allow the decoding to continue if the old spool file cannot be deleted. For this, the call to {{File#delete}} needs to be replaced with {{java.nio.file.Files#delete}} which would throw an exception if something wrong happens.\n\nBy ensuring that the spool file has the same size as the original blob we solve this problem. This check is sufficient, since all the chunks received are individually checked by hash, before appending them to the spool file. Moreover, the single threaded nature of the client ensures that races in which a new thread starts appending new content, after the length check has just passed can never happen.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ResponseDecoder should check that the length of the received blob matches the length of the sent blob"
   },
   {
      "_id": "13101940",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-13 12:12:40",
      "description": "Due to changes done in OAK-4969, currently there are two 'sync blob' cycles triggered by {{StandbyDiff#childNodeChanged}}. The test scenario is the same as the one in {{DataStoreTestBase#testSyncBigBlob}}: on the primary file store, a new big blob (1GB) is added and then a standby sync is triggered to sync this content to the secondary file store. \n\nThe first 'sync blob' cycle happens as a result of {{#process}} being called in {{StandbyDiff#childNodeChanged}}. Therefore, a new 'get blob' request is created on the client and the server starts sending chunks from the big blob. Now, if the time needed for transferring the entire blob from server to client exceeds {{readTimeoutMs}} an {{IllegalStateException}} will be correctly thrown by {{StandbyDiff#readBlob}}, but will be swallowed by the {{StandbyDiff#childNodeChanged}} in its catch clause. A second 'sync blob' cycle will be triggered and, -this might succeed with the same {{readTimeoutMs}} for which it was failing before-, if {{readTimeoutMs * 2}} is enough, the blob will be synced on the standby. This happens because the server will continue sending the remaining chunks after {{IllegalStateException}} was thrown (first 'sync blob' cycle).\n\nThe consequence of these two 'sync blob' cycles is that sometimes, deleting the temporary file to which chunks are spooled to on the client fails (see Windows for example and OAK-6641 specifically). This way, instead of deleting the previous incomplete transfer, new chunks from the second 'sync blob' cycle are added. The blob persisted in the blob store on the client won't have the same size and id as the initial blob sent by the server.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Cold standby should fail loudly when a big blob can't be timely transferred"
   },
   {
      "_id": "13101632",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-12 12:46:53",
      "description": "Currently the standby server sends an un-persisted head record to clients. Under normal circumstances, the TarMK flush thread is able to persist it and its corresponding segment at a 5 seconds interval.\nHowever, there are cases (uploading a very large blob > 10 GB) in which the flush thread writes the segment too late, and the 20s allowed by {{FileStoreUtil#readSegmentWithRetry}} are not enough. Therefore the server can't read the segment containing the head record and a timeout occurs on the client.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Standby server must always send the persisted head to clients"
   },
   {
      "_id": "13101295",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-11 15:03:38",
      "description": "{noformat}\nRunning org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@6bb75258\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@5b04476e\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@5b04476e\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@5b04476e\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nTests run: 4, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 18.543 sec <<< FAILURE! - in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\noffRCUpgradesSegments(org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT)  Time elapsed: 5.578 sec  <<< FAILURE!\njava.lang.AssertionError: Segment version mismatch. Expected V_13, found V_12 expected:<V_13> but was:<V_12>\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.checkSegmentVersion(UpgradeIT.java:143)\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.offRCUpgradesSegments(UpgradeIT.java:109)\n\n\nResults :\n\nFailed tests:\n  UpgradeIT.offRCUpgradesSegments:109->checkSegmentVersion:143 Segment version mismatch. Expected V_13, found V_12 expected:<V_13> but was:<V_12>\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "test failure seen in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT"
   },
   {
      "_id": "13101189",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-11 08:00:52",
      "description": "Backport the fix from OAK-6110 to the 1.6 branch.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc",
         "memory",
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Backport OAK-6110 to 1.6 (Offline compaction uses too much memory)"
   },
   {
      "_id": "13100831",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-08 14:38:13",
      "description": "{noformat}\nTests run: 10, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 99.858 sec <<< FAILURE! - in org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT\ntestSyncBigBlob(org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT)  Time elapsed: 71.122 sec  <<< ERROR!\njava.lang.RuntimeException: Error occurred while obtaining InputStream for blobId [8098b6ac1491be80b7e58a85767ede178c432866d90caf6726f556406ecc84a4#1073741824]\nCaused by: java.io.IOException: org.apache.jackrabbit.core.data.DataStoreException: Record 8098b6ac1491be80b7e58a85767ede178c432866d90caf6726f556406ecc84a4 does not exist\nCaused by: org.apache.jackrabbit.core.data.DataStoreException: Record 8098b6ac1491be80b7e58a85767ede178c432866d90caf6726f556406ecc84a4 does not exist\n\n{noformat}\n\n(might be specific to Windows)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "test failure in org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT"
   },
   {
      "_id": "13100451",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-07 12:57:33",
      "description": "When the memory requirements for running OnRC are not met before the estimation phase the estimator will run nevertheless. The process will only be cancelled at the beginning of the compaction phase. The entries in the log file reflect this:\n\n{code}\nTarMK GC #1: canceling compaction because available memory level 306.4 MB (306395472 bytes) is too low...\nTarMK GC #1: estimation started\nTarMK GC #1: estimation completed in 343.5 ms (343 ms). Estimation skipped because of missing gc journal data (expected on first run)\nTarMK GC #1: running full compaction\nTarMK GC #1: compaction started ...\nTarMK GC #1: unable to estimate number of nodes for compaction, missing gc history.\nTarMK GC #1: compaction cancelled: Not enough memory.\nTarMK GC #1: cleaning up after failed compaction\n{code}\n\nHowever they can easily be (mis-)read as compaction being re-triggered after having been cancelled and then being cancelled again. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Confusing log entries when memory requirements are not met at start of OnRC"
   },
   {
      "_id": "13100448",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-09-07 12:44:47",
      "description": "oak-upgrade should support azuredatastore in addition to s3",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "azureblob"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "[upgrade] oak-upgrade should support azure blobstorage"
   },
   {
      "_id": "13100402",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332917",
            "id": "12332917",
            "name": "blob-cloud"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332555",
            "id": "12332555",
            "name": "blob-plugins",
            "description": "Oak Blob Plugins"
         }
      ],
      "created": "2017-09-07 08:45:39",
      "description": "Parent task for removing older code relying on JR2 caching.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove unused datastore code relying on JR2 data store caching"
   },
   {
      "_id": "13100179",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-09-06 15:20:58",
      "description": "The backup command in oak-run should not accidentally perform a transparent upgrade of the FileStore. Instead, it should use a strict version check to fail fast if the code is run on an outdated version of the FileStore.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "production",
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "The backup command should not silently upgrade the FileStore"
   },
   {
      "_id": "13100178",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-06 15:16:36",
      "description": "We should remove the {{StandbyStoreService#BLOB_CHUNK_SIZE}} OSGi configuration and replace it with a feature flag. Rational: we expect customer to rarely change this thus not justifying the additional configuration complexity and testing overhead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby",
         "configuration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Replace standby blob chunk size configuration with feature flag"
   },
   {
      "_id": "13100175",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-06 15:09:40",
      "description": "The transparent upgrade feature for segments from version 12 to 13 should not cause \"accidental upgrades\". That is, running Oak 1.8 oak-run compact on a store with segment version 12 should bail out unless a special option was specified on the command line. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid oak-run compact inadvertently upgrading the segment format "
   },
   {
      "_id": "13099813",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-05 11:47:22",
      "description": "If this fixture is chosen, a cold standby instance will be started, syncing with the primary every {{n}} seconds. All the benchmarks specified via {{[testcases]}} argument will be run on primary instance, and all statistics and reports will be linked to primary.\n\nThis could work similarly to {{Oak-Segment-Tar-DS}} and have dedicated options like {{--no-data-store}}, {{--private-data-store}} or {{--shared-data-store}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add new segment-tar fixture for attaching a cold-standby to benchmarked primary"
   },
   {
      "_id": "13099592",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-09-04 11:50:59",
      "description": "For OAK-6353 we need to know all bundled nodestate in a given parent. For this purpose we should provide following method in DocumentNodeState\n\n{code}\npublic Iterable<DocumentNodeState> getBundledNodesStates() {\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Provide list of all bundled nodes within a given DocumentNodeState"
   },
   {
      "_id": "13098847",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-31 11:45:38",
      "description": "{{BulkTransferBenchmark}} should be moved from {{oak-segment-tar}} to {{oak-benchmarks}} to allow standard run of this cold standby related benchmark.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move BulkTransferBenchmark to oak-benchmarks module"
   },
   {
      "_id": "13098793",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-31 07:52:15",
      "description": "BulkTransferBenchmark might improperly dispose of test resources if error conditions occur. This is mostly due to improper resource tracking and finalization in BenchmarkBase, but similar mistakes have been made in BulkTransferBenchmark too.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve resource management in BulkTransferBenchmark"
   },
   {
      "_id": "13098752",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-31 07:00:26",
      "description": "The {{SegmentWriteOperation.isOldGeneration()}} predicate includes some segments that are not \"old\". This leads to more deferred compaction operations than strictly necessary. The affected segments are those generated by tail compaction. Tail compaction created segments should only be included in the predicate once they are from another full compaction operation. Otherwise referencing such segments is fine as they will not be reclaimed in a cleanup following a tail compaction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentWriteOperation.isOldGeneration() too eager"
   },
   {
      "_id": "13098388",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-08-29 20:58:32",
      "description": "I mentioned that properties that got indexed due to an aggregation are not considered for excerpts (highlighting) as they are not indexed as stored fields.\r\n\r\nSee the attached patch that implements a test for excerpts in {{LuceneIndexAggregationTest2}}.\r\n\r\nIt creates the following structure:\r\n\r\n{code}\r\n/content/foo [test:Page]\r\n + bar (String)\r\n - jcr:content [test:PageContent]\r\n  + bar (String)\r\n{code}\r\n\r\nwhere both strings (the _bar_ property at _foo_ and the _bar_ property at _jcr:content_) contain different text. \r\n\r\nAfterwards it queries for 2 terms (\"tinc*\" and \"aliq*\") that either exist in _/content/foo/bar_ or _/content/foo/jcr:content/bar_ but not in both. For the former one the excerpt is properly provided for the later one it isn't.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "excerpt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "rep:excerpt not working for content indexed by aggregation in lucene"
   },
   {
      "_id": "13097912",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-28 08:48:54",
      "description": "When {{UpgradeIT}} is executed, the following output is produced.\n\n{noformat}\nRunning org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@75e01201\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@75e01201\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@75e01201\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nTests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.17 sec - in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\n{noformat}\n\nThe test should not produce any output, especially such a useless one.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "UpgradeIT produces unwanted output"
   },
   {
      "_id": "13097268",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-24 08:49:36",
      "description": "h3. Current situation\nCurrent segment store related tools are implemented ad-hoc by potentially relying on internal implementation details of Oak Segment Tar. This makes those tools less useful, portable, stable and potentially applicable than they should be.\n\nh3. Goal\nProvide a common and sufficiently stable Oak Tooling API for implementing segment store related tools. The API should be independent of Oak and not available for normal production use of Oak. Specifically it should not be possible to it to implement production features and production features must not rely on it. It must be possible to implement the Oak Tooling API in Oak 1.8 and it should be possible for Oak 1.6.\n\nh3. Typical use cases\n* Query the number of nodes / properties / values in a given path satisfying some criteria\n* Aggregate a certain value on queries like the above\n* Calculate size of the content / size on disk\n* Analyse changes. E.g. how many binaries bigger than a certain threshold were added / removed between two given revisions. What is the sum of their sizes?\n* Analyse locality: measure of locality of node states. Incident plots (See https://issues.apache.org/jira/browse/OAK-5655?focusedCommentId=15865973&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15865973).\n* Analyse level of deduplication (e.g. of checkpoint) \n\nh3. Validation\nReimplement [Script Oak|https://github.com/mduerig/script-oak] on top of the tooling API. \n\nh3. API draft\n* Whiteboard shot of the [API entities|https://wiki.apache.org/jackrabbit/Oakathon%20August%202017?action=AttachFile&do=view&target=IMG_20170822_163256.jpg] identified initially.\n* Further [drafting of the API|https://github.com/mduerig/oak-tooling-api] takes place on Github for now. We'll move to the Apache SVN as soon as considered mature enough and have a consensus of where to best move it. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add tooling API"
   },
   {
      "_id": "13096992",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-08-23 11:04:18",
      "description": "Similar to OAK-4637 but for lucene indexes\n\nIn some cases, property indexes contain many nodes, and updating them can be slow. Right now we have filters for node and mixin types, path (include and exclude). \n\nAn include and exclude list of values (patterns) would be useful. For example the property \"status\", if we only ever run queries with the condition \"status = 'ACTIVE'\", then nodes with status INACTIVE and DONE don't need to be indexed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Lucene index: include/exclude key pattern list"
   },
   {
      "_id": "13096362",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-21 08:07:14",
      "description": "After netty update in OAK-6564, {{OSGiIT}} fails with the following exception:\n\n{code}\nRunning org.apache.jackrabbit.oak.osgi.OSGiIT\nERROR: Bundle org.apache.jackrabbit.oak-segment-tar [36] Error starting file:/oak-it-osgi/target/test-bundles/oak-segment-tar.jar (org.osgi.framework.BundleException: Unresolved constraint in bundle org.apache.jackrabbit.oak-segment-tar [36]: Unable to resolve 36.0: missing requirement [36.0] osgi.wiring.package; (osgi.wiring.package=com.ning.compress))\norg.osgi.framework.BundleException: Unresolved constraint in bundle org.apache.jackrabbit.oak-segment-tar [36]: Unable to resolve 36.0: missing requirement [36.0] osgi.wiring.package; (osgi.wiring.package=com.ning.compress)\n\tat org.apache.felix.framework.Felix.resolveBundleRevision(Felix.java:3974)\n\tat org.apache.felix.framework.Felix.startBundle(Felix.java:2037)\n\tat org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1291)\n\tat org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:304)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix OSGi wiring after netty update to 4.1.x"
   },
   {
      "_id": "13095635",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-18 13:31:33",
      "description": "{{GetBlobResponseEncoder}} writes too fast all the chunks, leaving the channel in a not-writable state, after the first write. The problem is not visible at a first glance, especially when using small blobs for testing. Increasing the blobs size, as done for OAK-6538, revealed the problem. Not only this triggers hidden {{OutOfMemory}} errors on either server or client, but sometimes incomplete blobs are sent along, which are interpreted by the client as valid.\n\nA more elegant solution, which also solves the memory consumption problem, would be to use {{ChunkedWriteHandler}} which employs complex logic on how and when to write the chunks. {{ChunkedWriteHandler}} must be used in conjunction with a custom {{ChunkedInput<ByteBuf>}} implementation to generate {{header}} + {{payload}} chunks from an {{InputStream}}, as done currently. This way the server will send more chunks only when the previous one was consumed by the client.\n\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "GetBlobResponseEncoder should not write all chunks at once"
   },
   {
      "_id": "13095632",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-18 13:16:06",
      "description": "Taking into account the improvements listed at [0], and also the individual issues solved since our current netty version (4.0.41.Final) was released, I propose to bump up netty version to latest 4.1.14.Final.\n\n/cc [~frm]\n\n[0] http://netty.io/wiki/new-and-noteworthy-in-4.1.html ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update netty dependency to 4.1.x"
   },
   {
      "_id": "13094761",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-15 13:41:37",
      "description": "Running offline gc currently adds an entry to the {{gc.log}} with a {{NULL}} record id. We should improve this and record the record id of the compacted root node state. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "gc.log should contain recordId of compacted root after offline compaction"
   },
   {
      "_id": "13094728",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-15 10:23:24",
      "description": "We need basic IT coverage for the rolling upgrade scenario from Oak 1.6. to Oak 1.8. See OAK-6531.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "IT",
         "migration",
         "test",
         "upgrade"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement ITs for rolling upgrade"
   },
   {
      "_id": "13094458",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-14 12:53:07",
      "description": "We should implement a basic progress indicator for compaction displaying percent completed. This could be done by estimating the number of nodes from the entries in the {{gc.log}} and the timestamp of the last entry in the {{journal.log}}. Such a feature would explicitly *not* give an ETA as too many factors have an impact here (concurrent activity, IO bandwidth, quota, etc.).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc",
         "operation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Progress indicator for compaction "
   },
   {
      "_id": "13094046",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-11 08:28:48",
      "description": "The {{gcType}} property should move from the {{FileStore}} class to the {{SegmentGCOptions}} along with all other GC related properties. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move gcType to SegmentGCOptions"
   },
   {
      "_id": "13093446",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-09 12:03:56",
      "description": "In an investigation from some time ago, 4GB of heap were needed for transferring 1GB blob and 6GB for 2GB blob. This was in part due to using {{addTestContent}} [0] in the investigation, which allocates a huge {{byte[]}} on the heap. \n\nOAK-5902 introduced chunking for transferring blobs between primary and standby. This way, the memory needed for syncing a big blob should be around the chunk size used. Solving the way test data is created, it should be possible to transfer a big blob (e.g. 2.5 GB) with less memory.\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/test/java/org/apache/jackrabbit/oak/segment/standby/DataStoreTestBase.java#L96",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Investigate cold standby memory consumption "
   },
   {
      "_id": "13093176",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-08 14:18:38",
      "description": "The segment format changes introduced for tail compaction (OAK-3349) must not require an explicit migration step. Instead there should be a rolling migration during normal operation. \n\nThings to consider:\n* Segments from Oak 1.6\n* Changes in tar index formats induced by the segment format changes\n* Changes in gc.log induced by the segment format changes\n* Required changes in the repository manifest and its interpretation\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "migration",
         "upgrade"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement rolling upgrade from Oak 1.6"
   },
   {
      "_id": "13092516",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2017-08-04 16:23:08",
      "description": "Slow queries (that traverse many nodes, load many nodes in memory, and those that don't use an index) are currently logged. It would be better if there is a way to retrieve at least the _number_ of slow queries (for example from the last seconds / minutes / hours / days), if there were any. Plus maybe the queries themselves, and the type of problem / how severe the problem was.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation-update"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Slow queries: ability to track them via JMX"
   },
   {
      "_id": "13092410",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-04 08:35:16",
      "description": "{{OnlineCompactor}} needs more unit test coverage going forward. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement unit tests for OnlineCompactor"
   },
   {
      "_id": "13092407",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-04 08:31:38",
      "description": "This is a follow up to OAK-3349: in tail compaction the {{FileStore.GarbageCollector.getBase()}} might fail to determine the base state to rebase onto. In this case we should fall back to full compaction and report (log, JMX) the problem and its exact cause. \n\nFailing to determine the base state might be caused by a missing or invalid {{gc.log}} file or a invalid or missing record id for the base state being recorded in {{gc.log}}. None of these cases should impact system stability. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve tail compactions resilience when base state cannot be determined"
   },
   {
      "_id": "13092402",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-04 08:20:22",
      "description": "This is a follow up to OAK-3349, which introduced tail compactions:\n\nThe deduplication caches currently only take the full generations into account and ignore the tail generations. Cache generations need to be a monotonically increasing, ordered sequence consisting of the full and tail part of the gc generation. See {{FileStoreBuilder.EvictingWriteCacheManager.evictOldGeneration}}. Optimally we find a way to decouple the segment generation from the cache generations as these are really separate concerns. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Properly handle tail compactions in deduplication caches"
   },
   {
      "_id": "13087518",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-07-17 09:16:24",
      "description": "The indexing tooling implemented in OAK-6081 can be used to perform reindex and import the indexes for any Oak 1.7+ setups. For older setups we would be using 2 phase approach\n\n# Perform [out-of-band indexing|https://jackrabbit.apache.org/oak/docs/query/oak-run-indexing.html#out-of-band-indexing]. This can be done via oak-run from 1.7.x against any older version of Oak\n# Import index - For this step we cannot use oak-run from trunk for older branches as write operations would not be compatible with older version of Oak. \n\nFor import then we have 2 options either \n# backport all the work in OAK-6271 to older branch \n# OR implement a script which can be used with oak-run or Felix Script Console to just import the lucene index with any other manual step\n\nPurpose of this task is to implement such a script\n\nNote - The proposed script is meant to be run from within running Oak server using Felix Script Console [1]. This is required as older version of oak-run do not support all types of BlobStores\n\n[1] http://felix.apache.org/documentation/subprojects/apache-felix-script-console-plugin.html\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Script to import oak-run generated indexing to older Oak setup"
   },
   {
      "_id": "13085141",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-07-06 09:17:41",
      "description": "In OAK-4732 the 50th percentile of the last 1000 commits is used as wait time before returning the current root. In order to parametrise the value of the percentile, it would be nice to have a new feature flag, e.g. {{oak.scheduler.head.lockWaitPercentile}}. Setting it to {{0}} would basically disable this. Setting it to a different value might be interesting in future experiments.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add flag for controlling percentile of commit time used in scheduler"
   },
   {
      "_id": "13083453",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2017-06-29 12:57:07",
      "description": "now that OAK-6304 and OAK-6355 have been resolved, i would like to suggest that we move the _o.a.j.oak.spi.query_ code base into a separate module/bundle in order to prevent the introduction of bogus cycles and odd package exports in the future.\n\n[~tmueller], patch will follow asap.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": " Refactor oak.spi.query into a separate module/bundle "
   },
   {
      "_id": "13083418",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-29 10:24:16",
      "description": "Some of the constants in the {{Segment}} class still refer to the old 255 segment references limit. We should fix the comments, the constants and their usage to reflect the current situation where that limit has been lifted. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cleanup constants in Segment class"
   },
   {
      "_id": "13082516",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-26 14:20:44",
      "description": "Currently monitoring is of the deduplication caches is hard wired into the cache manager. It would be cleaner (and is in fact a pre-requisite for OAK-5790) to decouple the monitoring from the caches. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor monitoring of deduplication caches"
   },
   {
      "_id": "13081072",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-20 10:18:03",
      "description": "{{oak-run check}} does currently *not* traverse and check the items in the checkpoint. I think we should change this and add an option to traverse all, some or none of the checkpoints. When doing this we need to keep in mind the interaction of this new feature with the {{filter}} option: the paths passed through this option need then be prefixed with {{/root}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "oak-run check should also check checkpoints "
   },
   {
      "_id": "13079958",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2017-06-15 04:47:45",
      "description": "Currently if multiple indexes compete for same query i.e. they report cost > 0 and less than infinity then the log output is confusing. For e.g. for a query like\n\n{noformat}\nQueryEngineImpl Parsing xpath statement: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')]\nQueryEngineImpl XPath > SQL2: select [jcr:path], [jcr:score], * from [dam:Asset] as a where contains(*, 'foo.png') and isdescendantnode(a, '/content/dam') /* xpath: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')] */\nQueryImpl cost using filter Filter(query=select [jcr:path], [jcr:score], * from [dam:Asset] as a where contains(*, 'foo.png') and isdescendantnode(a, '/content/dam') /* xpath: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')] */ fullText=\"foo.png\", path=/content/dam//*)\nQueryImpl cost for aggregate lucene is 2.2424751E7\nQueryImpl cost for lucene-property[/oak:index/index-a][/oak:index/index-b] is 146914.0\nQueryImpl cost for reference is Infinity\nQueryImpl cost for ordered is Infinity\nQueryImpl cost for nodeType is Infinity\nQueryImpl cost for property is Infinity\nQueryImpl cost for traverse is Infinity\nQueryImpl query execute select [jcr:path], [jcr:score], * from [dam:Asset] as a where contains(*, 'foo.png') and isdescendantnode(a, '/content/dam') /* xpath: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')] */\nQueryImpl query plan [dam:Asset] as [a] /* lucene:index-b(/oak:index/index-b) +(((...) +:ancestors:/content/dam ft:(\"foo.png\") where (contains([a].[*], 'foo.png')) and (isdescendantnode([a], [/content/dam])) */\nQueryImpl query execute select [jcr:path], [jcr:score], * from [dam:Asset] as a where contains(*, 'foo.png') and isdescendantnode(a, '/content/dam') /* xpath: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')] */\nQueryImpl query plan [dam:Asset] as [a] /* lucene:index-b(/oak:index/index-b) +(((...)) +:ancestors:/content/dam ft:(\"foo.png\") where (contains([a].[*], 'foo.png')) and (isdescendantnode([a], [/content/dam])) */\n{noformat}\n\nHere both index-a and index-b satisfy the query. However from logs it appears that both have same cost. While actually the reported cost is the lowest one which in this case would be for index-b\n\n{noformat}\nQueryImpl cost for lucene-property[/oak:index/index-a][/oak:index/index-b] is 146914.0\n{noformat}\n\nSo as a fix\n* Report cost for multiple plans returned by same index type separately\n* If cost is less than infinity and that plan is eventually not selected then also log its plan. This would help to see why specific plan lost\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve log reporting if multiple indexes compete for same query"
   },
   {
      "_id": "13079441",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-13 10:19:56",
      "description": "Recently we saw OutOfMemory using [oakRepoStats|https://github.com/chetanmeh/oak-console-scripts/tree/master/src/main/groovy/repostats] script with a SegmentNodeStore setup where uuid index has 16M+ entries and thus creating a very flat hierarchy. This happened while computing Tree#getChildren iterator which internally invokes MapRecord#getKeys to obtain an iterable for child node names.\n\nThis happened because code in getKeys computes the key list eagerly by calling bucket.getKeys() which recursivly calls same for each child bucket and thus resulting in eager evaluation.\n{code}\n        if (isBranch(size, level)) {\n            List<MapRecord> buckets = getBucketList(segment);\n            List<Iterable<String>> keys =\n                    newArrayListWithCapacity(buckets.size());\n            for (MapRecord bucket : buckets) {\n                keys.add(bucket.getKeys());\n            }\n            return concat(keys);\n        }\n{code}\n\nInstead here we should use same approach as used in MapRecord#getEntries i.e. evalate the iterable for child buckets lazily\n{code}\n        if (isBranch(size, level)) {\n            List<MapRecord> buckets = getBucketList(segment);\n            List<Iterable<MapEntry>> entries =\n                    newArrayListWithCapacity(buckets.size());\n            for (final MapRecord bucket : buckets) {\n                entries.add(new Iterable<MapEntry>() {\n                    @Override\n                    public Iterator<MapEntry> iterator() {\n                        return bucket.getEntries(diffKey, diffValue).iterator();\n                    }\n                });\n            }\n            return concat(entries);\n        }\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MapRecord#getKeys should should initialize child iterables lazily"
   },
   {
      "_id": "13078419",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 20:07:22",
      "description": "There is a few places where this annotation is missing and should be added.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add missing @Nonnull annotations"
   },
   {
      "_id": "13078418",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 20:05:32",
      "description": "Remove the throws clause for the {{IOException}}, which never thrown.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Closeable.close in StandbyStoreService declares exception that is never thrown"
   },
   {
      "_id": "13078417",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 20:03:08",
      "description": "Remove the throws clause for the {{InterruptedException}}, which never thrown.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "LockBasedScheduler.execute declares exception that is never thrown"
   },
   {
      "_id": "13078414",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 20:00:12",
      "description": "Immutable fields should be final",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Declare immutable field of FileStore.CompactionResult final"
   },
   {
      "_id": "13078413",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 19:57:31",
      "description": "The field is immutable and should thus be declared final.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Declare StandbyStoreService.closer final"
   },
   {
      "_id": "13078412",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 19:55:13",
      "description": "That field is only used in the constructor an can thus be converted to a local variable. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Convert FileStore.maxFileSize fiels into local variable"
   },
   {
      "_id": "13078411",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 19:52:30",
      "description": "That field is not used any more since the explicit commit queue was introduced. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove unused field SegmentNodeStore.reader"
   },
   {
      "_id": "13076144",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-05-31 09:34:10",
      "description": "This is a leftover from when we switched from record ids to record numbers as at that point it became unnecessary to track such references. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Unreferenced argument reference in method SegmentBufferWriter.writeRecordId"
   },
   {
      "_id": "13076114",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332555",
            "id": "12332555",
            "name": "blob-plugins",
            "description": "Oak Blob Plugins"
         }
      ],
      "created": "2017-05-31 07:24:22",
      "description": "Jenkins CI failure: https://builds.apache.org/view/J/job/Jackrabbit%20Oak/\n\nFailed run: [Jackrabbit Oak #357|https://builds.apache.org/job/Jackrabbit%20Oak/357/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/357/console]\n\nInitially reported by @Hudson with OAK-6275. See https://issues.apache.org/jira/browse/OAK-6275?focusedCommentId=16029669&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16029669\n\n{noformat}\nRegression\n\norg.apache.jackrabbit.oak.plugins.blob.UploadStagingCacheTest.testUpgrade\nFailing for the past 1 build (Since Failed#357 )\nTook 5.3 sec.\nadd description\nError Message\n\nexpected null, but was:<target/junit454362693043657302/junit3108871978195343785/upload/12/34/50/123450>\n\nStacktrace\n\njava.lang.AssertionError: expected null, but was:<target/junit454362693043657302/junit3108871978195343785/upload/12/34/50/123450>\n\tat org.apache.jackrabbit.oak.plugins.blob.UploadStagingCacheTest.testUpgrade(UploadStagingCacheTest.java:608)\n\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: UploadStagingCacheTest.testUpgrade"
   },
   {
      "_id": "13076111",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-05-31 07:21:12",
      "description": "Jenkins CI failure: https://builds.apache.org/view/J/job/Jackrabbit%20Oak/\n\nThe build Jackrabbit Oak #356 has failed.\nFirst failed run: [Jackrabbit Oak #356|https://builds.apache.org/job/Jackrabbit%20Oak/356/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/356/console]\n\n(Initially reported by @Hudson with OAK-6275)\n\n{noformat}\nRegression\n\norg.apache.jackrabbit.oak.upgrade.cli.JdbcToSegmentTest.validateMigration\nFailing for the past 1 build (Since Failed#356 )\nTook 1 min 1 sec.\nadd description\nError Message\n\nFailed to copy content\n\nStacktrace\n\njavax.jcr.RepositoryException: Failed to copy content\nCaused by: java.lang.IllegalStateException: Branch with failed reset\nCaused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakOak0100: Branch reset failed\nCaused by: org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: Empty branch cannot be reset\n\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: JdbcToSegmentTest.validateMigration"
   },
   {
      "_id": "13074194",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-05-23 13:10:44",
      "description": "Regression\n\norg.apache.jackrabbit.oak.plugins.document.VersionGCTest.gcMonitorInfoMessages\nFailing for the past 1 build (Since Failed#330 )\nTook 28 ms.\nError Message\n\nexpected:<3> but was:<7>\n\nStacktrace\n\njava.lang.AssertionError: expected:<3> but was:<7>\n\tat org.apache.jackrabbit.oak.plugins.document.VersionGCTest.gcMonitorInfoMessages(VersionGCTest.java:224)\n\nFailed run: [Jackrabbit Oak #330|https://builds.apache.org/job/Jackrabbit%20Oak/330/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/330/console]\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: VersionGCTest.gcMonitorInfoMessages"
   },
   {
      "_id": "13074117",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-05-23 08:50:07",
      "description": "OAK-5956 improved the statistics collected for the segment cache. As I expected this had an impact on performance as measured by our micro benchmarks. An impact is visible for {{ConcurrentReadTest}}, {{ConcurrentReadWriteTest}} and {{ConcurrentWriteTest}}. Impact on full stack operation is yet to be determined (I assume it is neglectable though). \n\n{noformat}\n# ConcurrentReadTest               C     min     10%     50%     90%     max       N \nOak-Segment-Tar (base)             1      43     101     112     129     219     525\nOak-Segment-Tar (OAK-5956)         1      45     104     118     138     264     496\n{noformat}\n\nThe impact seems to be mostly caused by the {{SegmentId.onAccess}} callback. \n\nPossible solutions:\n* Replace the {{SegmentId.onAccess}} callback with a direct reference to the underlying counter. \n* Allow disabling of the cache statistics. \n* Do nothing and accept the performance impact. \n\nThe first approach is least attractive as it breaks encapsulation. Depending on the impact of this on full stack operations I'd either go with the 2nd or 3rd option.  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Minor performance impact by collecting data for SegmentCache statistics "
   },
   {
      "_id": "13073321",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-05-19 04:09:00",
      "description": "Seondary NodeStore feature (OAK-4180) currently creates the secondary NodeStore upon initialization. This may take long time for existing repo. To simplify that we should add support in sidegrade to migrate an existing DocumentNodeStore setup to Secondary NodeStore\n\nThis would also allow us to use the sidegraded repository as a clone of existing repository with the advantage that it would support incremental updates. Currently if a repository is cloned it does not support incremental update as NodeState comparison is done based on default implementation (actual comparison) as it cannot make use of recordId or revision to optimize the diff to determine trees which are not changed between source and target",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Sidegrade support for DocumentNodeStore to Secondary NodeStore"
   },
   {
      "_id": "13073003",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2017-05-18 03:57:56",
      "description": "- Rename config to be used for S3 to s3.config mirroring the azure.config used for Azure\n- Closing InputStream",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Minor cleanup for S3 tests"
   },
   {
      "_id": "13072474",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-05-16 14:43:19",
      "description": "For implementing OAK-2808 (eager/unsafe blob garbage collection approach), we need a way for nodestores to expost last safe timestamp such that blobs deleted before that timestamp can be eagerly collected (uniqueness of blob and that it won't be resurrected elsewhere is assumed to be guaranteed elsewhere e.g. OakDirectory's blobs have randomly generated bytes as content).\n\nWhat we want to ensure in this task is that the garbage collection shouldn't collect stuff that could still be retrieved back - for example checkpoints.\n\n[~chetanm] suggested that it might be an overkill to have this API in NodeStore - but maybe, it's ok to expose it in NodeStore mbean (where the impl specific mbeans known implementation detail of the nodestore to expose such data).\nThe mbean just needs to expose the safe oldest timestamp (UTC epoch!?).\n\nAnother thing that is potentially done in repositories (albeit not really supported afaik) is rolling back repository head state by say offline journal edit.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "datastore",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "There should be a way to retrieve oldest timestamp to keep from nodestores"
   },
   {
      "_id": "13070838",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-05-10 14:52:02",
      "description": "Before 1.6 {{oak-run compact}} had a way to explicitly enable/disable memory mapping of the tar files. Somehow this got lost in {{oak-segment-tar}}. \n\nWe need to add this back as e.g. on Windows memory mapping does not work well and we need to be able to explicitly disable it. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run compact should have an option to disable/enable memory mapping"
   },
   {
      "_id": "13070389",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-05-09 11:52:33",
      "description": "When the file store is shut down during gc compaction is properly aborted. Afterwards it will trigger a cleanup cycle though, which runs concurrently to the proceeding shutdown potentially causing an {{ISE}}:\n\n{noformat}\nat com.google.common.base.Preconditions.checkState(Preconditions.java:134)\nat org.apache.jackrabbit.oak.segment.file.TarWriter.close(TarWriter.java:333)\nat org.apache.jackrabbit.oak.segment.file.TarWriter.createNextGeneration(TarWriter.java:376)\nat org.apache.jackrabbit.oak.segment.file.FileStore.newWriter(FileStore.java:682)\nat org.apache.jackrabbit.oak.segment.file.FileStore.access$1700(FileStore.java:100)\nat org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.cleanup(FileStore.java:1069)\nat org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.cleanupGeneration(FileStore.java:1195)\nat org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.run(FileStore.java:803)\nat org.apache.jackrabbit.oak.segment.file.FileStore.gc(FileStore.java:387)\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "IllegalStateException when closing the FileStore during garbage collection"
   },
   {
      "_id": "13069938",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2017-05-08 10:17:29",
      "description": "The set returned by {{MongoMissingLastRevSeeker.getCandidates()}} may be incomplete. See also discussion in OAK-4535 and on [oak-dev|https://lists.apache.org/thread.html/36ade745b7f6a0417aab578c21ca9fb072a7d6e5c43c724b85a153bf@%3Coak-dev.jackrabbit.apache.org%3E].",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MongoMissingLastRevSeeker may return incomplete candidate set"
   },
   {
      "_id": "13069223",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2017-05-04 17:44:42",
      "description": "There is no unit test coverage for {{IOUtils.humanReadableByteCount}} in {{oak-commons}}.\n\nI will add a patch shortly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "unit-test-missing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add unit test coverage for IOUtils.humanReadableByteCount"
   },
   {
      "_id": "13069198",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-05-04 16:30:46",
      "description": "Jenkins CI failure: https://builds.apache.org/view/J/job/Jackrabbit%20Oak/\n\nThe build Jackrabbit Oak #253 has failed.\nFirst failed run: [Jackrabbit Oak #253|https://builds.apache.org/job/Jackrabbit%20Oak/253/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/253/console]\n\n{code}\njava.lang.AssertionError: expected:<[INITIALIZING, COLLECTING, UPDATING, SPLITS_CLEANUP, IDLE]> but was:<[INITIALIZING, COLLECTING, CHECKING, COLLECTING, DELETING, SORTING, DELETING, UPDATING, SPLITS_CLEANUP, IDLE]>\n\tat org.apache.jackrabbit.oak.plugins.document.VersionGCTest.gcMonitorStatusUpdates(VersionGCTest.java:207)\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: VersionGCTest.gcMonitorStatusUpdates"
   },
   {
      "_id": "13069197",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2017-05-04 16:30:26",
      "description": "There is no unit test coverage for {{IOUtils.copy}} in {{oak-commons}}.\n\nI will add a patch shortly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "unit-test-missing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add unit test coverage for IOUtils.copy"
   },
   {
      "_id": "13069132",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2017-05-04 13:02:17",
      "description": "...to extend from {{BlobReferenceIterator}} once OAK-6162 is ready.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor MongoBlobReferenceIterator"
   },
   {
      "_id": "13068885",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2017-05-03 19:04:05",
      "description": "There is no unit test coverage for IOUtils.writeInt(), IOUtils.writeLong(), IOUtils.readInt(), and IOUtils.readLong() in oak-commons.\n\nI am working on a patch and will have one to submit shortly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "easyfix",
         "patch",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add unit test coverage for IOUtils.writeInt/writeLong and IOUtils.readInt/readLong"
   },
   {
      "_id": "13068793",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-05-03 14:40:52",
      "description": "- generic iterator should use {{Utils.getSelectedDocuments()}} to obtain iterator\n\n- {{MongoBlobReferenceIterator}} should just extend {{BlobReferenceIterator}}, using its own iterator (EDIT: will move this into a separate ticket)\n\n- {{Utils.getSelectedDocuments()}} should allow specifying the batch size",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "BlobReferenceIterator refactoring"
   },
   {
      "_id": "13067389",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2017-04-27 14:05:16",
      "description": "Mirroring {{MongoBlobReferenceIterator}}, using the capabilities added in OAK-5855.\n\n(might lead to refactoring of {{MongoBlobReferenceIterator}})",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Create RDB-specific BlobReferenceIterator"
   },
   {
      "_id": "13065492",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-20 11:36:17",
      "description": "Using offline compaction on a repository with nodes having many direct child node I observed a steady increase of heap usage. This is cause by using a {{MemoryNodeBuilder}} in {{CompactDiff.childNodeAdded()}}, which causes all those child nodes to be cached in memory. \n\nChanging the line\n\n{code}\nchild = EMPTY_NODE.builder();\n{code}\n\nto \n\n{code}\nchild = writer.writeNode(EMPTY_NODE).builder();\n{code}\n\nfixes the problem as the latter returns a {{SegmentNodeBuilder}} where the former returns a {{MemoryNodeBuilder}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "memory",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction uses too much memory "
   },
   {
      "_id": "13065446",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-20 08:59:43",
      "description": "The references of a segment to other segments are cached within {{Segment.readReferencedSegments()}}. However caching the {{SegmentId}} instances themselves leads to excessive heap usage as each id also keeps a reference to its underlying segment. \n\nI suggest to cache those references as msb, lsb pairs instead and create the {{SegmentId}} instance on the fly when required. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Excessive memory usage by the cached segment references"
   },
   {
      "_id": "13065049",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-04-19 10:32:42",
      "description": "Jenkins CI failure: https://builds.apache.org/view/J/job/Jackrabbit%20Oak/\n\nThe build Jackrabbit Oak #182 has failed.\nFirst failed run: [Jackrabbit Oak #182|https://builds.apache.org/job/Jackrabbit%20Oak/182/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/182/console]\n\n{noformat}\nconcurrentGetCached(org.apache.jackrabbit.oak.plugins.blob.CompositeDataStoreCacheTest)  Time elapsed: 0.013 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<2> but was:<1>\n\tat org.apache.jackrabbit.oak.plugins.blob.CompositeDataStoreCacheTest.concurrentGetCached(CompositeDataStoreCacheTest.java:468)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: CompositeDataStoreCacheTest.concurrentGetCached()"
   },
   {
      "_id": "13064749",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12327574",
            "id": "12327574",
            "name": "exercise",
            "description": "Oak Exercises and Training Material"
         }
      ],
      "created": "2017-04-18 15:23:43",
      "description": "building the {{oak-exercise}} module generates warnings due to occupation of same package space:\n\n{quote}\n[WARNING] Bundle org.apache.jackrabbit:oak-exercise:bundle:1.8-SNAPSHOT : Split package, multiple jars provide the same package:org/apache/jackrabbit/oak/security/authentication\nUse Import/Export Package directive -split-package:=(merge-first|merge-last|error|first) to get rid of this warning\nPackage found in   [Jar:., Jar:oak-core, Jar:oak-core]\nClass path         [Jar:., Jar:jcr, Jar:oak-jcr, Jar:oak-core-spi, Jar:oak-store-spi, Jar:oak-api, Jar:oak-core, Jar:oak-blob, Jar:jackrabbit-data, Jar:jcl-over-slf4j, Jar:oak-blob-plugins, Jar:commons-codec, Jar:commons-io, Jar:oak-commons, Jar:oak-auth-external, Jar:jackrabbit-api, Jar:jackrabbit-jcr-commons, Jar:jsr305, Jar:org.apache.felix.scr.annotations, Jar:org.apache.felix.jaas, Jar:org.osgi.core, Jar:org.osgi.compendium, Jar:guava, Jar:slf4j-api, Jar:junit, Jar:hamcrest-core, Jar:mongo-java-driver, Jar:logback-classic, Jar:logback-core, Jar:jul-to-slf4j, Jar:h2, Jar:jackrabbit-jcr-tests, Jar:concurrent, Jar:oak-commons, Jar:oak-jcr, Jar:oak-core, Jar:geronimo-jta_1.0.1B_spec]\n[WARNING] Bundle org.apache.jackrabbit:oak-exercise:bundle:1.8-SNAPSHOT : Split package, multiple jars provide the same package:org/apache/jackrabbit/oak/security/authorization/restriction\nUse Import/Export Package directive -split-package:=(merge-first|merge-last|error|first) to get rid of this warning\nPackage found in   [Jar:., Jar:oak-core, Jar:oak-core]\nClass path         [Jar:., Jar:jcr, Jar:oak-jcr, Jar:oak-core-spi, Jar:oak-store-spi, Jar:oak-api, Jar:oak-core, Jar:oak-blob, Jar:jackrabbit-data, Jar:jcl-over-slf4j, Jar:oak-blob-plugins, Jar:commons-codec, Jar:commons-io, Jar:oak-commons, Jar:oak-auth-external, Jar:jackrabbit-api, Jar:jackrabbit-jcr-commons, Jar:jsr305, Jar:org.apache.felix.scr.annotations, Jar:org.apache.felix.jaas, Jar:org.osgi.core, Jar:org.osgi.compendium, Jar:guava, Jar:slf4j-api, Jar:junit, Jar:hamcrest-core, Jar:mongo-java-driver, Jar:logback-classic, Jar:logback-core, Jar:jul-to-slf4j, Jar:h2, Jar:jackrabbit-jcr-tests, Jar:concurrent, Jar:oak-commons, Jar:oak-jcr, Jar:oak-core, Jar:geronimo-jta_1.0.1B_spec]\n[WARNING] Bundle org.apache.jackrabbit:oak-exercise:bundle:1.8-SNAPSHOT : Split package, multiple jars provide the same package:org/apache/jackrabbit/oak/security/principal\nUse Import/Export Package directive -split-package:=(merge-first|merge-last|error|first) to get rid of this warning\nPackage found in   [Jar:., Jar:oak-core, Jar:oak-core]\nClass path         [Jar:., Jar:jcr, Jar:oak-jcr, Jar:oak-core-spi, Jar:oak-store-spi, Jar:oak-api, Jar:oak-core, Jar:oak-blob, Jar:jackrabbit-data, Jar:jcl-over-slf4j, Jar:oak-blob-plugins, Jar:commons-codec, Jar:commons-io, Jar:oak-commons, Jar:oak-auth-external, Jar:jackrabbit-api, Jar:jackrabbit-jcr-commons, Jar:jsr305, Jar:org.apache.felix.scr.annotations, Jar:org.apache.felix.jaas, Jar:org.osgi.core, Jar:org.osgi.compendium, Jar:guava, Jar:slf4j-api, Jar:junit, Jar:hamcrest-core, Jar:mongo-java-driver, Jar:logback-classic, Jar:logback-core, Jar:jul-to-slf4j, Jar:h2, Jar:jackrabbit-jcr-tests, Jar:concurrent, Jar:oak-commons, Jar:oak-jcr, Jar:oak-core, Jar:geronimo-jta_1.0.1B_spec]\n{quote}\n\nMoving the exercises and the sample code to an _execise_ package space would also make it really obvious that this is not part of the productive code base.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move exercise code to separate packages to avoid build warnings"
   },
   {
      "_id": "13064720",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-04-18 14:17:43",
      "description": "See OAK-6020.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.management.ManagementOperation should use TimeDurationFormatter"
   },
   {
      "_id": "13064699",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2017-04-18 13:32:49",
      "description": "With OAK-2106 Oak now attempts to read from a MongoDB secondary when it detects the requested data is available on the secondary.\n\nWhen multiple Oak cluster nodes are deployed on a MongoDB replica set, many reads are still directed to the primary. One of the reasons why this is seen in practice, are observers and JCR event listeners that are triggered rather soon after a change happens and therefore read recently modified documents. This makes it difficult for Oak to direct calls to a nearby secondary, because changes may not yet be available there.\n\nA rather simple solution for the observers may be to delay processing of changes until they are available on the near secondary.\n\nA more sophisticated solution discussed offline could hide the replica set entirely and always read from the nearest secondary. Writes would obviously still go to the primary, but only return when the write is available also on the nearest secondary. This guarantees that any subsequent read is able to see the preceding write.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid reads from MongoDB primary"
   },
   {
      "_id": "13064434",
      "assignee": "baedke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-04-17 17:36:07",
      "description": "The page at [0] (documentation page for tarMK Cold Standby) has several images missing.  Example : http://jackrabbit.apache.org/oak/docs/coldstandby/client_mbean_server_working.png\n\n[0] http://jackrabbit.apache.org/oak/docs/coldstandby/coldstandby.html\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "Missing Images"
   },
   {
      "_id": "13063204",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-11 14:06:13",
      "description": "For easier understanding of the cold standby behaviour, threads used by the cold standby implementations should be assigned more human readable names.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Assign meaningful names to cold standby threads"
   },
   {
      "_id": "13063168",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-04-11 11:30:48",
      "description": "This was uncovered with the work on OAK-6051.\n\nOn {{NodeStore.merge()}} the TarMK uses {{SegmentNodeState#fastEquals}} to efficiently determine whether there is something to commit and whether the base state changed since the builder about to commit was acquired. For efficiency reasons {{fastEquals}} can return \"false negatives\". AFAIU migration of binaries depends on this implementation detail because without this optimisation migration fails. ({{SegmentToExternalMigrationTest}} and {{ExternalToExternalMigrationTest}} fail). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "migration",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Migration of binaries relies on implementation details of the TarMK"
   },
   {
      "_id": "13062916",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-10 14:41:34",
      "description": "Jenkins CI failure: https://builds.apache.org/view/J/job/Jackrabbit%20Oak/\n\nThe build Jackrabbit Oak #144 has failed.\nFirst failed run: [Jackrabbit Oak #144|https://builds.apache.org/job/Jackrabbit%20Oak/144/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/144/console]\n\nError Message\n\n{code}\nexpected: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }> but was: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }>\n{code}\n\nStacktrace\n\n{code}\njava.lang.AssertionError: expected: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }> but was: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }>\n    at org.apache.jackrabbit.oak.segment.standby.StandbyTestIT.testSyncLoop(StandbyTestIT.java:126)\n{code}\n\nStandard Output\n\n[^stdout.log]\n\nAlso failed at https://builds.apache.org/job/Jackrabbit%20Oak/394/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "flaky-test",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: StandbyTestIT.testSyncLoop"
   },
   {
      "_id": "13062146",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-04-06 15:43:13",
      "description": "see http://markmail.org/message/2wgjv6obefbfpd7u?q=list:org%2Eapache%2Ejackrabbit%2Eoak-dev&page=2 for discussion.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move OakInitializer from org.apache.jackrabbit.oak.spi.lifecycle to o.a.j.oak"
   },
   {
      "_id": "13062144",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-06 15:38:54",
      "description": "The refactoring from OAK-6002 moved the cleanup of the tar readers into the read lock, which blocks concurrent writers from progressing. This was a problem with {{oak-segment}} before and fixed with OAK-3329.\nAs cleanup can take up to a couple of minutes on busy system we should re-establish the former behaviour. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cleanup blocks writers"
   },
   {
      "_id": "13062077",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-04-06 11:58:22",
      "description": "see OAK-6041",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.plugins.tika.TextExtractorMain must have private constructor"
   },
   {
      "_id": "13062043",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-04-06 09:02:46",
      "description": "see OAK-6041",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.util.OakVersion must have private constructor"
   },
   {
      "_id": "13062035",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2017-04-06 08:17:05",
      "description": "see also OAK-6041",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.commons.jmx.JmxUtil must have a private constructor"
   },
   {
      "_id": "13062021",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-04-06 07:14:37",
      "description": "the utility class {{o.a.j.oak.plugins.identifier.ClusterRepositoryInfo}} should have a private constructor to avoid instantiation... I consider it a utility because all it's fields and methods are declared static.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "o.a.j.oak.plugins.identifier.ClusterRepositoryInfo should have private constructor"
   },
   {
      "_id": "13061714",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-04-05 12:14:18",
      "description": "the {{AbstractSecurityTest}} provides the setup of an Oak content repository that relies on the default implementation of the various security modules. In the light of modularization efforts I would like to refactor those security related tests in oak.spi.security.* that depend on {{AbstractSecurityTest}} as they should not require a particular implementation.\n\nThis currently affects the following classes:\n\n- -org.apache.jackrabbit.oak.spi.security.authorization.accesscontrol.AbstractAccessControlTest.java-\n- -org.apache.jackrabbit.oak.spi.security.authorization.restriction.AbstractRestrictionProviderTest.java-\n- -org.apache.jackrabbit.oak.spi.security.authorization.restriction.CompositeRestrictionProviderTest.java-\n- -org.apache.jackrabbit.oak.spi.security.privilege.PrivilegeBitsProviderTest.java-\n- -org.apache.jackrabbit.oak.spi.security.privilege.PrivilegeBitsTest.java-\n- -org.apache.jackrabbit.oak.spi.security.user.action.AccessControlActionTest.java-\n- -org.apache.jackrabbit.oak.spi.security.user.action.ClearMembershipActionTest.java-\n                    ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Drop dependency of spi.security.* tests from AbstractSecurityTest"
   },
   {
      "_id": "13061659",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-04-05 08:08:30",
      "description": "Seems the added value of this method is minimal, worse it adds an unneeded dependency to the {{Observer}} class. [0]\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/spi/whiteboard/WhiteboardUtils.java#L101",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove WhiteboardUtils#registerObserver method"
   },
   {
      "_id": "13061657",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2017-04-05 07:50:25",
      "description": "With OAK-5903 the {{AbstractLoginModule}} and {{Authentication}} interfaces received new methods and the exported package version was bumped from 1.1.0 to 2..0.0. This is unfortunately a breaking change for anyone importing the {{org.apache.jackrabbit.oak.spi.security.authentication}}, including Sling's oak-server module.\n\nTo me these classes do not look as they are usually implemented by clients, but part of an SPI implemented mostly by oak-core, e.g. they are 'provider types' in OSGi vocabulary.\n\nI've marked them with the {{@ProviderType}} annotation which allows the exported package version to only be increased to 1.2.0 and allows consumer to reference those packages without changing import ranges across all Oak version.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Mark AbstractLoginModule and Authentication as provider types"
   },
   {
      "_id": "13061639",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-04-05 07:01:56",
      "description": "while investigating possibilities to improve modularization we spotted user management related classes being located in the oak.spi.whiteboard package. IMHO it would make sense to move those to oak.security.user.whiteboard as they don't belong to the spi package space.\n\n[~alexparvulescu], wdyt?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move security related service trackers from spi.whiteboard to oak.security package space "
   },
   {
      "_id": "13061466",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-04 16:05:05",
      "description": "That test fails for me on every 2nd run or so. This seems to be a regression introduced with OAK-6002. \n\n{code}\norg.junit.ComparisonFailure: Expected nothing to be cleaned but generation 'b' for file data00002b.tar indicates otherwise. \nExpected :a\nActual   :b\n\n\nat org.junit.Assert.assertEquals(Assert.java:115)\norg.apache.jackrabbit.oak.segment.CompactionAndCleanupIT.concurrentCleanup(CompactionAndCleanupIT.java:1252)\n{code}\n\n[~frm], could you have a look?\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: CompactionAndCleanupIT.concurrentCleanup"
   },
   {
      "_id": "13061396",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-04 09:56:35",
      "description": "The newly created {{TarFiles}} should be added to the architecture diagram for oak-segment-tar.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add TarFiles to the architecture diagram"
   },
   {
      "_id": "13061085",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-03 10:31:54",
      "description": "We could probably remove the segment graph functionality from oak-run. This has been implemented mainly (and solely?) for the purpose of analysing the problems around OAK-3348 and I assume it would quickly start falling behind as we move forward. Also for this kind of analysis I have switched to [oak-script|https://github.com/mduerig/script-oak], which is far more flexible. \n\nLet's decide closer to cutting 1.8 how to go forward here.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove segment graph functionality from oak-run"
   },
   {
      "_id": "13061054",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-04-03 08:02:55",
      "description": "Comparing node states in read-only mode may fail with an IllegalStateException when the journal is used to perform a diff.\n\n{noformat}\njava.lang.IllegalStateException: Root document does not have a lastRev entry for local clusterId 0\n    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199)\n    at com.google.common.cache.LocalCache.get(LocalCache.java:3932)\n    at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721)\n    at org.apache.jackrabbit.oak.plugins.document.MemoryDiffCache.getChanges(MemoryDiffCache.java:83)\n    at org.apache.jackrabbit.oak.plugins.document.TieredDiffCache.getChanges(TieredDiffCache.java:50)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.compare(DocumentNodeStore.java:1632)\n[...]\nCaused by: java.lang.IllegalStateException: Root document does not have a lastRev entry for local clusterId 0\n    at org.apache.jackrabbit.oak.plugins.document.JournalDiffLoader.call(JournalDiffLoader.java:82)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.diffImpl(DocumentNodeStore.java:2428)\n{noformat}\n\nSee also OAK-6011.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore.compare() fails with IllegalStateException in read-only mode"
   },
   {
      "_id": "13060317",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-03-30 09:57:20",
      "description": "{code}\njava.lang.RuntimeException: javax.jcr.RepositoryException: Failed to copy content\n    at com.google.common.io.Closer.rethrow(Closer.java:149)\n    at org.apache.jackrabbit.oak.upgrade.cli.OakUpgrade.migrate(OakUpgrade.java:81)\n    at org.apache.jackrabbit.oak.upgrade.cli.OakUpgrade.migrate(OakUpgrade.java:67)\n    at org.apache.jackrabbit.oak.upgrade.cli.OakUpgrade.main(OakUpgrade.java:48)\n    at org.apache.jackrabbit.oak.upgrade.cli.AbstractOak2OakTest.prepare(AbstractOak2OakTest.java:112)\nCaused by: javax.jcr.RepositoryException: Failed to copy content\n    at org.apache.jackrabbit.oak.upgrade.RepositorySidegrade.copy(RepositorySidegrade.java:264)\n    at org.apache.jackrabbit.oak.upgrade.cli.OakUpgrade.sidegrade(OakUpgrade.java:92)\n    at org.apache.jackrabbit.oak.upgrade.cli.OakUpgrade.migrate(OakUpgrade.java:78)\n    ... 34 more\nCaused by: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Root document does not have a lastRev entry for local clusterId 0\n    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199)\n    at com.google.common.cache.LocalCache.get(LocalCache.java:3932)\n    at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721)\n    at org.apache.jackrabbit.oak.plugins.document.MemoryDiffCache.getChanges(MemoryDiffCache.java:83)\n    at org.apache.jackrabbit.oak.plugins.document.TieredDiffCache.getChanges(TieredDiffCache.java:50)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.compare(DocumentNodeStore.java:1632)\n    at org.apache.jackrabbit.oak.plugins.document.AbstractDocumentNodeState.compareAgainstBaseState(AbstractDocumentNodeState.java:114)\n    at org.apache.jackrabbit.oak.upgrade.RepositorySidegrade.migrateWithCheckpoints(RepositorySidegrade.java:369)\n    at org.apache.jackrabbit.oak.upgrade.RepositorySidegrade.copyState(RepositorySidegrade.java:294)\n    at org.apache.jackrabbit.oak.upgrade.RepositorySidegrade.copy(RepositorySidegrade.java:257)\n    ... 36 more\nCaused by: java.lang.IllegalStateException: Root document does not have a lastRev entry for local clusterId 0\n    at org.apache.jackrabbit.oak.plugins.document.JournalDiffLoader.call(JournalDiffLoader.java:82)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.diffImpl(DocumentNodeStore.java:2428)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.access$1100(DocumentNodeStore.java:136)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore$8.call(DocumentNodeStore.java:1637)\n    at org.apache.jackrabbit.oak.plugins.document.MemoryDiffCache$1.call(MemoryDiffCache.java:89)\n    at org.apache.jackrabbit.oak.plugins.document.MemoryDiffCache$1.call(MemoryDiffCache.java:83)\n    at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724)\n    at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522)\n    at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315)\n    at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278)\n    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193)\n    ... 45 more\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: JdbcToSegmentTest:validateMigration "
   },
   {
      "_id": "13060292",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-30 08:08:45",
      "description": "Cancellation of (force) compaction by timeout is currently implemented on top of the {{CancelCompactionSupplier}}. It should better be implemented within though to simplify the implementation of OAK-3349. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "refactoring",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Simplify cancellation of compaction by timeout "
   },
   {
      "_id": "13060282",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-03-30 07:50:05",
      "description": "Introduce a DocumentStore wrapper that can be instructed to fail after some number of operations or with some probability.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Introduce a FailingDocumentStore"
   },
   {
      "_id": "13060280",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-03-30 07:43:28",
      "description": "If the DocumentNodeStore is used as a part of the MultiplexingNodeStore, we should check whether the checkpoint name refers to a valid checkpoint in release() and retrieve() methods. Otherwise we can get an IllegalArgumentException.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "multiplexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MultiplexingNodeStore sometimes fails to release checkpoint"
   },
   {
      "_id": "13060276",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-30 07:22:31",
      "description": "We should also add the record id of the root node resulting from compaction to the gc log. This would have been helpful a couple of times already in the past for testing and post mortems. It will likely also be a requirement to implement the tail compaction approach form OAK-3349. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add record id of the compacted root to the GC journal"
   },
   {
      "_id": "13059956",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-29 07:53:41",
      "description": "Currently {{Revisions.setHead(Function, Option)}} returns a {{boolean}} to indicate success or failure. The caller has no access to the head resulting from this call. I would thus like to change this into the record id of the new head in case of success and {{null}} otherwise. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Revisions.setHead(Function) should return the new head or null instead of boolean"
   },
   {
      "_id": "13058911",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2017-03-24 14:40:12",
      "description": "Needed by OAK-5855 but tracked separately so it can be independently back-ported.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "add CloseableIterator similar to CloseableIterable"
   },
   {
      "_id": "13058163",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-03-22 09:34:03",
      "description": "Secondary NodeStore feature (OAK-4180) for now currently supports path inclusion. It would be useful to have support for path exclusion also.\n\nUsing this a user can can include all content  under / but exclude /oak:index/uuid/:index entries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support path exclusion in secondary nodestore"
   },
   {
      "_id": "13058120",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2017-03-22 06:21:30",
      "description": "Caching should be disabled in the tests by default as these tests require synchronous uploads.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Disable caching for S3 integration tests"
   },
   {
      "_id": "13057878",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-03-21 12:40:44",
      "description": "The Metrics related classes and interfaces in {{org.apache.jackrabbit.oak.stats}} and {{org.apache.jackrabbit.oak.plugins.metric}} are largely undocumented. Specifically it is not immediately how they should be used, how a new {{Stats}} instance should be added, what the effect this would have and how it would (or would) not be exposed (e.g. via JMX). \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document Metrics related classes and interfaces"
   },
   {
      "_id": "13057868",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-21 12:19:04",
      "description": "The statistics provided by the segment cache are off due to the fact it serves as 2nd level cache: as it doesn't see all the hits in the 1st level cache ({{SegmentId.getSegment()}}), it reports a hit/miss rate that is to low. \n\nWe should look into how we could expose better statistics wrt. caching of segments. Possible consolidated over 1st and 2nd level caches. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve cache statistics of the segment cache"
   },
   {
      "_id": "13057842",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-21 10:12:38",
      "description": "As a preparation to enable better monitoring and add more precise monitoring probes to the deduplication caches I would like to unify their interfaces and simplify their setup. \n* Don't expose the cache statistics via the {{FileStore}} and leverage the the {{FileStoreBuilder}} instead for this.\n* All deduplication caches should implement a unified {{Cache}} interface to simplify wrapping them (e.g. for additional access statistics collection). \n* Replace the ad-hoc collection of cache statistics in the {{NodeWriteStats}} inner class of the {{SegmentWriter}} and replace it with a more structured approach. \n* Expose additional cache access statistics via Metrics. \n* The additional statistics should discriminate caches access occurring as regular writes from such occurring during compaction. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring",
         "refactoring",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Unify and simplify the deduplication caches "
   },
   {
      "_id": "13057836",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-21 09:46:03",
      "description": "Currently {{CacheStats.loadExceptionCount()}} always returns 0 on a cache statistics retrieved from the {{PriorityCache}}. I would like to implement this statistics by returning the number of times a {{put()}} failed on that cache because it did not find an empty slot. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "PriorityCache statistics should support load exception count"
   },
   {
      "_id": "13056628",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-03-16 11:33:59",
      "description": "Right now, the checkpoint retrieval & release uses the checkpoint reference to get the checkpoint metadata from the global store. This metadata contains checkpoint references on the other stores.\n\nWe should also support a case in which the checkpoint id exists on all the configured stores. This happens if we clone the repository and configure it under different mounts.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "multiplexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve the checkpoint release & retrieve for multiplexing node store"
   },
   {
      "_id": "13056362",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-03-15 17:22:25",
      "description": "The CachedNodeDocument interface was introduced with OAK-891 but then the feature was later removed with OAK-2937. The interface is not used anywhere and should be removed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove CachedNodeDocument"
   },
   {
      "_id": "13056257",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-15 11:06:36",
      "description": "That depth parameter is a leftover from when the node de-duplication cache used the depth of a node in the tree for its eviction strategy. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove unused depth parameter SegmentWriteOperation#writeNode and related methods"
   },
   {
      "_id": "13049988",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-10 09:47:30",
      "description": "{{oak-segment-tar}} imports {{org.apache.log4j}}. I didn't investigate why {{oak-segment-tar}} is importing {{org.apache.log4j}} at all (no direct use), but that import could be optional (did some tests in Sling).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "OSGi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make import org.apache.log4j optional"
   },
   {
      "_id": "13049537",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-09 09:07:43",
      "description": "Running that IT (with 4g heap) currently results in an {{OOME}}. We need to check whether the expectations are still valid for Segment Tar and either adapt the test or look into the memory consumption. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "OOM in SegmentReferenceLimitTestIT"
   },
   {
      "_id": "13049223",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-08 10:08:21",
      "description": "The idea is to reduce the amount of extra byte buffers created when reading mmapped records, if possible pushing the ByteBuffer all the way to the consumer.\nFor example reading a String from a Segment right now means first reading the bytes of of the record into a byte array, then creating a string with an encoding (which behind the scenes will copy the byte array again and run it through the decoder). An alternative is to call {{decode}} on the Charset and pass in the ByteBuffer, skipping the intermediate operations.\n\nThere are a few cases of this I included in the patch, but there may be others (like the {{SegmentStream}} which needs a full rewrite).\n\nInterested in what others think of this!",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "memory",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce copying of data when reading mmapped records"
   },
   {
      "_id": "13048908",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-03-07 15:04:57",
      "description": "In the current default setup the implementations of the {{Authentication}} interface resolve a user for the given login credentials but don't provide means to retrieve the associated principal. Consequently upon {{LoginModule.commit}} the user needs to resolved a second time to compute the set of all principals. This could be simplified by using {{PrincipalProvider.getGroupMembership(Principal)}} if the users principals was available upon successful call to {{Authentication.authenticate}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Authentication: add extension to retrieve user principal"
   },
   {
      "_id": "13048893",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-07 13:54:09",
      "description": "Currently there is a limitation for the maximum binary size (in bytes) to be synced between primary and standby instances. This matches {{Integer.MAX_VALUE}} (2,147,483,647) bytes and no binaries bigger than this limit can be synced between the instances.\n\nPer comment at [1], the current protocol needs to be changed to allow sending of binaries in chunks, to surpass this limitation.\n\n[1] https://github.com/apache/jackrabbit-oak/blob/1.6/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/standby/client/StandbyClient.java#L125",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cold standby should allow syncing of blobs bigger than 2.2 GB"
   },
   {
      "_id": "13048486",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-03-06 11:14:16",
      "description": "while measuring performance of possible fixes for OAK-4920, i noticed a possible improvement within the ResultRowToAuthorizable used to within the user query code base: instead of retrieving authorizables by ID the code can be simplified by using the tree that has already been obtained.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ResultRowToAuthorizable: create user/group from tree"
   },
   {
      "_id": "13048032",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2017-03-03 12:52:49",
      "description": "This issue tracks the {{oak-core}} changes on the {{TypeEditor}} to have better protection against corruption when changing a node's primary type.\n\nBasically first 2 items on [~mreutegg]'s summarization of OAK-5229 [0].\n\n\n[0] https://issues.apache.org/jira/browse/OAK-5229?focusedCommentId=15863871&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15863871",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Stricter validation on primary type change"
   },
   {
      "_id": "13047970",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-03 10:07:49",
      "description": "{{oak-segment}} had a {{tarmkrecovery}} command responsible with listing candidates for head journal entries. We should re-enable this also for {{oak-segment-tar}}.\n\n/cc [~mduerig] [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "segment-tar should have a tarmkrecovery command"
   },
   {
      "_id": "13047961",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-03 09:51:37",
      "description": "{{RepositoryGrowthTest}} is a benchmark which makes use of the deprecated {{SegmentFixture}}. Since OAK-5834 removes the old {{oak-segment}} module and the code associated with it, {{RepositoryGrowthTest}} was also removed. If there's value in it, we can adapt it to work with the new {{SegmentTarFixture}}.\n\n/cc [~chetanm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "benchmark"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Evaluate utility of RepositoryGrowthTest benchmark"
   },
   {
      "_id": "13047677",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-03-02 13:34:03",
      "description": "Running {{java -jar oak-upgrade*.jar}}\u00a0prints \n\n{noformat}\nUsage: java -jar oak-run-*-jr2.jar upgrade [options] jcr2_source [destination]\n       (to upgrade a JCR 2 repository)\n\n       java -jar oak-run-*-jr2.jar upgrade [options] source destination\n       (to migrate an Oak repository)\n{noformat}\n\nWhich incorrectly refers to {{oak-run upgrade}}. The latter will send me back to {{oak-run}}: \"This command was moved to the oak-upgrade module\". ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "production",
         "tooling",
         "usability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Oak upgrade usage note refers to oak-run"
   },
   {
      "_id": "13047606",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2017-03-02 08:36:00",
      "description": "If a file is staged for async upload in UploadStagingCache and then another call to AbstractSharedCachingDataStore.addRecord is made for a file with same SHA1, the new call goes directly to the backed to write the file, because the cache is not taking into account pending uploads. This makes 2 uploads to happen for the same blob: one async (from UploadStagingCache) and one sync (from AbstractSharedCachingDataStore.addRecord  \n\n(cc [~amitjain])",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Duplicate uploads might happen with AbstractSharedCachingDataStore"
   },
   {
      "_id": "13046916",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-28 09:47:04",
      "description": "It would be interesting to see the effect of compressing the segments within the tar files with a sufficiently effective and performant compression algorithm:\n\n* Can we increase overall throughput by trading CPU for IO?\n* Can we scale to bigger repositories (in number of nodes) by squeezing in more segments per MB and thus pushing out onset of thrashing?\n* What would be a good compression algorithm/library?\n* Can/should we make this optional? \n* Migration and compatibility issues?\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compressed segments"
   },
   {
      "_id": "13046660",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-27 15:04:13",
      "description": "On of the {{Template}} constructors (the one used when writing templates) performs a call to {{NodeState.getChildNodeCount()}} to determine the value of {{Template.childName}}. I have seen this call comping up in performance traces on various occasions, which leads me to believe there is room for improvement here. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Potential expensive call to NodeState.getChildNodeCount() in constructor of Template"
   },
   {
      "_id": "13046007",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2017-02-24 12:46:27",
      "description": "The {{oak-segment}} module has been deprecated for 1.6 with OAK-4247. We should remove it entirely now:\n\n* Remove the module\n* Remove fixtures and ITs pertaining to it\n* Remove references from documentation where not needed any more\n\nAn open question is how we should deal with the tooling for {{oak-segment}}. Should we still maintain this in trunk and keep the required classes (which very much might be all) or should we maintain the tooling on the branches? What about new features in tooling? \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "deprecation",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove the deprecated oak-segment module"
   },
   {
      "_id": "13045908",
      "assignee": "amitjain",
      "components": [],
      "created": "2017-02-24 07:06:14",
      "description": "A [collision for SHA-1|https://www.schneier.com/blog/archives/2017/02/sha-1_collision.html] has been published. We still use SHA-1 for the FileDataStore, and I believe the S3 DataStore right now. Given there is a collision, we should switch to a stronger algorithm, for example SHA-256, for new binaries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Don't use SHA-1 for new DataStore binaries"
   },
   {
      "_id": "13045682",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-23 17:07:20",
      "description": "With {{oak-run check}} we can determine the last good revision of a repository and use it to manually roll back a corrupted segment store. \n\nComplementary to this we should implement a tool to roll forward a broken revision to a fixed new revision. Such a tool needs to detect which items are affected by a corruption and replace these items with markers. With this the repository could brought back online and the markers could be used to identify the locations in the tree where further manual action might be needed. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "production",
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TarMK: Implement tooling to repair broken nodes"
   },
   {
      "_id": "13045662",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-23 16:00:16",
      "description": "Currently the compactor does just a rewrite of the super root node without any special handling of the checkpoints. It just relies on the node de-duplication cache to avoid fully exploding the checkpoints. \nI think this can be improved by subsequently rebasing checkpoints on top of each other during compaction. (Very much like checkpoints are handled in migration). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Chronologically rebase checkpoints on top of each other during compaction"
   },
   {
      "_id": "13045626",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-02-23 13:56:27",
      "description": "If a single node is modified in a commit then currently it performs 2 remote calls\n\n# The actual update\n# Update of commit root\n\nas for single node update commitRoot == node being updated we can optimize this case to see if both operations can be done in same call",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Perform update of single node in one remote call if possible"
   },
   {
      "_id": "13045620",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2017-02-23 13:34:20",
      "description": "{{DocumentNodeStore}} currently calls {{close()}} if the blob store instance implements {{Closeable}}.\r\n\r\nThis has led to problems where wrapper implementations did not implement it, and thus the actual blob store instance wasn't properly shut down.\r\n\r\nProposal: make {{BlobStore}} extend {{Closeable}} and get rid of all {{instanceof}} checks.\r\n\r\n[~thomasm] [~amitjain] - feedback appreciated.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "BlobStore should be AutoCloseable"
   },
   {
      "_id": "13045547",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-02-23 08:44:59",
      "description": "The hashCode generation of {{RestrictionImpl}} currently looks as follows:\n\n{code}\n    public int hashCode() {\n        return Objects.hashCode(definition, property);\n    }\n{code}\n\nHowever, the hashCode of our {{PropertyState}} implementation doesn't include the value. See {{AbstractPropertyState}}:\n\n{code}\npublic static int hashCode(PropertyState property) {\n        return property.getName().hashCode();\n    }\n{code}\n\nConsequently the hashCode of the {{AccessControlEntry}} implementation, the validation of ACEs in {{AccessControlValidator}} and the {{AcEntry}} created in the {{PermissionHook}} generates the same hashCode for entries that only differ by the value of a restriction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "hashCode of RestrictionImpl doesn't include value"
   },
   {
      "_id": "13045516",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326717",
            "id": "12326717",
            "name": "cache"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-02-23 06:08:55",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1447 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1447|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1447/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1447/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: persistentCache.BroadcastTest.broadcastTCP "
   },
   {
      "_id": "13045336",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-22 18:54:25",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=integrationTesting #472 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=integrationTesting #472|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=integrationTesting/472/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=integrationTesting/472/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: segment.standby.MBeanIT.testClientAndServerEmptyConfig"
   },
   {
      "_id": "13045164",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-22 09:40:34",
      "description": "To better explain the bug I'll describe the content of the revisions:\n# Valid Revision\nAdds child nodes {{a}}, {{b}}, {{c}}, {{d}}, {{e}}, {{f}} with various properties (blobs included)\n# Invalid Revision\nAdds child node {{z}} with some blob properties and then corrupts the {{NODE}} record holding {{z}}.\nNow when the consistency check is run, it correctly detects that the second revision is broken, *marks the path {{/z}} as corrupt* and then continues checking the first valid revision. Because of a check introduced for OAK-5556 [1], which tries to validate the user provided absolute paths before checking them, the checker tries to check {{/z}} in the first revision, where of course it can't find it. Therefore the check incorrectly fails for this revision, although it shouldn't have to.\n\n/cc [~mduerig], [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Consistency check incorrectly fails for broken partial paths "
   },
   {
      "_id": "13045162",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-02-22 09:36:32",
      "description": "There are multiple places in DocumentNodeStore where background operations log timing. This should be consolidated.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove duplicate code for background operation timing log"
   },
   {
      "_id": "13045070",
      "assignee": "jsedding",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2017-02-22 04:24:36",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1441 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1441|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1441/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1441/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: PojoSR run.osgi.SecurityProviderRegistrationTest"
   },
   {
      "_id": "13044813",
      "assignee": "egli",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2017-02-21 11:21:51",
      "description": "As [reported|http://markmail.org/message/2qxle24f6zu2vpms] by [~catholicon] on oak-dev the observation queue only delivers the so-called _overflow entry/change_ only when new commits are 'coming in'. We might want to consider fixing this, even though arguably this is a very rare case (since typically the observation queue is configured to be very large)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4",
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "deliver overflow change even without new commit"
   },
   {
      "_id": "13044658",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2017-02-20 21:59:47",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=unittesting #465 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=unittesting #465|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=unittesting/465/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=unittesting/465/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: org.apache.jackrabbit.oak.run.osgi.SegmentNodeStoreConfigTest.testDeadlock"
   },
   {
      "_id": "13043539",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-02-16 08:13:33",
      "description": "I think we should prepare for cases where the permission store (managed as a tree mirrored to the content tree) goes out of sync with the content tree for whatever reason.\n\nIdeally, that would be an online tool (maybe exposed via JMX) that goes back the MVCC revisions to find the offending commit (so that have a chance to reduce the number of such occurences) and fixes the inconsistency on head.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "production",
         "resilience",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Tool to detect permission store inconsistencies"
   },
   {
      "_id": "13043378",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2017-02-15 20:40:46",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=DOCUMENT_RDB,profile=unittesting #452 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=DOCUMENT_RDB,profile=unittesting #452|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=DOCUMENT_RDB,profile=unittesting/452/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=DOCUMENT_RDB,profile=unittesting/452/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: observation.ObservationQueueFullWarnTest.warnOnRepeatedQueueFull"
   },
   {
      "_id": "13042975",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-02-14 15:29:45",
      "description": "[~chetanm], in the light of OAK-4975 a dependency to the document nodestore code got introduced in {{org.apache.jackrabbit.oak.plugins.nodetype.write.InitialContent}} by adding the following line:\n{code}\n        BundlingConfigInitializer.INSTANCE.initialize(builder);\n{code}\n\nthe {{BundlingConfigInitializer}} is defined in the {{org.apache.jackrabbit.oak.plugins.document.bundlor}}.\n\nTo me that looks quite troublesome and I don't think the generic JCR-InitialContent should have any dependency on the document nodestore code base.\n\nWhy not defining a dedicated {{RepositoryInitializer}} for that kind of init an making sure it is listed in the (default) setup scenarios (or at least in those that actually have a document store and thus require this)?\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "modularization",
         "tech-debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "InitialContent depends on document.bundlor.BundlingConfigInitializer"
   },
   {
      "_id": "13042569",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-13 13:06:28",
      "description": "This is a bigger refactoring item to revisit the format of the exposed data, moving towards having it in a more machine consumable friendly format.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Revisit FileStoreStats mbean stats format"
   },
   {
      "_id": "13042568",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-13 13:04:48",
      "description": "Followup of OAK-5632 and OAK-5631, to expose the collected data via JMX for external use.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Expose IOMonitor stats via JMX"
   },
   {
      "_id": "13041869",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-02-09 22:40:58",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=DOCUMENT_NS,profile=unittesting #445 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=DOCUMENT_NS,profile=unittesting #445|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=DOCUMENT_NS,profile=unittesting/445/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=DOCUMENT_NS,profile=unittesting/445/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: org.apache.jackrabbit.oak.cache.ConcurrentTest.testLoaderBlock"
   },
   {
      "_id": "13041683",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-09 12:26:23",
      "description": "The current implementation of the consistency check ({{ConsistencyChecker}},{{CheckCommand}})\nis cluttered with unnecessary checks regarding deprecated arguments of the {{check}} command. \nWith OAK-5595, deep traversals are enabled by default, therefore the code needs to be revised to take this into account. The same applies to the argument taken by {{--bin}} option, which was removed in OAK-5604.\n\nMoreover, {{ConsistencyChecker}} could be refactored in order to better distinguish when:\n* a full path at the given revision is checked\n* a node and its properties are checked\n* a node and its descendants are checked",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Simplify consistency check"
   },
   {
      "_id": "13041595",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2017-02-09 05:54:16",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_MK,profile=integrationTesting #443 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_MK,profile=integrationTesting #443|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_MK,profile=integrationTesting/443/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_MK,profile=integrationTesting/443/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: segment.standby.ExternalSharedStoreIT.testProxyFlippedIntermediateByteChange2"
   },
   {
      "_id": "13041591",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2017-02-09 05:14:55",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_MK,profile=unittesting #1412 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_MK,profile=unittesting #1412|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_MK,profile=unittesting/1412/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_MK,profile=unittesting/1412/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: org.apache.jackrabbit.oak.run.osgi.DocumentNodeStoreConfigTest.testRDBDocumentStoreRestart"
   },
   {
      "_id": "13041582",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-02-09 04:04:42",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=integrationTesting #443 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=integrationTesting #443|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=integrationTesting/443/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=integrationTesting/443/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: org.apache.jackrabbit.mk.util.CommitGateIT.test"
   },
   {
      "_id": "13041547",
      "assignee": "baedke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-02-09 00:40:53",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_MK,profile=unittesting #441 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_MK,profile=unittesting #441|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_MK,profile=unittesting/441/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_MK,profile=unittesting/441/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: security.authentication.ldap.LdapProviderTest.testGetUnknownUserByRef"
   },
   {
      "_id": "13041411",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-08 15:25:25",
      "description": "Currently the {{--bin}} option expects a {{Long}} argument, as the {{LENGTH}} up to which to scan the content of binary properties. The {{--bin}} option should be simplified so that it doesn't take any arguments. Running {{check}} without the {{--bin}} flag won't scan any binary properties, while including {{--bin}} option will scan all binaries, no matter their size.\n\nIf an argument is given with {{--bin}}, there will be a failure and a warning will be displayed.\n\nThe message displayed at the end of the consistency check will be changed to take into account whether binary properties were traversed or not.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command should accept a non-argument \"bin\" option for checking binaries"
   },
   {
      "_id": "13041376",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-02-08 13:05:44",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=DOCUMENT_NS,profile=unittesting #438 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=DOCUMENT_NS,profile=unittesting #438|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=DOCUMENT_NS,profile=unittesting/438/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=DOCUMENT_NS,profile=unittesting/438/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: oak.upgrade.cli.blob.CopyBinariesTest"
   },
   {
      "_id": "13041330",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-08 09:39:12",
      "description": "We should add tests for {{o.a.j.o.r.CheckCommand}} in order to validate recent changes introduced by adding/removing options and their arguments (see OAK-5275, OAK-5276, OAK-5277, OAK-5595). There is also a new feature introduced by OAK-5556 (filter paths) and a refactoring in OAK-5620 which must be thoroughly tested in order to avoid regressions.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test coverage for CheckCommand"
   },
   {
      "_id": "13041209",
      "assignee": "edivad",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-02-07 23:32:47",
      "description": "oak-run is rather big (50MB). Let's see what we can do to slim it down",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Slim oak-run"
   },
   {
      "_id": "13040675",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-06 16:08:57",
      "description": "Only checking accessibility of the root nodes doesn't make much sense. Even more so because the file store automatically rolls back on startup if a root revision is not accessible. In terms of not doing full traversals, it is more interesting to restrict by path (aka OAK-5556).\n\nThe {{--deep}} option will still be accepted, but there will be a failure when it is specified. An explanation that full traversal is now done regardless of that option will be printed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command should do deep traversals by default"
   },
   {
      "_id": "13040625",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-06 12:51:21",
      "description": "When the {{check}} command is used without {{--deep}} option, there is no check/traversal being done against the repository.\n\nFirst relevant line in code is [1], where a check is supposed to happen, but due to a mismatch between argument expected/argument provided, {{null}} is always returned without checking anything. The method which should do the actual check [2] expects a set of paths to be traversed, but this set is always empty. Therefore, relevant code for running the check is never executed [3].\n\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/tooling/ConsistencyChecker.java#L120\n[2] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/tooling/ConsistencyChecker.java#L183\n[3] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/tooling/ConsistencyChecker.java#L194",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "The check command doesn't do any check when \"deep\" option is not provided"
   },
   {
      "_id": "13040030",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-03 04:10:23",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_MK,profile=integrationTesting #1399 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_MK,profile=integrationTesting #1399|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_MK,profile=integrationTesting/1399/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_MK,profile=integrationTesting/1399/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby",
         "test-failure",
         "ubuntu",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.segment.standby.StandbyTestIT.testSyncLoop"
   },
   {
      "_id": "13039435",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-02-01 11:19:24",
      "description": "Reading a node state in a past revision can become expensive when the change history in the previous documents have overlapping changes. In this case, the changes in the previous documents must be merge sorted to find the correct value for the properties on the node. The more overlapping ranges there are, the more sorting is needed.\n\nThere is a prominent node in the repository that seems to create quite many of those previous documents. The {{/:async}} nodes gets frequent updates and is therefore split on a regular basis. Because the properties on this node are not all updated at the same time, it is quite likely that previous document ranges overlap.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce reads with overlapping previous documents"
   },
   {
      "_id": "13039208",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2017-01-31 15:01:09",
      "description": "It would be good if the {{check}} command would allow for filtering on content path. This would help in quickly identifying what is the good revision of a specific broken node in cases of very large repos.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow filter paths for Check command"
   },
   {
      "_id": "13038925",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-30 16:13:41",
      "description": "We should improve our documentation of the internal design of the the TarMK. There is currently a [single section|http://jackrabbit.apache.org/oak/docs/nodestore/segment/overview.html#design]. \n\n* Add a high level class diagram and description of the overall structure of the TarMK. \n* Decide what to do with {{segmentmk.md}}. My preference would be to incorporate everything from it we didn't cover so far into {{segment/overview.md}}, {{segment/records.md}} and {{segment/tar.md}}. \n* Rewrite, clarify the design section in {{segment/overview.md}}. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document TarMK design"
   },
   {
      "_id": "13038747",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-01-29 12:22:52",
      "description": "grouping the improvements for indexer resilience in this issue for easier tracking",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Improve indexing resilience"
   },
   {
      "_id": "13038623",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-01-28 06:53:48",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting #1390 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting #1390|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting/1390/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting/1390/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: security.authentication.ldap.LdapProviderTest (Address already in use)"
   },
   {
      "_id": "13038418",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-01-27 11:19:23",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_RDB,profile=unittesting #1386 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_RDB,profile=unittesting #1386|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_RDB,profile=unittesting/1386/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_RDB,profile=unittesting/1386/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: standalone.RepositoryBootIT.repositoryLogin"
   },
   {
      "_id": "13038374",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2017-01-27 06:57:47",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1384 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1384|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1384/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1384/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: segment.standby.ExternalSharedStoreIT/BrokenNetworkTest.test..."
   },
   {
      "_id": "13037891",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2017-01-25 23:45:43",
      "description": "If a text extraction is blocked (weird PDF) or a blob cannot be found in the datastore or any other error upon indexing one item from the repository that is outside the scope of the indexer, it currently halts the indexing (lane). Thus one item (that maybe isn't important to the users at all) can block the indexing of other, new content (that might be important to users), and it always requires manual intervention  (which is also not easy and requires oak experts).\n\nInstead, the item could be remembered in a known issue list, proper warnings given, and indexing continue. Maintenance operations should be available to come back to reindex these, or the indexer could automatically retry after some time. This would allow normal user activity to go on without manual intervention, and solving the problem (if it's isolated to some binaries) can be deferred.\n\nI think the line should probably be drawn for binary properties. Not sure if other JCR property types could trigger a similar issue, and if a failure in them might actually warrant a halt, as it could lead to an \"incorrect\" index, if these properties are important. But maybe the line is simply a try & catch around \"full text extraction\".",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Skip problematic binaries instead of blocking indexing"
   },
   {
      "_id": "13037770",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-25 17:16:16",
      "description": "When a gc run is cancelled the subsequent run (compaction phase to be precise) can result in a {{SNFE}}. The reason for this is the node deduplication cache not being purged in the cancellation case. This causes the subsequent compaction to reference node states from that cache that have been cleaned. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "SNFE when running compaction after a cancelled gc"
   },
   {
      "_id": "13037624",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-25 09:06:49",
      "description": "The OSGi setting controlling standby automatic cleanup, {{standby.autoclean}}, should be set to {{true}} by default. When the automatic cleanup is on, the {{cleanup()}} method will be called on standby, provided the size of the store increases over 25% on a sync cycle.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Standby Automatic Cleanup should be on by default"
   },
   {
      "_id": "13037570",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2017-01-25 04:10:07",
      "description": "Currently {{IndexUpdate}} does a lookup for {{oak:index}} node under each changed node. This is done to pickup index definitions and create IndexEditor based on those so as to index content under that subtree. \n\nThis lookup results in extra remote calls on DocumentNodeStore based setup as for non leaf nodes NodeStore has to check from remote storage to determine if {{oak:index}} node is present or not.\n\nThis lookup can be avoided by\n# Having an {{Editor}} which adds a hidden property {{:oak-index-present}} in parent node upon addition of {{oak:index}} as a child node\n# IndexUpdate would then does a lookup for {{oak:index}} node only if such a hidden property is found\n\nFor upgrade we would have some logic which would make use of Nodetype index to identify all such nodes and mark them\n\nDiscussion [thread|https://lists.apache.org/thread.html/70d5ffff0f950d7fc25bc1bbb41527f5672825f8cf2b238f54df2966@%3Coak-dev.jackrabbit.apache.org%3E] on oak-dev",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce lookup for oak:index node under each changed node"
   },
   {
      "_id": "13036530",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-01-20 11:41:31",
      "description": "Let's introduce a new option, {{\\-\\-name\\-fragments}}. It'll traverse the paths specified in the {{\\-\\-include\\-paths}}, looking for nodes which contain specified strings in their names. Only such names (and their subtrees) will be migrated.\n\nIt can be used to migrate the contents that belongs to the given mount, eg. by using:\n\n{noformat}\n--include-paths=/oak:index --name-fragments=:oak:mount-libs\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "multiplexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow to migrate only paths matching given path fragment"
   },
   {
      "_id": "13036529",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-01-20 11:40:45",
      "description": "Let's assume we have a working instance with multiplexing in place, the /libs is mounted in the read-only mode. Now, when an index is created or modified, the whole repository (including /libs) will be reindexed. Then, the IndexUpdate will try to store part of the generated data to {{/oak:index/lucene/:oak:mount-libs-index-data}}. The MultiplexingNodeStore won't allow this (as the libs store is a read-only one) - so the whole reindexing operation will fail and be started again.\n\nA solution proposal: let's allow to disable mounting the path fragments. Indexing data for the libs mount will be stored on the main repository, but under a separate path.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "multiplexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow to disable mounting path fragments in the MultiplexingNodeStore"
   },
   {
      "_id": "13036145",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-01-19 09:12:56",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1375 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1375|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1375/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1375/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: LdapDefaultLoginModuleTest address already in use"
   },
   {
      "_id": "13036089",
      "assignee": "edivad",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-01-19 04:09:22",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1374 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1374|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1374/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1374/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: LdapProviderTest - Address already in use"
   },
   {
      "_id": "13035890",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-01-18 14:36:33",
      "description": "There are cases where a document split is overdue and it continues to grow until it hits the MongoDB limit of 16MB.\n\nIt gets more likely, the more cluster nodes are running and when they all update the same property with a somewhat larger value. E.g. the :childOrder property of a node with many children.\n\nThe current split logic has multiple triggers that will result in creating a previous document.\n\n- There are 100 old changes for a cluster node that can be moved\n- A node was recreated with a binary bigger than 4k\n- The main document is bigger than 256k and 30% of its size can be moved to a previous document\n\nThe last condition may cause the uncontrolled growth of the document when there are many cluster nodes. If all cluster nodes continuously change a property on a node, then none of the cluster nodes will be able to move 30% of the document.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Overdue document split with many cluster nodes"
   },
   {
      "_id": "13035770",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-01-18 04:53:45",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=rat #1372 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=rat #1372|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=rat/1372/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=rat/1372/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "licensing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Too many files with unapproved license"
   },
   {
      "_id": "13035466",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-17 10:45:57",
      "description": "The TarMK's write throughput is limited by the way concurrent commits are processed: rebasing and running the commit hooks happen within a lock without any explicit scheduling. This epic covers improving the overall transaction rate. The proposed approach would roughly be to first make scheduling of transactions explicit, then add monitoring on transaction to gather a better understanding and then experiment and implement explicit scheduling strategies to optimise particular aspects. \n\nh2. Summary of ideas mentioned in an offline sessions\n\nh3. Advantages of explicit scheduling:\n* Control over (order) of commits\n* Sophisticated monitoring (commit statistics, e.g. commit rate, time in queue, etc.) \n* Favour certain commits (e.g. checkpoints)\n* Reorder commits to simplify rebasing\n* Suspend the compactor on concurrent commits and have it resume where it left off afterwards\n* Parallelise certain commits (e.g. by piggy backing)\n* Implement a concurrent commit editor. we'd need to take care of proper access to the shared state; [~frm] maybe introduce the idea of a common context to enforce concurrent access semantics.\n\nh3. Scheduler Implementation\n* Expedite\n* Prioritise\n* Defer\n* Collapse\n* Coalesce\n* Parallelise\n* Piggy back: can we piggy back commits on top of each other? The idea would be while processing the changes of one commit to also check them for conflicts with the changes of other commits waiting to commit. If a conflict is detected there, that other commit can immediately be failed (given the current commit doesn't fail).\n* Merging non conflicting commits. Given multiple transactions ready to commit at the same time. Can we process them as one (given they don't conflict) instead of one after each other, which requires rebasing the later transaction to be rebase on the former.\n* Shield the file store from {{InterruptedException}} because of thread boundaries introduced\n* Implement tests, benchmarks and fixtures for verification\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve the transaction rate of the TarMK"
   },
   {
      "_id": "13035392",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328326",
            "id": "12328326",
            "name": "examples"
         }
      ],
      "created": "2017-01-17 04:01:49",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_MK,profile=integrationTesting #1369 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_MK,profile=integrationTesting #1369|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_MK,profile=integrationTesting/1369/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_MK,profile=integrationTesting/1369/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: RepositoryBootIT.repositoryLogin"
   },
   {
      "_id": "13033612",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-01-11 06:43:51",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=unittesting #1363 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=unittesting #1363|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=unittesting/1363/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=unittesting/1363/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: BasicServerTest.testServerOk() Address already in use"
   },
   {
      "_id": "13033423",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-01-10 15:45:25",
      "description": "Commands in oak-run currently live in a flat namespace. If a command is specific to only one implementation, it will leave along other implementation-specific commands without any means of distinguishing what belongs where.\n\nI would like to add a layer of indirection to the oak-run command line interface, so to parse commands in the following fashion:\n\n{noformat}\noak-run segment debug /path/to/folder\noak-run mongo debug mongodb://host:12345\noak-run rdb debug jdbc:oracle:oci8:scott/tiger@myhost\n{noformat}\n\nIn this scenario, oak-run would become a simple entry point that would delegate to implementation-specific command line utilities based on the first argument. In the previous example, {{segment}}, {{mongo}} and {{rdb}} would delegate to three different implementation specific CLI utilities. Each of these CLI utilities will understand the {{debug}} command and will collect command-line parameters as it sees fit.\n\nIf the code for a command is so generic that can be reused from different commands, it can be parameterised and reused from different implementation-specific commands.\n\nThe benefit of this approach is that we can start moving commands closer to the implementations. This approach would benefit oak-run as well, which is overloaded with many commands from many different implementations.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add a persistence-dependent namespace when running CLI commands"
   },
   {
      "_id": "13033355",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-01-10 12:00:48",
      "description": "ExternalIndexObserver is currently backed by a queue (its wrapped in BackgroundObserver). Currently it processed the changes one by one as received from the queue. If this processing takes long time then its possible that it would lag behind the async indexing cycle.\n\nSo ExternalIndexObserver may be busy indexing changes from [r1-r2] but async indexing is already done indexing changes upto r3 (r3 > r2) and IndexTracker would move to newer index version. In such case work done by ExternalIndexObserver is wasted. \n\nThis can be optimized by ensuring that ExternalIndexObserver can see the lastIndexTo of :async as per latest entry in queue. If that is newer than one its processing then it can skip processing the queue entry and thus free up space in queue",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Skip processing of queued changes if async index update is detected in ExternalIndexObserver"
   },
   {
      "_id": "13033276",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-10 05:38:07",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting #1360 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting #1360|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting/1360/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting/1360/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test Failure: org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT.compactionNoBinaryClone"
   },
   {
      "_id": "13032769",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328326",
            "id": "12328326",
            "name": "examples"
         }
      ],
      "created": "2017-01-07 04:04:59",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1357 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1357|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1357/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1357/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: TomcatIT.testTomcat()"
   },
   {
      "_id": "13032554",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-01-06 14:09:54",
      "description": "Async reindex of a property index creates a checkpoint to use as a reference, but it fails to clean it up when done. In the usual reindexing scenario the async indexer needs to keep the created checkpoint as a reference for subsequent runs, but this is a 'one off' case, so cleanup of this reference checkpoint must also happen at the end of the cycle.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Async reindex of a sync property does't release created checkpoint"
   },
   {
      "_id": "13032466",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2017-01-06 04:38:31",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1356 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1356|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1356/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1356/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: org.apache.jackrabbit.oak.run.osgi.DocumentNodeStoreConfigTest"
   },
   {
      "_id": "13032183",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-01-05 07:42:26",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_MK,profile=unittesting #1355 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_MK,profile=unittesting #1355|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_MK,profile=unittesting/1355/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_MK,profile=unittesting/1355/console]\n\nInitially reported test failure: testProxyFlippedStartByte()\nAdditional test failure reported via OAK-5476: testProxySSLSkippedBytes()\nAdditional test failure reported via OAK-5477: testProxyFlippedStartByteSSL()\nAdditional test failures reported via OAK-5478: all tests failed",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: segment.standby.BrokenNetworkTest"
   },
   {
      "_id": "13031946",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2017-01-04 11:52:14",
      "description": "{noformat}\njava.lang.AssertionError\n\tat org.junit.Assert.fail(Assert.java:86)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.junit.Assert.assertTrue(Assert.java:52)\n\tat org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTestIT.testNativeMLTQueryWithStream(SolrIndexQueryTestIT.java:286)\n\njava.lang.AssertionError\n\tat org.junit.Assert.fail(Assert.java:86)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.junit.Assert.assertTrue(Assert.java:52)\n\tat org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTestIT.testNativeMLTQuery(SolrIndexQueryTestIT.java:264)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure:  SolrIndexQueryTestIT.testNativeMLTQuery and testNativeMLTQueryWithStream"
   },
   {
      "_id": "13030476",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2016-12-24 07:30:44",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1351 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1351|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1351/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1351/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ...stats.ClockTest.testClockDrift"
   },
   {
      "_id": "13030290",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-12-23 03:43:46",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1347 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1347|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1347/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1347/console]\n\n{noformat}\nbroadcastTCP(org.apache.jackrabbit.oak.plugins.document.persistentCache.BroadcastTest)  Time elapsed: 0.047 sec  <<< FAILURE!\njava.lang.AssertionError: expected null, but was:<Hello World 1>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotNull(Assert.java:755)\n\tat org.junit.Assert.assertNull(Assert.java:737)\n\tat org.junit.Assert.assertNull(Assert.java:747)\n\tat org.apache.jackrabbit.oak.plugins.document.persistentCache.BroadcastTest.broadcastTry(BroadcastTest.java:220)\n\tat org.apache.jackrabbit.oak.plugins.document.persistentCache.BroadcastTest.broadcast(BroadcastTest.java:195)\n\tat org.apache.jackrabbit.oak.plugins.document.persistentCache.BroadcastTest.broadcastTCP(BroadcastTest.java:146)\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: persistentCache.BroadcastTest.broadcastTCP"
   },
   {
      "_id": "13030176",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2016-12-22 16:38:22",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1345 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1345|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1345/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1345/console]\n\n{noformat}\ncacheUpdate[RDBFixture: RDB-H2(file)](org.apache.jackrabbit.oak.plugins.document.ConcurrentQueryAndUpdateIT)  Time elapsed: 54.353 sec  <<< FAILURE!\njava.lang.AssertionError: Unexpected revision timestamp for 1:/node-39 expected:<867> but was:<866>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotEquals(Assert.java:834)\n\tat org.junit.Assert.assertEquals(Assert.java:645)\n\tat org.apache.jackrabbit.oak.plugins.document.ConcurrentQueryAndUpdateIT.cacheUpdate(ConcurrentQueryAndUpdateIT.java:80)\n\nFailed tests:   cacheUpdate[RDBFixture: RDB-H2(file)](org.apache.jackrabbit.oak.plugins.document.ConcurrentQueryAndUpdateIT): Unexpected revision timestamp for 1:/node-39 expected:<867> but was:<866>\n{noformat}\n\nAlso seen on Windows: https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=DOCUMENT_NS,profile=integrationTesting/448/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Windows",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ConcurrentQueryAndUpdateIT.cacheUpdate[RDBFixture: RDB-H2(file)]"
   },
   {
      "_id": "13029783",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-21 15:19:49",
      "description": "When revision garbage collection is cancelled because one of the conditions in {{CancelCompactionSupplier}} then this should be reported to {{GCMonitor.skipped}}. Currently it is not. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc",
         "monitoring",
         "production",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cancelled garbage collection not reported to GCMonitor"
   },
   {
      "_id": "13029507",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-20 16:49:36",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting #1338 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting #1338|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting/1338/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting/1338/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: CompactionAndCleanupIT"
   },
   {
      "_id": "13029502",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-12-20 16:34:42",
      "description": "{{SecureNodeBuilder.baseChanged()}} calls {{SecureNodeBuilder.getTreePermission()}} even though the tree permission would be calculated lazily as needed anyway. Re-calculating the tree permissions at this point bears the risk of accessing stale data from the underlying not yet fully refreshed root (when being called e.g. from {{MutableRoot.refresh()}}. \n\nI would thus argue for removing the call to {{SecureNodeBuilder.getTreePermission()}} from {{SecureNodeBuilder.baseChanged()}}. \n\nSee also OAK-5296 for an in-depth analysis. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Too eager refreshing of tree permissions in SecureNodeBuilder"
   },
   {
      "_id": "13029416",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-20 10:49:01",
      "description": "As explained in OAK-5351 the RevisionGCMBean is not being registered for secondary SegmentNodeStore. This task is meant to enable that once OAK-5309 is resolved ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "gc",
         "monitoring",
         "operations",
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Enable RevisionGC task for non primary SegmentNodeStore"
   },
   {
      "_id": "13029400",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-20 09:57:22",
      "description": "Improve code coverage of oak-segment-tar.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve code coverage of oak-segment-tar"
   },
   {
      "_id": "13029134",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-19 13:27:31",
      "description": "In {{SegmentNodeStoreService}} there is {{repository.home}}, {{DIRECTORY}}, {{getRootDirectory()}}, {{getDirectory()}} and {{getBaseDirectory()}} mostly without documentation about their intention. I think we should clarify, document and consolidate them. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clarify the various directories and their usages in SegmentNodeStoreService"
   },
   {
      "_id": "13028399",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-15 14:46:13",
      "description": "{{org.apache.jackrabbit.oak.segment.file.ReversedLinesFileReaderTestParamBlockSize}} should actually have been removed with OAK-4467, where we replaced our {{ReversedLinesFileReader}} implementation with the one from {{commons-io}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove ReversedLinesFileReaderTestParamBlockSize"
   },
   {
      "_id": "13028126",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-14 15:34:03",
      "description": "{{AbstractFileStore.collectFiles()}} contains legacy upgrade code dating back to special handling of binaries in older version of {{oak-segment}} (bulkFiles). We should remove this code. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove legacy upgrade code from AbstractFileStore.collectFiles"
   },
   {
      "_id": "13028123",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-14 15:22:44",
      "description": "{{MapEntry.compareTo()}} passes possibly {{null}} {{MapEntry.value}} to {{ComparisonChain.compare(Comparable, Comparable)}}, which does not accept {{null}} values. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Possible null dereference in MapRecord"
   },
   {
      "_id": "13027751",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-13 10:28:28",
      "description": "We should run some static analysis (i.e. sonar, find bugs, etc.) on our code base and fix the most sever issues. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Static code analysis and code cleanup"
   },
   {
      "_id": "13027713",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-13 08:01:58",
      "description": "The {{tarmkdiff}} command is actually the combination of two commands. \n\nThe first command, activated when the {{\\-\\-list}} flag is specified, list available revisions in the Segment Store. For this command, only the {{\\-\\-output}} option is relevant. If other options are specified, they are ignored.\n\nThe second command is the proper logic of {{tarmkdiff}}. This logic is activated only if the {{\\-\\-list}} flag is not specified. For this command, every option on the command line is relevant.\n\nThe logic listing available revisions in the Segment Store should be encapsulated in its own command, without cluttering the CLI of {{tarmkdiff}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The tarmkdiff command does too many things"
   },
   {
      "_id": "13027472",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-12 14:59:27",
      "description": "The {{check}} command enables the traversal of binary properties via the {{--bin}} option. The user could provide a value for this option to specify the amount of bytes that should be traversed for every binary value. The default value for the {{--bin}} option is zero, effectively disabling the traversal of binary properties. Instead, if a value for this property is not specified, the tools should traverse the binary properties in their entirety. A value should be specified only to restrict the amount of bytes to traverse.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command defines a useless default value for the \"bin\" option"
   },
   {
      "_id": "13027471",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-12 14:52:58",
      "description": "The {{--deep}} option accepted by the {{check}} command is semantically overloaded. It is used both as a flag to enable deep content traversal and as a way to specify the frequency of debug messages printed by the tool. \n\nThis option should be split in two. In particular, {{--deep}} should retain its behaviour of on/off flag for deep traversal, and a new command line option should be introduced to specify the interval of debug messages.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command overloads the meaning of the \"deep\" option"
   },
   {
      "_id": "13027470",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-12 14:48:33",
      "description": "The {{check}} tool requires the path to the store to be specified. The path is passed to the tool via a required option {{--path}}. This way of specifying the path to the store is verbose for no good reason. It would be nicer if the path to the Segment Store would be specified via a positional argument instead.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command should accept the path to the store as a positional argument"
   },
   {
      "_id": "13027169",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2016-12-10 04:52:47",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting #1323 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting #1323|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting/1323/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting/1323/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: SolrIndexHookIT.testPropertyAddition"
   },
   {
      "_id": "13027002",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-09 13:47:59",
      "description": "The default value for the size delta estimation used during garbage collection should be changed to 1GB.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Better default for size delta estimation "
   },
   {
      "_id": "13026547",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-08 03:50:37",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1320 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1320|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1320/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1320/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ExternalPrivateStoreIT. testSyncUpdatedBinaryProperty()"
   },
   {
      "_id": "13025018",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-12-02 08:59:46",
      "description": "As noted in OAK-5211 directory listing was getting modified (due to reorder) even if no change happens in index. \n\nAnother place where we update state post index close is at \":status\" node where we store {{lastUpdated}} and {{indexedNodes}} post index close. In normal cases LuceneIndexEditor avoids initializing the IndexWriter if there is no change. However it can happen that when any node gets deleted the editor performs a delete operation. It can happen that tree being deleted is not indexed but still editor would do this as it cannot determine that easily. And in doing that IndexWriter would be initialized.\n\nCurrently IndexWriter being initialized is considered same as index updated. Due to this index status nodes gets unnecessarily updated even if there is no change in index which causes the IndexTracker to reopen the index even when it has not changed. \n\nWe should make this more explicit and find a way to determine if index has been updated or not",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Avoid updating the index nodestate if no change is done in index"
   },
   {
      "_id": "13025009",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-12-02 08:09:35",
      "description": "[~alex.parvulescu] noted that OakDirectory saves the directory listing even if no actual change happened in the directory. Only change that happens is the order of entries in set. \n\nIn normal cases LuceneIndexEditor avoids initializing the IndexWriter if there is no change. However it can happen that when any node gets deleted the editor performs a delete operation. It can happen that tree being deleted is not indexed but still editor would do this as it cannot determine that easily. This would lead to OakDirectory being closed without any change and thus can lead save of dir listing with just change in order of entries",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "OakDirectory should not save dir listing if no change is done"
   },
   {
      "_id": "13024402",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-30 11:34:20",
      "description": "I observed Lucene indexing contributing to up to 99% of repository growth. While the size of the index itself is well inside reasonable bounds, the overall turnover of data being written and removed again can be as much as 99%. \n\nIn the case of the TarMK this negatively impacts overall system performance due to fast growing number of tar files / segments, bad locality of reference, cache misses/thrashing when looking up segments and vastly prolonged garbage collection cycles.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce Lucene related growth of repository size"
   },
   {
      "_id": "13024389",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2016-11-30 10:46:41",
      "description": "I would like to deprecate the various fixtures and stubs for {{oak-segment}} and replace them where possible with its corresponding variants of {{oak-segment-tar}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "deprecation",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Deprecate stubs and fixtures related to oak-segment"
   },
   {
      "_id": "13023967",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-11-29 05:30:04",
      "description": "{{IndexUpdate}} allows passing in a custom {{MissingIndexProviderStrategy}}. However the custom provider is only stored as instance variable in {{IndexUpdate}} and does not get passed to child IndexUpadate instance.\n\nAs a fix it should be stored in IndexUpdateRootState and accessed from that",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Non default MissingIndexProviderStrategy is not being passed to child editor"
   },
   {
      "_id": "13023742",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2016-11-28 14:16:12",
      "description": "See <http://mail-archives.apache.org/mod_mbox/www-legal-discuss/201611.mbox/%3C0CE2E8C9-D9B7-404D-93EF-A1F8B07189BF%40apache.org%3E>\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "legal"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Get rid of test dependency to json.org JSON parser"
   },
   {
      "_id": "13023222",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-11-24 15:49:21",
      "description": "To mitigate problems when hitting the observation queue limit (OAK-2683) we should bump the default size from 1000 to 10000.\r\n\r\ncc [~stefanegli]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Increase default size of the observation queue from 1000 to 10000"
   },
   {
      "_id": "13022465",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-11-22 10:32:23",
      "description": "At times we see very long time in async index update cycle\n\n{noformat}\n06.11.2016 18:16:18.703 *INFO* [aysnc-index-update-async] org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate [async] AsyncIndex update run completed in 25.58 min. Indexed 7498 nodes\n06.11.2016 18:41:43.088 *INFO* [aysnc-index-update-async] org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate [async] AsyncIndex update run completed in 24.79 min. Indexed 28335 nodes\n{noformat}\n\nIt would be good to also include the number of nodes traversed in that diff. For the record such high times were seen on a setup which did not had persistent cache enabled which probably caused slow diff",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Collect stats around number of nodes traversed by AsyncIndexer"
   },
   {
      "_id": "13020824",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-15 15:16:07",
      "description": "The current default of the node deduplication cache is 8M. We should consider changing this to a smaller value still resulting in effective compactions. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Change default size of the node deduplication cache"
   },
   {
      "_id": "13020468",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-14 10:26:15",
      "description": "Performing two backups via {{RepositoryManagementMBean.startBackup}}, directory size increases not only with the delta, but also again with the size of existing tar files. This lead me to the conclusion that backup is not incremental.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "operations",
         "production",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Backup is not incremental i.e. previous tar files are duplicated"
   },
   {
      "_id": "13020123",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2016-11-11 14:47:36",
      "description": "It appears that very strange things can happen when the system isn't configured properly, for instance when multiple DataSources with the same name are configured.\n\nTODO:\n\n- log.info unbindDataSource() calls\n- prevent registrations of multiple node stores when bindDataSource() is called multiple times\n- in unbindDataSource(), check that the datasource is actually the one that was bound before\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "patch-available",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "improve DocumentNodeStoreService robustness for RDB configs"
   },
   {
      "_id": "13018193",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-11-04 18:23:37",
      "description": "For changes in bundled nodes diff is not reporting change in properties of bundled node",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Journal diff not working for changes in bundled node"
   },
   {
      "_id": "13017939",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-11-04 04:35:11",
      "description": "Saw a test failure [here|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/1262/jdk=JDK%201.7%20(latest),label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=unittesting/testReport/junit/org.apache.jackrabbit.oak.run.osgi/DocumentNodeStoreConfigTest/testRDBDocumentStore_CustomBlobDataSource/]\n\nIn the logs following can be seen\n{noformat}\nCaused by: org.h2.jdbc.JdbcSQLException: Syntax error in SQL statement \"create alias if not exists unix_timestamp as [*]$$ long unix_timestamp() { return System.currentTimeMillis()/1000L; }\"; SQL statement:\ncreate alias if not exists unix_timestamp as $$ long unix_timestamp() { return System.currentTimeMillis()/1000L; } $$; [42000-193]\n\tat org.h2.message.DbException.getJdbcSQLException(DbException.java:345) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.message.DbException.get(DbException.java:179) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.message.DbException.get(DbException.java:155) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.message.DbException.getSyntaxError(DbException.java:191) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.command.Parser.getSyntaxError(Parser.java:530) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.command.Parser.checkRunOver(Parser.java:3694) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.command.Parser.initialize(Parser.java:3559) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.command.Parser.parse(Parser.java:304) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.command.Parser.parse(Parser.java:293) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.command.CommandContainer.recompileIfRequired(CommandContainer.java:73) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.command.CommandContainer.update(CommandContainer.java:93) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.command.Command.executeUpdate(Command.java:258) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:184) ~[h2-1.4.193.jar:1.4.193]\n\tat org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:158) ~[h2-1.4.193.jar:1.4.193]\n\tat org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.initialize(RDBDocumentStore.java:802) ~[oak-core-1.6-SNAPSHOT.jar:1.6-SNAPSHOT]\n\tat org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.<init>(RDBDocumentStore.java:209) ~[oak-core-1.6-SNAPSHOT.jar:1.6-SNAPSHOT]\n\t... 26 common frames omitted\n03.11.2016 14:52:10.662 *ERROR* [CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreService)] org.apache.jackrabbit.oak-core [org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreService(23)] Failed creating the component instance; see log for reason\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failure in DocumentNodeStoreConfigTest.testRDBDocumentStore_CustomBlobDataSource"
   },
   {
      "_id": "13017636",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-03 13:40:55",
      "description": "This issue is about making TarMK gc more scalable: \n* how to deal with huge repositories.\n* how to deal with massive concurrent writes.\n* how can we improve monitoring to determine gc health. \n** Monitor deduplication caches (e.g. deduplication of checkpoints)\n\nPossible avenues to explore:\n* Can we partition gc? (e.g. along sub-trees, along volatile vs. static content)\n* Can we pause and resume gc? (e.g. to give precedence to concurrent writes) \n* Can we make gc a real background process not contending with foreground operations? \n\nThis issue is a follow up to OAK-2849, which was about efficacy of gc.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "gc",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve GC scalability on TarMK"
   },
   {
      "_id": "13017275",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-02 15:14:31",
      "description": "{{ImmutableRecordNumbers}} is based on a map. This turns to be expensive as the items in the map are accessed very frequently. I would like to look into way of optimising this using a linear storage model instead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimise ImmutableRecordNumbers"
   },
   {
      "_id": "13017273",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-02 15:13:14",
      "description": "The methods in {{RepositoryManagementMBean}} do not provide any description to the end user and might seem unclear for someone trying to trigger them via JMX.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "osgi-config"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "Add @Description annotations to methods in RepositoryManagementMBean"
   },
   {
      "_id": "13017185",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-11-02 11:50:17",
      "description": "Oak Lucene index is currently using Tika 1.5 version while current latest release of Apache Tika is 1.14, I think there are lots of \"interesting\" bugs fixed, and possibly improvements (performance, more accurate text extraction, etc.) we could get at almost 0 cost by just bumping the version number.\r\n\r\nRelease notes https://tika.apache.org/1.15/index.html",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Upgrade to Tika 1.15 version"
   },
   {
      "_id": "13017154",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-02 10:19:33",
      "description": "Currently, there are two implementations for finding out the gain in repository size after running compaction: the old one, {{CompactionGainEstimate}} and the new one, {{SizeDeltaGcEstimation}}. Similarly, there are also two configurations for customising them, in {{SegmentNodeStoreService}}, {{compaction.gainThreshold}} and {{compaction.sizeDeltaEstimation}}.\n\nAt the moment both of them are exposed as OSGi configurations, but only the new one should be exposed (e.g. {{compaction.sizeDeltaEstimation}}). \n\nIt must be evaluated whether it makes sense to keep the logic associated with the old implementation.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "osgi-config"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove the old estimation OSGi setting (compaction.gainThreshold)"
   },
   {
      "_id": "13017105",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-11-02 06:47:31",
      "description": "Bundling logic would not work for node structures which are present in versionstore i.e. nodes stored under /jcr:system/jcr:versionStorage as the nodes there always have type {{nt:frozenNode}}. So any node structure which gets version would not get benefit of bundling\n\nCurrently bundling logic looks for {{jcr:primaryType}} and {{jcr:mixinTypes}} for determining type information. To support bundling for nodes stored in version store we should also look for \n\n* jcr:frozenPrimaryType\n* jcr:frozenMixinTypes\n\nThese properties contains the type information of original node stored which got versioned",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support bundling of nodes present in version store"
   },
   {
      "_id": "13016843",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-01 09:35:34",
      "description": "Various aspects of how Segment Tar caches segments could possibly improved. The current cache is a result of replacing the former ad-hoc cache with a proper one in OAK-3055. While the former was prone to contention under concurrent load the current cache is too oblivious about reads: read accesses are always served through {{SegmentId.segment}} and never actually hit the cache. This results in frequently accessed segments not to be seen as such by the cache and potentially being prematurely evicted. \n\nPossibly approaches to address this problem include: \n* Reinstantiating the cache we had pre OAK-3055 but making in fully concurrent. \n* Convey the information about read accesses to the current cache. \n* In either of the above cases avoid bulk segments from being placed into the cache. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve caching of segments"
   },
   {
      "_id": "13015883",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2016-10-27 16:14:37",
      "description": "This is a follow up to OAK-4970: when defining an workspace name that doesn't match the name of the workspace of the source repository (via the {{WORKSPACE_NAME_PROP}} system property), upgrading is still very slow and causes the repository size to grow way too much. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Copying the versions store is slow and increase the repository size"
   },
   {
      "_id": "13015847",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2016-10-27 14:41:54",
      "description": "OAK-3018 removed the single production usage of DocumentStore.update(). I propose we remove the method to reduce maintenance.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove DocumentStore.update()"
   },
   {
      "_id": "13015787",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-10-27 12:02:47",
      "description": "Currently, {{o.a.j.oak.security.authorization.accesscontrol.Util#generateAceName}} is traversing all the existing ACE of a certain node in order to generate continuous numbering (allow0, allow1, allow2).\nWhile that certainly helps to produce human readable names, it represents quite a performance bottleneck when the number of existing ACE starts to grow.\n\nSince the naming is a pure implementation detail, my proposal is to keep the continuous numbering for the first hundreds of nodes and then use a random number to generate unique names in a faster fashion.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Speed up ACE node name generation"
   },
   {
      "_id": "13015762",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-27 10:13:52",
      "description": "I would like to improve how the {{SegmentWriter}} is used for compaction. In particular I dislike how the {{SegmentBufferWriter}} needs to be looped into {{SegmentWriter.writeNode()}}.\nFurthermore creating a {{SegmentWriter}} for offline compaction with its own cache (instead of using the caches we have) is a bit wasteful wrt. to memory. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve the usage of the SegmentWriter for compaction"
   },
   {
      "_id": "13015707",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-27 07:27:57",
      "description": "I've recently seen a couple of the standby tests fail. E.g. on Jenkins: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/1245/\n\n{noformat}\njava.lang.AssertionError: expected: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }> but was: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }>\n\tat org.apache.jackrabbit.oak.segment.standby.StandbyTestIT.testSyncLoop(StandbyTestIT.java:122)\n{noformat}\n\n{noformat}\njava.lang.AssertionError: expected: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }> but was: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }>\n\tat org.apache.jackrabbit.oak.segment.standby.StandbyTestIT.testSyncLoop(StandbyTestIT.java:122)\n{noformat}\n\n{{org.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT.testProxySkippedBytes}}:\n{noformat}\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n{noformat}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Standby test failures"
   },
   {
      "_id": "13015704",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-27 07:22:12",
      "description": "I've seen that test going OOM on our Jenkins: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/1245/#showFailuresLink\n\n{noformat}\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.jackrabbit.oak.segment.SegmentDataStoreBlobGCIT.setUp(SegmentDataStoreBlobGCIT.java:220)\n\tat org.apache.jackrabbit.oak.segment.SegmentDataStoreBlobGCIT.setUp(SegmentDataStoreBlobGCIT.java:141)\n\tat org.apache.jackrabbit.oak.segment.SegmentDataStoreBlobGCIT.consistencyCheckInit(SegmentDataStoreBlobGCIT.java:317)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "OOM in SegmentDataStoreBlobGCIT"
   },
   {
      "_id": "13015399",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-26 12:24:43",
      "description": "{noformat}\nTests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 13.484 sec <<< FAILURE! - in org.apache.jackrabbit.oak.segment.migration.ExternalToExternalMigrationTest\nblobsCanBeReadAfterSwitchingBlobStore(org.apache.jackrabbit.oak.segment.migration.ExternalToExternalMigrationTest)  Time elapsed: 0.463 sec  <<< ERROR!\njava.io.IOException: Unable to delete file: C:\\tmp\\1477483643533-0\\segmentstore\\data00001a.tar\n\nblobsExistsOnTheNewBlobStore(org.apache.jackrabbit.oak.segment.migration.ExternalToExternalMigrationTest)  Time elapsed: 13.021 sec  <<< ERROR!\njava.io.IOException: Unable to delete file: C:\\tmp\\1477483643996-0\\segmentstore\\data00000a.tar\n\nRunning org.apache.jackrabbit.oak.segment.migration.SegmentToExternalMigrationTest\nTests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 12.719 sec <<< FAILURE! - in org.apache.jackrabbit.oak.segment.migration.SegmentToExternalMigrationTest\nblobsCanBeReadAfterSwitchingBlobStore(org.apache.jackrabbit.oak.segment.migration.SegmentToExternalMigrationTest)  Time elapsed: 0.157 sec  <<< ERROR!\njava.io.IOException: Unable to delete file: C:\\tmp\\1477483657018-0\\segmentstore\\data00001a.tar\n\nblobsExistsOnTheNewBlobStore(org.apache.jackrabbit.oak.segment.migration.SegmentToExternalMigrationTest)  Time elapsed: 12.561 sec  <<< ERROR!\njava.io.IOException: Unable to delete file: C:\\tmp\\1477483657193-0\\segmentstore\\data00000a.tar\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ExternalToExternalMigrationTest failures on Windows"
   },
   {
      "_id": "13015240",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-25 21:30:07",
      "description": "Running offline compaction on a repository with checkpoints will explode those into full copies. Observed e.g. with OAK-5001. \n\nI think we should consider improving this by compacting checkpoints on top of each other in the proper order ({{oak-upgrade}} does this successfully). \n\n[~alex.parvulescu], WDYT? What was our take on this in the previous Oak versions? ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction explodes checkpoints "
   },
   {
      "_id": "13014980",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-25 04:50:53",
      "description": "With OAK-4180 its possible to use a SegmentNodeStore as secondary store and thus like a cache for certain set of path. In such kind of setup persistent cache should not cache those NodeStates which are covered by DocumentNodeStateCache",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Persistent cache should not cache those paths which are covered by DocumentNodeStateCache"
   },
   {
      "_id": "13014773",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-24 16:00:36",
      "description": "The former depends on the latter only for generation sequence numbers of segments, which are subsequently used to generate the segment meta information. I suggest to replace that dependency with a generalised one. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentBufferWriter should not depend on SegmentTracker"
   },
   {
      "_id": "13014772",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-24 15:56:02",
      "description": "We should simplify {{GCListener}} to minimise the boilerplate necessary in {{FileStoreBuilder}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Simplify GCListener"
   },
   {
      "_id": "13014670",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-10-24 09:59:25",
      "description": "The MongoDocumentStore gets the current server time with the {{serverStatus}} command. When MongoDB is configured with authentication, the command may fail because it requires the [clusterMonitor|https://docs.mongodb.com/manual/reference/built-in-roles/#clusterMonitor] role.\n\nThe method will then simply log a WARN message and assume no time difference. Maybe there is a different command we can use to get the time on the server?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Server time unavailable with authenticated connection to MongoDB"
   },
   {
      "_id": "13014649",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-24 07:53:54",
      "description": "With OAK-4975 Oak would be shipping some default bundling config. An application might want to disable such bundling and for those cases we need to support some config option to disable bundling for specific nodetypes.\n\n*Proposal*\n\nHave a boolean property {{disabled}} on bundling config for specific nodetype to indication that this bundling config is not to be used\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bundling",
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Config option to disable specific bundling config"
   },
   {
      "_id": "13014175",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-10-21 09:26:39",
      "description": "Oak QueryEngine exposes few settings options via {{QueryEngineSettings}}. Currently they can be configured via\n\n# System properties\n# JMX - The settings are not persistent \n\nWe should have a way to configure them via OSGi also. A simple option can be to have a OSGi component which obtains a reference to {{QueryEngineSettingsMBean}} and then modifies the config upon activation",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable configuring QueryEngineSettings via OSGi config"
   },
   {
      "_id": "13013781",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-20 08:02:49",
      "description": "SegmentDataStoreBlobGCIT seems to crash the JVM on Java 7. Following is the relevant part of the build output.\n\n{noformat}\n[INFO] --- maven-failsafe-plugin:2.19.1:integration-test (default) @ oak-segment-tar ---\n\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.jackrabbit.oak.segment.file.FileStoreIT\nTests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.301 sec - in org.apache.jackrabbit.oak.segment.file.FileStoreIT\nRunning org.apache.jackrabbit.oak.segment.file.SegmentReferenceLimitTestIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 sec - in org.apache.jackrabbit.oak.segment.file.SegmentReferenceLimitTestIT\nRunning org.apache.jackrabbit.oak.segment.file.LargeNumberOfPropertiesTestIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.001 sec - in org.apache.jackrabbit.oak.segment.file.LargeNumberOfPropertiesTestIT\nRunning org.apache.jackrabbit.oak.segment.SegmentOverflowExceptionIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 sec - in org.apache.jackrabbit.oak.segment.SegmentOverflowExceptionIT\nRunning org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 45.78 sec - in org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT\nRunning org.apache.jackrabbit.oak.segment.standby.FailoverSslTestIT\nTests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.202 sec - in org.apache.jackrabbit.oak.segment.standby.FailoverSslTestIT\nRunning org.apache.jackrabbit.oak.segment.standby.BrokenNetworkIT\nTests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 63.024 sec - in org.apache.jackrabbit.oak.segment.standby.BrokenNetworkIT\nRunning org.apache.jackrabbit.oak.segment.standby.FailoverMultipleClientsTestIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.052 sec - in org.apache.jackrabbit.oak.segment.standby.FailoverMultipleClientsTestIT\nRunning org.apache.jackrabbit.oak.segment.standby.MBeanIT\nTests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.287 sec - in org.apache.jackrabbit.oak.segment.standby.MBeanIT\nRunning org.apache.jackrabbit.oak.segment.standby.FailoverIPRangeIT\nTests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.691 sec - in org.apache.jackrabbit.oak.segment.standby.FailoverIPRangeIT\nRunning org.apache.jackrabbit.oak.segment.standby.StandbyTestIT\nTests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.303 sec - in org.apache.jackrabbit.oak.segment.standby.StandbyTestIT\nRunning org.apache.jackrabbit.oak.segment.standby.RecoverTestIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.415 sec - in org.apache.jackrabbit.oak.segment.standby.RecoverTestIT\nRunning org.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.002 sec - in org.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT\nRunning org.apache.jackrabbit.oak.segment.SegmentDataStoreBlobGCIT\n\nResults :\n\nTests run: 65, Failures: 0, Errors: 0, Skipped: 3\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 10:17 min\n[INFO] Finished at: 2016-10-19T20:45:40+00:00\n[INFO] Final Memory: 63M/553M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.19.1:integration-test (default) on project oak-segment-tar: Execution default of goal org.apache.maven.plugins:maven-failsafe-plugin:2.19.1:integration-test failed: The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\n[ERROR] Command was /bin/sh -c cd /apps/jenkins/workspace/oak-segment-tar && /opt/jdk-7/jre/bin/java -Xmx512m -XX:MaxPermSize=64m -XX:+HeapDumpOnOutOfMemoryError -Dupdate.limit=100 -Djava.awt.headless=true -jar /apps/jenkins/workspace/oak-segment-tar/target/surefire/surefirebooter4283069132546797078.jar /apps/jenkins/workspace/oak-segment-tar/target/surefire/surefire8963659563100379656tmp /apps/jenkins/workspace/oak-segment-tar/target/surefire/surefire_03767892930481742588tmp\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: SegmentDataStoreBlobGCIT"
   },
   {
      "_id": "13013555",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-19 14:52:47",
      "description": "Currently there is no easy way to run the tools provided by {{oak-run}} against a snapshot version of Segment Tar. In order to have better CI coverage (e.g. benchmarks) of Segment Tar, we need to introduce a way for running such tools independently of {{oak-run}}. Eventually {{oak-run}} should even be using that tooling front-end instead of directly depending on {{oak-segment-tar}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Standalone tooling for segment tar"
   },
   {
      "_id": "13013458",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-19 10:01:25",
      "description": "Bundling pattern currently supports wild card pattern. This makes it powerful but at same time can cause issue if it misconfigured. \n\nWe should review this aspect before 1.6 release to determine if this feature needs to be exposed or not. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Review the support for wildcards in bundling pattern"
   },
   {
      "_id": "13013457",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-19 09:59:05",
      "description": "The config for node bundling feature in DocumentNodeStore is currently stored under {{jcr:system/rep:documentStore/bundlor}}. This task is meant to \n\n* Review the access control aspect - This config should be only updatetable by system admin\n* Config under here should be writeable via JCR api",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Review the security aspect of bundling configuration"
   },
   {
      "_id": "13013452",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-19 09:40:37",
      "description": "On some machines the {{BrokenNetworkTest}} fails:\n\n{noformat}\nFailed tests:\n  BrokenNetworkTest.testProxyFlippedEndByteSSL:103->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxyFlippedIntermediateByte:88->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxyFlippedIntermediateByteSSL:93->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxyFlippedStartByte:78->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxySSLSkippedBytes:63->useProxy:113->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxySSLSkippedBytesIntermediateChange:73->useProxy:113->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxySkippedBytesIntermediateChange:68->useProxy:113->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n{noformat}\n\nStack traces are all similar to \n{noformat}\ntestProxySkippedBytesIntermediateChange(org.apache.jackrabbit.oak.segment.standby.BrokenNetworkTest)  Time elapsed: 5.577 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n\tat org.apache.jackrabbit.oak.segment.standby.BrokenNetworkTest.useProxy(BrokenNetworkTest.java:146)\n\tat org.apache.jackrabbit.oak.segment.standby.BrokenNetworkTest.useProxy(BrokenNetworkTest.java:113)\n\tat org.apache.jackrabbit.oak.segment.standby.BrokenNetworkTest.testProxySkippedBytesIntermediateChange(BrokenNetworkTest.java:68)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: BrokenNetworkTest"
   },
   {
      "_id": "13013446",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-19 09:09:55",
      "description": "Regarding this, the current \"Status\" is showing the last log info. This is useful, but it would also be interesting to expose the real-time status. For monitoring it would be useful to know exactly in which phase we are, e.g. a field showing on of the following:\n- idle\n- estimation\n- compaction\n- compaction-retry-1\n- compaction-retry-2\n- compaction-forcecompact\n- cleanup\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentRevisionGC MBean should report more detailed gc status information  "
   },
   {
      "_id": "13013225",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-18 15:29:59",
      "description": "The {{SetPropertyTest}} fails on Oak Segment Tar:\n\n{noformat}\njavax.jcr.InvalidItemStateException: This item [/testfb3e8f1a/ca1ef350-f650-4466-b9e3-7f77d83e6303] does not exist anymore\n\tat org.apache.jackrabbit.oak.jcr.delegate.ItemDelegate.checkAlive(ItemDelegate.java:86)\n\tat org.apache.jackrabbit.oak.jcr.session.ItemImpl$ItemWriteOperation.checkPreconditions(ItemImpl.java:96)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl$35.checkPreconditions(NodeImpl.java:1366)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.prePerform(SessionDelegate.java:615)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:205)\n\tat org.apache.jackrabbit.oak.jcr.session.ItemImpl.perform(ItemImpl.java:112)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.internalSetProperty(NodeImpl.java:1363)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.setProperty(NodeImpl.java:506)\n\tat org.apache.jackrabbit.oak.benchmark.SetPropertyTest.runTest(SetPropertyTest.java:65)\n\tat org.apache.jackrabbit.oak.benchmark.AbstractTest.execute(AbstractTest.java:372)\n\tat org.apache.jackrabbit.oak.benchmark.AbstractTest.runTest(AbstractTest.java:221)\n\tat org.apache.jackrabbit.oak.benchmark.AbstractTest.run(AbstractTest.java:197)\n\tat org.apache.jackrabbit.oak.benchmark.BenchmarkRunner.main(BenchmarkRunner.java:456)\n\tat org.apache.jackrabbit.oak.run.BenchmarkCommand.execute(BenchmarkCommand.java:26)\n\tat org.apache.jackrabbit.oak.run.Mode.execute(Mode.java:63)\n\tat org.apache.jackrabbit.oak.run.Main.main(Main.java:49)\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SetPropertyTest benchmark fails on Segment Tar"
   },
   {
      "_id": "13013213",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-18 14:37:26",
      "description": "{{MutableRecordNumbers}} is based on a map. This turns to be expensive as the items in the map are accessed very frequently. I would like to look into way of optimising this using a linear storage model instead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimise MutableRecordNumbers"
   },
   {
      "_id": "13013126",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-18 10:27:28",
      "description": "The {{SegmentWriter}} currently buffers the list of child nodes changed on a nodestate update [0] (new node or updated node). This can be problematic in a scenario where there are a large number of children added to a node (ie. unique index size seen to spike above {{10MM}} in one case).\n\nTo have a reference for the impact of this, at the {{SegmentWriter}} level, for a list of map entries of almost {{3MM}} items, I saw it take up around {{245MB}} heap.\n\nThis issue serves to track a possible improvement here in how we handle this update scenario.\n\n\n\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentWriter.java#L516",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentWriter buffers child node list changes"
   },
   {
      "_id": "13012799",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-17 09:29:18",
      "description": "This is the {{oak-segment-tar}} side of OAK-4919",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide status for gc process "
   },
   {
      "_id": "13012756",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-10-17 04:31:46",
      "description": "Currently if any one of the async index gets corrupted it brings down the whole async indexer and no other index gets updated untill system administrator reindexes the problamatic async index. \n\nInstead of fail all we should isolate such corrupted index and mark them as corrupted. And still let async indexer progress for other working indexes. \n\nThis would ensure that one corrupted index does not affect the whole system and allow the application to work partially. \n\nFeature branch - https://github.com/chetanmeh/jackrabbit-oak/compare/trunk...chetanmeh:OAK-4939?expand=1",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Isolate corrupted index and make async indexer more resilient"
   },
   {
      "_id": "13012324",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-14 11:00:17",
      "description": "See OAK-4937",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "clarify contract for UpdateOp with missing operation on _id"
   },
   {
      "_id": "13012046",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-13 16:18:45",
      "description": "Running the {{ConcurrentWriteTest}} benchmark and monitoring the hits and misses of the segment cache (LIRS), I noticed that some segments are loaded over and over again (up to 3000 times). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Too many segment cache misses"
   },
   {
      "_id": "13011274",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2016-10-11 07:22:28",
      "description": "The tests are currently failing with \n\n{noformat}\nava.lang.RuntimeException: Unable to invoke method 'activate' for class org.apache.jackrabbit.oak.segment.SegmentNodeStoreService\n\n\tat org.apache.sling.testing.mock.osgi.OsgiServiceUtil.invokeMethod(OsgiServiceUtil.java:262)\n\tat org.apache.sling.testing.mock.osgi.OsgiServiceUtil.activateDeactivate(OsgiServiceUtil.java:86)\n\tat org.apache.sling.testing.mock.osgi.MockOsgi.activate(MockOsgi.java:162)\n\tat org.apache.sling.testing.mock.osgi.MockOsgi.activate(MockOsgi.java:173)\n\tat org.apache.sling.testing.mock.osgi.context.OsgiContextImpl.registerInjectActivateService(OsgiContextImpl.java:142)\n\tat org.apache.jackrabbit.oak.segment.SegmentS3DataStoreStatsTest.registerSegmentNodeStoreService(SegmentS3DataStoreStatsTest.java:113)\n\tat org.apache.jackrabbit.oak.segment.SegmentS3DataStoreStatsTest.testUseS3BlobStore(SegmentS3DataStoreStatsTest.java:74)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n\tat org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:239)\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:117)\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:43)\n\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:239)\n\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)\nCaused by: java.lang.NoSuchMethodError: org.apache.jackrabbit.oak.spi.state.RevisionGC.<init>(Ljava/lang/Runnable;Ljava/util/concurrent/Executor;)V\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStoreService.registerSegmentStore(SegmentNodeStoreService.java:471)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStoreService.registerNodeStore(SegmentNodeStoreService.java:339)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStoreService.activate(SegmentNodeStoreService.java:304)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.sling.testing.mock.osgi.OsgiServiceUtil.invokeMethod(OsgiServiceUtil.java:253)\n\t... 38 more\n{noformat}\n\nMost likely our changes in OAK-4835 caused this regression. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "regression",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentS3DataStoreStatsTest failing"
   },
   {
      "_id": "13011261",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2016-10-11 05:57:16",
      "description": "DefaultSyncHandler.listIdentities() collects users by [searching for all nodes under /home|https://github.com/apache/jackrabbit-oak/blob/b3e62e3467bf6433b5a419c2f371331f33e57820/oak-auth-external/src/main/java/org/apache/jackrabbit/oak/spi/security/authentication/external/impl/DefaultSyncHandler.java#L143] \u2013 the xpath query executed is\n\n{noformat}\n/jcr:root/home//element(*)[@jcr:primaryType]\n{noformat}\n\nWith a few hundred users this easily gives an oak index traversal warning:\n{noformat}\norg.apache.jackrabbit.oak.spi.query.Cursors$TraversingCursor Traversed 1000 nodes with filter Filter(query=select [jcr:path], [jcr:score], * from [nt:base] as a where [jcr:primaryType] is not null and isdescendantnode(a, '/home') /* xpath: /jcr:root/home//element(*)[@jcr:primaryType] */, path=/home//*, property=[jcr:primaryType=[is not null]]); consider creating an index or changing the query\n{noformat}\n\nA few lines later [it actually reduces|https://github.com/apache/jackrabbit-oak/blob/b3e62e3467bf6433b5a419c2f371331f33e57820/oak-auth-external/src/main/java/org/apache/jackrabbit/oak/spi/security/authentication/external/impl/DefaultSyncHandler.java#L151] the result to authorizables which have a {{rep:externalId}}. Since OAK-4301 there is an oak index for {{rep:externalId}}, so the query can be optimized by searching for anything with {{rep:externalId}} instead:\n{code:java}\nuserManager.findAuthorizables(\"rep:externalId\", null);\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DefaultSyncHandler.listIdentities() search too broad, triggers traversal warning"
   },
   {
      "_id": "13011087",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-10-10 15:59:23",
      "description": "The methods to invoke and cancel revision gc return void. This is by design as those calls are asynchronous. The idea is that {{RevisionGC.getRevisionGCStatus()}} would return the current status of an ongoing gc operation. However, currently that method only returns the status of the asynchronous task that was fired off. It should instead be able to convey back the real status of the underlying operation. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Better feedback from method invocations on RevisionGCMBean"
   },
   {
      "_id": "13011031",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-10 13:20:11",
      "description": "Sub task of OAK-4835 for the {{document}} specific changes",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "management"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Interrupt online revision cleanup on documentmk"
   },
   {
      "_id": "13011027",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-10 13:13:38",
      "description": "Sub task of OAK-4835 for the {{segment-tar}} specific changes",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "management"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Interrupt online revision cleanup on segment-tar"
   },
   {
      "_id": "13010921",
      "assignee": "egli",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-10-10 07:31:34",
      "description": "This is a subtask as a result of [discussions|https://issues.apache.org/jira/browse/OAK-4796?focusedCommentId=15550962&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15550962] around design in OAK-4796:\n\nBased on the ChangeSet provided with OAK-4907 in the CommitContext, the ChangeProcessor should do a best-effort prefiltering of commits before they get added to the (BackgroundObserver's) queue.\n\nThis consists of the following parts:\n* -the support for optionally excluding commits from being added to the queue in the BackgroundObserver- EDIT: factored that out into OAK-4916\n* -the BackgroundObserver signaling downstream Observers that a change should be excluded via a {{NOOP_CHANGE}} CommitInfo- EDIT: factored that out into OAK-4916\n* the ChangeProcessor using OAK-4907's ChangeSet of the CommitContext for best-effort prefiltering - and handling the {{NOOP_CHANGED}} CommitInfo introduced in OAK-4916\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "review"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Best-effort prefiltering in ChangeProcessor based on ChangeSet"
   },
   {
      "_id": "13010407",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-10-07 09:49:01",
      "description": "Currently for queries involving unique index like \n\n{noformat}\nSELECT * FROM [nt:base] WHERE [jcr:uuid] = $id\n{noformat}\n\nQueryEngine would start consulting all types of index in order of minimum cost. Where minimum cost are\n* PropertyIndex - 2.0\n* LucenePropertyIndex - 2.1\n\nFor such queries in case of match property index returns a cost of (base) 2 + (count) 1 = 3 due to which QE has to consult Lucene index also. Given such queries a very frequent it would be better to avoid consulting Lucene index as that adds unnecessary overhead",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "For unique indexes avoid consulting indexes other than property index"
   },
   {
      "_id": "13010103",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-06 08:48:58",
      "description": "The diff persistent cache is important for efficient processing of external changes and should be enabled by default.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable persistent caches by default"
   },
   {
      "_id": "13010089",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-10-06 07:57:14",
      "description": "With OAK-4765 Oak Segment Tar acquired the capability for stopping a running revision gc task. This is currently exposed via {{SegmentRevisionGCMBean.stopCompaction}}. I think it would make to expose this functionality through {{RevisionGCMBean}} and {{RepositoryManagementMBean}} also/instead. \n\n[~mreutegg], [~alex.parvulescu] WDYT? Could the document node store also implement this or would we just not support it there? ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "management",
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Include option to stop GC in RevisionGCMBean and RepositoryManagementMBean"
   },
   {
      "_id": "13009902",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-05 15:42:41",
      "description": "{{FileStore.cleanup()}} currently returns a list of {{File}} instances relying on the caller to remove those files. This breaks encapsulation as the file store is the sole owner of these files and only the file store should be removing them.\n\nI suggest to replace the current cleanup method with one that returns {{void}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "FileStore cleanup should not leak out file handles"
   },
   {
      "_id": "13009826",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2016-10-05 09:56:31",
      "description": "We should add documentation how Oak deals with conflicts. This was once documented in the Javadocs of {{MicroKernel.rebase()}} but got lost along with that class. Note that OAK-1553 refines conflict handling but this refinement has not been implemented in all backends yet. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document conflict handling"
   },
   {
      "_id": "13009693",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-10-04 20:56:48",
      "description": "*Problem:* It's easy to run into performance problems with queries that are not backed by an index or miss the right one. Developers writing these queries typically do not have the real large production data, and thus don't see that a query would scale badly, and would not see any traversal warnings, as these only happen with a large number of results.\n\n*Proposal:* Oak's query engine already calculates a cost estimate to make a decision which index to use, or even if there is any at all. This cost estimate could be used to find out if a query is not supported by an index or with one that is not suitable enough (e.g. ordering by property that is not indexed)\n\nIf a query is above a certain cost value, a big warning could be put out or even the query could be made to fail (maybe a per query option, that you might want to have to \"fail\" by default to ensure people are not overlooking the problem). The cost limit should be configurable, as it might depend on the hardware power.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Warn or fail queries above a configurable cost value"
   },
   {
      "_id": "13009491",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-10-04 10:24:00",
      "description": "The {{BlobGarbageCollection}} MBean is no longer available on a standby instance, this affects non-shared datastore setups (on a shared datastore you'd only need to run blob gc on the primary).\nThis change was introduced by OAK-4089 (and backported to 1.4 branch with OAK-4093).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Missing BlobGarbageCollection MBean on standby instance"
   },
   {
      "_id": "13009466",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-10-04 08:02:33",
      "description": "Currently the merge semaphore in SegmentNodeStore is by default non fair. OAK-3588 provided a config option to make it fair.\n\nWe should change the default to fair so as to ensure writer threads never get starved. \n\nEventually this change would need to be backported to branches. Further going forward OAK-4122 would replace the lock",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make merge semaphore in SegmentNodeStore fair by default"
   },
   {
      "_id": "13009230",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-03 13:24:28",
      "description": "With OAK-2404 we started logging all segment ids that a cleanup cycle removes. While this is useful for post mortems in the case of a {{SNFE}}, it also increases log files by many megabytes. \n\nSince OAK-2405 added some additional gc information, which is logged along with the missing segment in the case of a {{SNFE}}, I think the logging of the cleaned segment ids is not superfluous and we should remove it. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "logging",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove logging of cleaned segment id on cleanup"
   },
   {
      "_id": "13009176",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-03 07:26:29",
      "description": "As {{RevisionGCMBean.startRevisionGC()}} can be used to manually invoke a gc cycle, there is the danger of running into a {{SNFE}} when gc is run multiple times in quick succession (due to the retention time being based on number of generations). We should come up with a mechanism to prevent this scenario. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Avoid running GC too frequently"
   },
   {
      "_id": "13008877",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-09-30 13:40:47",
      "description": "For a variety of use cases it is useful to multiplex multiple node stores behind a single interface.\n\nTogether with [~tomek.rekawek] I have been working on a limited-purpose MultiplexingNodeStore which aims to multiplex multiple stores with the limitation that only one store may be written to, while others are read-only.\n\nThe implementation has been validated to be functional, but not yet tested for behaviour under heavy load, performance, etc.\n\nI believe that we can still incorporate this early to make maintenance simpler and ensure that the high-level design is correct.\n\nLink to pull request -  https://github.com/apache/jackrabbit-oak/pull/55",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "multiplexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Multiplexing NodeStore"
   },
   {
      "_id": "13008676",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-29 19:06:27",
      "description": "Revision GC in a first phase finds all documents for deleted nodes and their previous documents. Reading the previous documents can be avoided in some cases. The ids of first level previous documents can be derived directly from the previous map in the main document.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Avoid queries for first level previous documents during GC"
   },
   {
      "_id": "13008560",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-29 14:57:21",
      "description": "Said test sometimes fails with the following stack trace:\n\n{noformat}\n09:46:40.900 ERROR [main] SegmentId.java:127                Segment not found: 8399230c-9338-47e3-acf5-b92d326cf171. SegmentId age=7473ms,gc-count=32,gc-status=success,store-generation=29,reclaim-predicate=(generation<=27),segment-generation27\norg.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment 8399230c-9338-47e3-acf5-b92d326cf171 not found\nat org.apache.jackrabbit.oak.segment.file.FileStore$14.call(FileStore.java:1345) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.file.FileStore$14.call(FileStore.java:1285) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.load(CacheLIRS.java:1013) ~[oak-core-1.5.8.jar:1.5.8]\nat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.get(CacheLIRS.java:974) ~[oak-core-1.5.8.jar:1.5.8]\nat org.apache.jackrabbit.oak.cache.CacheLIRS.get(CacheLIRS.java:285) ~[oak-core-1.5.8.jar:1.5.8]\nat org.apache.jackrabbit.oak.segment.SegmentCache.getSegment(SegmentCache.java:92) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:1285) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:123) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.Record.getSegment(Record.java:70) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeState.getStableIdBytes(SegmentNodeState.java:139) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeState.getStableId(SegmentNodeState.java:122) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeState.fastEquals(SegmentNodeState.java:633) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.execute(SegmentNodeStore.java:604) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeStore.merge(SegmentNodeStore.java:265) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.HeavyWriteIT.heavyWrite(HeavyWriteIT.java:85) [test-classes/:na]\n{noformat}\n\nThis is a problem with the test, not a regression:\n\n{noformat}\nSegment not found: 8399230c-9338-47e3-acf5-b92d326cf171. SegmentId age=7473ms,gc-count=32,gc-status=success,store-generation=29,reclaim-predicate=(generation<=27),segment-generation27\n{noformat}\n\nThis means the missing segment was successfully gc'ed at GC #32. Its generation was 27 while the store just got bumped to generation 29. This causes a cleanup of all generations <= 27. \n\nThe test itself calls {{FileStore.gc()}} in quick succession while at the same time writing to the store. This is likely to at some point cause a write to be based on an already collected segment. I suggest to fix this by increasing the number of retained generations to a sufficiently high value (for this test). \n\nOn a side node, this issue (and being able to to a root cause analysis) validates the additional logging that we added with OAK-2405! \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failure: HeavyWriteIT"
   },
   {
      "_id": "13008550",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-09-29 14:30:59",
      "description": "MongoVersionGCSupport uses the default batchSize when it queries for possibly deleted documents. The default will initially read 100 documents and then as many as fit into a 4MB response. Depending on the document size a couple of thousand will fit in there and take time to process. It may happen that the MongoDB cursor then times out and the VersionGC fails.\n\nAn easy and safe solution is to reduce the batch size to a given number of documents.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Reduce query batch size for deleted documents"
   },
   {
      "_id": "13008092",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-09-28 00:16:45",
      "description": "Oak (like Jackrabbit) does not allow spaces commonly used in CJK like {{u3000}} (ideographic space) or {{u00A0}} (no-break space) _inside_ a node name, while allowing some of them (the non breaking spaces) at the _beginning or end_.\r\n\r\nThey should be supported for better globalization readiness, and filesystems allow them, making common filesystem to JCR mappings unnecessarily hard. Escaping would be an option for applications, but there is currently no utility method for it ([Text.escapeIllegalJcrChars|https://jackrabbit.apache.org/api/2.8/org/apache/jackrabbit/util/Text.html#escapeIllegalJcrChars(java.lang.String)] will not escape these spaces), nor is it documented for applications how to do so.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support space chars common in CJK inside item names"
   },
   {
      "_id": "13007081",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2016-09-23 08:06:54",
      "description": "Most S3 DataStore tests inherit from Jackrabbit 2's TestCaseBase. To make extend them we should copy the class into Oak and let S3DataStore inherit from that. In doing do we can also use the DataStore initialization part already available.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Improve oak-blob-cloud tests"
   },
   {
      "_id": "13006824",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-22 11:51:36",
      "description": "OAK-4631 introduced a simplified serialisation for record ids. This causes their footprint on disk to increase from 3 bytes to 18 bytes. OAK-4631 has some initial analysis on the effect this is having on repositories as a whole. \n\nI'm opening this issue as a dedicated task to further look into mitigation strategies (if necessary). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Analyse effects of simplified record ids"
   },
   {
      "_id": "13006821",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-22 11:44:29",
      "description": "Oak segment tar does not export {{org.apache.jackrabbit.oak.backup}}, which makes backup restore functionality unavailable from OSGi containers. \n\nInstead of just exporting this package I think we should:\n* Separate API from implementation\n* Add semantic versioning to the exported API\n\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "API",
         "OSGi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Missing export for org.apache.jackrabbit.oak.backup package"
   },
   {
      "_id": "13006739",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2016-09-22 03:57:34",
      "description": "Some S3 related classes are present in oak-core module. These should be moved to oak-blob-cloud.\nThis would also flip the module dependencies to oak-core -> oak-blob-cloud",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Move S3 classes to oak-blob-cloud module"
   },
   {
      "_id": "13006737",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2016-09-22 03:55:27",
      "description": "The current CachingDataStore implementation used with S3DataStore has certain problems:\n* Lack of stats to show hit rate/miss rates for files being requested for downloads\n* Lack of stats for async uploads\n* CachingDataStore starts proactively downloading files in the background when a call to {{getRecord}} is made.\n* Async upload functionality leaks into Backend implementations, LocalCache classes.\n* The call to {{DataStore#getRecord()}} which makes multiple calls to backends which is problematic for S3 (i.e. when not being served bu cache)\n* There is some functionality which is not used with Oak like length cache, sync/async touch etc. which can be removed and code simplified.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improved caching for DataStore"
   },
   {
      "_id": "13006493",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-09-21 13:18:24",
      "description": "JMX binding for stopping a running compaction process",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "management",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide generic option to interrupt online revision cleanup"
   },
   {
      "_id": "13006454",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-21 10:26:36",
      "description": "This issue serves as collection of all changes to the storage format introduced with  Oak Segment Tar and their impact. Once sufficiently stabilised this information should serve as basis for the documentation in {{oak-doc}}. \n\n|| Change || Rational || Impact || Migration || Since || Issues ||\n|Generation in segment header |Required to unequivocally determine the generation of a segment during cleanup. Segment retention time is given in number of generations (2 by default). |No performance, space impact expected |offline |0.0.2 |OAK-3348 | \n|Stable id for node states |Required to efficiently determine equality of node states. This can be seen as an intermediate step to decoupling the address of records from their identity. The next step is to introduce logical record ids (OAK-4659). |Node states increase by the size of one record id (3 bytes / 20 bytes after OAK-4631). On top of that there is an additional block record \u00e0 18 bytes per node state. |offline |0.0.2 |OAK-3348\n|Binary index in tar files |Avoid traversing the repository to collect the gc roots for DSGC. Fetch them from an index instead. |Additional index entry per tar file. Adds a couple of bytes per external binary to each tar file. Exact size to be determined. [~frm] could you help with this? OAK-4740 is a regression wrt. to resiliency caused by this change (and the fact that the blob store might return blob ids longer than 2k chars).  |offline |0.0.4 |OAK-4101\n|Simplified record ids |Preparation and precondition for logical record ids (OAK-4659). At the same time the simplest possible fix for OAK-2896. The latter leads to degeneration of segment sizes, which in turn has adverse effects on overall performance, resource utilisation and memory requirements. Without this fix OAK-2498 would need to be fixed in a different way that would require other changes in the storage format. I started to regard this issue as removing a premature optimisation (which caused OAK-2498). OTOH with OAK-4844 we should also start looking into mitigations and what those would mean to size vs. simplicity vs. performance.  |Record ids grow from 3 bytes to 18 bytes when serialised into records. Impact on repositories to be assessed but can be anywhere between almost none to x6. OAK-4812 is a performance regression caused by this chance. Its overall impact is yet to be assessed. |offline |0.0.10 |OAK-4631, OAK-4844\n|Storage format versioning |In order to be able to further evolve the storage format with minimal impact on existing deployments we need to carefully versions the various storage entities (segments, tar files, etc.) |No performance, space impact expected |offline |0.0.2/ 0.0.10 |OAK-4232, OAK-4683, OAK-4295\n|Logical record ids |We need to separate addresses of records from their identity to be able to further scale the TarMK. OAK-3348 (the online compaction misery) can be seen as a symptom of failing to understand this earlier. The stable ids introduced with OAK-3348 are a first step into this direction. However this is not sufficient to implement features like e.g. background compaction (OAK-4756), partial compaction (OAK-3349) or incremental compaction (OAK-3350).  |A small size overhead per segment for the logical id table. Further impact to be evaluated ([~frm], please add your assessment here). |offline |0.0.14 (planned) |OAK-4659\n|External index for segments |Avoid recreating tar files if indexes are corrupt/missing. Just recreate the indexes. |Faster startup after a crash. Overall less disk space usage as no unnecessary backup files are created. |online |not yet planned |OAK-4649\n|In-place journal |Reduce complexity by in-lining the journal log. Less files, less chances to break something. Also the granularity of the log would increase as flushing of the persisted head would not be required any more. Resilience would improve as the roll-back functionality could operate at a finer granularity. |No more journal.log. Better resiliency. Significant risk for regression of OAK-4291 if not implemented properly. Most likely a significant refactoring of some parts of the code is required before we can proceed with this issue.  |online |not yet planned |OAK-4103\n|Root record types |With the information currently available from the segment headers we cannot collect statistics about segment usage on repositories of non trivial sizes. This fix would allow us to build more scalable tools to that respect.  |None expected wrt. to performance and size under normal operation. |offline |0.0.14 (planned) (waiting for OAK-4659 as implementation depends on how we progress there) |OAK-2498\n\nMisc ideas currently on the back burner:\n* SegmentMK: Arch segments (OAK-1905)\n* Extension headers for segments (no issue yet)\n* More memory efficient serialisation of values (e.g. boolean) (no issue yet)\n* Protocol Buffer for serialising records (no issue yet)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document storage format changes"
   },
   {
      "_id": "13006181",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-20 13:18:23",
      "description": "OAK-4775 upgraded Netty to 4.0.41.Final. This version seem to bring a couple of optional dependencies that we should also specify as optional in the Import-Package clause. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "OSGi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use optional resolution for optional dependencies"
   },
   {
      "_id": "13005960",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-19 16:12:25",
      "description": "There is the potential for a deadlock between concurrent calls to {{TarWriter#createNextGeneration()}} and {{TarWriter#flush()}}: both methods try to acquire a lock on this and another lock on {{TarWriter.file}} but in different order. I observed the deadlock when running {{CompactionAndCleanupIT.randomAccessFileConcurrentReadAndLength()}}.\n\nThis is a regression introduced with OAK-4746: the method {{TarWriter.createNextGeneration()}} seems over eagerly synchronized. I would argue that we could drop synchronization for that method entirely as the part after the call to {{close()}} will in any case only ever be executed once by a single thread. All other threads will fail with an {{IllegalStateException}}).\n\n[~alexparvulescu], WDYT?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "deadlock",
         "resilience",
         "threading"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Deadlock in TarWriter"
   },
   {
      "_id": "13005873",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-19 10:57:25",
      "description": "Revision GC may currently fail when a document with a malformed id is read from the DocumentStore. E.g. a document stored accidentally in the nodes collection or malformed for some other reason.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve revision GC resilience"
   },
   {
      "_id": "13005064",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-09-15 04:19:03",
      "description": "{{LuceneIndexEditor}} currently creates 2 tree instances for determining IndexRule. [~ianeboston] highlighted this on list [1] and this is something which we should avoid and remove usage of Tree api\n\nThis was earlier done so as to simplify future support for conditional rules (OAK-2281) which might need access to ancestor which is not possible with NodeState api.  As that is not going to be done so we can get rid of Tree construction in the editor.\n\n[1] https://lists.apache.org/thread.html/7d51b45296f5801c3b510a30a4847ce297707fb4e0d4c2cefe19be62@%3Coak-dev.jackrabbit.apache.org%3E\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove usage of Tree in LuceneIndexEditor"
   },
   {
      "_id": "13004849",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-14 11:47:13",
      "description": "OAK-4774 and OAK-4793 aim to check if the cache behaviour of a DocumentStore implementation when the underlying backend throws an exception even though the operation succeeded. E.g. the response cannot be sent back because of a network issue.\n\nThis issue will provide the DocumentStore independent part of those tests.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Basic cache consistency test on exception"
   },
   {
      "_id": "13004315",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-12 14:51:00",
      "description": "Currently {{SegmentNodeState#getStableId()}} returns a string with all its associated overhead:\n* high memory requirements (42 characters plus the overhead of a {{String}} instance. The raw requirements are a mere 20 bytes (long msb, long lsb, int offset). The memory overhead is problematic as the stable id is used as key in the node deduplication cache (See OAK-4635).\n* high serialisation cost. I have seen {{getStableId()}} occurring in stack traces. This is to be expected as that method is called quite often when comparing node states. \n\nThis issue is to explore options for reducing both CPU and memory overhead of stable ids. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "memory",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimise stable ids "
   },
   {
      "_id": "13004309",
      "assignee": "egli",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-09-12 14:12:30",
      "description": "Currently the [ChangeProcessor.contentChanged|https://github.com/apache/jackrabbit-oak/blob/f4f4e01dd8f708801883260481d37fdcd5868deb/oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/observation/ChangeProcessor.java#L335] is in charge of doing the event diffing and filtering and does so in a pooled Thread, ie asynchronously, at a later stage independent from the commit. This has the advantage that the commit is fast, but has the following potentially negative effects:\n# events (in the form of ContentChange Objects) occupy a slot of the queue even if the listener is not interested in it - any commit lands on any listener's queue. This reduces the capacity of the queue for 'actual' events to be delivered. It therefore increases the risk that the queue fills - and when full has various consequences such as loosing the CommitInfo etc.\n# each event==ContentChange later on must be evaluated, and for that a diff must be calculated. Depending on runtime behavior that diff might be expensive if no longer in the cache (documentMk specifically).\n\nAs an improvement, this diffing+filtering could be done at an earlier stage already, nearer to the commit, and in case the filter would ignore the event, it would not have to be put into the queue at all, thus avoiding occupying a slot and later potentially slower diffing.\n\nThe suggestion is to implement this via the following algorithm:\n\n* During the commit, in a {{Validator}} the listener's filters are evaluated - in an as-efficient-as-possible manner (Reason for doing it in a Validator is that this doesn't add overhead as oak already goes through all changes for other Validators). As a result a _list of potentially affected observers_ is added to the {{CommitInfo}} (false positives are fine).\n** Note that the above adds cost to the commit and must therefore be carefully done and measured\n** One potential measure could be to only do filtering when listener's queues are larger than a certain threshold (eg 10)\n* The ChangeProcessor in {{contentChanged}} (in the one created in [createObserver|https://github.com/apache/jackrabbit-oak/blob/f4f4e01dd8f708801883260481d37fdcd5868deb/oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/observation/ChangeProcessor.java#L224]) then checks the new commitInfo's _potentially affected observers_ list and if it's not in the list, adds a {{NOOP}} token at the end of the queue. If there's already a NOOP there, the two are collapsed (this way when a filter is not affected it would have a NOOP at the end of the queue). If later on a no-NOOP item is added, the NOOP's {{root}} is used as the {{previousRoot}} for the newly added {{ContentChange}} obj.\n** To achieve that, the ContentChange obj is extended to not only have the \"to\" {{root}} pointer, but also the \"from\" {{previousRoot}} pointer which currently is implicitly maintained.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "filter events before adding to ChangeProcessor's queue"
   },
   {
      "_id": "13004306",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-12 14:00:13",
      "description": "The statistics about writing nodes collected by the {{SegmentWriter}} instances is a bit off. This was caused by the changes introduced with OAK-4570. Starting with these changes also base node states of a node being written are de-duplicated. Collecting the node writer stats does not differentiate however e.g. the cache hits/misses between deduplication for the base state or the actual state being written. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Node writer statistics is skewed"
   },
   {
      "_id": "13004290",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2016-09-12 13:05:27",
      "description": "With OAK-4771 the usage of DocumentStoreException was clarified in the DocumentStore interface. The purpose of this task is to check usage of the DocumentStoreException in RDBDocumentStore and make sure JDBC driver specific exceptions are handled consistently and wrapped in a DocumentStoreException. At the same time, cache consistency needs to be checked as well in case of a driver exception. E.g. invalidate if necessary.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Check usage of DocumentStoreException in RDBDocumentStore"
   },
   {
      "_id": "13003584",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-08 13:51:31",
      "description": "ClusterNodeInfo.renewLease() does not detect when it is being recovered by another cluster node.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ClusterNodeInfo may renew lease while recovery is running"
   },
   {
      "_id": "13003477",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-09-08 07:30:14",
      "description": "With OAK-4771 the usage of DocumentStoreException was clarified in the DocumentStore interface. The purpose of this task is to check usage of the DocumentStoreException in MongoDocumentStore and make sure MongoDB Java driver specific exceptions are handled consistently and wrapped in a DocumentStoreException. At the same time, cache consistency needs to be checked as well in case of a driver exception. E.g. invalidate if necessary.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Check usage of DocumentStoreException in MongoDocumentStore"
   },
   {
      "_id": "13003229",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-07 13:12:10",
      "description": "The current DocumentStore contract is rather vague about exceptions. The class JavaDoc mentions implementation specific runtime exceptions, but does not talk about the DocumentStoreException used by all the DocumentStore implementations. We should make this explicit in all relevant methods.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Clarify exceptions in DocumentStore"
   },
   {
      "_id": "13003226",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-07 13:04:05",
      "description": "ClusterNodeInfo.renewLease() does not handle a potential DocumentStoreException on {{findAndModify()}}. This may leave {{previousLeaseEndTime}} in an inconsistent state and a subsequent {{renewLease()}} call then considers the lease timed out. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Missing exception handling in ClusterNodeInfo.renewLease()"
   },
   {
      "_id": "13002928",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-06 13:55:32",
      "description": "JMX binding for stopping a running compaction process",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide option to interrupt online revision cleanup"
   },
   {
      "_id": "13002866",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2016-09-06 09:17:15",
      "description": "Some default values timeouts of the RDBDocumentStore driver do not work well with the lease time we use in Oak.\n\nSee also OAK-4739.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Adjust default timeout values for RDBDocumentStore"
   },
   {
      "_id": "13002851",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-09-06 08:09:13",
      "description": "Some default values timeouts of the MongoDB Java driver do not work well with the lease time we use in Oak.\n\nPer default there is no socket timeout set and the driver waits for a new connection up to 120 seconds, which is too log for lease update operations. \n\nSee also OAK-4739.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Adjust default timeout values for MongoDocumentStore"
   },
   {
      "_id": "13002746",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-05 15:08:09",
      "description": "Assuming that:\n\n# Logic record IDs are implemented.\n# TAR files are ordered in reverse chronological order.\n# When reading segments, TAR files are consulted in order.\n# Segments in recent TAR files shadow segments in older TAR files with the same segment ID.\n\nA new algorithm for garbage collection can be implemented:\n\n# Define the input for the garbage collection process. The input consists of the current set of TAR files and a set of record IDs representing the GC roots.\n# Traverse the GC roots and mark the records that are still in use. The mark phase traverses the record graph and produces a list of record IDs. These record IDs are referenced directly or indirectly by the given set of GC roots and need to be kept. The list of record IDs is ordered by segment ID first and record number next. This way, it is possible to process this list in one pass and figure out which segment and which record should be saved at the end of the garbage collection.\n# Remove unused records from segments and rewrite them in a new set of TAR files. The list is produced in the previous step is traversed. For each segment encountered, a new segment is created containing only the records that were marked in the previous phase. This segment is then saved in a new set of TAR files. The set of new TAR files is the result of the garbage collection process. \n# Add the new TAR files to the system. The system will append the new TAR files to the segment store. The segments in these TAR files will shadow the ones in older TAR files.\n# Remove TAR files from the old generation. It is safe to do so because the new set of TAR files are currently shadowing the initial set of TAR files.\n\nWhile the garbage collection process is running, the system can work as usual by starting a fresh TAR file. The result of the garbage collection is made visible atomically only at the end, when the new TAR files are integrated into the running system.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "gc",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "A parallel approach to garbage collection"
   },
   {
      "_id": "13002722",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-09-05 12:30:56",
      "description": "ConsolidatedListenerMBean contains various stats about JCR event listeners. However, it is rather difficult to get an overview of how expensive listeners are.\n\nThe MBean should expose a simple leaderboard that orders the listener according to the processing time (producer & consumer time).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Leaderboard in ConsolidatedListenerMBean"
   },
   {
      "_id": "13002681",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-09-05 07:58:40",
      "description": "The jackrabbit-jcr-commons {{ListenerTracker}} collects timing for JCR event listeners. It tracks producer (oak internal) and consumer (JCR EventListener) time. The initial producer cost is currently not reflected in these stats, because {{ChangeProcessor}} in oak-jcr does an initial {{hasNext()}} on the {{EventIterator}} outside of the {{ListenerTracker}}. For some listeners this initial producer time may even account for the entire cost when the event filter rejects all changes.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Include initial cost in stats for observation processing"
   },
   {
      "_id": "13002069",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-01 14:27:20",
      "description": "We should add further data to that MBean (if feasible):\n\n* Number of commits\n* Number of commits queuing (blocked on the commit semaphore)\n* Percentiles of commit times (exclude queueing time)\n* Percentiles of commit queueing times \n* Last gc run / size before gc and after gc / time gc took broken down into the various phases\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve FileStoreStatsMBean"
   },
   {
      "_id": "13001917",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-01 07:06:43",
      "description": "There is another case where the local cache is incorrectly updated, which leads to unnecessary reads from the DocumentStore. See also OAK-4715.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Reduce DocumentStore reads for local changes (2)"
   },
   {
      "_id": "13001743",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-31 16:23:34",
      "description": "When fetching the current root from the {{SegmentNodeStore}} an older revision will be returned when a commit is being processed concurrently. I think it would make sense to wait for a short time in this case increasing the chance of returning an up to date state. The idea is that this would lower the rebasing work that need to be done later on should the returned root be used for further modifications. \n\nAn interesting value for the wait time is to use  the median (or more general a percentile) of the commit time of the last say 1000 commits. This would mean that (for the median) we have a 50% chance of getting up to date date. For a 90% percentile we would have longer wait times but then a 90% chance of getting up to date date. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "(Slightly) prioritise reads over writes "
   },
   {
      "_id": "13001737",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-31 16:16:04",
      "description": "Forced compaction currently acquires an exclusive write lock on the repository blocking all concurrent commits during the complete time it needs to finish compaction. I think we should refine this:\n\n* Add a time out so we could limit the time during which the repository does not accept writes while still giving compaction another chance to finish.\n\n* Boost the compaction threads priority. This could actually already be done during the regular compaction cycles to increase the changes to finish in time. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refine forced compaction"
   },
   {
      "_id": "13001705",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-31 15:09:22",
      "description": "This follows OAK-4293 which needs to be exposed via OSGi configs as well.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "OSGi config for the size based estimation"
   },
   {
      "_id": "13001638",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-31 12:39:27",
      "description": "Checking the node store fixture {{commons.FixturesHelper#getFixtures()}} is a left over from when the segment node store was part of {{oak-core}} and we wanted to avoid running the tests multiple times. As we are now in a separate module this check is not necessary any more. It is currently even harmful as certain tests are skipped. The default value for the fixtures is still {{SEGMENT_MK}} because {{oak-segment-tar}} cannot yet depend on Oak 1.5.9 (not released yet) where the default was switched to {{SEGMENT_TAR}} (see OAK-4706).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tests"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak Segment Tar tests should not check node store fixture"
   },
   {
      "_id": "13001354",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-30 15:12:41",
      "description": "In a cluster with listeners that are registered to receive external changes, pulling in external changes can become a bottleneck. While processing those external changes, further local changes are put into the observation queue leading to a system where the queue eventually fills up.\n\nInstead of processing external changes one after another, the implementation could prefetch them as they come in and if needed pull them in parallel.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Prefetch external changes"
   },
   {
      "_id": "13001317",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-30 13:59:18",
      "description": "PathRev instances are used as keys for various cache entries and asString() / fromString() methods are called frequently when the persistent cache is enabled.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimize PathRev as/from String"
   },
   {
      "_id": "13000913",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-29 10:06:52",
      "description": "The observation test added for OAK-4528 shows significant time spent in reading documents from the store when local changes are processed. Since those changes were done on the local cluster node, they should be served from cache and not reach out to the underlying store.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": " Reduce DocumentStore reads for local changes"
   },
   {
      "_id": "13000012",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-25 13:29:13",
      "description": "Oak's integration tests still run against the {{SEGMENT_MK}} fixture. I suggest we switch to the {{SEGMENT_TAR}} fixture. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "testing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Run tests against SEGMENT_TAR fixture"
   },
   {
      "_id": "12999637",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-24 11:43:48",
      "description": "Reading a node state with an old revision from a document can be expensive when many changes happened on a property in the meantime.\n\nA typical stack trace looks like this:\n\n{noformat}\n\tat org.apache.jackrabbit.oak.plugins.document.NodeDocument.getPreviousDocument(NodeDocument.java:1337)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$1.apply(PropertyHistory.java:70)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$1.apply(PropertyHistory.java:63)\n\tat com.google.common.collect.Iterators$8.transform(Iterators.java:794)\n\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:48)\n\tat com.google.common.collect.Iterators$7.computeNext(Iterators.java:646)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n\tat com.google.common.collect.Iterators$PeekingImpl.hasNext(Iterators.java:1139)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$2.refillQueue(PropertyHistory.java:121)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$2.computeNext(PropertyHistory.java:96)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$2.computeNext(PropertyHistory.java:88)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n\tat org.apache.jackrabbit.oak.plugins.document.ValueMap$1$3.nextIterator(ValueMap.java:105)\n\tat org.apache.jackrabbit.oak.plugins.document.util.MergeSortedIterators.fetchNextIterator(MergeSortedIterators.java:98)\n\tat org.apache.jackrabbit.oak.plugins.document.util.MergeSortedIterators.next(MergeSortedIterators.java:85)\n\tat com.google.common.collect.Iterators$PeekingImpl.peek(Iterators.java:1162)\n\tat org.apache.jackrabbit.oak.plugins.document.util.MergeSortedIterators.adjustFirst(MergeSortedIterators.java:117)\n\tat org.apache.jackrabbit.oak.plugins.document.util.MergeSortedIterators.next(MergeSortedIterators.java:78)\n\tat org.apache.jackrabbit.oak.plugins.document.NodeDocument.getLatestValue(NodeDocument.java:1972)\n\tat org.apache.jackrabbit.oak.plugins.document.NodeDocument.getNodeAtRevision(NodeDocument.java:990)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readNode(DocumentNodeStore.java:1079)\n{noformat}\n\nThe read operation goes through the property history until it finds the most recent change. The old the read revision, the more changes are scanned.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize read of old node state"
   },
   {
      "_id": "12998462",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-08-19 11:21:10",
      "description": "At the moment it is possible to have concurrent calls to {{FileStore.cleanup}} and to {{FileStore.compact()}}. The former is called from the latter and also from {{FileStore.flush()}} (this is tracked in OAK-4138). We should change this status quo and also make the calls to {{compact()}} and {{cleanup()}} mutually exclusive.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid concurrent calls to FileStore.cleanup() and FileStore.compact()"
   },
   {
      "_id": "12997573",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-08-16 12:55:29",
      "description": "{{SegmentNotFoundException}} is thrown from time to time in the following scenario: plenty of concurrent writes (each creating a {{625 bytes}} blob) interrupted by a cleanup. \n\nStack trace (including some debugging statements added by me):\n{code:java}\nPre cleanup readers: []\nBefore cleanup readers: [/Users/dulceanu/work/test-repo/data00000a.tar]\nInitial size: 357.4 kB\nAfter cleanup readers: [/Users/dulceanu/work/test-repo/data00000a.tar]\nAfter cleanup size: 357.4 kB\nFinal size: 361.0 kB\nException in thread \"pool-5-thread-74\" org.apache.jackrabbit.oak.segment.SegmentNotFoundException: Cannot copy record from a generation that has been gc'ed already\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.isOldGeneration(SegmentWriter.java:1207)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNodeUncached(SegmentWriter.java:1096)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNode(SegmentWriter.java:1013)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNodeUncached(SegmentWriter.java:1074)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNode(SegmentWriter.java:1013)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNode(SegmentWriter.java:987)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.access$700(SegmentWriter.java:379)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$8.execute(SegmentWriter.java:337)\n\tat org.apache.jackrabbit.oak.segment.SegmentBufferWriterPool.execute(SegmentBufferWriterPool.java:105)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter.writeNode(SegmentWriter.java:334)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:111)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.prepare(SegmentNodeStore.java:550)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.optimisticMerge(SegmentNodeStore.java:571)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.execute(SegmentNodeStore.java:627)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore.merge(SegmentNodeStore.java:287)\n\tat org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT$1.run(CompactionAndCleanupIT.java:961)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment 4fb637cc-5013-4925-ab13-0629c4406481 not found\n\tat org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:1341)\n\tat org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:123)\n\tat org.apache.jackrabbit.oak.segment.RecordId.getSegment(RecordId.java:94)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.isOldGeneration(SegmentWriter.java:1199)\n\t... 18 more\nCaused by: java.util.concurrent.ExecutionException: java.lang.IllegalStateException: Invalid segment format. Dumping segment 4fb637cc-5013-4925-ab13-0629c4406481\n00000000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000030 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000040 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000060 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000070 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000080 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000090 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000B0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000C0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000D0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000E0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000F0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000100 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000110 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000120 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000130 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000140 39 37 39 31 31 36 30 38 2D 63 31 63 65 2D 34 62 97911608-c1ce-4b\n00000150 35 63 2D 61 36 33 37 2D 39 36 61 65 39 34 38 38 5c-a637-96ae9488\n00000160 61 37 65 38 2E 30 61 62 34 30 36 38 36 00 00 00 a7e8.0ab40686...\n00000170 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000180 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000190 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000001A0 00 00 00 00 30 30 30 30 34 30 30 00 30 30 30 30 ....0000400.0000\n000001B0 30 30 30 00 30 30 30 30 30 30 30 00 30 30 30 30 000.0000000.0000\n000001C0 30 30 30 31 33 30 30 00 31 32 37 35 34 36 30 33 0001300.12754603\n000001D0 37 32 32 00 30 31 32 33 30 37 00 20 30 00 00 00 722.012307. 0...\n000001E0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000001F0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000200 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000210 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000220 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000230 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000240 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000250 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000260 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000270 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000280 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000290 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000002A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000002B0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.load(CacheLIRS.java:1015)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.get(CacheLIRS.java:972)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS.get(CacheLIRS.java:283)\n\tat org.apache.jackrabbit.oak.segment.SegmentCache.getSegment(SegmentCache.java:92)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:1275)\n\t... 21 more\nCaused by: java.lang.IllegalStateException: Invalid segment format. Dumping segment 4fb637cc-5013-4925-ab13-0629c4406481\n00000000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000030 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000040 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000060 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000070 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000080 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000090 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000B0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000C0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000D0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000E0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000F0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000100 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000110 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000120 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000130 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000140 39 37 39 31 31 36 30 38 2D 63 31 63 65 2D 34 62 97911608-c1ce-4b\n00000150 35 63 2D 61 36 33 37 2D 39 36 61 65 39 34 38 38 5c-a637-96ae9488\n00000160 61 37 65 38 2E 30 61 62 34 30 36 38 36 00 00 00 a7e8.0ab40686...\n00000170 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000180 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000190 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000001A0 00 00 00 00 30 30 30 30 34 30 30 00 30 30 30 30 ....0000400.0000\n000001B0 30 30 30 00 30 30 30 30 30 30 30 00 30 30 30 30 000.0000000.0000\n000001C0 30 30 30 31 33 30 30 00 31 32 37 35 34 36 30 33 0001300.12754603\n000001D0 37 32 32 00 30 31 32 33 30 37 00 20 30 00 00 00 722.012307. 0...\n000001E0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000001F0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000200 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000210 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000220 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000230 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000240 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000250 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000260 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000270 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000280 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000290 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000002A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000002B0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:150)\n\tat org.apache.jackrabbit.oak.segment.Segment.<init>(Segment.java:185)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore$15.call(FileStore.java:1292)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore$15.call(FileStore.java:1)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.load(CacheLIRS.java:1011)\n\t... 25 more\n0\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SNFE thrown while testing FileStore.cleanup() running concurrently with writes"
   },
   {
      "_id": "12996938",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-12 13:05:48",
      "description": "On some deployments I have seen tar files with a quite hight generation post-fix (e.g. 'v'). From the log files I could deduce that this particular tar file was rewritten multiple times without actually any segment being removed.\nI assume this is caused by the 25% gain threshold not taking the sizes contributed by the index and the graph entries into account.\n\nThe attached test case can be used to verify the above hypothesis.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cleanup creates new generation of tar file without removing any segments "
   },
   {
      "_id": "12996529",
      "assignee": "egli",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-11 05:24:02",
      "description": "While writing a cluster test where multiple DocumentNodeStore instance are created the test case log exception like \n\n{noformat}\n17:20:34.852 TRACE [DocumentNodeStore lease update thread (1)] ClusterNodeInfo.java:761 renewLease - leaseEndTime: 1470829945825, leaseTime: 120000, leaseUpdateInterval: 10000\n17:20:35.006 TRACE [DocumentNodeStore lease update thread (2)] ClusterNodeInfo.java:761 renewLease - leaseEndTime: 1470829945987, leaseTime: 120000, leaseUpdateInterval: 10000\n17:20:35.855 TRACE [DocumentNodeStore lease update thread (1)] ClusterNodeInfo.java:761 renewLease - leaseEndTime: 1470829945825, leaseTime: 120000, leaseUpdateInterval: 10000\n17:20:35.856 ERROR [DocumentNodeStore lease update thread (1)] ClusterNodeInfo.java:779 This oak instance failed to update the lease in time and can therefore no longer access this DocumentNodeStore.\n17:20:35.857 WARN  [DocumentNodeStore lease update thread (1)] DocumentNodeStore.java:2590 Background operation failed: java.lang.AssertionError: This oak instance failed to update the lease in time and can therefore no longer access this DocumentNodeStore.\njava.lang.AssertionError: This oak instance failed to update the lease in time and can therefore no longer access this DocumentNodeStore.\n\tat org.apache.jackrabbit.oak.plugins.document.ClusterNodeInfo.renewLease(ClusterNodeInfo.java:780) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.renewClusterIdLease(DocumentNodeStore.java:1772) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore$BackgroundLeaseUpdate.execute(DocumentNodeStore.java:2643) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore$NodeStoreTask.run(DocumentNodeStore.java:2588) ~[classes/:na]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.7.0_55]\n{noformat}\n\nThis happens because {{instanceId}} is same (same JVM process used for both cluster node). To enable such test we need to disable the leasecheck but doing that via DocumentMK does not work",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Disabling lease check via DocumentMK builder does not work"
   },
   {
      "_id": "12995640",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-08 12:24:35",
      "description": "For the document node store it should be possible to mount \"another\" node store under some path. Assumptions for the OSGi setup:\n\n* the mounted node store provider has to be registered with {{(role=secondary)}} in OSGi,\n* the MountInfoProvider contains a Mount registered as {{private}},\n* all reads of the paths configured in MountInfoProvider are redirected to the mounted node store,\n* mounted subtrees are read-only,\n* the properties characteristic to the document node store (lastRev, rootRev) are set to a constant value.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow to mount the secondary node store as a read-only subtree"
   },
   {
      "_id": "12994907",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-04 13:58:46",
      "description": "Improve the page at [1] to include a picture of the contents of a TAR file, as done for segments in [2], to cover missing parts (e.g. binary references files) and to better align it with latest oak-segment-tar improvements.\n\n[1] http://jackrabbit.apache.org/oak/docs/nodestore/segment/tar.html\n[2] http://jackrabbit.apache.org/oak/docs/nodestore/segment/records.html",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve documentation about structure of TAR files"
   },
   {
      "_id": "12994527",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-03 09:10:58",
      "description": "{{NodeCache}} uses one stripe per depth (of the nodes in the tree). Once its overall capacity (default 1000000 nodes) is exceeded, it clears all nodes from the stripe with the greatest depth. This can be problematic when the stripe with the greatest depth contains most of the nodes as clearing it would result in an almost empty cache. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve cache eviction policy of the node deduplication cache"
   },
   {
      "_id": "12993523",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-29 12:08:41",
      "description": "The background operations (flush, compact, cleanup, etc.) are historically part of the implementation of the {{FileStore}}. They should better be scheduled and invoked by an external agent. The code deploying the {{FileStore}} might have better insights on when and how these background operations should be invoked. See also OAK-3468.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "External invocation of background operations"
   },
   {
      "_id": "12993518",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-29 11:58:50",
      "description": "There is {{org.apache.jackrabbit.oak.cache.CacheStats}} in {{oak-core}} and {{org.apache.jackrabbit.oak.segment.RecordCacheStats}} in {{oak-segment-tar}}. Both exposing quite similar functionality. We should try to unify them as much as possible. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Unify RecordCacheStats and CacheStats"
   },
   {
      "_id": "12993517",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-29 11:55:50",
      "description": "The {{GCMonitorMBean}} MBean still dates back to the old {{oak-segment}}. We need to review its endpoints and only keep those that make sense for {{oak-segment-tar}}, adapt the others as necessary any add further functionality as required. \n\nSpecifically I think we should get rid of the time series for {{getRepositorySize()}} and {{getReclaimedSize()}}.\n\nAlso the name {{getRepositorySize()}} is confusing and we should change it. It leads callers to think it would return current size of the repository opposed to the size it had after the last cleanup. (There is {{FileStoreStatsMBean.getRepositorySize()}} for the latter.)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Align GCMonitorMBean MBean with new generation based GC"
   },
   {
      "_id": "12993514",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-29 11:51:45",
      "description": "The {{SegmentRevisionGC}} MBean still dates back to the old {{oak-segment}}. We need to review its endpoints and only keep those that make sense for {{oak-segment-tar}}, adapt the others as necessary any add further functionality as required. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Align SegmentRevisionGC MBean with new generation based GC"
   },
   {
      "_id": "12992910",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-07-27 12:28:35",
      "description": "This is related to JCR-4000 and the remaining work in Oak that hooks into the ListenerTracker and exposes the info also in the consolidated listener MBean.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Report age of oldest queue entry in EventListenerMBean and ConsolidatedListenerMBean"
   },
   {
      "_id": "12992628",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-26 16:00:27",
      "description": "The DocumentNodeStore currently uses a single persistent cache for all types (node, nodeChildren, diff, etc.). With this setup it is not possible to assign a specific amount of disk space for some cache type(s). If there are many inserts for one cache type, entries of another type may become unavailable. In practice this can be a problem for the local_diff cache entries that are important for efficient node state comparison.\n\nSeparating the diff and local_diff cache entries would also allow for different configuration options like compression and different behaviour when the async write back queue is full.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Separate persistent cache for diff and local_diff"
   },
   {
      "_id": "12992483",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-26 05:08:58",
      "description": "When large number of external blobs are added to the DataStore (50000) and a cycle of compaction executed then the reference collection logic only returns lesser number of blob references. It reports correct number of blob references when number of blobs added are less indicatingsome sort of overflow.\nAnother related issue observed when testing with lesser number of blobs is that the references returned are double the amount expected, so maybe there should be some sort of de-duplication which should be added.\n\nWithout compaction the blob references are returned correctly atleast till 100000 (ExternalBlobId#testNullBlobId)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "datastore",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Collection of references retrieves less when large number of blobs added"
   },
   {
      "_id": "12991809",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-22 13:09:18",
      "description": "There is a few peculiarities with that method:\n\n* The Javadoc \"A bulk segment is reclaimable if it is in bulkRefs\" is wrong. It should be \"A bulk segment is reclaimable if it is *not* in bulkRefs\".\n* (Why) is it necessary to iterate in reverse over the entries in tar file?\n* Why the extra check for bulk references in the else branch?\n* The condition {{!reclaim.remove(id)}} is always true as {{id}} can only be in {{reclaim}} it it had been added in the same iteration (as ids are unique). But this would have been in the if branch, contradicting us being in the else branch. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clarify implementation and documentation of TarReader#mark"
   },
   {
      "_id": "12991403",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-07-21 10:06:30",
      "description": "The bulk createOrUpdate operation needs to have old versions of all updated documents. If some documents are not in the cache, they are requested from the Mongo. However, if the document key is cached with the NULL value (which means it doesn't exists), the createOrUpdate ignores such information and tries to load the document from Mongo anyway.\n\nWe shouldn't ignore these NULLs but assume that keys cached with the NULL value indicate an non-existing document.\n\nIf the document exists (because the cache became outdated), the sendBulkUpdate() method will detect it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Don't ignore the cached NULLs in bulk createOrUpdate for Mongo"
   },
   {
      "_id": "12991357",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-21 07:11:08",
      "description": "There are some DocumentMK specific methods in DocumentNodeStore, which should be moved to the DocumentMK.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move DocumentMK specific methods from DocumentNodeStore"
   },
   {
      "_id": "12991135",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-20 14:24:43",
      "description": "A new approach for calculating {{FileStore::size}} is needed because this method is prone to lock contention and should not be called too often.\n\nThe steps to implement the approach are:\n# reduce the lock surface of the size() method. This should be simple enough by creating a copy of the readers / writer inside the lock and do the actual size calculation on that snapshot but outside of the lock.\n# lower size() visibility to package to avoid misuse (from monitoring tools)\n# remove {{approximateSize}} and associated logic and replace it with {{size()}}.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve FileStore.size calculation"
   },
   {
      "_id": "12991058",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-07-20 09:28:31",
      "description": "{{CacheLIRS}} has various means for specifying the weight of an element:\n\n* via {{setAverageMemory()}}\n* via {{CacheLIRS.Builder.averageWeight()}}\n* via {{CacheLIRS.Builder.weigher()}}\n* via the {{memory}} argument of {{put()}}\n\nIt is not clear how this various ways interact which each other when specifying one but not the other and which would take precedence if multiple are specified. \n\nMoreover there is the related {{CacheStats}} class, which also require a {{Weigher}}. How does that one related to the arguments of the respective cache instance? \n\n[~tmueller], could you please help clarifying these points? E.g. by expanding on the Javadoc.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clarify weight related methods/parameters/arguments of the LIRS cache"
   },
   {
      "_id": "12990990",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2016-07-20 04:03:14",
      "description": "Parent task for blob gc performance improvements",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "BlobGC performance improvements"
   },
   {
      "_id": "12990383",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-18 13:07:35",
      "description": "The overflow to disk threshold for {{StringSort}} used by JournalEntry is too high. JournalEntry assumes the threshold is in bytes, whereas the threshold is actually the number of Strings.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Overflow to disk threshold too high"
   },
   {
      "_id": "12990286",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-18 07:56:39",
      "description": "While applying the changes from {{StringSort}} to the diff cache, the method recreates the entire change tree in memory. Depending on the revision range, the number of changes can be very high and cause an OOME.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JournalEntry.applyTo() creates complete change tree in memory"
   },
   {
      "_id": "12990274",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-07-18 07:04:38",
      "description": "In most cases where code uses JcrUtils.putFile [1] it leads to\ncreation of below content structure\n\n{noformat}\n+ foo.jpg (nt:file)\n   + jcr:content (nt:resource)\n       - jcr:data\n{noformat}\n\nDue to usage of nt:resource each nt:file node creates a entry in uuid\nindex as nt:resource is referenceable. So if a system has 1M\nnt:file nodes then we would have 1M entries in /oak:index/uuid as in\nmost cases the files are created via [1] and hence all such files are\nreferenceable\n\nThe nodetype defn for nt:file does not mandate that the\nrequirement for jcr:content being nt:resource. To support such non referenceable files we would define a new nodeType similar to nt:resource but which is non referenceable.\n\nSee [2] for related discussion\n\n[1] https://github.com/apache/jackrabbit/blob/trunk/jackrabbit-jcr-commons/src/main/java/org/apache/jackrabbit/commons/JcrUtils.java#L1062\n[2] http://jackrabbit-oak.markmail.org/thread/qicpzm5ltnzfsd42",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Define oak:Resource nodetype as non referenceable alternative to nt:resource"
   },
   {
      "_id": "12989746",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2016-07-15 10:45:09",
      "description": "If a large enough metadata record is added to a S3 DS (like the list of blob references collected during the mark phase of the MarkSweepGC) the upload will fail (i.e. never start). This is caused by {{S3Backend.addMetadataRecord()}} providing an InputStream to the S3 TransferManager without specifying the size in the Metadata. \nA warning to this effect is logged by the AWS SDK each time you add a metadata record: \n{noformat}\n[s3-transfer-manager-worker-1] AmazonS3Client.java:1364 No content length specified for stream data.  Stream contents will be buffered in memory and could result in out of memory errors.\n{noformat}\n\nNormally this shouldn't be too big of a problem but in a repository with over 36 million blob references the list of marked refs produced by the GC is over 5GB. In this case the S3 transfer worker thread will be stuck in a seemingly endless loop where it tries to allocate the memory reading the file into memory and never finishes (although the JVM has 80GB of heap), eating away resources in the process:\n\n{noformat}\n   java.lang.Thread.State: RUNNABLE\n\tat org.apache.http.util.ByteArrayBuffer.append(ByteArrayBuffer.java:90)\n\tat org.apache.http.util.EntityUtils.toByteArray(EntityUtils.java:137)\n\tat org.apache.http.entity.BufferedHttpEntity.<init>(BufferedHttpEntity.java:63)\n\tat com.amazonaws.http.HttpRequestFactory.newBufferedHttpEntity(HttpRequestFactory.java:247)\n\tat com.amazonaws.http.HttpRequestFactory.createHttpRequest(HttpRequestFactory.java:126)\n\tat com.amazonaws.http.AmazonHttpClient$ExecOneRequestParams.newApacheRequest(AmazonHttpClient.java:650)\n\tat com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:730)\n\tat com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:505)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:317)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:3595)\n\tat com.amazonaws.services.s3.AmazonS3Client.putObject(AmazonS3Client.java:1382)\n\tat com.amazonaws.services.s3.transfer.internal.UploadCallable.uploadInOneChunk(UploadCallable.java:131)\n\tat com.amazonaws.services.s3.transfer.internal.UploadCallable.call(UploadCallable.java:123)\n\tat com.amazonaws.services.s3.transfer.internal.UploadMonitor.call(UploadMonitor.java:139)\n\tat com.amazonaws.services.s3.transfer.internal.UploadMonitor.call(UploadMonitor.java:47)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat} \n\nThe last log message by the GC thread will be like this:\n{noformat}\n*INFO* [sling-oak-observation-1273] org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector Number of valid blob references marked under mark phase of Blob garbage collection [36147734]\n{noformat} \n\nfollowed by the above AWS warning, then it will stall waiting for the transfer to finish.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc",
         "s3"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "S3Backend fails to upload large metadata records"
   },
   {
      "_id": "12989714",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-07-15 08:36:47",
      "description": "While running Oak in Sling we rely on Sling Scheduler to ensure that async indexing task are run on leader (OAK-1246) with specified frequency. \n\nBe default Sling Scheduler uses a default pool for managing all tasks. It can happen that number of task can be quite hight which can then lead to default thread pool getting exhausted and that causes async indexing to get delayed.\n\nTo ensure that async indexing is not affected by such scenarios we should make use of a dedicated thread pool. This is now supported by SLING-5831",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Specify thread pool name which should be used by Async Indexing task"
   },
   {
      "_id": "12989393",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-14 09:08:48",
      "description": "The implementation of {{SegmentNodeState.fastEquals()}} compares the stable IDs of two instances of {{SegmentNodeState}}. In some cases, reading the stable ID would trigger a read of an additional record, the block record containing the serialized version of the segment ID.\n\nThis issue is about evaluating the performance implications of this strategy and, in particular, if it would be better to store the serialized stable ID in the node record itself.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeState.fastEquals() can trigger two I/O operations"
   },
   {
      "_id": "12987729",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-07-08 08:51:48",
      "description": "Possibly followup of OAK-3793, the {{SegmentDataStoreBlobGCIT}} fails sporadically, there's probably a timing issue with collecting the {{SegmentId}} instances as UUIDs so they can be GC'ed, then later loading them, which in turn could fail after a GC.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "datastore",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentDataStoreBlobGCIT failures"
   },
   {
      "_id": "12987139",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-07-06 13:16:54",
      "description": "I'm not sure if it's possible in the current scheme of things (implementation), but it'd useful to be able to easily differentiate between slow diff calculation or slow observer as a reason to see why observation queue might fill up.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "monitoring",
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add info about event generation and consumption by observer"
   },
   {
      "_id": "12987138",
      "assignee": "catholicon",
      "components": [],
      "created": "2016-07-06 13:13:43",
      "description": "Currently, {{PerfLogger}} logs at DEBUG if time spent in operation is more that threshold ms.\n\nWe should also be able to have a second level threshold of time, beyond which the log should happen at INFO. It helps to catch cases for which the timing gets too poor at the onset of some performance issue and by the time of investigation (opportunity to add DEBUG logger) is too late already.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "PerfLogger should also allow a threshold to log at INFO"
   },
   {
      "_id": "12987119",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-06 11:01:10",
      "description": "When caches are updated after a commit (within CommitQueue.Callback.headOfQueue()), other threads are blocked when they try to acquire new revisions from the queue.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cache update blocks new commits"
   },
   {
      "_id": "12986196",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-01 14:12:30",
      "description": "Currently, diff information is filled into caches actively (local commits pushed in local_diff, externally read changes pushed into memory_diff). At the time of event processing though, the entries could have already been evicted.\nIn that case, we fall back to computing diff by comparing 2 node-states which becomes more and more expensive (and eventually fairly non-recoverable leading to OAK-2683).\n\nTo improve the situation somewhat, we can probably try to consult journal entries to read a smaller-superset of changed paths before falling down to comparison.\n\n/cc [~mreutegg], [~chetanm], [~egli]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "diff calculation in DocumentNodeStore should try to re-use journal info on diff cache miss"
   },
   {
      "_id": "12984997",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-06-29 13:25:49",
      "description": "The CommitRateLimiter of OAK-1659 can delay commits, but doesn't currently block them, and delays even those commits that are part of handling events. Because of that, the queue can still get full, and possibly delaying commits while handling events can make the situation even worse.\n\nIn Jackrabbit 2.x, we had a similar feature: JCR-2402. Also related is JCR-2746.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve CommitRateLimiter to optionally block some commits"
   },
   {
      "_id": "12982613",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-06-24 08:44:34",
      "description": "I'd like to have offline compaction return a failure code in case of any error happening during the process (like an OOME). this would help greatly with scripting efforts for automated maintenance operations.\n\nOther ideas worth pursuing:\n* a one line status at the end of the process: \"Compaction succeeded in XXX min\" or \"Compaction failed in XXX mins\".\n* a better directory listing pre and post compaction (sorted list, and possibly including the last modified date).\n* bonus points for delta output (tar files removed, tar files added).\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction clearer output values"
   },
   {
      "_id": "12982552",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-06-24 02:59:53",
      "description": "When querying for suggestions, the {{LucenePropertyIndex}} performs the ACL checks for the suggested terms incorrectly if the {{oak:index}} definition is not located under the root.\n\nIn my example, I have an {{oak:index}} definition under {{/content/wcgcom/demo/example/oak:index/lucene-suggest}} looking like this:\n{code}\n          <lucene-suggest\n              jcr:primaryType=\"oak:QueryIndexDefinition\"\n              async=\"async\"\n              compatVersion=\"{Long}2\"\n              reindex=\"{Boolean}false\"\n              reindexCount=\"{Long}5\"\n              type=\"lucene\">\n              <indexRules jcr:primaryType=\"nt:unstructured\">\n                  <nt:base jcr:primaryType=\"nt:unstructured\">\n                      <properties jcr:primaryType=\"nt:unstructured\">\n                          <props\n                              jcr:primaryType=\"nt:unstructured\"\n                              analyzed=\"{Boolean}true\"\n                              isRegexp=\"{Boolean}true\"\n                              name=\"jcr:(title|description)|title|subtitle|boldTitle\"\n                              propertyIndex=\"{Boolean}true\"\n                              useInSuggest=\"{Boolean}true\"/>\n                      </properties>\n                  </nt:base>\n              </indexRules>\n              <suggestion\n                  jcr:primaryType=\"nt:unstructured\"\n                  suggestAnalyzed=\"{Boolean}true\"\n                  suggestUpdateFrequencyMinutes=\"{Long}20\"/>\n          </lucene-suggest>\n{code}\n\nAnd most relevant content under this path: {{/content/wcgcom/demo/example/home}}\n\nWhen inspecting the ACL checks happening in the suggestion part of {{LucenePropertyIndex#loadDocs}} it seems the Document's path as returned by {{retrievedDoc.get(FieldNames.PATH)}} starts from the root path of the index. So in this case an example of a document path from the index above could be {{/home/about-us/news/jcr:content/headerParagraph/shortheader}} (notice that it's missing the full path to the root of the JCR workspace (specifically missing {{/content/wcgcom/demo/example}} in this case)\n\nI believe this could be solved by simply prefixing the document path with {{filter.getPath()}}. And looking through the code, it looks like the same problem is present for the spellcheck type queries.\n\nHere's a patch that could potentially fix this (untested): \n\n{noformat}\ndiff --git a/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java b/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java\nindex 7e5291f..a262f3e 100644\n--- a/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java\n+++ b/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java\n@@ -464,7 +464,7 @@ public class LucenePropertyIndex implements AdvancedQueryIndex, QueryIndex, Nati\n                             if (topDocs.totalHits > 0) {\n                                 for (ScoreDoc doc : topDocs.scoreDocs) {\n                                     Document retrievedDoc = searcher.doc(doc.doc);\n-                                    if (filter.isAccessible(retrievedDoc.get(FieldNames.PATH))) {\n+                                    if (filter.isAccessible(filter.getPath() + retrievedDoc.get(FieldNames.PATH))) {\n                                         queue.add(new LuceneResultRow(suggestion.string));\n                                         break;\n                                     }\n@@ -492,7 +492,7 @@ public class LucenePropertyIndex implements AdvancedQueryIndex, QueryIndex, Nati\n                             if (topDocs.totalHits > 0) {\n                                 for (ScoreDoc doc : topDocs.scoreDocs) {\n                                     Document retrievedDoc = searcher.doc(doc.doc);\n-                                    if (filter.isAccessible(retrievedDoc.get(FieldNames.PATH))) {\n+                                    if (filter.isAccessible(filter.getPath() + retrievedDoc.get(FieldNames.PATH))) {\n                                         queue.add(new LuceneResultRow(suggestion.key.toString(), suggestion.value));\n                                         break;\n                                     }\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "patch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "LucenePropertyIndex doesn't use filter's path for ACL checks of suggest queries"
   },
   {
      "_id": "12981819",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-06-22 09:08:37",
      "description": "I'm investigating a case where offline compaction is unable to finish, and crashes with OOMEs because of the content structure, namely large child node lists. The biggest issue is with the UUID index which has 55M nodes.\n\nIn the current implementation, the compactor will use an inmemory nodestate to collect all the data, and persist at the very end, once compaction is done [0]. \nThis is prone to OOME once the size of the data parts (no binaries involved) grows beyond a certain size (in this case I have 350Gb but there's a fair amount of garbage due to compaction not running).\n\nMy proposal is to add a special flag {{oak.compaction.eagerFlush=true}} that should be enabled only in case the size of the repo will not allow running offline compaction with the available heap size. This will turn the inmemory compaction transaction into one based on a persisted SegmentNodeState, meaning we're trading disk space (and IO) for memory.\n\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/Compactor.java#L248\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction persisted mode"
   },
   {
      "_id": "12979807",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-16 12:41:56",
      "description": "Followup of OAK-4279, offline compaction should use the default writer cache.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Enable writer cache for offline compaction"
   },
   {
      "_id": "12979401",
      "assignee": "chetanm",
      "components": [],
      "created": "2016-06-15 15:53:49",
      "description": "These failures are caused by adding the SEGMENT_TAR fixture to the matrix. That one doesn't exit in the branches thus the {{IllegalArgumentException}} \"No enum constant\".\n\nSee discussion http://markmail.org/message/oaptnvco5y2a4rjk",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "build",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CI failing on branches due to unknown fixture SEGMENT_TAR"
   },
   {
      "_id": "12979389",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-15 15:07:22",
      "description": "{{SegmentCache}} needs documentation, management instrumentation and monitoring tests and logging. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cache",
         "monitoring",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Finalise SegmentCache"
   },
   {
      "_id": "12979326",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-15 10:31:10",
      "description": "The {{SegmentReader.readHeadState()}} introduces a de-facto dependency to {{Revisions}} as access to the latter is required for obtaining the record id of the head. \n\nTo decouple SegmentReader from Revisions I propose to replace {{SegmentReader.readHeadState()}} with {{SegmentReader.readHeadState(Revisions revisions)}}. As this results in a lot of boilerplate for callers (i.e. {{fileStore.getReader().getHeadState(fileStore.getRevisions())}}), we should also introduce a convenience method {{FileStore.getHead()}} clients could use to that matter.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Decouple SegmentReader from Revisions"
   },
   {
      "_id": "12979249",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-06-15 05:23:12",
      "description": "Aim of this task is to evaluate storage cost of current approach for various Documents in DocumentNodeStore. And then evaluate possible alternative to see if we can get a significant reduction in storage size.\n\nPossible areas of improvement\n# NodeDocument\n## Use binary encoding for property values - Currently property values are stored in JSON encoding i.e. arrays and single values are encoded in json along with there type\n## Use binary encoding for Revision values - In a given document Revision instances are a major part of storage size. A binary encoding might provide more compact storage\n# Journal - The journal entries can be stored in compressed form\n\nAny new approach should support working with existing setups i.e. provide gradual change in storage format. \n\n*Possible Benefits*\nMore compact storage would help in following ways\n# Low memory footprint of Document in Mongo and RDB\n# Low memory footprint for in memory NodeDocument instances - For e.g. property values when stored in binary format would consume less memory\n# Reduction in IO over wire - That should reduce the latency in say distributed deployments where Oak has to talk to remote primary\n\nNote that before doing any such change we must analyze the gains. Any change in encoding would make interpreting stored data harder and also represents significant change in stored data where we need to be careful to not introduce any bug!",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "More compact storage format for Documents"
   },
   {
      "_id": "12978771",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328326",
            "id": "12328326",
            "name": "examples"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12327590",
            "id": "12327590",
            "name": "webapp"
         }
      ],
      "created": "2016-06-14 12:34:33",
      "description": "For OAK-2605 we copied the source of {{ReversedLinesFileReader}} to Oak to get the fix for IO-471 in. As this is now fixed in {{commons-io}} 2.5, I suggest we upgrade our dependency and remove that duplicated class.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Upgrade commons-io to 2.5 and remove ReversedLinesFileReader"
   },
   {
      "_id": "12977615",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-10 13:56:07",
      "description": "I like to remove {{SegmentNodeStore.getSuperRoot}} That method leaks implementations details (e.g. checkpoints). Access to the super root is still possible through lower level APIs (e.g. {{SegmentReader#readHeadState}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove SegmentNodeStore.getSuperRoot()"
   },
   {
      "_id": "12977548",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-10 09:39:20",
      "description": "When compaction needs to go into cycles because of concurrent commits the number of total cycles should be logged alongside with the number of attempted cycles. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve logging during compaction cycles"
   },
   {
      "_id": "12977379",
      "assignee": "mduerig",
      "components": [],
      "created": "2016-06-09 20:50:55",
      "description": "As [discussed | http://markmail.org/message/2dk6i3yxjfkknrzp] we should also have CI coverage on Windows.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "CI",
         "build",
         "infrastructure",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Setup Windows builds "
   },
   {
      "_id": "12977102",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2016-06-09 05:49:22",
      "description": "The various blob gc related tests have a fair bit of duplication. These should be de duplicated and cleaned up.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cleanup blob gc related tests"
   },
   {
      "_id": "12976918",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 16:13:59",
      "description": "We should make an effort to consistently use the term \"segment-tar\" instead of \"SegmentMK\", \"TarMK\", etc. in logging, exceptions, labels, descriptions, documentation etc.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Consistently use the term segment-tar"
   },
   {
      "_id": "12976915",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 16:08:39",
      "description": "The template cache is currently just a map per segment. This is problematic in various ways: \n* A segment needs to be in memory and probably loaded first only to read something from the cache. \n* No monitoring, instrumentation of the cache\n* No control over memory consumption \n\nWe should there for come up with a proper template cache implementation in the same way we have done for strings ({{StringCache}}) in OAK-3007. Analogously that cache should be owned by the {{CachingSegmentReader}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cache",
         "monitoring",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement a proper template cache"
   },
   {
      "_id": "12976911",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 15:57:37",
      "description": "The {{ReadOnlyFileStore}} class currently simply overrides the {{FileStore}} class replacing all mutator methods with a trivial implementation. This approach however leaks into its ancestor as the read only store needs to pass a flag to the constructor of its super class so some fields can be instantiated properly for the read only case. \n\nWe should clean this up to properly separate the read only and the r/w store. Most likely we should factor the commonalities into a common, abstract base class.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Properly split the FileStore into read-only and r/w variants "
   },
   {
      "_id": "12976909",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 15:51:47",
      "description": "{{SegmentNodeStoreBuilder}} and {{FileStoreBuilder}} should log the arguments used to build new instances of the respective classes when one of its {{build()}} methods is called. This facilitates post mortem analysis of log files.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "logging",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeStore and SegmentStore builders should log their parameters on build()"
   },
   {
      "_id": "12976870",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 13:38:34",
      "description": "Tweak our setup in order to be able to cut an initial release of {{oak-segment-tar}} and perform the release. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "release"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release oak-segment-tar"
   },
   {
      "_id": "12976859",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 13:12:24",
      "description": "We should come up with a good set of write statistics to collect like number of records/nodes/properties/bytes. Additionally those statistics should be collected for normal operation vs. compaction related operation. This would allow us to more precisely analyse the effect of compaction on the overall system. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Collect write statistics "
   },
   {
      "_id": "12976857",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-06-08 13:06:54",
      "description": "The result of the static {{MergingNodeStateDiff.merge}} method is only used in the base case of a recursive diff. In all other cases while traversing the child diffs that result is simply discarded. As calculating the result involves an extra call to {{NodeBuilder.getNodeState}} it inflicts a performance penalty in the case of segment-tar: in that case this call causes the changes in the builder to be written ahead into the store. I figure it is simple enough to specialise the merge method in a way so that call is only done when its result is actually used. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce number of calls to NodeBuilder.getNodeState from MergingNodeStateDiff"
   },
   {
      "_id": "12976475",
      "assignee": "frm",
      "components": [],
      "created": "2016-06-07 14:44:49",
      "description": "Some Javadoc is not strict enough according to the Javadoc tool shipped in JDK8.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix the errors reported by the Javadoc tool in JDK8"
   },
   {
      "_id": "12976451",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-07 13:58:44",
      "description": "Cleaning of segment created by an unsuccessful compaction run currently only works if forced compaction is enabled. Otherwise those segments will only get cleaned in a much later cleanup cycle. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Segments created by an unsuccessful compaction run should get cleaned"
   },
   {
      "_id": "12976346",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-07 08:19:55",
      "description": "I've seen {{HeavyWriteIT}} fail sporadically on my local checkout.\n\n{noformat}\n3d13e2927fc0d75454a692ef5c8703880dc2ea0d\norg.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment 31b75992-aaf7-4f2b-a5de-b5a268c1fdb3 not found\n\n\tat org.apache.jackrabbit.oak.segment.file.FileStore$14.call(FileStore.java:1377)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore$14.call(FileStore.java:1317)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.load(CacheLIRS.java:1011)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.get(CacheLIRS.java:972)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS.get(CacheLIRS.java:283)\n\tat org.apache.jackrabbit.oak.segment.SegmentCache.geSegment(SegmentCache.java:80)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:1317)\n\tat org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:111)\n\tat org.apache.jackrabbit.oak.segment.RecordId.getSegment(RecordId.java:94)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.isOldGeneration(SegmentWriter.java:1010)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNodeUncached(SegmentWriter.java:906)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNode(SegmentWriter.java:885)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.access$700(SegmentWriter.java:319)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$8.execute(SegmentWriter.java:277)\n\tat org.apache.jackrabbit.oak.segment.SegmentBufferWriterPool.execute(SegmentBufferWriterPool.java:110)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter.writeNode(SegmentWriter.java:274)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:111)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.<init>(SegmentNodeStore.java:516)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore.merge(SegmentNodeStore.java:284)\n\tat org.apache.jackrabbit.oak.segment.HeavyWriteIT.heavyWrite(HeavyWriteIT.java:91)\n{noformat}\n\nI suspect this is a problem with {{isOldGeneration}} itself not being prepared for the old segment actually being gone. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "HeavyWriteIT sporadically fails"
   },
   {
      "_id": "12976344",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-07 08:12:27",
      "description": "{{CompactionAndCleanupIT.checkpointDeduplication}} irregularly [fails|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/938/jdk=latest1.7,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=integrationTesting/console] on Jenkins. \n\nThis might point to an issue with the de-duplication caches, which are crucial in getting the checkpoints de-duplicated. \n\n{code}\ncheckpointDeduplicationTest(org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT)  Time elapsed: 0.15 sec  <<< FAILURE!\norg.junit.ComparisonFailure: expected:<[7211975a-04ce-45ff-aff5-16795ec2cc72]:261932> but was:<[11083c4b-9b2e-4d17-a8c0-8f6b1f2a3173]:261932>\n\tat org.junit.Assert.assertEquals(Assert.java:115)\n\tat org.junit.Assert.assertEquals(Assert.java:144)\n\tat org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT.checkpointDeduplicationTest(CompactionAndCleanupIT.java:899)\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "checkpointDeduplicationTest sometimes fails on Jenkins"
   },
   {
      "_id": "12976334",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-07 07:40:43",
      "description": "The {{SegmentWriter}} and its related classes accept a {{SegmentVersion}} argument. This is confusing since that version is only stored in the segment's segment version field. The writer cannot and does not actually write segments at older version than the latest (12). \n\nI suggest we remove the explicit segment version from all classes where it can be specified and hard code the segment version to 12 for now. This is the only segment version {{segment-tar}} currently supports anyway. Should  the need to support other segment version arise in the future, we need to decide at that point how to parametrise {{segment-tar}} on the segment version. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove segment version argument from segment writer and and related classes"
   },
   {
      "_id": "12975788",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-06-05 06:30:35",
      "description": "{{RevisionVector}} is used in very critical paths and we should look into optimzing some of its critical method\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimize RevisionVector methods"
   },
   {
      "_id": "12975375",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2016-06-03 04:25:04",
      "description": "{{PathUtils.concat}} does not specify the default size of StringBuilder. Default string constructor uses a string.length() + 16 as the buffer size. Given size of appended path is known we can properly size the string builder buffer to avoid any expansion during actual append",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimize PathUtils.concat by using a properly sized StringBuilder"
   },
   {
      "_id": "12975125",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-06-02 11:04:58",
      "description": "Current implementation of Revision {{fromString}} and {{toString}} make use of std JDK API to perform string manipulation. While running some performance test it was seen that these 2 methods are called quite frequently and that adds up to some decent times. Further they also generate quite a bit of short lived objects.\n\n!hot-methods.png!\n\nIt would be worthwhile to perform a micro benchmark of these method and optimize them further such that they perform better and also generate less garbage. The micro optimized code would be bit more complex but if performance numbers are better we can look into changing the current implementation",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize Revison fromString and toString implementation"
   },
   {
      "_id": "12974757",
      "assignee": "frm",
      "components": [],
      "created": "2016-06-01 10:21:52",
      "description": "(Some of?) the changes done in the other subtasks cause the temporary files to be created in the systems temporary folder instead of the target folder as before. This causes issues on system where the temporary folder resides on a small partition. \n\nSee my [comment |https://issues.apache.org/jira/browse/OAK-4208?focusedCommentId=15296019&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15296019] on OAK-4208 where we have been seeing this on the Apache Jenkins instance. See also  INFRA-11837.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move temp files to target directory"
   },
   {
      "_id": "12972439",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-05-24 16:36:42",
      "description": "Currently, if the definition of an index is changed without reindexing, it will get in an \"inconsistent\" state. \n\nOf course, the reindexing is usually necessary, but it would be useful to know with which definition the index was built. This could increase the visibility of the indexing state and help debugging issues related to it.\n\nSome questions this improvement should respond to:\n# What is the definition of the index when the (re)indexing was triggered?\n# Are there any changes in the definition since the trigger? Which?\n\nI can imagine a solution built by \"versioning\" the definition nodes (oak:QueryIndexDefinition). When the reindex is triggered, a new version of the node is created and the indexer stores a reference to it.\nThis would also allow the indexer to keep using the same definition until a new reindex, even if changes are made meanwhile (i.e. use a fixed version instead of the latest definition).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Correlate index with the index definition used to build it"
   },
   {
      "_id": "12972329",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2016-05-24 09:18:51",
      "description": "With the following scenario the {{DefaultSyncContext.syncMembership}} may end up synchronizing (i.e. updating) a group defined by an foreign IDP and even add the user to be synchronized as a new member:\n\n- configuration with different IDPs\n- foreign IDP synchronizes a given external group 'groupA' => rep:externalID points to foreign-IDP (e.g. rep:externalId = 'groupA;foreignIDP')\n- my-IDP contains a group with the same ID (but obviously with a different rep:externalID) and user that has declared group membership pointing to 'groupA' from my IDP\n\nif synchronizing my user first the groupA will be created with a rep:externalId = 'groupA;myIDP'.\nhowever, if the group has been synced before by the foreignIDP the code fails to verify that an existing group 'groupA' really belongs to the same IDP and thus may end up synchronizing the group and updating it's members.\n\nIMHO that's a critical issue as it violates the IDP boundaries.\nthe fix is pretty trivial as it only requires testing for the IDP of the existing group as we do it in other places (even in the same method).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "DefaultSyncContext.syncMembership may sync group of a foreign IDP"
   },
   {
      "_id": "12972025",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-05-23 10:30:23",
      "description": "Running of the memory store would improve test speed without impacting test coverage.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Run SegmentParserTest off memory store instead of file store"
   },
   {
      "_id": "12972022",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-05-23 10:21:29",
      "description": "OAK-3007 replaced the now deprecated strings cache with a proper cache. We should now remove the former. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove deprecated string cache"
   },
   {
      "_id": "12972018",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-05-23 10:09:02",
      "description": "That test is currently unnecessarily strongly tied to the file store, which makes it prone to failing if implementation details in the store change. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Decouple FileStoreStatsTest"
   },
   {
      "_id": "12971136",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2016-05-19 12:43:25",
      "description": "the {{SyncMBeanImpl}} currently calls {{Session.save()}} for every single sync, which IMO make the synchronization methods extra expensive.\n\nIMHO we should consider introducing a batch mode that reduces the number of save calls. the drawback of this was that the complete set of sync-calls withing a given batch would succeed or fail. in case of failure the 'original' sync-result would need to be replaced by one with operation status 'ERR'.\n\nnow that we have the basis for running benchmarks for the {{SyncMBeanImpl}}, we should be able to verify if this proposal actually has a positive impact (though benchmark results from OAK-4119 and OAK-4120 seem to indicate that this is the case).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Batch mode for SyncMBeanImpl"
   },
   {
      "_id": "12970406",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-05-17 15:36:45",
      "description": "The {{SegmentTracker}} class has become the dumping ground for everything that wouldn't fit else where. In a personal discussion with [~frm], we figured that this class might be a good starting point refactoring {{segment-tar}} towards better encapsulation. \nThe aim would be to return {{SegmentTracker}} to its initial purpose (i.e. tracking segments) and move all unrelated concerns elsewhere.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor SegmentTracker"
   },
   {
      "_id": "12970308",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-05-17 09:23:47",
      "description": "{{FileStore.compact}} logs a warning {{TarMK GC #{}: compaction found {} checkpoints, you might need to run checkpoint cleanup}} if there is more than a single checkpoints. \n\nAFIK this is now the norm as async indexing has uses 2 checkpoints ([~chetanm], [~edivad] please clarify). \n\nIn any case should we improve this and not hard code any number of expected checkpoints. Maybe make the threshold configurable?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "logging"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Overly zealous warning about checkpoints on compaction "
   },
   {
      "_id": "12962944",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-27 09:34:09",
      "description": "{{BlobReferenceRetriever#collectReferences}} currently does not allow implementations to throw an exception. In case anything goes wrong during reference collection, implementations should be able to indicate this through an exception so the DSGC can safely abort. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "datastore",
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "BlobReferenceRetriever#collectReferences should allow exceptions"
   },
   {
      "_id": "12962623",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-26 15:08:29",
      "description": "{{SegmentDataStoreBlobGCIT#gcWithInlined}}, {{gc}}, {{gcLongRunningBlobCollection}} and {{consistencyCheckWithGc}} fail since the removal of the old cleanup strategy in OAK-4276. \n\nThe test setup needs to be adapted to the brutal strategy: i.e. {{setup()}} needs to simulate so many compaction cycles until a subsequent cleanup actually remove the segments in question. \n\nThis is not sufficient though as then {{SegmentTracker#collectBlobReferences}} causes a SNFE for those segment ids actually removed but still in the segment id tables. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix test failures in SegmentDataStoreBlobGCIT"
   },
   {
      "_id": "12962573",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-26 12:06:47",
      "description": "We need to align / improve the labels and descriptions in {{SegmentNodeStoreService}} to match their actual purpose. At the same time I would opt for changing \"compaction\" to \"revision gc\" in all places where it is used synonymously for the latter. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Align property labels and descriptions in SegmentNodeStoreService"
   },
   {
      "_id": "12962192",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2016-04-25 09:23:57",
      "description": "Since the oak-segment will be deprecated, let's switch to oak-segment-next in all oak-upgrade tests (apart from the specific test covering the \"classic\" oak-segment support).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "migration",
         "upgrade"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use the oak-segment-next in the oak-upgrade tests"
   },
   {
      "_id": "12962161",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2016-04-25 07:37:09",
      "description": "while working on OAK-4101 i noticed that the current implementation doesn't provide any protection for the system maintained property {{rep:externalId}}, which is intended to be an identifier for a given synchronized user/group within an external IDP.\n\nin other words:\n- the system doesn't assert the uniqueness of a given external-id\n- the external-id properties can be changed using regular JCR API \n\nup to now i didn't manage to exploit the missing protection with the current default implementation but i found that minor (legitimate) changes have the potential to turn this into a critical vulnerability.\n\ntherefore I would strongly recommend to change the default implementation such that the rep:externalId really becomes system-maintained and prevent any unintentional or malicious modification outside of the scope of the sync-operations. furthermore uniqueness of this property should be asserted.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Missing protection for system-maintained rep:externalId "
   },
   {
      "_id": "12962140",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-04-25 04:19:11",
      "description": "Currently default cost per entry for Lucene index of type\n# v1 - which uses query time aggregation\n# v2 - which uses index time aggregation\n\nAre same. However given that query time aggregation would require more effort it should result in a higher cost per entry.\n\nThis fact impacts the result in cases like OAK-2081 (see last few comments) where with usage of limits both index are currently considered equals",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cost per entry for Lucene index of type v1 should be higher than that of v2"
   },
   {
      "_id": "12962133",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-04-25 03:24:58",
      "description": "With OAK-4182 and OAK-4298, oak-run->console supports connecting to a repository in read only mode. But, as [~edivad] suggested [here|https://issues.apache.org/jira/browse/OAK-4182?focusedCommentId=15245661&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15245661], it might be more useful to connect to repositories in read-only mode by default and require an explicit read-write flag for write operations.\n\nThis, of course, doesn't align with 'always read-write mode' that's operational currently.\n\nBtw, since, 1.5.2 hasn't been release yet, so, we can do this switch pretty cleanly currently. Post 1.5.2 (which would then have {{--read-only}}, we might have to retain that flag)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run console should connect to repository in read-only mode by default"
   },
   {
      "_id": "12962103",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-04-24 20:05:18",
      "description": "Similar to OAK-4182, we should expose a parameter ({{\\-\\-read-only}}) to oak-run->console while stating oak-run to connect to a segment storage. Note, read-only mode can be a global boolean for lifetime of oak-run (i.e. we don't really need dynamic switching between read-only and read-write modes)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run->console should have a read-only mode to connect to segment store"
   },
   {
      "_id": "12961897",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 20:05:14",
      "description": "OAK-3348 introduced changes to the segment format (which has been bumped to 12 with OAK-4232). However it also changes the format of the tar files (the gc generation of the segments is written to the index file) which would also require proper versioning.\n\nIn a offline discussion [~frm] brought up the idea of adding a manifest file to the store that would specify the format versions of the individual components. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "resilience",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Proper versioning of storage format"
   },
   {
      "_id": "12961896",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 20:01:12",
      "description": "That filed is not volatile although access by different threads. We should consider changing it to volatile.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Consider making FileStore.writer volatile"
   },
   {
      "_id": "12961892",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:49:25",
      "description": "I think we have to take another look at {{CompactionGainEstimate}} and see whether we can up with a more efficient way to estimate the compaction gain. The current implementation is expensive wrt. IO, CPU and cache coherence. If we want to keep an estimation step we need IMO come up with a cheap way (at least 2 orders of magnitude cheaper than compaction). Otherwise I would actually propose to remove the current estimation approach entirely ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor / rework compaction gain estimation "
   },
   {
      "_id": "12961891",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:43:02",
      "description": "Document Oak Segment Tar. Specifically:\n* New and changed configuration and monitoring options\n* Changes in gc (OAK-3348 et. all)\n* Changes in segment / tar format (OAK-3348)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document oak-segment-tar"
   },
   {
      "_id": "12961884",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:36:57",
      "description": "There is a small window in {{FileStore.flush}} that could lead to data corruption: if we crash right after setting the persisted head but before any delay-flushed {{SegmentBufferWriter}} instance flushes (see {{SegmentBufferWriterPool.returnWriter()}}) then that data is lost although it might already be referenced from the persisted head.\n\nWe need to come up with a test case for this. \n\nA possible fix would be to return a future from {{SegmentWriter.flush}} and rely on a completion callback. Such a change would most likely also be useful for OAK-3690. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "FileStore.flush prone to races leading to corruption"
   },
   {
      "_id": "12961872",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:23:42",
      "description": "{{SegmentParser}} does not correctly handle the record id added to the segment node states: for those segment node state containing an actual record id the segment parser should process it and call the respective call backs. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update segment parser to work with the new segment format"
   },
   {
      "_id": "12961864",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:14:59",
      "description": "The segment meta info (OAK-3550) still contains the segment's gc generation. As with OAK-3348 the gc generation gets written to the segment header directly we should remove it from the segment meta info and update {{oak-run graph}} accordingly. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove the gc generation from the segment meta data"
   },
   {
      "_id": "12961852",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:09:49",
      "description": "{{TarReader.calculateForwardReferences}} is not used for production but only for tooling so it would be good if we could remove that method from the production code an put it into a tooling specific module. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "TarReader.calculateForwardReferences only used by oak-run graph tool"
   },
   {
      "_id": "12961845",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:03:44",
      "description": "{{SegmentBufferWriter#checkGCGen}} is an after the fact check for back references (see OAK-3348), logging a warning if detects any. As this check loads the segment it checks the reference for, it is somewhat expensive. We should either come up with a cheaper way for this check or remove it (at least disable it by default). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "assertion",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Disable / remove SegmentBufferWriter#checkGCGen"
   },
   {
      "_id": "12961706",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:58:09",
      "description": "The fix for OAK-3348 caused some of the tests in {{CompactionAndCleanupIT}} to fail and I put the to ignored for the time being. We need to check whether the test expectations still hold and rework them as required. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc",
         "tests"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Rework failing tests in CompactionAndCleanupIT"
   },
   {
      "_id": "12961705",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:53:12",
      "description": "We need to align cleanup of the segment id tables with the new \"brutal\" strategy introduced with OAK-3348. That is, we need to remove those segment id's from the segment id tables whose segment have actually been gc'ed. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Align cleanup of segment id tables with the new cleanup strategy "
   },
   {
      "_id": "12961701",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:48:55",
      "description": "As a result of the new cleanup approach introduced with OAK-3348 (brutal) a compaction cycle that is not successful (either because of cancellation of because of giving up waiting for the lock) leaves garbage behind, which is only cleaned up 2 generations later. \n\nWe should look into ways to remove such garbage more pro-actively. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Garbage left behind when compaction does not succeed"
   },
   {
      "_id": "12961693",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:41:32",
      "description": "The argument taken by {{GCMonitor.compacted}} related to parameters of the compaction map. The latter has gone with OAK-3348. We need to come up with a way to adjust this API accordingly. Also it might make sense to broaden the scope of {{GCMonitor}} from its initial intent (logging) to a more general one as this is how it is already used e.g. by the {{RefreshOnGC}} implementation and for OAK-4096. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "api-change",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Align GCMonitor API with implementation "
   },
   {
      "_id": "12961684",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:34:56",
      "description": "The number of retained gc generations (\"brutal\" cleanup strategy) is currently hard coded to 2. I think we need to make this configurable. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make the number of retained gc generation configurable"
   },
   {
      "_id": "12961679",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:29:31",
      "description": "As a result of OAK-3348 we need to partially rework the memory estimation step done for deciding whether compaction can run or not. In {{oak-segment}} there was a {{delta}} value derived from the compaction map. As the latter is gone in {{oak-segment-next}} we need to decide whether there is another way to derive this delta or whether we want to drop it entirely. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Rework memory estimation for compaction"
   },
   {
      "_id": "12961673",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:20:26",
      "description": "As a result of the de-duplication cache based online compaction approach from OAK-3348 compaction cannot be cancelled any more (in the sense of OAK-3290). \n\nAs I assume we still need this feature we should look into ways to re-implement it on top of the current approach. \n\nAlso I figure implementing a [partial compaction | https://issues.apache.org/jira/browse/OAK-4122?focusedCommentId=15223924&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15223924]\u00a0approach on top of a commit scheduler (OAK-4122) would need a feature of this sort. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction cannot be cancelled "
   },
   {
      "_id": "12961664",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 14:57:07",
      "description": "The fix for OAK-3348 broke some of the previous functionality of offline compaction:\n* No more progress logging\n* Compaction is not interruptible any more (in the sense of OAK-3290)\n* Offline compaction could remove the ids of the segment node states to squeeze out some extra space. Those are only needed for later generations generated via online compaction. \n\nWe should probably implement offline compaction again through a dedicated {{Compactor}} class as it was done in {{oak-segment}} instead of relying on the de-duplication cache (aka online compaction). \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Rework offline compaction"
   },
   {
      "_id": "12961662",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 14:45:38",
      "description": "{{FileStoreBackup}} and {{FileStoreRestore}} are currently broken as a side effect of the fix from OAK-3348. ({{FileStoreBackupTest}} is currently being skipped). \n\nIn {{oak-segment}} backup and restore functionality relied on the {{Compactor}} class. The latter is gone in {{oak-segment-next}} as it is not needed for online compaction any more. \nInstead of sharing functionality from compaction directly, I think backup and restore should come up with its own implementation that could be individually tweaked for its task. If there is commonalities with offline compaction those can still be shared thorough a common base class. See OAK-4279",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "backup",
         "restore",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Fix backup and restore"
   },
   {
      "_id": "12961656",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 14:29:25",
      "description": "OAK-3348 \"promoted\" the record cache to a de-duplication cache, which is heavily relied upon during compaction. Now also node states go through this cache, which can seen as one concern of the former compaction map (the other being equality). \nThe current implementation of these caches is quite simple and served its purpose for a POC for getting rid of the \"back references\" (OAK-3348). Before we are ready for a release we need to finalise a couple of things though:\n\n* Implement cache monitoring and management\n* Make cache parameters now hard coded configurable\n* Implement proper UTs \n* Add proper Javadoc\n* Fine tune eviction logic and move it into the caches themselves (instead of relying on the client to evict items pro-actively)\n* Fine tune caching strategies: For the node state cache the cost of the item is determined just by its position in the tree. We might want to take further things into account (e.g. number of child nodes). Also we might want to implement pinning so e.g. checkpoints would never be evicted. \n* Finally we need to decide who should own this cache. It currently lives with the {{SegmentWriter}}. However this is IMO not the correct location as during compaction there is dedicated segment writer whose cache need to be shared with the primary's segment writer upon successful completion. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "caching",
         "compaction",
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Finalise de-duplication caches"
   },
   {
      "_id": "12961650",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 14:05:01",
      "description": "After the changes from OAK-3348 many if not all of the options in {{CompactionStrategy}} do not apply any more. Specifically the new \"brutal\" strategy is hard coded to always be in effect. We need to:\n\n* Decide which cleanup methods we want to keep supporting,\n* decide which options to expose through CompactionStrategy. E.g. {{cloneBinaries}} was so far always set to {{false}} and I would opt to remove the option as implementing might be tricky with the de-duplication cache based compaction we now have,\n* optimally refactor {{CompactionStrategy}} into a proper abstract data type. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor / rework compaction strategies "
   },
   {
      "_id": "12960635",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-04-21 07:39:17",
      "description": "In some cases where a user is tweaking the indexing config it can happen that he saves the config mid way which triggers a long indexing run. Currently there is no easy way to abort such a run and only way to avoid wasting time in the long indexing cycle is to shut down the system.\n\nFor such cases it would be good to provide an \"abort\" operation as part of {{IndexStatsMBean}} which user can invoke to abort any run safely and cleanly",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide a way to abort an async indexing run"
   },
   {
      "_id": "12960374",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2016-04-20 15:01:17",
      "description": "We need to come up with a plan, implementation and documentation for how we deal with migrating from {{oak-segment}} to {{oak-segment-next}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "migration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Define and implement migration from oak-segment to oak-segment-tar"
   },
   {
      "_id": "12960367",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 14:35:39",
      "description": "We need fixtures to run UTs / ITs against either or both segment implementations {{oak-segment}} and {{oak-segment-next}}. \n\nIdeally we can enable them individually through e.g. environment variables. A standard build would run against {{oak-segment}} so not to affect others. {{oak-segment-next}} could be enabled on request locally or for the CI. \nOnce we deprecate {{oak-segment}} we would switch the default fixture to {{oak-segment-next}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "testing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Implement fixtures for running again oak-segment and/or oak-segment-next"
   },
   {
      "_id": "12960329",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-04-20 12:47:20",
      "description": "I suspect that certain write operations during compaction can cause references from compacted segments to pre-compacted ones. This would effectively prevent the pre-compacted segments from getting evicted in subsequent cleanup phases. \n\nThe scenario is as follows:\n* A session is opened and a lot of content is written to it such that the update limit is exceeded. This causes the changes to be written to disk. \n* Revision gc runs causing a new, compacted root node state to be written to disk.\n* The session saves its changes. This causes rebasing of its changes onto the current root (the compacted one). At this point any node that has been added will be added again in the sub-tree rooted at the current root. Such nodes however might have been written to disk *before* revision gc ran and might thus be contained in pre-compacted segments. As I suspect the node-add operation in the rebasing process *not* to create a deep copy of such nodes but to rather create a *reference* to them, a reference to a pre-compacted segment is introduced here. \n\nGoing forward we need to validate above hypothesis, assess its impact if necessary come up with a solution.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "CLONE - Cross gc sessions might introduce references to pre-compacted segments"
   },
   {
      "_id": "12960318",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 12:29:20",
      "description": "{{FileStore.containsSegment()}} looks [funky|https://github.com/mduerig/jackrabbit-oak/blob/36cb3bf6e5078e3afa75581fb789eeca7b5df2e2/oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/file/FileStore.java#L1197-L1197]. This \"optimisation\" causes it to always return {{true}}. \n\n{{containsSegment}} is used for deduplication and revision gc. The current implementation causes {{SNFE}} exceptions once gc is effective (as I experienced while working on OAK-3348). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "stability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "CLONE - FileStore.containsSegment returns alway true (almost)"
   },
   {
      "_id": "12960315",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 12:24:48",
      "description": "If the run method of a {{BackgroundThread}} instance hits an {{Error}} it dies silently. Instead it should log an re-throw the error. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CLONE - BackgroundThread should log and re-throw instances of Error"
   },
   {
      "_id": "12960313",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 12:19:56",
      "description": "{{org.apache.jackrabbit.oak.plugins.segment.file.TarReader#loadGraph}} sometimes detects a segment graph as corrupt although it isn't. This results in cleanup rewriting the tar file (all over again). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CLONE - TarReader#loadGraph wrongly detects segment graph as corrupt "
   },
   {
      "_id": "12960275",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-04-20 09:20:15",
      "description": "Before the next major release we need to deprecate {{oak-segment}} and make {{oak-segment-tar}} the new default implementation:\n\n* Deprecate all classes in {{oak-segment}}\n* Update documentation to reflect this change\n* Update tooling to target {{oak-segment-tar}} (See OAK-4246). \n* Update dependencies of upstream modules / projects from {{oak-segment}} to {{oak-segment-tar}}. \n* Ensure {{oak-segment-tar}} gets properly released (See OAK-4258). \n* Tests run against the {{SEGMENT_TAR}} fixture.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Deprecate oak-segment"
   },
   {
      "_id": "12960273",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 09:16:20",
      "description": "We need to add command line options segment specific tooling so users could chose between {{oak-segment}} and {{oak-segment-next}}. {{oak-segment}} should be the default until deprecated, where {{oak-segment-next}} should be made the default. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Update segment tooling to choose target store"
   },
   {
      "_id": "12959937",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-19 08:47:03",
      "description": "We need to bump {{SegmentVersion}} to 12 to properly reflect the change in persistence format. At the same time we need to remove our dependencies to older segment versions as this is a non backward compatible change. \n\nAll segment stores written by code prior to this change will not work any more with code once this change has been applied and vice versa. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "compatibility",
         "version"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bump segment version to 12"
   },
   {
      "_id": "12958457",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-04-13 12:37:53",
      "description": "Oak-run console should export a command to export relevant documents from connected repository.\nSomething like:\n{noformat}\n/> export-docs /oak:index/my_index/:index/test/content/a export.json\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run console should have command to export relevant documents (same as oak-mongo.js' printMongoExportCommand)"
   },
   {
      "_id": "12958434",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-04-13 10:27:52",
      "description": "Switch API clients to {{SegmentNodeStoreBuilder}} instead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove deprecated constructors from SegmentNodeStore"
   },
   {
      "_id": "12958390",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-04-13 07:39:11",
      "description": "With OAK-4148 we can now have a read only document node store. That required us to put if(readOnly){} at places. It'd be cleaner to refactor out a ReadOnlyDocumentNodeStore to take care of the read-only parts.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Refactor DocumentNodeStore to have a ReadOnlyDocumentNodeStore which is gives read-only behavior"
   },
   {
      "_id": "12958024",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-04-12 08:26:46",
      "description": "oak-run, when connecting to a persistence storage, works like a live/independent oak instance. For clustered setup (read doc stores such backed by mongo or rdb), this means that another connected instance would treat oak-run's connection as a new one. While, theoretically, there is no issue with it and the world would work fine BUT an investigative tool such as oak-run->console should minimize touching the system as much as possible (especially while collecting forensics).\n\nSo, we should expose a parameter (say {{\\-\\-read-only}} to oak-run->console while stating oak-run to connect to a document store storage. Note, read-only mode can be a global boolean for lifetime of oak-run (i.e. we don't really need dynamic switching between read-only and read-write modes)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting",
         "production",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run->console should have a read-only mode to connect to document stores (mongo, rdb, etc)"
   },
   {
      "_id": "12958002",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-04-12 07:08:01",
      "description": "DocumentNodeStore makes use of persistent cache to speed up its processing and save on making remote calls for data already present in cache\n\nIn addition to that we can look into make use of Segment NodeStore as kind of \"local copy\" for certain paths in repository and route calls to it if possible. As part of this task I would like to prototype such an approach. At high level it would work as below\n\n# At start bootstrap the setup and shutdown it down\n# Use a modified \"sidegrade\" and copy over the NodeStats from Document store to Segment store. In such a copy we also store some Document specific properties like {{readRevision}} and {{lastRevision}} as hidden property in Segment NodeStates\n# In DocumentNodeStore we refactor the current code to extract a \n## {{AbstractDocumentNodeState}} - Abase class which has some logic move out from {{DocumentNodeState}}\n## {{SegmentDocumentNodeState}} extends above and delegate calls to a wrapped {{SegmentNodeState}}\n## {{DocumentNodeState}} would also extend {{AbstractDocumentNodeState}} and hence delegate to some calls to parent. In this when a call comes for {{getChildNode}} it can check if that can be served by a local copy of {{SegmentNodeStore}} for given {{rootRevision}} then it delegates to that\n# For update plan is to make use of {{Observer}} which listens to changes and updates the local copy for certain configured paths. \n## Key aspect to address here is handle the restart case where in a cluster a specific node restarts after some time then how it refreshes itself there\n\n*Usage*\nFollowing 2 OSGi configs would need to be seed\n\n* org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.config\n{noformat}\nsecondary=B\"true\"\n{noformat}\n* org.apache.jackrabbit.oak.plugins.document.secondary.SecondaryStoreCacheService.config\n{noformat}\nincludedPaths=[ \\\n  \"/\",\n  ]\n{noformat}\n\nWith these settings if DocumentNodeStoreService gets started it would pickup the cache and use it. Change {{includedPaths}} depending on paths in repository which you want to include in secondary store.\n\n*Feature Docs*\nhttp://jackrabbit.apache.org/oak/docs/nodestore/document/secondary-store.html",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use another NodeStore as a local cache for a remote Document store"
   },
   {
      "_id": "12955262",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-01 10:34:58",
      "description": "{{FileStore.cleanup}} logs the segment id of any forward reference found when including those in the reference graph. The logged information can amount to several MBs impacting normal operation. Furthermore the actually reclaimed segments are logged, which also makes the log files explode. Finally the processing of the references and individual tar files might be too wordy. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc",
         "logging"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Too verbose logging during revision gc"
   },
   {
      "_id": "12952883",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-03-23 16:06:58",
      "description": "Add some helper steps on output and what you can actually do with it:\n\n{quote}\n1. Run tarmkrecovery command\n{code:none}\nnohup java -Xmx2048m -jar oak-run-*.jar tarmkrecovery repository/segmentstore &> tarmkrecovery.log &\n{code}\n\n2. Take the output of the tarmkrecovery, take the top 10 items output (excluding \"Current head revision line\") then reverse the order of those and format them to journal.log file format (revision:offset root) and put those values in a fresh journal.log in that format\nFor example:\n{code:none}\n6ee64a26-491e-4630-ac2e-bdad1f27e73a:257016 root\n5ee64a26-491e-4630-ac2e-bdad1f27e73b:257111 root\n{code}\n\n3. After setting up the new journal.log then run this command on the segmentstore\n{code:none}\nnohup java -Xmx2048m -jar oak-run-*.jar check -p repository/segmentstore -d &> check.log &\n{code}\n\n4. That command will give you output of which of those 10 items in the journal.log are good. Now remove all lines from the journal that come after the last known good revision.\n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve tarmkrecovery docs"
   },
   {
      "_id": "12952459",
      "assignee": "edivad",
      "components": [],
      "created": "2016-03-22 14:46:04",
      "description": "Back in the days we introduced the maven variable\n{{-Dsurefire.skip.ut=true}} which we use on jenkins in order to skip\nthe unit testing when running the integrationTesting profile.\n\nThis is because we have a unittesting profile as well.\n\nThe default value for such variable is {{false}} anyhow.\n\nNoticed that the {{pedantic}} profile does not use such variable and\ntherefore we have on jenkins the unit testing running twice which\nconsume resources and time.\n\nAttaching a [patch|^OAK-4142-1.patch] which allows the pendatic to skip running the unit\ntesting.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "allow skip UT in pedantic profile"
   },
   {
      "_id": "12952080",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-21 16:15:40",
      "description": "I suggest we decouple revision cleanup from the flush thread. With large repositories where cleanup can take several minutes to complete it blocks the flush thread from updating the journal and the persisted head thus resulting in larger then necessary data loss in case of a crash. \n\n/cc [~alex.parvulescu]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Decouple revision cleanup from the flush thread"
   },
   {
      "_id": "12951446",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2016-03-18 06:14:36",
      "description": "Following failure is seen on some CI\n\n{noformat}\nRunning org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.98 sec <<< FAILURE!\ndefaultConfigSpiAuth(org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest)  Time elapsed: 0.97 sec  <<< ERROR!\njava.lang.reflect.UndeclaredThrowableException\n\tat com.sun.proxy.$Proxy16.login(Unknown Source)\n\tat javax.jcr.Repository$login.call(Unknown Source)\n\tat org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:45)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:108)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:116)\n\tat org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest.defaultConfigSpiAuth(JaasConfigSpiTest.groovy:78)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.jackrabbit.oak.run.osgi.OakOSGiRepositoryFactory$RepositoryProxy.invoke(OakOSGiRepositoryFactory.java:485)\n\t... 39 more\nCaused by: javax.jcr.LoginException: No LoginModules configured for jackrabbit.oak\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:288)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:244)\n\t... 44 more\nCaused by: javax.security.auth.login.LoginException: No LoginModules configured for jackrabbit.oak\n\tat javax.security.auth.login.LoginContext.init(LoginContext.java:272)\n\tat javax.security.auth.login.LoginContext.<init>(LoginContext.java:520)\n\tat org.apache.jackrabbit.oak.spi.security.authentication.JaasLoginContext.<init>(JaasLoginContext.java:49)\n\tat org.apache.jackrabbit.oak.security.authentication.LoginContextProviderImpl.getLoginContext(LoginContextProviderImpl.java:85)\n\tat org.apache.jackrabbit.oak.core.ContentRepositoryImpl.login(ContentRepositoryImpl.java:164)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:280)\n\t... 45 more\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "JaasConfigSpiTest fails intermittently with missing LoginModule exception"
   },
   {
      "_id": "12951120",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-03-17 08:30:01",
      "description": "with the improvements suggested in OAK-4119 we can simplify {{IdentifierManager.getReferences}} it is will only be used by {{Node.get(Weak)References}}, which doesn't need the whole bunch of flexibility provided by the method as it is today.\n\nthis might also be beneficial from a performance point of view as with the proposed changes the tree associated with a given result row is no longer resolved in case a property-name has been specified. also the nt-verification can be completely omitted, which afaik isn't perfectly cheap either.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Simplify IdentifierManager.getReferences"
   },
   {
      "_id": "12949107",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-11 14:45:34",
      "description": "{{SegmentNodeStore}} currently uses a semaphore to coordinate concurrent commits thus relying on the scheduling algorithm of that implementation and ultimately of the JVM for in what order commits are processed. \n\nI think it would be beneficial to replace that semaphore with an explicit queue of pending commit. This would allow us to implement a proper scheduler optimising for e.g. minimal system load, maximal throughput or minimal latency etc. A scheduler could e.g. give precedence to big commits and order commits along the order of its base revisions, which would decrease the amount of work to be done in rebasing. \n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "operations",
         "performance",
         "scalability",
         "throughput"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Replace the commit semaphore in the segment node store with a scheduler"
   },
   {
      "_id": "12949098",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-03-11 14:21:13",
      "description": "{{CompactionMap#get(RecordId before)}} searches through the compaction maps until it finds one containing {{before}} returning its value. However that one might already have been compacted again an be present as key in a later compaction map generation. \n\nA correct implementation of {{CompactionMap#get(RecordId before)}} should consider the transitive closure over all maps starting at {{before}}. Note however that in this case we would also need to stop removing keys from the compaction map after cleanup as this would break transitivity again. (See http://svn.apache.org/viewvc?view=revision&revision=1673791)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CompactionMap#get not transitive across compaction map generations"
   },
   {
      "_id": "12948663",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-03-10 05:31:47",
      "description": "Currently Oak Lucene support would copy index files to local file system as part of CopyOnRead feature. In one of the setup it has been observed that index logic was failing with following error\n\n{noformat}\n04.02.2016 17:47:52.391 *WARN* [oak-lucene-3] org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier [/oak:index/lucene] Found local copy for _2ala.cfs in MMapDirectory@/mnt/crx/author/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 lockFactory=NativeFSLockFactory@/mnt/crx/author/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 but size of local 9320 differs from remote 3714150. Content would be read from remote file only\n04.02.2016 17:47:52.399 *WARN* [oak-lucene-3] org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier [/oak:index/lucene] Found local copy for segments_28je in MMapDirectory@/mnt/crx/author/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 lockFactory=NativeFSLockFactory@/mnt/crx/author/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 but size of local 1214 differs from remote 1175. Content would be read from remote file only\n04.02.2016 17:47:52.491 *ERROR* [oak-lucene-3] org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker Failed to open Lucene index at /oak:index/lucene\norg.apache.lucene.index.CorruptIndexException: codec header mismatch: actual header=1953790076 vs expected header=1071082519 (resource: SlicedIndexInput(SlicedIndexInput(_2ala.fnm in _2ala.cfs) in _2ala.cfs slice=8810:9320))\n\tat org.apache.lucene.codecs.CodecUtil.checkHeader(CodecUtil.java:128)\n\tat org.apache.lucene.codecs.lucene46.Lucene46FieldInfosReader.read(Lucene46FieldInfosReader.java:56)\n\tat org.apache.lucene.index.SegmentReader.readFieldInfos(SegmentReader.java:215)\n{noformat}\n\nHere size of __2ala.cfs_ differed from remote copy and possible other index file may have same size but different content. Comparing the modified time of the files with those in Oak it can be seen that one of file system was older than one in Oak\n\n{noformat}\n\n_2alr.cfs={name=_2alr.cfs, size=1152402, sizeStr=1.2 MB, modified=Thu Feb 04 17:52:31 GMT 2016, osModified=Feb 4 17:52, osSize=1152402, mismatch=false}\n_2ala.cfe={name=_2ala.cfe, size=224, sizeStr=224 B, modified=Thu Feb 04 17:47:28 GMT 2016, osModified=Feb 4 17:17, osSize=224, mismatch=false}\n_2ala.si={name=_2ala.si, size=252, sizeStr=252 B, modified=Thu Feb 04 17:47:28 GMT 2016, osModified=Feb 4 17:17, osSize=252, mismatch=false}\n_2ala.cfs={name=_2ala.cfs, size=3714150, sizeStr=3.7 MB, modified=Thu Feb 04 17:47:28 GMT 2016, osModified=Feb 4 17:17, osSize=9320, mismatch=true}\n_14u3_29.del={name=_14u3_29.del, size=1244036, sizeStr=1.2 MB, modified=Thu Feb 04 16:37:35 GMT 2016, osModified=Feb 4 16:37, osSize=1244036, mismatch=false}\n_2akw.si={name=_2akw.si, size=252, sizeStr=252 B, modified=Thu Feb 04 16:37:07 GMT 2016, osModified=Feb 4 16:37, osSize=252, mismatch=false}\n_2akw.cfe={name=_2akw.cfe, size=224, sizeStr=224 B, modified=Thu Feb 04 16:37:07 GMT 2016, osModified=Feb 4 16:37, osSize=224, mismatch=false}\n_2akw.cfs={name=_2akw.cfs, size=4952761, sizeStr=5.0 MB, modified=Thu Feb 04 16:37:07 GMT 2016, osModified=Feb 4 16:37, osSize=4952761, mismatch=false}\n{noformat}\n\nAnd on same setup the system did saw a rollback in segment node store \n{noformat}\n\n-rw-rw-r--. 1 crx crx  25961984 Feb  4 16:47 data01357a.tar\n-rw-rw-r--. 1 crx crx  24385536 Feb  4 16:41 data01357a.tar.bak\n-rw-rw-r--. 1 crx crx    359936 Feb  4 17:18 data01358a.tar\n-rw-rw-r--. 1 crx crx    345088 Feb  4 17:17 data01358a.tar.bak\n-rw-rw-r--. 1 crx crx  70582272 Feb  4 18:35 data01359a.tar\n-rw-rw-r--. 1 crx crx  66359296 Feb  4 18:33 data01359a.tar.bak\n-rw-rw-r--. 1 crx crx    282112 Feb  4 18:46 data01360a.tar\n-rw-rw-r--. 1 crx crx    236544 Feb  4 18:45 data01360a.tar.bak\n-rw-rw-r--. 1 crx crx    138240 Feb  4 18:56 data01361a.tar\n{noformat}\n\nSo one possible cause is that \n# At some time earlier to 17:17 lucene index got updated and __2ala.cfs_ got created. \n# Post update the head revision in Segment store was updated but the revision yet to made it to journal log\n# Lucene CopyOnRead logic got event for the change and copied the file\n# System crashed and hence journal did not got updated\n# System restarted and per last entry in journal system suffered with some \"data loss\" and hence index checkpoint also moved back\n# As checkpoint got reverted index started at earlier state and hence created a file with same name __2ala.cfs_ \n# CopyOnRead detected file length change and logged a warning routing call to remote\n# However other files like _2ala.si, _2ala.cfe which were created in same commit had same size but likely different content which later cause lucene query to start failing\n\nIn such a case a restart after cleaning the existing index content would have brought back the system to normal state.\n\nSo as a fix we would need to come up with some sanity check at time of system startup",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Cached lucene index gets corrupted in case of unclean shutdown and journal rollback in SegmentNodeStore"
   },
   {
      "_id": "12948373",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-03-09 11:06:57",
      "description": "The {{MongoDocumentStore#query()}} method uses an expensive {{TreeLock#acquireExclusive}} method, introduced in OAK-1897 to avoid caching outdated documents.\n\nIt should be possible to avoid acquiring the exclusive lock, by tracking the cache changes that occurs during the Mongo find() operation. When the find() is done, we can update the cache with the received documents if they haven't been invalidated in the meantime.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Replace the query exclusive lock with a cache tracker"
   },
   {
      "_id": "12948139",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-08 19:49:35",
      "description": "The current implementation simply reports the difference between the repository size before cleanup to the size after cleanup. As cleanup runs concurrently to other commits, the size increase contributed by those is not accounted for. In the extreme case where cleanup cannot reclaim anything this can even result in negative values being reported. \n\nWe should either change the wording of the respective log message and speak of before and after sizes or adjust our calculation of reclaimed size (preferred). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Reclaimed size reported by FileStore.cleanup is off"
   },
   {
      "_id": "12948135",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-08 19:43:06",
      "description": "{{FileStore.size()}} is prone to lock contention and should not be called too often. As OAK-2879 already introduced an approach for tracking the current size of the file store without having to lock, we might as well promote his to be \"the official\" implementation. \n\n[~frm] WDYT?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Implement FileStore.size through FileStore.approximateSize"
   },
   {
      "_id": "12948120",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-08 19:14:51",
      "description": "Instead of writing the current head revision to the {{journal.log}} file we could make it an integral part of the node states: as OAK-3804 demonstrates we already have very good heuristics to reconstruct a lost journal. If we add the right annotations to the root node states this could replace the current approach. The latter is problematic as it relies on the flush thread properly and timely updating {{journal.log}}. See e.g. OAK-3303. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Replace journal.log with an in place journal"
   },
   {
      "_id": "12948112",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-08 19:03:23",
      "description": "{{SegmentTracker}} and {{FileStore}} are mutually dependent on each other. This is problematic and makes initialising instances of these classes difficult: the {{FileStore}} constructor e.g. passes a not fully initialised instance to the {{SegmentTracker}}, which in turn writes an initial node state to the store. Notably using the not fully initialised {{FileStore}} instance!",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Break cyclic dependency of FileStore and SegmentTracker"
   },
   {
      "_id": "12947985",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-03-08 12:09:13",
      "description": "While running on SegmentNodStore and online compaction enabled it can happen that access to Lucene index start failing with SegmentNotFoundException\n\n{noformat}\nCaused by: org.apache.jackrabbit.oak.plugins.segment.SegmentNotFoundException: Segment a949519a-8903-44f9-a17e-b6d83fb32186 not found\n       at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:870)\n       at org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.getSegment(SegmentTracker.java:136)\n       at org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:108)\n       at org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n       at org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.getNewStream(SegmentBlob.java:64)\n       at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexFile.loadBlob(OakDirectory.java:259)\n       at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexFile.readBytes(OakDirectory.java:307)\n       at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.readBytes(OakDirectory.java:404)\n       at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.readByte(OakDirectory.java:411)\n       at org.apache.lucene.store.DataInput.readVInt(DataInput.java:108)\n       at org.apache.lucene.codecs.BlockTreeTermsReader$FieldReader$SegmentTermsEnum$Frame.loadBlock(BlockTreeTermsReader.java:2397)\n       at org.apache.lucene.codecs.BlockTreeTermsReader$FieldReader$SegmentTermsEnum.seekCeil(BlockTreeTermsReader.java:1973)\n       at org.apache.lucene.index.FilteredTermsEnum.next(FilteredTermsEnum.java:225)\n       at org.apache.lucene.search.TermCollectingRewrite.collectTerms(TermCollectingRewrite.java:78)\n       at org.apache.lucene.search.ConstantScoreAutoRewrite.rewrite(ConstantScoreAutoRewrite.java:95)\n       at org.apache.lucene.search.MultiTermQuery$ConstantScoreAutoRewrite.rewrite(MultiTermQuery.java:220)\n       at org.apache.lucene.search.MultiTermQuery.rewrite(MultiTermQuery.java:288)\n       at org.apache.lucene.search.BooleanQuery.rewrite(BooleanQuery.java:418)\n       at org.apache.lucene.search.IndexSearcher.rewrite(IndexSearcher.java:636)\n       at org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:683)\n       at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:378)\n{noformat}\n\nThe above segmentId was mentioned in the compaction log\n\n{noformat}\n06.03.2016 02:03:30.706 *INFO* [TarMK flush thread [/app/repository/segmentstore], active since Sun Mar 06 02:03:29 GMT 2016, previous max duration 8218ms] org.apache.jackrabbit.oak.plugins.segment.file.TarReader-GC Cleaned segments from data00233a.tar:\n       37ec786e-a9f7-46eb-a3b5-ce5d4777ea01, f36051fe-d8c4-46d1-ac1d-081946389eb6, fae91ff2-8ca6-4ac1-a8d8-d4bd09b7f6a6, 16d87f09-721b-4155-a9c8-b8ecf471bfc3,\n       e641f1a3-b323-44e6-aad0-7b894a1efb69, edc9d141-6c05-42c9-a2a2-d7130fd9c826, b602372c-b17a-448a-a8e9-8bdccc64fb82, acc2f032-07ba-46ed-a9c7-d3a05ab53d7a,\n       a7323ed2-b2de-4006-ae51-e4f84165a0e4, cb320c70-5ca9-4ed1-a972-e87a6bba9f9b, f45afd7e-5417-42dd-a2f7-4624f74b6c6e, c66f66ef-cdd0-4327-abc6-bf910cb5768d,\n       7f925a07-ff56-4613-ac8f-272a0e481926, 4ad044ec-3b2d-4c3e-aeb0-d5f5a04bc23e, 82f1c3aa-2e0c-421c-a033-e4ffcb6002c7, 1387655b-f633-4011-a55c-d9580e40929b,\n       c50c94fc-2e8b-4904-a37f-0a33cc001312, 7915e9ce-bb9d-4628-ad6f-e7f2844b2399, e7cd013b-a147-426a-af29-fa025058a08a, f16d43b0-2113-4808-aea6-5910102e5c7d,\n...\n*31edad2e-e14b-463d-a6af-540bac6009f1*,\n...,\n*a949519a-8903-44f9-a17e-b6d83fb32186*,\n...\n{noformat}\n\n*Note that system recovered after a restart so the corruption was transient*\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Lucene index appear to be corrupted with compaction enabled"
   },
   {
      "_id": "12947896",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-03-08 03:45:39",
      "description": "Currently the journal log has entries like below. At times while debugging crash or some issue we need to determine the probable root state at some point in the past. \n\n{noformat}\n3dea11bb-bd43-4319-a37d-59df778a7271:260988 root\na7a509ac-a9d4-4e2c-a0d8-df71ebe123a0:259736 root\n1d889da9-b41c-4889-a0cd-a9aa9dcc1737:259992 root\nb78e4aa6-ec68-4e70-a364-f04ccbf4c3b3:259964 root\n{noformat}\n\nCurrently there is no way to determine from above log what is the root state wrt time. So we need to workaround that by reading each root state and look for some path which has some time related property. To simplify such case it would be helpful to also include timestamp while adding a journal entry\n\n{noformat}\n1d889da9-b41c-4889-a0cd-a9aa9dcc1737:259992 root 1457408708772\nb78e4aa6-ec68-4e70-a364-f04ccbf4c3b3:259964 root 1457408708899\n{noformat}\n\n*Key points*\n# Timestamp comes at end\n# Such a feature can be enabled without affecting backward compatibility - Just that new entries would have timestamp included\n# {{JournalReader}} - Just reads the first column so would work as is",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Include timestamp in journal log entries"
   },
   {
      "_id": "12946622",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2016-03-03 17:37:00",
      "description": "the {{DefaultSyncConfig}} comes with a configuration option {{PARAM_USER_AUTO_MEMBERSHIP}} indicating the set of groups a given external user must always become member of upon sync into the repository.\n\nthis results in groups containing almost all users in the system (at least those synchronized form the external IDP). while this behavior is straight forward (and corresponds to the behavior in the previous crx version), it wouldn't be necessary from a repository point of view as a given {{Subject}} can be populated from different principal sources and dealing with this kind of dynamic-auto-membership was a typical use-case.\n\nwhat does that mean:\ninstead of performing the automembership on the user management, the external authentication setup could come with an auto-membership {{PrincipalProvider}} implementation that would expose the desired group membership for all external principals (assuming that they were identified as such).\n\n[~tripod], do you remember if that was ever an option while building the {{oak-auth-external}} module? if not, could that be worth a second thought also in the light of OAK-3933?\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Replace Sync of configured AutoMembership by Dynamic Principal Generation"
   },
   {
      "_id": "12944830",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-02-26 09:17:05",
      "description": "Mongo 3.2 introduces new query option: {{readConcern}}. It allows to read only these changes that have been already committed to the majority of secondary instances.\n\nIt prevents stale reads - a situation in which a change has been committed on the primary (and read from it), but due to the network partition a new primary is elected and the change is rolled back.\n\nWe should use this new option (together with {{w:majority}} implemented in OAK-3554) when running Oak on MongoDB replica set.\n\nReferences:\n* [Jepsen: MongoDB stale reads|https://aphyr.com/posts/322-jepsen-mongodb-stale-reads]\n* [MongoDB documentation: Read Concern in|https://docs.mongodb.org/manual/reference/read-concern/]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use read concern majority when connected to a replica set"
   },
   {
      "_id": "12944433",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-02-25 09:26:21",
      "description": "Pre Extraction support was implemented with an assumption that such big indexing would happen as part of reindex so it was used in reindex phase only. Reason to avoid using it in incremental indexing (non reindex case) were\n# Incremental index would does not have text for newly added files. So checking with pre extracted cache would not be useful\n# PreExtraction logic keeps in memory state (blobs_empty.txt,blobs_error.txt) which would then unnecessary hog memory.\n\nHowever in some cases people make use of new incremental migration feature in upgrade. Which would lead to one big incremental indexing step once next migration is done and that would then not able to make use of pre extraction support.\n\nSo as a fix we should provide a policy option to ignore the reindex clause per admin setting",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Allow use of pre extrcated text cache for incremental indexing"
   },
   {
      "_id": "12943081",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-02-24 20:52:14",
      "description": "{{FileStore.containsSegment()}} looks [funky|https://github.com/mduerig/jackrabbit-oak/blob/36cb3bf6e5078e3afa75581fb789eeca7b5df2e2/oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/file/FileStore.java#L1197-L1197]. This \"optimisation\" causes it to always return {{true}}. \n\n{{containsSegment}} is used for deduplication and revision gc. The current implementation causes {{SNFE}} exceptions once gc is effective (as I experienced while working on OAK-3348). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "stability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "FileStore.containsSegment returns alway true (almost)"
   },
   {
      "_id": "12941554",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-23 21:53:59",
      "description": "{code}\nException in thread \"main\" java.lang.NumberFormatException: null\n\tat java.lang.Long.parseLong(Long.java:404)\n\tat java.lang.Long.valueOf(Long.java:540)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentGraph.asLong(SegmentGraph.java:494)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentGraph.writeNode(SegmentGraph.java:464)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentGraph.writeSegmentGraph(SegmentGraph.java:173)\n\tat org.apache.jackrabbit.oak.run.GraphCommand.execute(GraphCommand.java:92)\n\tat org.apache.jackrabbit.oak.run.Mode.execute(Mode.java:63)\n{code}\n\nThe cause for this is not properly checking the info map before deciding whether to print a bulk or a data node. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NPE in oak-run graph when repository contains bulk segments"
   },
   {
      "_id": "12941553",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-23 21:48:57",
      "description": "Running oak-run from within the IDE causes a {{NPE}}:\n\n{code}\nException in thread \"main\" java.lang.NullPointerException\n\tat java.util.Properties$LineReader.readLine(Properties.java:434)\n\tat java.util.Properties.load0(Properties.java:353)\n\tat java.util.Properties.load(Properties.java:341)\n\tat org.apache.jackrabbit.oak.run.Main.getProductVersion(Main.java:76)\n\tat org.apache.jackrabbit.oak.run.Main.getProductVersion(Main.java:66)\n\tat org.apache.jackrabbit.oak.run.Main.getProductInfo(Main.java:53)\n\tat org.apache.jackrabbit.oak.run.Main.printProductInfo(Main.java:86)\n{code}\n\nThis is caused by not checking the return value of {{getResourceAsStream}} for {{null}} when trying to load {{/META-INF/maven/org.apache.jackrabbit/oak-run/pom.properties}}. That file is not on the class path when running from within the IDE. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NPE when running oak-run from within the IDE"
   },
   {
      "_id": "12941339",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-02-23 09:31:16",
      "description": "Classes {{org.apache.jackrabbit.oak.plugins.segment.compaction.CompactionStrategy}} and {{org.apache.jackrabbit.oak.plugins.segment.compaction.CompactionStrategyMBean}} should be exported. The former is used in the public API of multiple classes from {{org.apache.jackrabbit.oak.plugins.segment.file}} and {{org.apache.jackrabbit.oak.plugins.segment}}, while the latter is used as interface type for a service registered in the whiteboard.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Some classes from o.a.j.o.plugins.segment.compaction should be exported"
   },
   {
      "_id": "12940564",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-02-19 17:13:43",
      "description": "The DocumentNodeStore currently requires that the local time and the persistence time differ at most 2 seconds.\n\nI recently tried to run a cluster with two Windows machines, and despite them being configured to use the same NTP service, they were still 4..5 s off.\n\nhttps://blogs.technet.microsoft.com/askds/2007/10/23/high-accuracy-w32time-requirements/ seems to confirm that by default, Windows can't provide the required accuracy.\n\nOne workaround seems to be to install custom ntp clients; but do we really want to require this?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore: required server time accuracy"
   },
   {
      "_id": "12938830",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-02-12 15:42:17",
      "description": "Concurrent commits during compaction cause those to be re-compacted. Currently it seems that the compaction thread can end up waiting for some time to acquire the commit lock [1], which in turn causes more commits to pile up to be re-compacted. I think this could be improved by tweaking the lock such that the compactor could jump ahead of the queue. I.e. use a lock which can be acquired in expedited mode. \n\n[1] SegmentNodeStore#commitSemaphore",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expedite commits from the compactor"
   },
   {
      "_id": "12938753",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-02-12 09:28:21",
      "description": "As online compaction is still not at the point where we would like it to have we will need to disable it by default for the upcoming major release. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Set online compaction default to paused"
   },
   {
      "_id": "12936960",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-05 06:36:28",
      "description": "Text pre extraction feature introduced in OAK-2892 only supports FileDataStore. For files present in S3 we should add support for S3DataStore",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add S3 datastore support for Text Pre Extraction"
   },
   {
      "_id": "12936605",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2016-02-04 04:36:14",
      "description": "As per discussion on the issue OAK-3935 [1] & [2] we could use sling to get a repository ID injected obviating the need for a Osgi config param override in case of a cloned instance.\n\n[1] - https://issues.apache.org/jira/browse/OAK-3935?focusedCommentId=15122957&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15122957\n[2] - https://issues.apache.org/jira/browse/OAK-3935?focusedCommentId=15126096&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15126096",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SharedDataStore - Set the unique repository ID using sling if configured"
   },
   {
      "_id": "12936387",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-03 16:45:09",
      "description": "The segment graph produced by {{oak-run graph}} should also contain the sizes of the segments. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add segment size to segment graph"
   },
   {
      "_id": "12936278",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-03 08:28:56",
      "description": "The graph produced by {{oak-run graph}} does not include forward edges (i.e. references from older segments to newer segments). Such references where introduced with  OAK-1828. See also OAK-3864, where this has been fixed for the file store cleanup.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc",
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Forward edges missing in SegmentGraph "
   },
   {
      "_id": "12935394",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-01-30 23:24:40",
      "description": "With index def of the form:\n{noformat}\n+/indexName/indexRules/nodeType1/properties/prop0\n     -name=subChild/indexedProp\n     -nodeScopeIndex=true\n     -boost=2.0\n+indexName/aggregates/nodeType1/include0\n     -path=subChild\n     -relativeNode=true\n{noformat}\n\nA query like {{//element(*, nodeType1)\\[jcr:contains(subChild, 'bar')]}} should rank nodes with {{subChild/\\@indexedProp=bar}} above other nodes with any prop {{=bar}} under subChild.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "lucene"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Boosted field don't work if parent nodes are covered in aggregate definition"
   },
   {
      "_id": "12935039",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2016-01-29 07:47:22",
      "description": "The code in oak-blob-cloud should sync with the following minor updates to jackrabbit-aws-ext.\n* JCR-3864\n* JCR-3867\n* JCR-3886\n* JCR-3889\n* JCR-3914",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "[oak-blob-cloud] Update oak-blob-cloud with jackrabbit-aws-ext updates"
   },
   {
      "_id": "12934692",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-28 05:39:38",
      "description": "Add an option in oak-run to dump blob references currently used. This should help in analyzing GC issues.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "[oak-run] Option to dump blob references "
   },
   {
      "_id": "12934691",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-28 05:33:15",
      "description": "For GC in a shared DataStore, a unique repository Id is currently saved in a hidden path in the node store on startup and registered in the DataStore.\nThis will cause problems where the publish environments are cloned and share a datastore.\n\nThere should be an option to specify a unique id in the config when setting up the node store.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SharedDataStore - Allow unique repository ID to be specified by config "
   },
   {
      "_id": "12934509",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-27 16:28:26",
      "description": "When {{CompactionStrategy.CleanupType#CLEAN_OLD}} releases a segment for gc because of its age it should log a message. This helps to determine the root cause of a {{SNFE}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Log ids of segments being released for gc because of their age. "
   },
   {
      "_id": "12934109",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-26 13:36:03",
      "description": "The primary and standby run modes should exit with an error if run on a store with non matching segment version.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "oak-run primary/standby should check segment version"
   },
   {
      "_id": "12934107",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-26 13:33:00",
      "description": "The checkpoint runmode should exit with an error if run on a store with non matching segment version.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run checkpoint should check segment version"
   },
   {
      "_id": "12934106",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-26 13:30:58",
      "description": "Backup/restore should exit with an error if run on a store with non matching segment version. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run backup/recover should check segment version"
   },
   {
      "_id": "12933790",
      "assignee": "amitjain",
      "components": [],
      "created": "2016-01-25 12:10:33",
      "description": "Currently, DataStoreBlobStore#resolveChunks resolves all blob ids including in-lined blobs. This is different from the AbstractBlobStore#resolveChunks which removes in-lined blobs.\nDue to this the InMemoryDataRecord had to be made public for OAK-3184 which it should not have. A proper solution would be to have the resolveChunks only return blobs stored in blob/data store. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DataStoreBlobStore - Limit resolveChunks only to non inlined blobs"
   },
   {
      "_id": "12933027",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-21 09:25:47",
      "description": "In the case of offline compaction, the Compactor predicate would try to evaluate if a specific node is candidate for the map of not based on a set of conditions.\nTo evaluate said conditions, the predicate currently uses the compacted state, the one that was just written by the SegmentWriter [0], but this offers very poor performance as this NodeState will be accessed from the TarWriter directly, a very IO intensive call (no memory mapping, no caching of the segment) [1].\nA much better thing is to use the cached nodestate, in my local test (on a SSD) this accounts for 10% of perf loss, I would imagine the gains are more significant on a non-SSD disk.\n\n\n\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/Compactor.java#L252\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/file/TarWriter.java#L190",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction Map predicate should use cached state for evaluation"
   },
   {
      "_id": "12933019",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-01-21 08:54:42",
      "description": "In some rare cases it may happen that the DocumentNodeStore considers a commit as failed even though the changes were applied entirely to the DocumentStore. The issue happens when the update of the commit root is applied to the storage of a DocumentStore but then shortly after the communication between Oak the the storage system fails. On the Oak side the call will be considered as failed, but the change was actually applied.\n\nThe issue can be reproduced with the test attached to OAK-1641 and a replica-set with 3 nodes. Killing the primary node and restarting it a after a while in a loop will eventually lead to a commit that conflicts itself.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Commit fails even though change made it to the DocumentStore"
   },
   {
      "_id": "12932451",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-19 15:35:37",
      "description": "I like to add a filter capability to {{oak-run graph}} to specify the inclusion criteria of segments via a regular expression.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add filter capabilities to the segment graph run mode"
   },
   {
      "_id": "12932156",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-01-18 13:41:32",
      "description": "The SegmentWriter keeps a records deduplication cache ('records' map) that maintains 2 types of mappings:\n* template -> recordid\n* strings -> recordid\n\nFor the first one (template-> recordid) we can come up with a thinner representation of a template (a hash function that is fast and not very collision prone) so we don't have to keep a reference to each template object.\n\nSame applies for second one, similar to what is happening in the StringsCache now, we could keep the string value up to a certain size and beyond that, hash it and use that for the deduplication map.\n\n\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentWriter records cache could use thinner keys"
   },
   {
      "_id": "12932118",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-18 10:45:13",
      "description": "{{FileStoreIT.testRecovery}} currently hard codes expected segment offsets. I would like to refactor this to make it more robust against changes in how exactly records are stored / de-duplicated. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Robuster test expectations for FileStoreIT"
   },
   {
      "_id": "12932101",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-01-18 09:09:11",
      "description": "The test failed rather frequently on Apache Jenkins as well as travis-ci.\n\nThe failure is:\n\n{noformat}\nbroadcastTCP(org.apache.jackrabbit.oak.plugins.document.persistentCache.BroadcastTest): min: 90 got: 80\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failure: BroadcastTest"
   },
   {
      "_id": "12930181",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-01-14 16:16:46",
      "description": "Following up [discussion|http://markmail.org/message/m5jk5nbby77nlqs5] \\[0] to avoid bad commits due to misbehaving clocks. Points from the discussion:\n* We can start self-destruct mode while updating lease\n* Revision creation should check that newly created revision isn't beyond leaseEnd time\n* Implementation done for OAK-2682 might be useful\n\n[0]: http://markmail.org/message/m5jk5nbby77nlqs5",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid commit from too far in the future (due to clock skews) to go through"
   },
   {
      "_id": "12930165",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-01-14 15:14:50",
      "description": "In some rare cases it may happen that a collision marks the wrong commit. OAK-3344 introduced a conditional update of the commit root with a collision marker. However, this may fail when the commit revision of the condition is moved to a split document at the same time.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Collision may mark the wrong commit"
   },
   {
      "_id": "12930078",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-01-14 08:43:32",
      "description": "When using a Lucene fulltext index with compatVersion 2, then the following query does not return any results. When using compatVersion 1, the correct result is returned.\n\n{noformat}\nSELECT * FROM [nt:unstructured] AS c \nWHERE CONTAINS(c.[jcr:description], 'abc!') \nAND ISDESCENDANTNODE(c, '/content')\n{noformat}\n\nWith compatVersion 1 and 2, searching for just 'abc' works. Also, searching with '=' instead of 'contains' works.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Lucene index / compatVersion 2: search for 'abc!' does not work"
   },
   {
      "_id": "12929747",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-13 09:07:53",
      "description": "That argument is unused and I'll remove it thus. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Don't pass the compaction map to FileStore.cleanup"
   },
   {
      "_id": "12929505",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-01-12 14:54:19",
      "description": "I think it would be cleaner if {{RecordId.write}} would always return a {{RecordId}} instead of depending on its type parametrisation and would like to refactor it to that respect.. \n\nThis is also a pre-requisite for my work on OAK-3348 and might also be for OAK-3864. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor RecordWriter.write to always return a RecordId"
   },
   {
      "_id": "12929502",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-12 14:41:06",
      "description": "I think it makes sense to move said method. This simplifies the code in various places as it somewhat decouples the concern \"writing segments\" from an implementation ({{FileStore}}). \n\nAlso this is somewhat a prerequisite for my current work on OAK-3348.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move createSegmentWriter() from FileStore to SegmentTracker"
   },
   {
      "_id": "12929498",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-01-12 14:07:24",
      "description": "*Introduction*\n\nIn the current trunk we'll only read document _D_ from the secondary instance if:\n(1) we have the parent _P_ of document _D_ cached and\n(2) the parent hasn't been modified in 6 hours.\n\nThe OAK-2106 tried to optimise (2) by estimating lag using MongoDB replica stats. It was unreliable, so the second approach was to read the last revisions directly from each Mongo instance. If the modification date of _P_ is before last revisions on all secondary Mongos, then secondary can be used.\n\nThe main problem with this approach is that we still need to have the _P_ to be in cache. I think we need another way to optimise the secondary reading, as right now only about 3% of requests connects to the secondary, which is bad especially for the global-clustering case (Mongo and Oak instances across the globe). The optimisation provided in OAK-2106 doesn't make the things much better and may introduce some consistency issues.\n\n*Proposal - tldr version*\n\nOak will remember the last revision it has ever seen. In the same time, it'll query each secondary Mongo instance, asking what's the available stored root revision. If all secondary instances have a root revision >= last revision seen by a given Oak instance, it's safe to use the secondary read preference.\n\n*Proposal*\n\nI had following constraints in mind preparing this:\n1. Let's assume we have a sequence of commits with revisions _R1_, _R2_ and _R3_ modifying nodes _N1_, _N2_ and _N3_. If we already read the _N1_ from revision _R2_ then reading from a secondary shouldn't result in getting older revision (eg. _R1_).\n2. If an Oak instance modifies a document, then reading from a secondary shouldn't result in getting the old version (before modification).\n\nSo, let's have two maps:\n* _M1_ the most recent document revision read from the Mongo for each cluster id,\n* _M2_ the oldest last rev value for root document for each cluster id read from all the secondary instances.\n\nMaintaining _M1_:\nFor every read from the Mongo we'll check if the lastRev for some cluster id is newer than _M1_ entry. If so, we'll update _M1_. For all writes we'll add the saved revision id with the current cluster id in _M1_.\n\nMaintaining _M2_:\nIt should be periodically updated. Such mechanism is already prepared in the OAK-2106 patch.\n\nThe method deciding whether we can read from the secondary instance should compare two maps. If all entries in _M2_ are newer than _M1_ it means that the secondary instances contains at least as new repository state as we already accessed and therefore it's safe to read from secondary.\n\nRegarding the documents modified by the local Oak instance, we should remember all the locally-modified paths and their revisions and use primary Mongo to access them as long as the changes are not replicated to all the secondaries. When the secondaries are up to date with the modification, we can remove it from the local-changes collections.\n\nAttached image diagram.png presents the idea.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "New strategy to optimize secondary reads"
   },
   {
      "_id": "12929459",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-12 11:05:42",
      "description": "In some situations {{FileStore.cleanup()}} may remove segments that are still referenced, subsequently causing a {{SNFE}}. \n\nThis is a regression introduced with OAK-1828. \n\n{{FileStore.cleanup()}} relies on the ordering of the segments in the tar files: later segments only reference earlier segments. As we have seen in other places this assumption does not hold any more (e.g. OAK-3794, OAK-3793) since OAK-1828.\n {{cleanup}} traverses the segments backwards maintaining a list of referenced ids. When a segment is not in that list, it is removed. However, this approach does not work with forward references as those are only seen later when the segment has been removed already. \n\ncc [~alex.parvulescu], [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "regression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Filestore cleanup removes referenced segments"
   },
   {
      "_id": "12929232",
      "assignee": "frm",
      "components": [],
      "created": "2016-01-11 17:08:56",
      "description": "While moving the Segment Store and related packages into its own bundle, I figured out that integration tests contained in {{oak-core}} contribute to a cyclic dependency between the (new) {{oak-segment}} bundle and {{oak-core}}.\n\nThe dependency is due to the usage of {{NodeStoreFixture}} to instantiate different implementations of {{NodeStore}} in a semi-transparent way.\n\nTests depending on {{NodeStoreFixture}} are most likely integration tests. A clean solution to this problem would be to move those integration tests into a new Maven module, referencing the API and implementation modules as needed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move integration tests in a different Maven module"
   },
   {
      "_id": "12929149",
      "assignee": "mreutegg",
      "components": [],
      "created": "2016-01-11 10:50:47",
      "description": "Some of the tests executed during a normal {{mvn clean test}} execution seem to be very slow if compared with the rest of the suite. On my machine, some problematic tests are:\n\n{noformat}\nRunning org.apache.jackrabbit.oak.spi.blob.FileBlobStoreTest\nTests run: 18, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 10.982 sec\nRunning org.apache.jackrabbit.oak.plugins.document.BasicDocumentStoreTest\nTests run: 50, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.961 sec\nRunning org.apache.jackrabbit.oak.plugins.document.BulkCreateOrUpdateTest\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.076 sec\nRunning org.apache.jackrabbit.oak.plugins.document.ConcurrentDocumentStoreTest\nTests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.054 sec\nRunning org.apache.jackrabbit.oak.plugins.document.DocumentDiscoveryLiteServiceTest\nTests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 982.526 sec\nRunning org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreTest\nTests run: 53, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.132 sec\nRunning org.apache.jackrabbit.oak.plugins.document.LastRevRecoveryAgentTest\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.068 sec\nRunning org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStorePerformanceTest\nTests run: 10, Failures: 0, Errors: 0, Skipped: 10, Time elapsed: 10.006 sec\nRunning org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStoreTest\nTests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.017 sec\nRunning org.apache.jackrabbit.oak.plugins.document.VersionGCWithSplitTest\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.128 sec\nRunning org.apache.jackrabbit.oak.security.authentication.ldap.LdapLoginStandaloneTest\nTests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.96 sec\n{noformat}\n\nThese tests should be analyzed for potential errors or moved to the integration test phase.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Review slow running tests"
   },
   {
      "_id": "12928734",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-08 21:02:51",
      "description": "{{SegmentGraphTest}} has a somewhat complicated setup phase to build a segment store of a certain structure. This is will probably prove unreliable when underlying implementation details of how segments are written change (e.g. with OAK-3348). I would like to refactor the test such that it becomes independent of such implementation details. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Simplify SegmentGraphTest"
   },
   {
      "_id": "12928689",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-08 17:06:48",
      "description": "Off line compaction should exit with a warning if run on a store with non matching segment version. It should provide a {{--force}} option to override this behaviour such that it can still be used for explicit upgrading. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "gc",
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "oak-run compact should check segment version"
   },
   {
      "_id": "12928688",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-08 17:02:40",
      "description": "Running tools that write into a segment store might result in unwanted upgrading if the version of the tool uses a more recent segment version than the store. E.g. off line compaction currently upgrades segment format 10 to 11. \n\nTo protected against inadvertent upgrades, a tool should check whether the segment version of the store matches its expectation (currently 11). If not, the tool should exit with a respective warning / error. For some tools it can make sense to provide a flag (e.g. {{--force}}) to override this. With this e.g. offline compaction can still be used for upgrading a segment store if explicitly told to do so. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "TarMK tools should check whether they run against a matching version of the repository"
   },
   {
      "_id": "12928653",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-08 14:38:28",
      "description": "Currently {{SegmentGraph}} just bails out upon hitting a {{SNFE}}. I would like to improve this and include the error in the generated graph. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve SegmentGraph resilience "
   },
   {
      "_id": "12928039",
      "assignee": "mduerig",
      "components": [],
      "created": "2016-01-06 15:31:32",
      "description": "We need to adjust the package export declarations such that they become manageable with our branch / release model. \n\nSee http://markmail.org/thread/5g3viq5pwtdryapr for discussion.\n\nI propose to remove package export declarations from all packages that we don't consider public API / SPI beyond Oak itself. This would allow us to evolve Oak internal stuff (e.g. things used across Oak modules) freely without having to worry about merges to branches messing up semantic versioning. OTOH it would force us to keep externally facing public API / SPI reasonably stable also across the branches. Furthermore such an approach would send the right signal to Oak API / SPI consumers regarding the stability assumptions they can make. \n\nAn external API / SPI having a (transitive) dependency on internals might be troublesome. In doubt I would remove the export version here until we can make reasonable guarantees (either through decoupling the code or stabilising the dependencies). \n\nI would start digging through the export version and prepare an initial proposal for further discussion. \n\n/cc [~frm], [~chetanm], [~mmarth]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "api",
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Adjust package export declarations "
   },
   {
      "_id": "12927995",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-06 11:08:47",
      "description": "The {{FileStore}} constructor consists of more than 150 LoC and is a mess as it depends on the order of initialisation, calls overrideable methods handles different concerns (read only vs. read / write) etc. \n\nWe should up with a cleaner way of instantiating a file store.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clean up the FileStore constructor"
   },
   {
      "_id": "12924230",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-12-24 22:25:16",
      "description": "One node was not in Solr after searching for it...\n\nAfter looking into logs have found following:\n\nERROR - 2015-12-21 17:05:29.598; org.apache.solr.common.SolrException; null:org.apache.solr.common.SolrException: Exception writing document id /content/dam/my/example.pdf/jcr:content/metadata/wn_previews:previews/wn_previews:spreads/1 to the index; possible analysis error.\n    at org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:168)\n    at org.apache.solr.update.processor.RunUpdateProcessor.processAdd(RunUpdateProcessorFactory.java:69)\n    at org.apache.solr.update.processor.UpdateRequestProcessor.processAdd(UpdateRequestProcessor.java:51)\n    at org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalAdd(DistributedUpdateProcessor.java:870)\n    at org.apache.solr.update.processor.DistributedUpdateProcessor.versionAdd(DistributedUpdateProcessor.java:1024)\n    at org.apache.solr.update.processor.DistributedUpdateProcessor.processAdd(DistributedUpdateProcessor.java:693)\n    at org.apache.solr.update.processor.LogUpdateProcessor.processAdd(LogUpdateProcessorFactory.java:100)\n    at org.apache.solr.handler.loader.JavabinLoader$1.update(JavabinLoader.java:96)\n    at org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readOuterMostDocIterator(JavaBinUpdateRequestCodec.java:166)\n    at org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readIterator(JavaBinUpdateRequestCodec.java:136)\n    at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:225)\n    at org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readNamedList(JavaBinUpdateRequestCodec.java:121)\n    at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:190)\n    at org.apache.solr.common.util.JavaBinCodec.unmarshal(JavaBinCodec.java:116)\n    at org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec.unmarshal(JavaBinUpdateRequestCodec.java:173)\n    at org.apache.solr.handler.loader.JavabinLoader.parseAndLoadDocs(JavabinLoader.java:106)\n    at org.apache.solr.handler.loader.JavabinLoader.load(JavabinLoader.java:58)\n    at org.apache.solr.handler.UpdateRequestHandler$1.load(UpdateRequestHandler.java:92)\n    at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:74)\n    at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n    at org.apache.solr.core.SolrCore.execute(SolrCore.java:1962)\n    at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:777)\n    at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:418)\n    at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:207)\n    at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)\n    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455)\n    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n    at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)\n    at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)\n    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075)\n    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384)\n    at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009)\n    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n    at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:255)\n    at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154)\n    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n    at org.eclipse.jetty.server.Server.handle(Server.java:368)\n    at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489)\n    at org.eclipse.jetty.server.BlockingHttpConnection.handleRequest(BlockingHttpConnection.java:53)\n    at org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:953)\n    at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1014)\n    at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:953)\n    at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n    at org.eclipse.jetty.server.BlockingHttpConnection.handle(BlockingHttpConnection.java:72)\n    at org.eclipse.jetty.server.bio.SocketConnector$ConnectorEndPoint.run(SocketConnector.java:264)\n    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n    at java.lang.Thread.run(Unknown Source)\nCaused by: java.lang.IllegalArgumentException: Document contains at least one immense term in field=\"wn_previews:base64_data\" (whose UTF8 encoding is longer than the max length 32766), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '[121, 113, 55, 102, 120, 121, 113, 55, 102, 120, 121, 113, 55, 102, 120, 121, 113, 55, 102, 120, 121, 113, 55, 102, 120, 121, 113, 55, 102, 120]...', original message: bytes can be at most 32766 in length; got 64627\n    at org.apache.lucene.index.DefaultIndexingChain$PerField.invert(DefaultIndexingChain.java:671)\n    at org.apache.lucene.index.DefaultIndexingChain.processField(DefaultIndexingChain.java:342)\n    at org.apache.lucene.index.DefaultIndexingChain.processDocument(DefaultIndexingChain.java:301)\n    at org.apache.lucene.index.DocumentsWriterPerThread.updateDocument(DocumentsWriterPerThread.java:241)\n    at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:451)\n    at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1539)\n    at org.apache.solr.update.DirectUpdateHandler2.addDoc0(DirectUpdateHandler2.java:240)\n    at org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:164)\n    ... 48 more\nCaused by: org.apache.lucene.util.BytesRefHash$MaxBytesLengthExceededException: bytes can be at most 32766 in length; got 64627\n    at org.apache.lucene.util.BytesRefHash.add(BytesRefHash.java:284)\n    at org.apache.lucene.index.TermsHashPerField.add(TermsHashPerField.java:151)\n    at org.apache.lucene.index.DefaultIndexingChain$PerField.invert(DefaultIndexingChain.java:645)\n    ... 55 more\n\nThis can be seen in the default solr.log file\n\nAs a result of this exception data transfer to solr is blocked and I have to manually fix the affected data by removing that node",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TarMK JCR data -> Solr == Exception"
   },
   {
      "_id": "12923060",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-18 16:28:37",
      "description": "I think we should disable compaction estimation when compaction is paused. Estimation interferes with the caches, wastes CPU and IO cycles and is not essential for Oak's operation when compaction is disabled. The only reason it was unconditionally enabled initially is to gather the respective information in production. I think this has turned out to be not too useful so it is safe to disable. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Disable compaction gain estimation if compaction is paused"
   },
   {
      "_id": "12923058",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-18 16:23:57",
      "description": "The {{check}} run mode currently has no option to be run with an external data store. We should probably add such an option. Or/and ensure the check works probably for a segment store with external binaries even if no data store is present.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide option to pass external data store to oak-run check"
   },
   {
      "_id": "12922985",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-12-18 09:44:55",
      "description": "{{org.apache.jackrabbit.oak.jcr.query.FacetTest}} keeps failing on Jenkins:\n\n{noformat}\ntestFacetRetrievalMV(org.apache.jackrabbit.oak.jcr.query.FacetTest)  Time elapsed: 5.927 sec  <<< FAILURE!\njunit.framework.ComparisonFailure: expected:<tags:[[repository (2), software (2), aem (1), apache (1), cosmetics (1), furniture (1)], tags:[repository (2), software (2), aem (1), apache (1), cosmetics (1), furniture (1)], tags:[repository (2), software (2), aem (1), apache (1), cosmetics (1), furniture (1)], tags:[repository (2), software (2), aem (1), apache (1), cosmetics (1), furniture (1)]]> but was:<tags:[[], tags:[], tags:[], tags:[]]>\n\tat junit.framework.Assert.assertEquals(Assert.java:100)\n\tat junit.framework.Assert.assertEquals(Assert.java:107)\n\tat junit.framework.TestCase.assertEquals(TestCase.java:269)\n\tat org.apache.jackrabbit.oak.jcr.query.FacetTest.testFacetRetrievalMV(FacetTest.java:80)\n{noformat}\n\nFailure seen at builds: 628, 629, 630, 633, 634, 636, 642, 643, 644, 645, 648, 651, 656, 659, 660, 663, 666\n\nSee e.g. https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/634/#showFailuresLink",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins",
         "test",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: FacetTest"
   },
   {
      "_id": "12922638",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-12-17 09:12:51",
      "description": "oak-core and oak-jcr modules uses the fixture mechanism to provide NodeStore implementations to the unit/integration tests. There is a few problems with the fixture implementation:\n\n* the {{NodeStoreFixture}} class is duplicated between two modules and supports different set of options (eg. the oak-core version doesn't support the RDB node store at all, while the oak-jcr doesn't support MemoryNodeStore)\n* it isn't possible to set the MongoDB URL manually from the Maven command line (it can be done for the RDB, though), which makes running the tests on a Mongo replica hard,\n* the Mongo fixture doesn't remove the test database after the test is done.\n\nThere should be just one NodeStoreFixture implementation (the oak-jcr can reuse the oak-core version), supporting all values of the {{Fixture}} enum. The Mongo fixture should be more customisable and also should clean-up the database.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "tech-debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clean up the fixtures code in core and jcr modules"
   },
   {
      "_id": "12922590",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-12-17 04:29:15",
      "description": "Due to changes done in OAK-3477 SessionMBean is not getting registered as it contains ',' in the ObjectName. Unfortunately the exception thrown gets lost and this did not got detected so far\n\n{noformat}\njavax.management.MalformedObjectNameException: Invalid character in value: `,'\n\tat javax.management.ObjectName.checkValue(ObjectName.java:1009)\n\tat javax.management.ObjectName.construct(ObjectName.java:725)\n\tat javax.management.ObjectName.<init>(ObjectName.java:1425)\n\tat org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils.registerMBean(WhiteboardUtils.java:79)\n\tat org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils.registerMBean(WhiteboardUtils.java:68)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl$RegistrationTask.run(RepositoryImpl.java:523)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n{noformat}\n\nThe name passed for ObjectName is \n{code}\n{name=admin@session-11@Dec 17, 2015 9:57:11 AM, type=SessionStatistics}\n{code}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "regresion"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SessionMBean not getting registered due to MalformedObjectNameException"
   },
   {
      "_id": "12922345",
      "assignee": "mduerig",
      "components": [],
      "created": "2015-12-16 11:19:24",
      "description": "The Oak checkout contains a module {{oak-js}}, which is mostly empty apart from a TODO statement. As we didn't work on this and AFAIK do not intend to work on this in the near future, I propose to drop the module for now. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Drop module oak-js"
   },
   {
      "_id": "12922309",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-16 09:32:04",
      "description": "{{SegmentTracker#collectBlobReferences}} currently keeps a queue of yet unprocessed {{SegmentId}} instances internally. This potentially impacts the system as those instances are also tracked in the segment tracker's segment id tables. I think we should improve the implementation to not retain so many {{SegmentId}} instances and rely on arrays of {{msb}}, {{lsb}} instead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "datastore",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentTracker#collectBlobReferences should retain fewer SegmentId instances"
   },
   {
      "_id": "12921095",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-11 16:29:57",
      "description": "While OAK-3560 allows us to detect reference to pre compacted segments through manual inspection, we also need tooling to help detect such cases on site, during longevity tests and for UT/IT.  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Tool for detecting references to pre compacted segments"
   },
   {
      "_id": "12920482",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-09 16:42:02",
      "description": "Once a compaction cycle is through the compaction progress logger prints a message like:\n\n{noforma}\nFinished compaction: 26 nodes, 7 properties, 0 binaries.\n{noformat}\n\nHowever the number for nodes and properties includes those items deduplicated through the compaction map, effectively counting some items multiple times even though those where compacted only once and reused later. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction progress logger: reported number of nodes and binaries is too high"
   },
   {
      "_id": "12920359",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-09 08:34:48",
      "description": "{{org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT}} failed on Jenkins:\n\n{noformat}\nheavyWrite[usePersistedMap: false](org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT)  Time elapsed: 106.519 sec  <<< ERROR!\njava.lang.IllegalStateException\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:134)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.<init>(Segment.java:214)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.<init>(Segment.java:198)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:1177)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.readSegment(SegmentTracker.java:224)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:149)\n\tat org.apache.jackrabbit.oak.plugins.segment.RecordId.getSegment(RecordId.java:88)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:506)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:79)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getChildNode(SegmentNodeState.java:381)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder$UnconnectedHead.update(MemoryNodeBuilder.java:651)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder$ConnectedHead.update(MemoryNodeBuilder.java:729)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.head(MemoryNodeBuilder.java:171)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.access$300(MemoryNodeBuilder.java:88)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder$UnconnectedHead.update(MemoryNodeBuilder.java:650)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder$ConnectedHead.update(MemoryNodeBuilder.java:729)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.head(MemoryNodeBuilder.java:171)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.exists(MemoryNodeBuilder.java:273)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setProperty(MemoryNodeBuilder.java:506)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setProperty(MemoryNodeBuilder.java:515)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createProperties(HeavyWriteIT.java:156)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createNodes(HeavyWriteIT.java:148)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createNodes(HeavyWriteIT.java:149)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.heavyWrite(HeavyWriteIT.java:129)\n{noformat}\n\nSeen at build 597",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Test failure: HeavyWriteIT"
   },
   {
      "_id": "12920357",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2015-12-09 08:29:48",
      "description": "{{org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT}} fails on Jenkins: \n\n{noformat}\ntestSync(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT)  Time elapsed: 54.498 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotEquals(Assert.java:834)\n\tat org.junit.Assert.assertEquals(Assert.java:118)\n\tat org.junit.Assert.assertEquals(Assert.java:144)\n\tat org.apache.jackrabbit.oak.plugins.segment.standby.DataStoreTestBase.testSync(DataStoreTestBase.java:104)\n{noformat}\n\nSeen at builds 163, 164, 598, 601\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ExternalSharedStoreIT"
   },
   {
      "_id": "12920094",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-08 14:33:39",
      "description": "To diagnose certain issues with gc / checkpoints / indexing we need a tool to trace the evolution of a given node through the revision history. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement tooling for tracing a node through the revision history"
   },
   {
      "_id": "12919998",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-08 08:23:33",
      "description": "This epic tracks the work done to move the Segment Store into an independent bundle, detached from oak-core.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move the Segment Store into its own bundle"
   },
   {
      "_id": "12919995",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-12-08 08:13:09",
      "description": "Every 2nd build or so is aborted after a time out (90 mins):\n\n{noformat}\nBuild timed out (after 90 minutes). Marking the build as aborted.\nBuild was aborted\n[FINDBUGS] Skipping publisher since build result is ABORTED\nRecording test results\nFinished: ABORTED\n{noformat}\n\nSee  e.g. https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/585/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=DOCUMENT_RDB,profile=unittesting/console\n\nInterestingly when successful, the build takes about 30mins, so way below the 90 min. timeout. \n\nAlso seen at builds 587, 590, 591, 593, 595, 597, 598, 604, 608, 609, 610 ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Build time out after 90 mins on Jenkins"
   },
   {
      "_id": "12919659",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-07 11:30:25",
      "description": "For post mortem analysis it would be helpful to have the revisions that where involved in a compaction run. I.e. the revision that was compacted, the revisions of the cycles (if any) and the revision that is ultimately applied?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Compactor should log revisions acting upon"
   },
   {
      "_id": "12919023",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-04 17:00:15",
      "description": "This is a regression introduced with OAK-3329 where cleaning up unreferenced tar files was taken out of {{FileStore#cleanup}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction doesn't clean up unreferenced tar files"
   },
   {
      "_id": "12917203",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-01 09:58:17",
      "description": "Having {{compaction.forceAfterFail}} set to {{true}} will block repository writes for an extended period of time (minutes, probably hours) if all previous compaction cycles couldn't catch up with the latest changes. I think this is not acceptable and we should change the default to {{false}}: if compaction is not able to catch up the recommendation should be to move it to a quieter time. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Change default of compaction.forceAfterFail to false"
   },
   {
      "_id": "12917183",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-01 08:41:23",
      "description": "{{SegmentStore.writeSegment}} doesn't specify its behaviour in the face of IO errors. Moreover {{FileStore.writeSegment}} just catches any {{IOException}} and throws a {{RuntimeException}} with the former as its cause. \n\nI think we need to clarify this as an immediate cause of the current state is that some of the {{SegmentWriter}} write methods *do* throw an {{IOException}} and some *don't*. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve handling of IOException"
   },
   {
      "_id": "12917177",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-01 08:28:50",
      "description": "Currently {{BackgroundThread}} dies silently when hit by an uncaught exception. We should log a warning. \n\nAlso calling {{Thread#start}} from within the constructor is an anti-pattern as it exposes {{this}} before fully initialised. This is potentially causing OAK-3303. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "More resilient BackgroundThread implementation"
   },
   {
      "_id": "12916997",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-11-30 16:12:09",
      "description": "We current INFO-level-log the startup, but not the shutdown (dispose()). This makes it harder to see in system logs whether the DocumentStore has been shutdown properly.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RDBDocumentStore shutdown: improve logging"
   },
   {
      "_id": "12916934",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-11-30 10:59:05",
      "description": "Epic for collection SegmentMK resilience improvements",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve SegmentMK resilience"
   },
   {
      "_id": "12916638",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-11-27 13:34:17",
      "description": "Currently {{SegmentBufferWriter.flush()}} directly calls {{SegmentStore.writeSegment()}} once the current segment does not have enough space for the next record. We should try to cut this dependency as {{SegmentBufferWriter}} should only be concerned with providing buffers for segments. Actually writing these to the store should be handled by a higher level component. \n\nA number of deadlock (e.g. (OAK-2560, OAK-3179, OAK-3264) we have seen is one manifestation of this troublesome dependency. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Decouple SegmentBufferWriter from SegmentStore"
   },
   {
      "_id": "12916181",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-11-25 15:32:13",
      "description": "ATM indexes break (by whatever circumstances) users need to perform a full re-index. Depending on the size off the repository this can take a long time.\nIf the user knows that the indexes were in a good state at a certain revision in the past then it would be very useful, if the user could trigger a \"partial\" re-index where only the content added after a certain revision was updated in the index.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Partial re-index from last known good state"
   },
   {
      "_id": "12915355",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-11-23 14:59:44",
      "description": "{{CompactionAndCleanupIT#testMixedSegments}} might fail under some circumstances. It can be certainly be made to fail by increasing concurrency. I suspect this to be caused by OAK-3348. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Potential test failure: CompactionAndCleanupIT#testMixedSegments"
   },
   {
      "_id": "12914080",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-11-18 11:03:37",
      "description": "As discussed in OAK-2187 and due to changes done in OAK-3002 HierrachialCacheInvalidator is now redundant and should be removed. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove HierarchicalCacheInvalidator"
   },
   {
      "_id": "12913682",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-11-17 12:35:04",
      "description": "This is similar to OAK-3388, but about hierarchy information like which child nodes exist at a given revision of the parent node. This issue only occurs in a cluster.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Inconsistent read of hierarchy "
   },
   {
      "_id": "12911832",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-11-10 11:12:36",
      "description": "Some of the issues related to TarMK revision gc should be back ported to the branches. This issue is for keeping track of which issues and which svn revisions we consider for back porting. The task consists of the following steps:\n\n# Identify issue to back port\n# Merge the respective commits into a private forks of the 1.0 and 1.2 branches\n# Run tests on builds from the private forks\n# On success merge the private forks to the 1.0 and 1.2 branches and update the fix versions of the respective issues. \n    * Update the svn merge info with the respective merged svn revisions. \n    * Update the fix versions of the affected issues.\n\n[~dhasler]: FYI\n[~alex.parvulescu], [~frm]: please refrain from merging potential conflicting changes into the branches in the meanwhile. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Backport TarMK revision gc related issues"
   },
   {
      "_id": "12911545",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-11-09 14:42:07",
      "description": "Given the fact that tar readers are immutable (we only create new generations of them once they reach a certain threshold of garbage) we can consider coming up with a heuristic for skipping cleanup entirely for consequent cleanup calls based on the same referenced id set (provided we can make this set more stable, aka. OAK-2849).\n\nEx: for a specific input set a cleanup call on a tar reader might decide that there's no enough garbage (some IO involved in reading through all existing entries). if the following cleanup cycle would have the exact same input, it doesn't make sense to recheck the tar file, we already know cleanup can be skipped, moreover we can skip the older tar files too, as their input would also not change. the gains increase the larger the number of tar files.\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Evaluate skipping cleanup of a subset of tar files"
   },
   {
      "_id": "12911540",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-11-09 14:33:50",
      "description": "It looks like the current head's segment id (coming from the SegmentWriter) is always passed to the cleanup's referenced segment ids set, even though it cannot be cleaned (similar to the TarWriter situation) so I propose removing it early from the mentioned set.\nbenefits include making the cleanup set more stable (head changes quite often so the cleanup set is more volatile) which will help in figuring out if we still need to clean a specific tar file or not based on previous cleanup runs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove the SegmentWriter segmentId from the cleanup set"
   },
   {
      "_id": "12908516",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2015-10-28 11:03:36",
      "description": "cloning from OAK-3523 in order to not mix the {{ClassCastException}} issue with additional improvements i suggested in the patch, which include e.g. minor refactoring to remove code duplication and improve overall readability (IMO).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve DefaultSyncContext"
   },
   {
      "_id": "12908277",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-10-27 16:36:57",
      "description": "[Gephi|https://gephi.org/] turned out to be very valuable for examining segment graphs. I would like to add some tooling so we could dump the segment graph of a {{FileStore}} to a file. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Tooling for writing segment graphs to a file"
   },
   {
      "_id": "12908135",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-10-27 06:41:11",
      "description": "Currently while connecting to Mongo MongoDocumentStore relies on default write concern provided as part of mongouri. \n\nRecently some issues were seen where Mongo based Oak was connecting to 3 member replica set and there were frequent replica state changes due to use of VM for Mongo. This caused data loss and corruption of data in Oak.\n\nTo avoid such situation Oak should default to write concern of majority by default. If some write concern is specified as part of mongouri then that should take precedence. This would allow system admin to take the call of tweaking write concern if required and at same time allows Oak to use the safe write concern.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use write concern of w:majority when connected to a replica set"
   },
   {
      "_id": "12907331",
      "assignee": "frm",
      "components": [],
      "created": "2015-10-23 08:52:41",
      "description": "The o.a.j.o.api has multiple dependencies on classes exported by the Google Guava bundle. The the o.a.j.o.api package should be made independent from Google Guava.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "o.a.j.o.api should not depend on Guava"
   },
   {
      "_id": "12907100",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-10-22 14:40:23",
      "description": "while testing my work in OAK-1268 and OAK-2008, i found that items with OPV IGNORE are being copied into the frozen node of a versionable node upon checkin and only the first level child nodes are being tested for the OPV flag.\n\nIMHO the OPV flag should be respected for all items in the subtree and act accordingly. The current bug might prevent versionable child nodes from being properly versioned and will copy items that are expected to be ignored (e.g. access control content) into the version store.\n\nif i am not mistaken the properties are actually tested for the their OPV flag... if that is true, we might even have a bigger issue as the content in the version store is no longer complete and valid (e.g. mandatory/protected/autocreated properties being ignored but the node still being copied over and thus being invalid)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "versioning"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "VersionableState.copy doesn't respect OPV flag in the subtree"
   },
   {
      "_id": "12905902",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-10-19 10:33:05",
      "description": "Most if not all calls to {{SessionDelegate#performVoid}} pass a raw type to that method instead of parametrizing it with the {{Void}} type, which leads to an \"unchecked assignment\" warning. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Unchecked assignements in calls to performVoid()"
   },
   {
      "_id": "12905230",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2015-10-15 15:41:44",
      "description": "the group and group-member sync code in the {{DefaultSyncContext}} twice catches {{ClassCastException}} and swallows exception situations, where a user is found, when actually a {{Group}} was expected.\n\ni would suggest to \n- explicitly test the assumption wrt {{ExternalIdentity}} being a group (instead of waiting for the exception)\n- make use of {{UserManager.getAuthorizable(String, Class) to explicitly retrieve a Group with a given ID, when this is actually expected. This method will throws an {{AuthorizableTypeException}} if there exists a {{User}} with that ID as thus properly raise the unexpected behavior instead of swallowing with a log-warning.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DefaultSyncContext catches ClassCastException"
   },
   {
      "_id": "12904464",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-13 07:26:55",
      "description": "Said test fails sporadically:\n\n{noformat}\nat org.junit.Assert.assertNull(Assert.java:562)\nat org.apache.jackrabbit.oak.plugins.segment.CompactionMapTest.removeSome(CompactionMapTest.java:156)\n{noformat}\n\nThis is a regression introduced with OAK-3501: the {{recent}} map gets not cleared when {{segmentIdMap}} is empty. This can happen when a recent key is removed again while there are no other changes. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: CompactionMapTest.removeSome"
   },
   {
      "_id": "12904208",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-10-12 15:11:48",
      "description": "The logs generated during different phases of tar garbage collection (compaction) are currently quite heterogenous and difficult to grep/parse.\n\nI propose with the attached patch to uniformize these logs, changing the following:\n# all logs start with the prefix {{TarMK GargabeCollection \\{\\}#:}}\n# different phases of garbage collection are easier to identify by the first word after prefix, e.g. estimation, compaction, cleanup\n# all values are also printed in a standard unit, with the following format: {{<human_readable_value> (<standard_unit_value>)}}. This makes extraction of information much easier.\n# messages corresponding to the same cycle (run) can be grouped by including the runId in the prefix.\n\nNote1: I don't have enough visibility, but the changes might impact any system relying on the old format. Yet, I've seen they have changed before so this might not be a real concern.\n\nNote2: the runId is implemented as a static variable, which is reset every time the class is reloaded (e.g. at restart), so it is unique only during one run.\n\nBelow you can find an excerpt of old logs and new logs to compare:\n\nNEW:\n{code}\n12.10.2015 16:11:56.705 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: started\n12.10.2015 16:11:56.707 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: estimation started\n12.10.2015 16:11:59.275 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: estimation completed in 2.569 s (2567 ms). Gain is 16% or 1.1 GB/1.3 GB (1062364160/1269737472 bytes), so running compaction\n12.10.2015 16:11:59.275 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: compaction started, strategy=CompactionStrategy{paused=false, cloneBinaries=false, cleanupType=CLEAN_OLD, olderThan=36000000, memoryThreshold=5, persistedCompactionMap=true, retryCount=5, forceAfterFail=true, compactionStart=1444659116706, offlineCompaction=false}\n12.10.2015 16:12:05.839 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.Compactor Finished compaction: 420022 nodes, 772259 properties, 20544 binaries.\n12.10.2015 16:12:07.459 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: compaction completed in 8.184 s (8183 ms), after 0 cycles\n12.10.2015 16:12:11.912 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:12:11 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: cleanup started. Current repository size is 1.4 GB (1368899584 bytes)\n12.10.2015 16:12:12.368 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:12:11 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: cleanup marking file for deletion: data00008a.tar\n12.10.2015 16:12:12.434 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:12:11 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: cleanup completed in 522.8 ms (522 ms). Post cleanup size is 1.2 GB (1217132544 bytes)and space reclaimed 151.8 MB (151767040 bytes). Compaction map weight/depth is 0 B/1 (0 bytes/1).\n{code} \n\nOLD:\n{code}\n12.10.2015 15:54:55.115 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK compaction started\n12.10.2015 15:54:56.082 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore Estimated compaction in 967.6 ms, gain is 7% (1083809280/1170960384) or (1.1 GB/1.2 GB), so running compaction\n12.10.2015 15:54:56.083 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK compaction running, strategy=CompactionStrategy{paused=false, cloneBinaries=false, cleanupType=CLEAN_OLD, olderThan=36000000, memoryThreshold=5, persistedCompactionMap=true, retryCount=5, forceAfterFail=true, compactionStart=1444658095115, offlineCompaction=false}\n12.10.2015 15:55:01.986 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.Compactor Finished compaction: 419878 nodes, 771824 properties, 20542 binaries.\n12.10.2015 15:55:03.273 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK compaction completed after 0 cycles in 7190ms\n12.10.2015 15:55:08.032 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:55:08 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK revision cleanup started. Current repository size 1.3 GB\n12.10.2015 15:55:08.719 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:55:08 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK revision cleanup completed in 688.0 ms. Post cleanup size is 1.3 GB and space reclaimed 0. Compaction map weight/depth is 0 B/1.\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Uniformization of compaction log messages"
   },
   {
      "_id": "12903762",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-09 15:01:22",
      "description": "We should have better logging during cleanup. E.g. why a file has been skipped / cleaned etc. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve logging during cleanup"
   },
   {
      "_id": "12903667",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-09 08:42:00",
      "description": "Whenever a PersistedCompactionMap becomes empty it will be eventually dropped from the compaction maps chain. this will happen on the next compaction cycle, which happens post-cleanup. so we're potentially keeping a reference to some collectable garbage for up to 2 cycles.\nI'd like to propose a patch that allows for eagerly nullifying the reference to the records, making this interval shorter.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "PersistedCompactionMap could release reference to records early"
   },
   {
      "_id": "12903311",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-10-08 09:32:54",
      "description": "The method is only used by the DocumentMK class, which is now considered a test helper (OAK-2907) and part of the API anymore.\n\nThe method should be removed from the DocumentNodeStore and functionality moved to the DocumentMK.find() method.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove DocumentNodeStore.diff()"
   },
   {
      "_id": "12902999",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-10-07 13:55:53",
      "description": "Each entry in {{MemoryDiffCache}} is keyed with {{(path, fromRev, toRev)}} for the list of modified children at {{path}}. A diff calcualted by {{DocumentNodeStore.diffImpl}} at '/' (passively via loader) or {{JournalEntry.applyTo}} (actively) fill each path for which there are modified children (including the hierarchy)\n\nBut, if an observer calls {{compareWithBaseState}} on a unmodified sub-tree, the observer will still go down to {{diffImpl}} although cached parent entry can be used to answer the query.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MemoryDiffCache should also check parent paths before falling to Loader (or returning null)"
   },
   {
      "_id": "12902989",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-07 13:27:14",
      "description": "A deadlock was detected while stopping the {{SegmentCompactionIT}} using the exposed MBean.\n\n{noformat}\n\"main@1\" prio=5 tid=0x1 nid=NA waiting for monitor entry\n waiting for pool-1-thread-10@2111 to release lock on <0xae8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.dropCache(SegmentWriter.java:871)\n  at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.close(FileStore.java:1031)\n  - locked <0xae7> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT.tearDown(SegmentCompactionIT.java:282)\n\n\"pool-1-thread-10@2111\" prio=5 tid=0x1d nid=NA waiting for monitor entry\n  java.lang.Thread.State: BLOCKED\n blocks main@1\n waiting for main@1 to release lock on <0xae7> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n  at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.writeSegment(FileStore.java:1155)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.flush(SegmentWriter.java:253)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.prepare(SegmentWriter.java:350)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeListBucket(SegmentWriter.java:468)\n  - locked <0xae8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeList(SegmentWriter.java:719)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1211)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1156)\n  at org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1147)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1175)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.prepare(SegmentNodeStore.java:451)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.optimisticMerge(SegmentNodeStore.java:474)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.execute(SegmentNodeStore.java:530)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:208)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Deadlock when closing a concurrently used FileStore 2.0"
   },
   {
      "_id": "12902929",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-10-07 08:58:41",
      "description": "Currently, when a cluster node starts and discovers that it wasn't properly shutdown, it first runs the complete LastRevRecovery and only continues startup when done.\n\nHowever, when it fails to acquire the recovery lock, which implies that a different cluster node is already running the recovery on its behalf, it simply skips recovery and continues startup?\n\nSo what is it? Is running the recovery before proceeding critical or not? If it is, this code in {{LastRevRecoveryAgent}} needs to change:\n\n{code}\n        //TODO What if recovery is being performed for current clusterNode by some other node\n        //should we halt the startup\n        if(!lockAcquired){\n            log.info(\"Last revision recovery already being performed by some other node. \" +\n                    \"Would not attempt recovery\");\n            return 0;\n        }\n{code}\n\nIf it's not critical, we may want to run the recovery always asynchronously. \ncc [~mreutegg]  and [~chetanm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "LastRevRecovery for self async?"
   },
   {
      "_id": "12902727",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-06 16:07:10",
      "description": "The test doesn't remove its created directories.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "FileStoreIT cleanup after tests"
   },
   {
      "_id": "12902653",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-06 10:04:52",
      "description": "Each test in the class retains about 16MB of heap and subsequent tests may fail with an OOME. E.g. see recent build failure on travis: https://travis-ci.org/apache/jackrabbit-oak/builds/83848567",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "CompactionMapTest does not close file store"
   },
   {
      "_id": "12902627",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-06 08:37:15",
      "description": "I'd like to add a counter that exposes the current generation of the compaction map, (meaning the number of compaction cycles).\nSo far I've been using the CompactionMap#getDepth as a heuristic but if you run long enough some old generations will be dropped decreasing the depth, making it unreliable as a generation counter.\nI don't want to persist this info, just start at 0 once the system starts up and increase on each CompactionMap#cons call.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add generation info to compaction map"
   },
   {
      "_id": "12902425",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-10-05 14:16:10",
      "description": "Running \n\n{{oak-run debug  /path/to/segmentStore}}\n\ncan result in {{SNFE}} s being logged if the file store has been compacted before. This can happen even though the repository is actually consistent according to {{oak-run check}}. \n\nThe reason is {{debug}} traversing all node states of all record ids in all tar files. When a previous cleanup of a tar file did not reach 25% gain it will not clean up that file leaving behind segments possibly containing node states pointing to limbo. Those nodes would result in said {{SNFE}} of {{oak-run}} debug. But as those node states are not reachable from the head node state the repository is still consistent itself. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Confusing SNFE whith oak-run debug"
   },
   {
      "_id": "12902419",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-10-05 13:12:45",
      "description": "{{NodeDocument.getNodeAtRevision}} tried to look at latest revisions entries for each property in current document. But it just looks at the *last* entry for a given property. In case this last entry isn't committed, the code would go into previous documents to look for a committed value.\n\n(cc [~mreutegg])",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NodeDocument.getNodeAtRevision can go into property history traversal when latest rev on current doc isn't committed"
   },
   {
      "_id": "12902115",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-10-02 13:07:22",
      "description": "I think we should replace the background thread with some kind of a scheduler. The goal would be to decouple threading from scheduling. IMO threads should not be managed by the application but by the container. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Replace BackgroundThread with Scheduler"
   },
   {
      "_id": "12900998",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-09-28 10:52:10",
      "description": "The offline compaction instantiates {{FileStore}} using a deprecated constructor. This constructor forces a no-op {{GCMonitor}} that swallows log messages and caught exception.\n\nIt would be more appropriate to create the {{FileStore}} using the corresponding {{Builder}}. This has the side effect of configuring a {{LoggingGCMonitor}}, which provides way more information than the current default.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve the logging capabilities of offline compaction"
   },
   {
      "_id": "12896376",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-09-25 11:21:42",
      "description": "We currently support explicit assignment of clusterId (builder.setClusterId()). In this case, DocumentNodeStore uses the specified cluster id and skips all code related to creating/maintaining ClusterNodeInfos.\n\nThis feature is mainly (only?) used for testing (mainly allowing multiple instances to run from the same machine/instance combination). This works, but causes the logic related to ClusterNodeInfo not to be used at all (for instance, LastRevRecovery).\n\nSo we ought to change this config option to use ClusterNodeInfo in a way that is at least similar to real-world use.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore support for predefined clusterIds should use ClusterNodeInfos"
   },
   {
      "_id": "12896027",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-09-24 08:13:54",
      "description": "Similarly to what is done for a shared datastore in OAK-3360, the start time of the mark should be used as a reference for deletion of blobs in GC for 1.0.x. The problem is that in 1.0.x the mark iterated over the data store which could take a lot of time (many hours) and the buffer due to {{blobGcMaxAgeInSecs}} may get stale due to which data loss could happen.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Track the start time of mark in GC"
   },
   {
      "_id": "12895331",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-09-22 04:49:21",
      "description": "Async indexing logic relies on embedding application to ensure that async indexing job is run as a singleton in a cluster. For Sling based apps it depends on Sling Discovery support. At times it is being seen that if topology is not stable then different cluster nodes can consider them as leader and execute the async indexing job concurrently.\n\nThis can cause problem as both cluster node might not see same repository state (due to write skew and eventual consistency) and might remove the checkpoint which other cluster node is still relying upon. For e.g. consider a 2 node cluster N1 and N2 where both are performing async indexing.\n\n# Base state - CP1 is the checkpoint for \"async\" job\n# N2 starts indexing and removes changes CP1 to CP2. For Mongo the checkpoints are saved in {{settings}} collection\n# N1 also decides to execute indexing but has yet not seen the latest repository state so still thinks that CP1 is the base checkpoint and tries to read it. However CP1 is already removed from {{settings}} and this makes N1 think that checkpoint is missing and it decides to reindex everything!\n\nTo avoid this topology must be stable but at Oak level we should still handle such a case and avoid doing a full reindexing. So we would need to have a {{MissingCheckpointStrategy}} similar to {{MissingIndexEditorStrategy}} as done in OAK-2203 \n\nPossible approaches\n# A1 - Fail the indexing run if checkpoint is missing - Checkpoint being missing can have valid reason and invalid reason. Need to see what are valid scenarios where a checkpoint can go missing\n# A2 - When a checkpoint is created also store the creation time. When a checkpoint is found to be missing and its a *recent* checkpoint then fail the run. For e.g. we would fail the run till checkpoint found to be missing is less than an hour old (for just started take startup time into account)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Prevent missing checkpoint due to unstable topology from causing complete reindexing"
   },
   {
      "_id": "12895116",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-21 13:12:19",
      "description": "The conflict check does not consider changes that are made visible between the rebase and the background read.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Background update may create journal entry with incorrect id"
   },
   {
      "_id": "12875802",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-09-18 08:16:43",
      "description": "Scenario (test case will follow):\n\n1) service configured for RDBDocumentStore with DataSources\n\n2) gets started\n\n3) DataSource unregisters, DocumentNodeStore gets shut down\n\n4) DataSource is registered again\n\n5) restart of DocumentNodeStore fails with NPE because at least one required component (executor?) now is null\n\nWe need to decide whether this is a scenario that should be supported or not. If yes, we need to fix it. If no, we need to make the code more robust and improve diagnostics.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStoreService fails to restart DocumentNodeStore"
   },
   {
      "_id": "12875411",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-17 16:17:18",
      "description": "{code}\n            String mId = \"\" + doc.get(MACHINE_ID_KEY);\n            String iId = \"\" + doc.get(INSTANCE_ID_KEY);\n            if (machineId.startsWith(RANDOM_PREFIX)) {\n                // remove expired entries with random keys\n                store.remove(Collection.CLUSTER_NODES, key);\n                continue;\n            }\n{code}\n\nThe intent seems to be to cleanup entries in the cluster node table that start with RANDOM_PREFIX. However, {{machineId}} is checked instead of {{mId}}. When {{createInstance}} is called with a random id, the whole table might get wiped out. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ClusterNodeInfo.createInstance fails to clean up random entries"
   },
   {
      "_id": "12875392",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-17 15:24:27",
      "description": "On Windows, all kinds of adapters (tunnel, VPN) return a hardware address of 00-00-00-00-00-00-00-E0 (note 8 bytes, not 6). These addresses are useless for the identification of the machine, however they get used because they are the lowest value.\n\nA potential fix is to change the validity check to:\n\nif (mac != null && mac.length == 6)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ClusterNodeInfo uses irrelevant network interface IDs on Windows"
   },
   {
      "_id": "12864161",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-15 07:27:07",
      "description": "Similar to OAK-3390, the instanceof check in LastRevRecoveryAgent does not work when the MongoDocumentStore is wrapped.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid instanceof check in LastRevRecoveryAgent"
   },
   {
      "_id": "12863902",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-14 15:17:51",
      "description": "Supporting multiplexing repository would have impact on various places in Oak design. There are various sub components in Oak which maintain there own storage built on top of NodeStore. For e.g. indexes are stored within NodeStore, permissions are also stored within NodeStore. Adding multiplexing support would impact such stores in following ways\n\nThe most basic application of multiplexing support is to support private and shared storage. Under this an Oak application would have a private store and a shared store. Content under certain paths would be stored under private repo while all other content is stored under shared repo\n\n# *Writing* - Any content written via JCR API passes through some {{CommitHooks}}. These hooks are responsible for updating the indexes, permission store etc. Now if any path say /foo/bar gets modified the commits hooks would need to determine under which path in NodeStore should the derived data (index entries, permission etc) should be stored. For simple case of private and shared store where we have 2 sets of paths private and shared these hooks would need to be aware of that and use different path in NodeStore to store the derived content. Key point to note here that any such storage has to differentiate wether the path from which the content is being derived is a private path or shared path\n\n# *Reading* - Reading requirement compliments the writing problem. While performing any JCR operation Oak might need to invoke QueryIndex, PermissionStore etc. These stores in turn would need to perform a read from there storage area within NodeStore. For multiplexing support these components would then need to be aware that there storage can exist in both shared and private stores\n\nh4. Terms Used\n\n# _private repo_ (PR) - Set of paths which are considered private to the application. Tentative example /lib,/apps\n# _shared repo_ (SR) - Set of paths which are considered shared and different versions of the application can perform read and write operations on them. Tentative example /content, /etc/workflow/instances\n# {{PathToStoreMapper}} - Responsible for mapping a path to store type. For now it can just answer either PR or SR. But the concept can be generalized \n\nAim of this story is to prototype changes in Oak layer in a fork to asses the impact on current implementation",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "multiplexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Multiplexing NodeStore support in Oak layer"
   },
   {
      "_id": "12863035",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-10 12:39:42",
      "description": "This issue is similar to OAK-2929 but related to how the DocumentNodeStore reads a node state when there is a clock difference between multiple cluster nodes. The node state read from a NodeDocument may not be correct when there is a clock difference.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Inconsistent read in cluster with clock differences"
   },
   {
      "_id": "12862768",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-09 14:29:01",
      "description": "I'm breaking this part off from OAK-3133 as the backport is harmless and this is a very important option to have.\nThis only applies to 1.0 and 1.2 branches, as trunk code has evolved quite a bit.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make compress-interval configurable"
   },
   {
      "_id": "12862712",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-09 09:15:49",
      "description": "Allow the option to choose the type of CompactionMaps oak-run uses, and set the default to the in-memory version.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak run should use InMemoryCompactionMap by default"
   },
   {
      "_id": "12862677",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-09-09 06:59:36",
      "description": "Various testcases in SuggestTest test are failing on *1.0 branch* for past few runs 390, 391, 394, 398\n\n{noformat}\ntestSuggestSql(org.apache.jackrabbit.oak.jcr.query.SuggestTest)  Time elapsed: 7.963 sec  <<< FAILURE!\njunit.framework.ComparisonFailure: expected:<[[{term=in 2015 a red fox is still a fox,weight=1}, {term=in 2015 my fox is red, like mike's fox and john's fox,weight=1}]]> but was:<[]>\n\tat junit.framework.Assert.assertEquals(Assert.java:85)\n\tat junit.framework.Assert.assertEquals(Assert.java:91)\n\tat org.apache.jackrabbit.oak.jcr.query.SuggestTest.testSuggestSql(SuggestTest.java:50)\ntestSuggestXPath(org.apache.jackrabbit.oak.jcr.query.SuggestTest)  Time elapsed: 0.149 sec  <<< FAILURE!\njunit.framework.ComparisonFailure: expected:<[[{term=in 2015 a red fox is still a fox,weight=1}, {term=in 2015 my fox is red, like mike's fox and john's fox,weight=1}]]> but was:<[]>\n\tat junit.framework.Assert.assertEquals(Assert.java:85)\n\tat junit.framework.Assert.assertEquals(Assert.java:91)\n\tat org.apache.jackrabbit.oak.jcr.query.SuggestTest.testSuggestXPath(SuggestTest.java:67)\n\t\n{noformat}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: SuggestTest"
   },
   {
      "_id": "12862389",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-08 11:49:32",
      "description": "BackgroundObserver currently merges external events if the last one in queue is also an external event. This leads to diff being done for a revision pair which is different from the ones pushed actively into cache during backgroud read (using JournalEntry) i.e. diff queries for {{diff(\"/a/b\", rA, rC)}} while background read had pushed results of {{diff(\"/a/b\", rA, rB)}} and {{diff(\"/a/b\", rB, rC)}}.\n\n(cc [~mreutegg], [~egli], [~chetanm], [~mduerig])",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Collapsing external events in BackgroundObserver even before queue is full leads to JournalEntry not getting used"
   },
   {
      "_id": "12862325",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-09-08 06:27:07",
      "description": "When the boost support was added the intention was to support a usecase like \n\n{quote}\nFor the fulltext search on a node where the fulltext content is derived from multiple field it should be possible to boost specific text contributed by individual field. Meaning that if a title field is boosted more than description, the title (part) in the fulltext field will mean more than the description (part) in the fulltext field.\n{quote}\n\nThis would enable a user to perform a search like _/jcr:root/content/geometrixx-outdoors/en//element(*, cq:Page)\\[jcr:contains(., 'Keyword')\\]_ and get a result where pages having 'Keyword' in title come above in search result compared to those where Keyword is found in description.\n\nCurrent implementation just sets the boost while add the field value to fulltext field with the intention that Lucene would use the boost as explained above. However it does not work like that and boost value gets multiplies with other field and hence boosting does not work as expected",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Boosting fields not working as expected"
   },
   {
      "_id": "12862207",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-09-07 12:20:27",
      "description": "Food for thought: try to base the compaction estimation on a diff between the latest compacted state and the current state.\n\nPros\n* estimation duration would be proportional to number of changes on the current head state\n* using the size on disk as a reference, we could actually stop the estimation early when we go over the gc threshold.\n* data collected during this diff could in theory be passed as input to the compactor so it could focus on compacting a specific subtree\n\nCons\n* need to keep a reference to a previous compacted state. post-startup and pre-compaction this might prove difficult (except maybe if we only persist the revision similar to what the async indexer is doing currently)\n* coming up with a threshold for running compaction might prove difficult\n* diff might be costly, but still cheaper than the current full diff\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Estimate compaction based on diff to previous compacted head state"
   },
   {
      "_id": "12862191",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-07 10:06:36",
      "description": "If a node is cached, 1/4 of the time which is used to call DocumentNodeStore.getNode is spent in PerfLogger.start and PerfLogger.end just for checking whether or not debug logging is enabled (this is likely much less if no TurboFilters are used).\n\nTo reduce the overhead of the PerfLogger, it should not check if debug is enabled in end() if start is below 0 anyway. Moreover, it would help to check only every second if debug is really enabled.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Reduce PerfLogger isDebugEnabled overhead"
   },
   {
      "_id": "12862181",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-09-07 09:12:39",
      "description": "Currently, for GC in a shared datastore, the last modified timestamp of the earliest references file is used to calculate the max age of blobs to be deleted. There is a possibility that the  process itself could have taken quite a long time which opens up a window that recent blobs could also be deleted. \nThe mark process is quite fast and with the default setting of {{blobGcMaxAgeInSecs}} of 24 hours this should not be a problem but if the {{blobGcMaxAgeInSec}} is specified to a lower value then it could create that window described above.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Tracking the start time of mark in GC for a shared datastore"
   },
   {
      "_id": "12862179",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-07 09:05:01",
      "description": "I'd like to introduce some logs to follow the compaction progress. It is very difficult to provide a progress expressed as a percentage because the diff has no knowledge of the total number of nodes, but we can follow the approach taken by the indexers and provide a log each 15k nodes.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compactor progress log"
   },
   {
      "_id": "12862161",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-09-07 07:37:49",
      "description": "{{org.apache.jackrabbit.oak.jcr.query.SpellcheckTest.testSpellcheckMultipleWords}} fails on Jenkins.\n\nFailure seen at builds: 389, 392, 395, 396, 562\n\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/396/jdk=jdk-1.6u45,label=Ubuntu,nsfixtures=DOCUMENT_RDB,profile=unittesting/console\n\n{noformat}\ntestSpellcheckMultipleWords(org.apache.jackrabbit.oak.jcr.query.SpellcheckTest)  Time elapsed: 0.907 sec  <<< FAILURE!\njunit.framework.ComparisonFailure: expected:<[voting[ in] ontario]> but was:<[voting[, voted,] ontario]>\n\tat junit.framework.Assert.assertEquals(Assert.java:85)\n\tat junit.framework.Assert.assertEquals(Assert.java:91)\n\tat org.apache.jackrabbit.oak.jcr.query.SpellcheckTest.testSpellcheckMultipleWords(SpellcheckTest.java:86)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins",
         "test",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: SpellcheckTest.testSpellcheckMultipleWords"
   },
   {
      "_id": "12861787",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-09-04 09:00:14",
      "description": "This is OAK-3349 taken to the extreme: given a segment that is almost not referenced any more we could just rewrite the still referenced content. That is, say a segment contains two properties reachable from the current root node state and all its remaining content is not reachable from the root node state. In that case we could rewrite these two properties and create a new root node state referencing the rewritten properties. This would effectively make the segment eligible for being gc-ed. \nSuch an approach would start from segments that are sparse and compact these instead of compacting everything as we currently do, which might cause a lot of copying around stuff that already is compact. The challenging part here is probably finding the segments that are sparse as this involves inverting the reference graph. \n\nTodo: Asses feasibility and impact, implement prototype.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Incremental compaction"
   },
   {
      "_id": "12861783",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-09-04 08:45:58",
      "description": "On big repositories compaction can take quite a while to run as it needs to create a full deep copy of the current root node state. For such cases it could be beneficial if we could partially compact the repository thus splitting full compaction over multiple cycles. \nPartial compaction would run compaction on a sub-tree just like we now run it on the full tree. Afterwards it would create a new root node state by referencing the previous root node state replacing said sub-tree with the compacted one. \n\nTodo: Asses feasibility and impact, implement prototype.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Partial compaction"
   },
   {
      "_id": "12861779",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-09-04 08:32:39",
      "description": "I suspect that certain write operations during compaction can cause references from compacted segments to pre-compacted ones. This would effectively prevent the pre-compacted segments from getting evicted in subsequent cleanup phases. \n\nThe scenario is as follows:\n* A session is opened and a lot of content is written to it such that the update limit is exceeded. This causes the changes to be written to disk. \n* Revision gc runs causing a new, compacted root node state to be written to disk.\n* The session saves its changes. This causes rebasing of its changes onto the current root (the compacted one). At this point any node that has been added will be added again in the sub-tree rooted at the current root. Such nodes however might have been written to disk *before* revision gc ran and might thus be contained in pre-compacted segments. As I suspect the node-add operation in the rebasing process *not* to create a deep copy of such nodes but to rather create a *reference* to them, a reference to a pre-compacted segment is introduced here. \n\nGoing forward we need to validate above hypothesis, assess its impact if necessary come up with a solution.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Cross gc sessions might introduce references to pre-compacted segments"
   },
   {
      "_id": "12861773",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-04 08:17:52",
      "description": "The cleanup phase after a compaction run is currently not able to remove the pre compacted segments as the previous (pre-compacted) root is still being referenced. Those references are coming from:\n\n* The {{before}} [local variable|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/file/FileStore.java#L653] in {{FileStore.flush}}.\n* The [current head|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeStore.java#L85-L85] of the {{SegmentNodeStore}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compac",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Ineffective cleanup after compaction due to references to root"
   },
   {
      "_id": "12861600",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-03 15:08:38",
      "description": "The session auto refresh feature is implemented by marking sessions pending for refresh. The refresh operation itself however only happens on the next access to the session. \n\nIt would be helpful if {{SessionMBean}} could expose the information whether a session has a pending refresh. Additionally we could expose the current {{RefreshStrategy}} to make the auto refresh behaviour more transparent. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SessionMBean should provide information about pending refresh"
   },
   {
      "_id": "12861552",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-03 12:20:39",
      "description": "It may happen that a commit adds a collision marker for a revision which is already committed. {{Collision.markCommitRoot()}} does not perform a conditional update when it adds the collision marker. Though, it checks the document after the update if the marked revision is committed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Commit may add collision marker for committed revision"
   },
   {
      "_id": "12861256",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-02 08:55:22",
      "description": "OAK-2528 introduced purging of _commitRoot entries without associated local changes on the document. Those _commitRoot entries are created when a child nodes is added and the _children flag is touched on the parent.\n\nThe purge operation is too eager and removes all such entries, which may result in an undetected hierarchy conflict.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SplitOperations purges _commitRoot entries too eagerly"
   },
   {
      "_id": "12861236",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-02 07:26:38",
      "description": "Concurrently writing to the file store can lead to a sever lock contention in {{FileStore#readSegment}}. That method searches the current {{TarWriter}} instance for the segment once it could not be found in any of the {{TarReader}} instances. This is the point where synchronizes on the {{FileStore}} instance, which leads to  the contention. \nThe effect is only observable once the segment cache becomes full and reads actually need to go to the file store. Thus a possible improvement could be to pin segments from the current tar writer to the cache. Alternatively we could try to ease locking by employing read/write locks where possible. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "FileStore lock contention with concurrent writers"
   },
   {
      "_id": "12861233",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-02 07:06:17",
      "description": "TarMK cleanup exclusively locks the {{FileStore}}, which causes concurrent writers to block until cleanup finished. Initially cleanup was expected to be reasonably fast, however I have seen it taking dozens of minutes under certain circumstances (most likely many tar files with many small segments, aka OAK-2896).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TarMK cleanup blocks writers"
   },
   {
      "_id": "12860662",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-31 12:15:08",
      "description": "{noformat}\nRunning org.apache.jackrabbit.oak.plugins.segment.SegmentOverflowExceptionIT\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2,426.873 sec <<< FAILURE!\nrun(org.apache.jackrabbit.oak.plugins.segment.SegmentOverflowExceptionIT)  Time elapsed: 2,426.373 sec  <<< ERROR!\njava.util.ConcurrentModificationException\n\tat java.util.ArrayList$Itr.checkForComodification(ArrayList.java:859)\n\tat java.util.ArrayList$Itr.next(ArrayList.java:831)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.wasCompactedTo(CompactionMap.java:60)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.wasCompactedTo(Record.java:64)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.equals(SegmentBlob.java:213)\n\tat com.google.common.base.Objects.equal(Objects.java:55)\n\tat org.apache.jackrabbit.oak.plugins.memory.AbstractPropertyState.equal(AbstractPropertyState.java:53)\n\tat org.apache.jackrabbit.oak.plugins.memory.AbstractPropertyState.equals(AbstractPropertyState.java:90)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1176)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.<init>(SegmentNodeStore.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentOverflowExceptionIT.run(SegmentOverflowExceptionIT.java:130)\n{noformat}\n\nThis is caused by concurrently accessing the underlying list of maps in {{CompactionMap#remove}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ConcurrentModificationException when running SegmentOverflowExceptionIT"
   },
   {
      "_id": "12859617",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-08-27 14:28:17",
      "description": "The existing Segment Cache has no loading-related stats, I'd like to see how complicated it would be to add some.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Segment Tar SegmentCache loader stats"
   },
   {
      "_id": "12859572",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-08-27 11:08:40",
      "description": "When a DocumentNodeStore instance is killed and restarted, the _lastRev recovery mechanism is triggered on startup. It may happen that the restarted instance does not see all changes that were recovered.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Self recovering instance may not see all changes"
   },
   {
      "_id": "12858956",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-26 11:45:50",
      "description": "{{org.apache.jackrabbit.oak.plugins.segment.SegmentOverflowExceptionIT}} can fail with an {{SNFE}}. This is somewhat expected due to the low segment retention time used for this test. That time is apparently needed for this test to reproduce the original issue. So I'd rather not touch it. \n\nI propose to ignore that exception and retry a couple of times until failing the test. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SNFE in SegmentOverflowExceptionIT "
   },
   {
      "_id": "12858640",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-25 14:36:20",
      "description": "Currently {{SegmentOverflowExceptionIT}} runs forever or until it fails. We should add a time out after which the test is considered passed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentOverflowExceptionIT runs forever unless it fails"
   },
   {
      "_id": "12858615",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-25 13:14:25",
      "description": "Shutting down the repository while revision gc is running might block for a long time until either compaction estimation/compaction or clean up has finished. We should provide a way to interrupt those operations for a timely shut down. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Revision gc blocks repository shutdown"
   },
   {
      "_id": "12858608",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-08-25 12:50:40",
      "description": "The DS API allows setting properties as java.lang.Integer, but implementations vary in whether they can roundtrip Integers; some do, some convert to Long.\n\nThe former is observed for MongoMK (which uses BSON internally), the latter is see in RDBMK (which uses JSON).\n\nWe should\n\n- clarify that integers can be set, but they will come back as longs, and\n- modify existing implementations to always return longs, so bugs surface early\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "clarify DocumentStore contract with respect to number formats"
   },
   {
      "_id": "12858601",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-08-25 12:22:44",
      "description": "Collector issue for DS performance improvements",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Datastore performance improvements"
   },
   {
      "_id": "12858540",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-08-25 07:25:53",
      "description": "{{org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTestIT.sql2}} fails regularly on Jenkins: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/350/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=DOCUMENT_RDB,profile=integrationTesting/testReport/junit/org.apache.jackrabbit.oak.plugins.index.solr.query/SolrIndexQueryTestIT/sql2/\n\n{noformat}\njava.lang.Exception: Results in target/oajopi.solr.query.SolrIndexQueryTestIT_sql2.txt don't match expected results in file:/x1/jenkins/jenkins-slave/workspace/Apache%20Jackrabbit%20Oak%20matrix/jdk/jdk1.8.0_11/label/Ubuntu/nsfixtures/DOCUMENT_RDB/profile/integrationTesting/oak-core/target/oak-core-1.4-SNAPSHOT-tests.jar!/org/apache/jackrabbit/oak/query/sql2.txt; compare the files for details\n\tat org.apache.jackrabbit.oak.query.AbstractQueryTest.test(AbstractQueryTest.java:232)\n\tat org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTestIT.sql2(SolrIndexQueryTestIT.java:91)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:47)\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:18)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failures on trunk: SolrIndexQueryTestIT.sql2"
   },
   {
      "_id": "12858277",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-08-24 11:57:55",
      "description": "Collection of DocMK resilience improvements",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Improve DocumentMK resilience"
   },
   {
      "_id": "12858273",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-08-24 11:52:32",
      "description": "As discussed bilaterally grouping the improvements for indexer resilience in this issue for easier tracking",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Improve indexing resilience"
   },
   {
      "_id": "12858272",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-08-24 11:47:26",
      "description": "As discussed bilaterally grouping the improvements for datastore resilience in this issue for easier tracking",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Improve datastore resilience"
   },
   {
      "_id": "12857823",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-21 11:30:38",
      "description": "Just seen this deadlock while running {{SegmentCompactionIT}}:\n\n{noformat}\n\"pool-1-thread-47\":\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:910)\n\t- waiting to lock <0x0000000700110bd0> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.readSegment(SegmentTracker.java:211)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:149)\n\t- locked <0x0000000700328b88> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:154)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:121)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:103)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.get(CompactionMap.java:93)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.uncompact(SegmentWriter.java:1074)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1098)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:85)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.updated(MemoryNodeBuilder.java:214)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:81)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.remove(MemoryNodeBuilder.java:355)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.modify(SegmentCompactionIT.java:448)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:430)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:406)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\"TarMK flush thread [target/SegmentCompactionIT9065337410200765612dir], active since Fri Aug 21 06:53:18 GMT+00:00 2015, previous max duration 40846ms\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:145)\n\t- waiting to lock <0x0000000700328b88> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:154)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.compress(PersistedCompactionMap.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.remove(PersistedCompactionMap.java:155)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.remove(CompactionMap.java:108)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.cleanup(FileStore.java:699)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.flush(FileStore.java:628)\n\t- locked <0x0000000700110bd0> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\t- locked <0x000000070017f1c0> (a java.util.concurrent.atomic.AtomicReference)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore$1.run(FileStore.java:413)\n\tat java.lang.Thread.run(Thread.java:745)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.BackgroundThread.run(BackgroundThread.java:70)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Deadlock between persisted compaction map and cleanup 2"
   },
   {
      "_id": "12857815",
      "assignee": "baedke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-08-21 10:41:54",
      "description": "As part of OAK-2599 support for excluding and including paths were added to Lucene index. It would be good to have such a support enabled for PropertyIndexe also",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support including and excluding paths for PropertyIndex"
   },
   {
      "_id": "12857550",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-08-20 14:45:01",
      "description": "Most of the time NodeDocument.getNewestRevision() is able to quickly identify the newest revision, but sometimes the code falls to a more expensive calculation, which attempts to read through available {{_revisions}} and {{_commitRoot}} entries. If either of those maps are empty, the method will go through the entire revision history.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize NodeDocument.getNewestRevision()"
   },
   {
      "_id": "12857186",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-08-19 11:53:38",
      "description": "FDS on SAN/NAS storage is not efficient as it involves network call. In OAK. indexes are stored SAN/NAS and even idle system does lot of read system generated data. \n\nEnable caching in FDS so the reads are done locally and async upload to SAN/NAS\n\nSee [previous discussions|https://issues.apache.org/jira/browse/OAK-3005?focusedCommentId=14700801&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14700801]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting",
         "features",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Support caching in FileDataStoreService"
   },
   {
      "_id": "12856839",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-08-18 07:32:20",
      "description": "{{DocumentNodeSTore#retrieve(checkpoint)}} may throw an {{IllegalArgumentException}} via {{Revision.fromString(checkpoint)}}.\n\nThe javadocs say that it returns a {{NodeState}} or {{null}}. The exception prevents recovery of {{AsyncIndexUpdate}} from a bad recorded checkpoint.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore.retrieve() should not throw IllegalArgumentException"
   },
   {
      "_id": "12856168",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-14 14:06:12",
      "description": "A deadlock was detected while stopping the {{SegmentCompactionIT}} using the exposed MBean.\n\n{noformat}\nFound one Java-level deadlock:\n=============================\n\"pool-1-thread-23\":\n  waiting to lock monitor 0x00007fa8cf1f0488 (object 0x00000007a0081e48, a org.apache.jackrabbit.oak.plugins.segment.file.FileStore),\n  which is held by \"main\"\n\"main\":\n  waiting to lock monitor 0x00007fa8cc015ff8 (object 0x00000007a011f750, a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter),\n  which is held by \"pool-1-thread-23\"\n\nJava stack information for the threads listed above:\n===================================================\n\"pool-1-thread-23\":\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.writeSegment(FileStore.java:948)\n\t- waiting to lock <0x00000007a0081e48> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.flush(SegmentWriter.java:228)\n\t- locked <0x00000007a011f750> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.prepare(SegmentWriter.java:329)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeListBucket(SegmentWriter.java:447)\n\t- locked <0x00000007a011f750> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeList(SegmentWriter.java:698)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1190)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1154)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:85)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.updated(MemoryNodeBuilder.java:214)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:81)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setChildNode(MemoryNodeBuilder.java:346)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeAdded(AbstractRebaseDiff.java:211)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:527)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:531)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$2.childNodeChanged(MapRecord.java:404)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:488)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:394)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:488)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compareBranch(MapRecord.java:565)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:470)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.prepare(SegmentNodeStore.java:446)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.optimisticMerge(SegmentNodeStore.java:471)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.execute(SegmentNodeStore.java:527)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:205)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:426)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:399)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\"main\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.dropCache(SegmentWriter.java:850)\n\t- waiting to lock <0x00000007a011f750> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.close(FileStore.java:830)\n\t- locked <0x00000007a0081e48> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT.tearDown(SegmentCompactionIT.java:266)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\n\nFound 1 deadlock.\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Deadlock when closing a concurrently used FileStore"
   },
   {
      "_id": "12855498",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-08-12 09:13:41",
      "description": "Currently the cost returned by Lucene index is a function of number of indexed documents present in the index. If the number of indexed entries are high then it might reduce chances of this index getting selected if some property index also support of the property constraint.\n\n{noformat}\n/jcr:root/content/freestyle-cms/customers//element(*, cq:Page)\n[(jcr:content/@title = 'm' or jcr:like(jcr:content/@title, 'm%')) \nand jcr:content/@sling:resourceType = '/components/page/customer\u2019]\n{noformat}\n\nConsider above query with following index definition\n* A property index on resourceType\n* A Lucene index for cq:Page with properties {{jcr:content/title}}, {{jcr:content/sling:resourceType}} indexed and also path restriction evaluation enabled\n\nNow what the two indexes can help in\n# Property index\n## Path restriction\n## Property restriction on  {{sling:resourceType}}\n# Lucene index\n## NodeType restriction\n## Property restriction on  {{sling:resourceType}}\n## Property restriction on  {{title}}\n## Path restriction\n\nNow cost estimate currently works like this\n* Property index - {{f(indexedValueEstimate, estimateOfNodesUnderGivenPath)}}\n** indexedValueEstimate - For 'sling:resourceType=foo' its the approximate count for nodes having that as 'foo'\n** estimateOfNodesUnderGivenPath - Its derived from an approximate estimation of nodes present under given path\n* Lucene Index - {{f(totalIndexedEntries)}}\n\nAs cost of Lucene is too simple it does not reflect the reality. Following 2 changes can be done to make it better\n* Given that Lucene index can handle multiple constraints compared (4) to property index (2), the cost estimate returned by it should also reflect this state. This can be done by setting costPerEntry to 1/(no of property restriction evaluated)\n* Get the count for queried property value - This is similar to what PropertyIndex does and assumes that Lucene can provide that information in O(1) cost. In case of multiple supported property restriction this can be minima of all",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Lucene IndexPlanner should also account for number of property constraints evaluated while giving cost estimation"
   },
   {
      "_id": "12855447",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-08-12 05:14:23",
      "description": "Often it can be seen that all test from oak-solr module fail. And in all such failure following error is reported \n\n{noformat}\norg.apache.solr.common.SolrException: No such core: oak\n\tat org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:112)\n\tat org.apache.solr.client.solrj.request.AbstractUpdateRequest.process(AbstractUpdateRequest.java:118)\n\tat org.apache.solr.client.solrj.SolrServer.add(SolrServer.java:116)\n\tat org.apache.solr.client.solrj.SolrServer.add(SolrServer.java:102)\n\tat org.apache.jackrabbit.oak.plugins.index.solr.query.SolrQueryIndexTest.testQueryOnIgnoredExistingProperty(SolrQueryIndexTest.java:330)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n{noformat}\n\nMost recent failure in https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/325/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Solr test often fail with  No such core: oak"
   },
   {
      "_id": "12852580",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-08-06 13:46:49",
      "description": "along with OAK-3170 and in the light of OAK-3165 i would like to create another benchmark test that adds 1-many members to groups.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "benchmark"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Benchmark for adding group members"
   },
   {
      "_id": "12852473",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-08-06 05:21:35",
      "description": "Consistency checker for data/blob store to report any missing blobs which can result as a consequence of erroneous gc or extraneous factors. \n* Will report any missing blob ids\n* Path of nodes referring to those blobs\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Consistency checker for data/blob store"
   },
   {
      "_id": "12852469",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-08-06 05:11:57",
      "description": "Container issue for improvements and reporting tools for the blob garbage collection.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "[Blob GC] Improvements/tools for blob garbage collection"
   },
   {
      "_id": "12851653",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-05 10:39:15",
      "description": "Just seen this deadlock while running {{SegmentCompactionIT}}:\n\n{noformat}\n\"TarMK flush thread [target/SegmentCompactionIT3250704011919039778dir], active since Wed Aug 05 09:25:57 GMT+00:00 2015, previous max duration 2325ms\" daemon prio=10 tid=0x00007f5674872800 nid=0x5dc8 waiting for monitor entry [0x00007f5666a00000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:145)\n\t- waiting to lock <0x0000000707fc7fe8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:154)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.compress(PersistedCompactionMap.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.remove(PersistedCompactionMap.java:155)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.remove(CompactionMap.java:108)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.cleanup(FileStore.java:694)\n\t- locked <0x000000070017b330> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.flush(FileStore.java:628)\n\t- locked <0x000000070017b330> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\t- locked <0x00000007000aed60> (a java.util.concurrent.atomic.AtomicReference)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore$1.run(FileStore.java:413)\n\tat java.lang.Thread.run(Thread.java:745)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.BackgroundThread.run(BackgroundThread.java:70)\n\n\"pool-1-thread-34\" prio=10 tid=0x00007f55ec002800 nid=0x5dea waiting for monitor entry [0x00007f56648de000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:904)\n\t- waiting to lock <0x000000070017b330> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.readSegment(SegmentTracker.java:210)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:149)\n\t- locked <0x0000000707fc7fe8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:215)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:121)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:103)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.get(CompactionMap.java:93)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.uncompact(SegmentWriter.java:1074)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1098)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1154)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1154)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1154)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.<init>(SegmentNodeStore.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:433)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:406)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Deadlock between persisted compaction map and cleanup"
   },
   {
      "_id": "12851413",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-04 14:58:15",
      "description": "OAK-2734 introduced retry cycles and the option to force compaction when all cycles fail. However OAK-2192 introduced a performance regression: each compaction cycle takes in the order of the size of the repository to complete instead of in the order of the number of remaining changes to compact. This is caused by comparing compacted with pre-compacted node states, which is necessary to avoid mixed segments (aka OAK-2192). To fix the performance regression I propose to pass the compactor an additional node state (the 'onto' state). The diff would then be calculated across the pre compacted states, which performs in the order of number of changes. The changes would then be applied to the 'onto' state, which is a compacted state to avoid mixed segments. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction slow on repository with continuous writes"
   },
   {
      "_id": "12851063",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-03 10:19:01",
      "description": "It looks like even if a component logs out a session, but keeps a reference to it around this will still prevent GC from running, as the session will wrap a _root_ reference pointing to the moment/revision when the session was last accessed.\n\nExtract from jvisualvm:\n{code}\nthis     - value: org.apache.jackrabbit.oak.plugins.segment.SegmentId #505\n <- [106]     - class: org.apache.jackrabbit.oak.plugins.segment.SegmentId[], value: org.apache.jackrabbit.oak.plugins.segment.SegmentId #505\n  <- refids     - class: org.apache.jackrabbit.oak.plugins.segment.Segment, value: org.apache.jackrabbit.oak.plugins.segment.SegmentId[] #67 (120 items)\n   <- segment     - class: org.apache.jackrabbit.oak.plugins.segment.SegmentId, value: org.apache.jackrabbit.oak.plugins.segment.Segment #81\n    <- [124]     - class: org.apache.jackrabbit.oak.plugins.segment.SegmentId[], value: org.apache.jackrabbit.oak.plugins.segment.SegmentId #496\n     <- refids     - class: org.apache.jackrabbit.oak.plugins.segment.Segment, value: org.apache.jackrabbit.oak.plugins.segment.SegmentId[] #17 (204 items)\n      <- segment     - class: org.apache.jackrabbit.oak.plugins.segment.SegmentId, value: org.apache.jackrabbit.oak.plugins.segment.Segment #17\n       <- segmentId     - class: org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState, value: org.apache.jackrabbit.oak.plugins.segment.SegmentId #551\n        <- base     - class: org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder, value: org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState #5557\n         <- builder     - class: org.apache.jackrabbit.oak.core.MutableRoot, value: org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder #5652\n          <- root     - class: org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl$1, value: org.apache.jackrabbit.oak.core.MutableRoot #151\n           <- sd     - class: com.adobe.granite.repository.impl.CRX3SessionImpl, value: org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl$1 #117\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Unreleased closed sessions can keep a root reference from getting collected"
   },
   {
      "_id": "12849923",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-07-29 12:38:43",
      "description": "OAK-2619 introduced the possibility to run the same upgrade repeatedly and achieve incremental upgrades. This reduces the time taken for {{CommitHook}} processing, because the diff is reduced.\n\nHowever, for incremental upgrades to be really useful, the content-copy phase needs to be fast. Currently an optimization that was proposed in OAK-2626 was lost due to the implementation of a better solution to some part of the problem. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve binary comparison during repeated upgrades"
   },
   {
      "_id": "12849891",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-07-29 10:10:48",
      "description": "Currently the documentation at http://jackrabbit.apache.org/oak/docs/osgi_config.html#SegmentNodeStore only documents the properties\n# repository.home and\n# tarmk.size\nAll the other properties like customBlobStore, tarmk.mode, .... are not documented. Please extend that. Also it would be good, if the table could be extended with what type is supported for the individual properties.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Extend documentation for SegmentNodeStoreService in http://jackrabbit.apache.org/oak/docs/osgi_config.html#SegmentNodeStore"
   },
   {
      "_id": "12849878",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-07-29 09:37:11",
      "description": "{{FileStore.newFileStore(dir).withCacheSize(2048)}} results in\n\n{noformat}Max memory must not be negative\njava.lang.IllegalArgumentException: Max memory must not be negative\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS.setMaxMemory(CacheLIRS.java:464)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS.<init>(CacheLIRS.java:163)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Builder.build(CacheLIRS.java:1537)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Builder.build(CacheLIRS.java:1533)\n\tat org.apache.jackrabbit.oak.plugins.segment.StringCache.<init>(StringCache.java:52)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.<init>(SegmentTracker.java:126)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:343)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:84)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore$Builder.create(FileStore.java:294)\n{noformat}\n\nThere is an integer overflow cause by using ints instead of longs to specify the cache size.\n\n[~tmueller], could you have a look?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "IAE when specifiying 2G cache for FileStore"
   },
   {
      "_id": "12849650",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-07-28 15:32:47",
      "description": "For the rendering of some pages we have to create a lot of sessions. Around 9% of the rendering time is spent inside of RepositoryImpl.login. Half of this time is spent creating the exception in SessionStats. Therefore, it would be useful if the recording of the exception could be disabled to improve the performance.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make it possible to disable recording of stack trace in SessionStats"
   },
   {
      "_id": "12849611",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-07-28 13:20:30",
      "description": "Currently in oak-lucene where ever call is made to Lucene it passes Version.LUCENE_47 as hardcoded version. To enable easier upgrade of Lucene and hence change of defaults for fresh setup this version should be instead based on {{IndexFormatVersion}}.\n\nSay\n* For IndexFormatVersion set to V2 (current default) - Lucene version used is LUCENE_47\n* For IndexFormatVersion set to V3 (proposed) - Lucene version used would be per Lucene library version\n\nIf the index is reindexed then it would automatically be updated to the latest revision",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Lucene Version should be based on IndexFormatVersion"
   },
   {
      "_id": "12849608",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-07-28 13:13:17",
      "description": "We should look into updating the Lucene version to 6.x. Java 8 is the minimum Java version required\n\nNote this is to be done for trunk only",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Update Lucene to 6.x series"
   },
   {
      "_id": "12848549",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-07-23 13:02:19",
      "description": "Currently, the BlobStore interface has a method \"String writeBlob(InputStream in)\". This issue is about adding a new method \"String writeBlob(String type, InputStream in)\", for the following reasons (in no particular order):\n\n* Store some binaries (for example Lucene index files) in a different place, in order to safely and quickly run garbage collection just on those files.\n\n* Store some binaries in a slow, some in a fast storage or location.\n\n* Disable calculating the content hash (de-duplication) for some binaries.\n\n* Store some binaries in a shared storage (for fast cross-repository copying), and some in local storage.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DataStore / BlobStore: add a method to pass a \"type\" when writing"
   },
   {
      "_id": "12848545",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-07-23 12:50:01",
      "description": "When using {{CLEAN_OLD}} it might happen that segments of the persisted compaction map get collected. --The reason for this is that only the segment containing the root of the map is pinned ({{SegmentId#pin}}), leaving other segments of the compaction map eligible for collection once old enough.--\n\n{noformat}\norg.apache.jackrabbit.oak.plugins.segment.SegmentNotFoundException: Segment 95cbb3e2-3a8c-4976-ae5b-6322ff102731 not found\n        at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:919)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.getSegment(SegmentTracker.java:134)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:108)\n        at org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n        at org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:154)\n        at org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n        at org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:118)\n        at org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:100)\n        at org.apache.jackrabbit.oak.plugins.segment.CompactionMap.get(CompactionMap.java:93)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.uncompact(SegmentWriter.java:1023)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1033)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.<init>(SegmentNodeStore.java:418)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:204)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "SNFE in persisted comapation map when using CLEAN_OLD"
   },
   {
      "_id": "12846785",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-07-22 08:04:20",
      "description": "The compaction map might be expensive. See OAK-2862 for the analysis. We should find ways to lower the impact of this on offline compaction. One option would be to make the compress cycle configurable, which would require more heap. Another option would be to leverage the persisted compaction map here also.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make compaction map more efficient for offline compaction"
   },
   {
      "_id": "12846450",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-07-21 07:41:21",
      "description": "as noted on OAK-3052, it would be good to have a way to skip the estimation if needed  and this can be easily achieved with the config we already in place for the threshold.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Skip compaction estimation if threshold is 0"
   },
   {
      "_id": "12845515",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-07-16 08:30:51",
      "description": "UnsavedModifications performance degrades when used in combination with the MapDB backed MapFactory. Calls become more and more expensive the longer the instance is in use. The is caused by a limitation of MapDB, which does not remove empty BTree nodes.\n\nA test performed with random paths added to the map and later removed again in a loop shows a increase to roughly 1 second to read keys present in the map when the underlying data file is about 50MB in size.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Performance degradation of UnsavedModifications on MapDB"
   },
   {
      "_id": "12845482",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-07-16 04:38:56",
      "description": "At times the CopyOnWrite reports following exception\n\n{noformat}\n15.07.2015 14:20:35.930 *WARN* [pool-58-thread-1] org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate The async index update failed\norg.apache.jackrabbit.oak.api.CommitFailedException: OakLucene0004: Failed to close the Lucene index\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:204)\n\tat org.apache.jackrabbit.oak.plugins.index.IndexUpdate.leave(IndexUpdate.java:219)\n\tat org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:63)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:56)\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.updateIndex(AsyncIndexUpdate.java:366)\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:311)\n\tat org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105)\n\tat org.quartz.core.JobRunShell.run(JobRunShell.java:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.FileNotFoundException: _2s7.fdt\n\tat org.apache.lucene.store.FSDirectory.fileLength(FSDirectory.java:261)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier$CopyOnWriteDirectory$COWLocalFileReference.fileLength(IndexCopier.java:837)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier$CopyOnWriteDirectory.fileLength(IndexCopier.java:607)\n\tat org.apache.lucene.index.SegmentCommitInfo.sizeInBytes(SegmentCommitInfo.java:141)\n\tat org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529)\n\tat org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:502)\n\tat org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:508)\n\tat org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:618)\n\tat org.apache.lucene.index.IndexWriter.doFlush(IndexWriter.java:3147)\n\tat org.apache.lucene.index.IndexWriter.flush(IndexWriter.java:3123)\n\tat org.apache.lucene.index.IndexWriter.closeInternal(IndexWriter.java:988)\n\tat org.apache.lucene.index.IndexWriter.close(IndexWriter.java:932)\n\tat org.apache.lucene.index.IndexWriter.close(IndexWriter.java:894)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorContext.closeWriter(LuceneIndexEditorContext.java:192)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:202)\n\t... 10 common frames omitted\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "AsyncIndexer fails due to FileNotFoundException thrown by CopyOnWrite logic"
   },
   {
      "_id": "12844356",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-07-11 07:54:53",
      "description": "It can happen that text can be extracted from same binary multiple times in a given indexing cycle. This can happen due to 2 reasons\n\n# Multiple Lucene indexes indexing same node - A system might have multiple Lucene indexes e.g. a global Lucene index and an index for specific nodeType. In a given indexing cycle same file would be picked up by both index definition and both would extract same text\n# Aggregation - With Index time aggregation same file get picked up multiple times due to aggregation rules\n\nTo avoid the wasted effort for duplicate text extraction from same file in a given indexing cycle it would be better to have an expiring cache which can hold on to extracted text content for some time. The cache should have following features\n# Limit on total size\n# Way to expire the content using [Timed Evicition|https://code.google.com/p/guava-libraries/wiki/CachesExplained#Timed_Eviction] - As chances of same file getting picked up are high only for a given indexing cycle it would be better to expire the cache entries after some time to avoid hogging memory unnecessarily \n\nSuch a cache would provide following benefit\n# Avoid duplicate text extraction - Text extraction is costly and has to be minimized on critical path of {{indexEditor}}\n# Avoid expensive IO specially if binary content are to be fetched from a remote {{BlobStore}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cache recently extracted text to avoid duplicate extraction"
   },
   {
      "_id": "12844158",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-07-10 12:09:14",
      "description": "Storing binaries in Mongo puts lots of pressure on the MongoDB for reads. To reduce the read load it would be useful to have a filesystem based cache of frequently used binaries. \n\nThis would be similar to CachingFDS (OAK-3005) but would be implemented on top of BlobStore API. \n\nRequirements\n* Specify the max binary size which can be cached on file system\n* Limit the size of all binary content present in the cache\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Caching BlobStore implementation "
   },
   {
      "_id": "12843395",
      "assignee": "egli",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-07-08 04:11:15",
      "description": "Following test failure was seen [here|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/248/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=unittesting/testReport/junit/org.apache.jackrabbit.oak.plugins.document/JournalTest/cleanupTest/]\n\n{noformat}\njava.lang.AssertionError: expected:<0> but was:<1>\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.failNotEquals(Assert.java:647)\n\tat org.junit.Assert.assertEquals(Assert.java:128)\n\tat org.junit.Assert.assertEquals(Assert.java:472)\n\tat org.junit.Assert.assertEquals(Assert.java:456)\n\tat org.apache.jackrabbit.oak.plugins.document.JournalTest.cleanupTest(JournalTest.java:183)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "JournalTest.cleanupTest failure on CI"
   },
   {
      "_id": "12843210",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-07-07 15:01:49",
      "description": "As mentioned in [OAK-2131|https://issues.apache.org/jira/browse/OAK-2131?focusedCommentId=14616391&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14616391] there can be a situation wherein the LastRevRecoveryAgent updates some nodes in the tree but not the root. This seems to happen due to OAK-2131's change in the Commit.applyToCache (where paths to update are collected via tracker.track): in that code, paths which are non-root and for which no content has changed (and mind you, a content change includes adding _deleted, which happens by default for nodes with children) are not 'tracked', ie for those the _lastRev is not update by subsequent backgroundUpdate operations - leaving them 'old/out-of-date'. This seems correct as per description/intention of OAK-2131 where the last revision can be determined via the commitRoot of the parent. But it has the effect that the LastRevRecoveryAgent then finds those intermittent nodes to be updated while as the root has already been updated (which is at first glance non-intuitive).\n\nI'll attach a test case to reproduce this.\n\nPerhaps this is a bug, perhaps it's ok. [~mreutegg] wdyt?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "LastRevRecoveryAgent can update _lastRev of children but not the root"
   },
   {
      "_id": "12842864",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-07-06 11:38:58",
      "description": "A lot of SegmentNotFoundExceptions happen during compaction (offline or online) and these are repeatable exceptions. I would like to add a 'trace' log to make it easy to follow up on the progress and get an indication of where the SNFE is happening, without relying on offline intervention (via oak-run).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction should trace log the current processed path"
   },
   {
      "_id": "12842854",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-07-06 10:36:52",
      "description": "It looks like the compaction estimation mechanism doesn't currently verify the type of the property it tries to load as binary, it will assume that the following call _property.getValue(BINARIES)_  will return nothing if the type is not BINARY. This behavior has changed since this code was written, the way it works now is the method will try to convert to BINARY the property's value.\nI'm assuming OAK-3007 is a side-effects of this change.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction Estimation should type check binary properties"
   },
   {
      "_id": "12842853",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-07-06 10:34:13",
      "description": "I suggest to remove the throws clause and fix the affected clients. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "FileStore.size doesn't throw IOException but declares it as thrown"
   },
   {
      "_id": "12842397",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-07-02 18:08:38",
      "description": "As explained in OAK-1966 diff logic makes a call like\n\nbq. db.nodes.find({ _id: { $gt: \"3:/content/foo/01/\", $lt: \"3:/content/foo010\" }, _modified: { $gte: 1405085300 } }).sort({_id:1})\n\nFor better and deterministic query performance we would need to create a compound index like \\{_modified:1, _id:1\\}. This index would ensure that Mongo does not have to perform object scan while evaluating such a query.\n\nCare must be taken that index is only created by default for fresh setup. For existing setup we should expose a JMX operation which can be invoked by system admin to create the required index as per maintenance window",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Add a compound index for _modified + _id"
   },
   {
      "_id": "12842389",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-07-02 17:58:34",
      "description": "As part of OAK-3062 [~mreutegg] suggested\n\n{quote}\nAs a further optimization we could also limit the lower bound of the _modified\nrange. The revision GC does not need to check documents with a _deletedOnce\nagain if they were not modified after the last successful GC run. If they\ndidn't change and were considered existing during the last run, then they\nmust still exist in the current GC run. To make this work, we'd need to\ntrack the last successful revision GC run. \n{quote}\n\nLowest last validated _modified can be possibly saved in settings collection and reused for next run",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use a lower bound in VersionGC query to avoid checking unmodified once deleted docs"
   },
   {
      "_id": "12842257",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-07-02 08:55:08",
      "description": "Previous (aka split) documents contain old revisions and are immutable documents. Those documents should go into the persistent cache to reduce calls to the underlying DocumentStore.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Persistent cache for previous documents"
   },
   {
      "_id": "12842186",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2015-07-02 04:29:16",
      "description": "Some of RemoteServerIT failing with Address already in use. Possibly the test setup needs to be changed to use random available port \n\n{noformat}\njava.net.BindException: Address already in use\n\tat sun.nio.ch.Net.bind0(Native Method)\n\tat sun.nio.ch.Net.bind(Net.java:444)\n\tat sun.nio.ch.Net.bind(Net.java:436)\n\tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)\n\tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\tat org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)\n\tat org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)\n\tat org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)\n\tat org.eclipse.jetty.server.Server.doStart(Server.java:291)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)\n\tat org.apache.jackrabbit.oak.remote.http.handler.RemoteServer.start(RemoteServer.java:54)\n\tat org.apache.jackrabbit.oak.remote.http.handler.RemoteServerIT.setUp(RemoteServerIT.java:134)\n{noformat}\n\n[1] https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/236/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "RemoteServerIT failing due to address already in use"
   },
   {
      "_id": "12841717",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-30 15:16:32",
      "description": "The hand crafted segment cache in {{SegmentTracker}} is prone to lock contentions in concurrent access scenarios. As {{SegmentNodeStore#merge}} might also end up acquiring this lock while holding the commit semaphore the situation can easily lead to many threads being blocked on the commit semaphore. The {{SegmentTracker}} cache doesn't differentiate between read and write access, which means that reader threads can block writer threads. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting",
         "resilience",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve segment cache in SegmentTracker"
   },
   {
      "_id": "12841676",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-06-30 12:00:00",
      "description": "If the background indexing fails for some reason it logs the exception for the first time then it logs the exception like _The index update failed ..._. After that if indexing continues to fail then no further logging is done so as to avoid creating noise.\n\nThis poses a problem on long running system where original exception might not be noticed and index does not show updated result. For such cases we should expose the indexing health as part of {{IndexStatsMBean}}. Also we can provide the last recorded exception. \n\nAdministrator can then check for MBean and enable debug logs for further troubleshooting",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "IndexStatsMBean should provide some details if the async indexing is failing"
   },
   {
      "_id": "12841626",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-30 09:17:12",
      "description": "Currently compaction is skipped if the compaction gain estimator determines that less than 10% of space could be reclaimed. Instead of relying on a hard coded value of 10% we should make this configurable. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Make compaction gain estimate threshold configurable"
   },
   {
      "_id": "12841623",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-30 09:13:31",
      "description": "When compaction is started on a new and sufficiently small repository such that there is yet no tar reader the compaction gain estimator logs the somewhat confusing message {{gain is 0% (0/0) or (0 B/0 B)}}. \n\nWe should improve the logging for this case.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve compaction gain estimation logging for the case where there are no tar readers"
   },
   {
      "_id": "12841614",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-06-30 08:53:06",
      "description": "The {{oak-it}} module only contains the single {{oak-it-osgi}} module, which in turn consists of a single test class. \n\nI suggest to at least move {{oak-it-osgi}} to the top level reactor to be consistent with the flat module hierarchy we adopted. IMO an even better solution would be to move the single test class to {{oak-run}}. Not sure whether this is viable though due to the custom assembly necessary. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move oak-it-osgi to top level "
   },
   {
      "_id": "12841567",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2015-06-30 05:03:47",
      "description": "Most of the test in {{RemoteServerIT}} at times fail on the CI server [1] with following exception\n\n{noformat}\nError Message\n\n/home/jenkins/jenkins-slave/workspace/Apache%20Jackrabbit%20Oak%20matrix/jdk/latest1.7/label/Ubuntu/nsfixtures/SEGMENT_MK/profile/unittesting/oak-remote/target/test-classes/org/apache/jackrabbit/oak/remote/http/handler/addNodeMultiPathProperty.json (No such file or directory)\nStacktrace\n\njava.io.FileNotFoundException: /home/jenkins/jenkins-slave/workspace/Apache%20Jackrabbit%20Oak%20matrix/jdk/latest1.7/label/Ubuntu/nsfixtures/SEGMENT_MK/profile/unittesting/oak-remote/target/test-classes/org/apache/jackrabbit/oak/remote/http/handler/addNodeMultiPathProperty.json (No such file or directory)\n\tat java.io.FileInputStream.open(Native Method)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:146)\n\tat com.google.common.io.Files$FileByteSource.openStream(Files.java:127)\n\tat com.google.common.io.Files$FileByteSource.openStream(Files.java:117)\n\tat com.google.common.io.ByteSource$AsCharSource.openStream(ByteSource.java:404)\n\tat com.google.common.io.CharSource.read(CharSource.java:155)\n\tat com.google.common.io.Files.toString(Files.java:391)\n\tat org.apache.jackrabbit.oak.remote.http.handler.RemoteServerIT.load(RemoteServerIT.java:119)\n\tat org.apache.jackrabbit.oak.remote.http.handler.RemoteServerIT.testPatchLastRevisionAddMultiPathProperty(RemoteServerIT.java:1199)\n{noformat}\n\n[1] https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/232/testReport/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "RemoteServerIT test are failing on the CI server"
   },
   {
      "_id": "12841279",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-06-29 09:18:49",
      "description": "A DocumentNodeStore cluster currently shows a conflict behavior, which\nis not intuitive. A modification may fail with a conflict even though\nbefore and after the conflict, the external change is not visible to\nthe current session. There are two aspects to this issue.\n\n1) a modification may conflict with a change done on another cluster\nnode, which is committed but not yet visible on the current cluster node.\n\n2) even after the InvalidItemStateException caused by the conflict, a\nrefreshed session may still not see the external change.\n\nThe first aspect is a fundamental design decision and cannot be changed\neasily.\n\nThe second part can be addressed by suspending the commit until the external\nconflict becomes visible on the current cluster node. This would at least\navoid the awkward situation where the external change is not visible after\nthe InvalidItemStateException.\n\nThe system would also become more deterministic. A commit currently goes\ninto a number of retries with exponential back off, but there's no guarantee\nthe external modification becomes visible within those retries. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Suspend commit on conflict"
   },
   {
      "_id": "12840750",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-06-26 06:43:59",
      "description": "update.limit decides whether a commit is persisted using a branch or not. The default is 10000 (and can be overridden using the system property).\n\nA typical call pattern in JCR is to persist batches of ~1024 nodes. These translate to more than 10000 changes (see PackageImportIT), due to JCR properties, and also indexing commit hooks.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "DocumentRootBuilder: revisit update.limit default"
   },
   {
      "_id": "12840562",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-06-25 14:52:35",
      "description": "This is a fix for OAK-2927 which has a broken reindex detection mechanism. The issue is closed so I cannot reopen it and I'm creating a new one for the fix.\n\nThe main issue is that _root_ will never be empty, the check needs to be on the #enter method against the _before_ node",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ReferenceEditor reindex detection broken"
   },
   {
      "_id": "12840148",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-06-24 09:47:10",
      "description": "For GC on a shared repository (OAK-1849) it is beneficial to add a JMX Mbean which can provide visibility on the state of GC. It could possibly show:\n* Various repositories registered in the DataStore\n* State of the blob reference collection for the registered repositories\n* Time of the reference files for each registered repository\n* Time interval for the earliest and the latest reference file of the registered repositories. This could be used to possibly automate the sweep phase if the time interval is less than a configured value.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "[Blob GC] Mbean for reporting shared repository GC stats"
   },
   {
      "_id": "12839799",
      "assignee": "mreutegg",
      "components": [],
      "created": "2015-06-23 09:38:48",
      "description": "Most queries on MongoDB are usually rather fast and the TreeLock acquired in MongoDocumentStore (to ensure cache consistency) is released rather quickly. However there may be cases when a query is more expensive and a TreeLock is held for a long time. This may block other threads from querying MongoDB and limit concurrency.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Long running MongoDB query may block other threads"
   },
   {
      "_id": "12839549",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-06-22 13:23:29",
      "description": "(From an earlier [post on the list|http://markmail.org/thread/mkrvhkfabit4osli]) The DocumentNodeStore.backgroundWrite goes through the heavy work of updating the lastRev for all pending changes and does so in a hierarchical-depth-first manner. Unfortunately, if the pending changes all come from separate commits (as does not sound so unlikely), the updates are sent in individual update calls to mongo (whenever the lastRev differs). Which, if there are many changes, results in many calls to mongo.\n\nOAK-2066 is about extending the DocumentStore API with a batch-update method. That one, once available, should thus be used in the {{backgroundWrite}} as well.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use batch-update in backgroundWrite"
   },
   {
      "_id": "12838792",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-18 13:40:24",
      "description": "The SegmentStore cache size calculation ignores the size of the field Segment.string (a concurrent hash map). It looks like a regular segment in a memory mapped file has the size 1024, no matter how many strings are loaded in memory. This can lead to out of memory. There seems to be no way to limit (configure) the amount of memory used by strings. In one example, 100'000 segments are loaded in memory, and 5 GB are used for Strings in that map.\n\nWe need a way to configure the amount of memory used for that. This seems to be basically a cache. OAK-2688 does this, but it would be better to have one cache with a configurable size limit.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting",
         "resilience",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentStore cache does not take \"string\" map into account"
   },
   {
      "_id": "12838403",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-06-17 07:46:38",
      "description": "As visible when running {{LoginWithMembershipTest}} default login performance (which uses the {{o.a.j.oak.security.principal.PrincipalProviderImpl}} to lookup the complete set of principals) suffers when a given user is member of a huge number of groups (see also OAK-2690 for benchmark data).\n\nWhile using dynamic group membership (and thus a custom {{PrincipalProvider}} would be the preferable way to deal with this, we still want to optimize {{PrincipalProvider.getPrincipals(String userId}} for the default implementation.\n\nWith the introduction of a less generic implementation in OAK-2690, we might be able to come up with an optimization that makes use of the very implementation details of the user management while at the same time being able to properly secure it as we won't need to extend the public API.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve login performance with huge group membership"
   },
   {
      "_id": "12838394",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-06-17 07:00:23",
      "description": "This subtask is about spawning out a [comment|https://issues.apache.org/jira/browse/OAK-2829?focusedCommentId=14588114&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14588114] on OAK-2829 re optimizing docCache invalidation using the newly introduced external diff journal:\n\n{quote}\nAttached OAK-2829-improved-doc-cache-invaliation.patch which is a suggestion on how to avoid invalidating the entire document cache when doing a {{backgroundRead}} but instead making use of the new journal: ie only invalidate from the document cache what has actually changed.\n\nI'd like to get an opinion ([~mreutegg], [~chetanm]?) on this first, I have a load test pending locally which found invalidation of the document cache to be the slowest part thus wanted to optimize this first.\n\nOpen still/next:\n * also invalidate only necessary parts from the docChildrenCache\n * junits for all of these\n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize docCache and docChildrenCache invalidation by filtering using journal"
   },
   {
      "_id": "12838393",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-06-17 06:56:55",
      "description": "This subtask is about spawning out a [comment|https://issues.apache.org/jira/browse/OAK-2829?focusedCommentId=14585733&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14585733] from [~chetanm] re JournalGC:\n{quote}\nFurther looking at JournalGarbageCollector ... it would be simpler if you record the journal entry timestamp as an attribute in JournalEntry document and then you can delete all the entries which are older than some time by a simple query. This would avoid fetching all the entries to be deleted on the Oak side\n{quote}\nand a corresponding [reply|https://issues.apache.org/jira/browse/OAK-2829?focusedCommentId=14585870&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14585870] from myself:\n{quote}\nRe querying by timestamp: that would indeed be simpler. With the current set of DocumentStore API however, I believe this is not possible. But: [DocumentStore.query|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentStore.java#L127] comes quite close: it would probably just require the opposite of that method too: \n{code}\n    public <T extends Document> List<T> query(Collection<T> collection,\n                                              String fromKey,\n                                              String toKey,\n                                              String indexedProperty,\n                                              long endValue,\n                                              int limit) {\n{code}\n.. or what about generalizing this method to have both a {{startValue}} and an {{endValue}} - with {{-1}} indicating when one of them is not used?\n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Simplify JournalGarbageCollector using a dedicated timestamp property"
   },
   {
      "_id": "12837604",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-06-13 16:27:58",
      "description": "See <https://people.apache.org/~fhanik/jdbc-pool/jdbc-pool.html>.\n\nIn addition, this is the datasource used in Sling's datasource service, so it's closer to what people will use in practice.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RDB: switch to tomcat datasource implementation "
   },
   {
      "_id": "12837067",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-06-11 07:43:18",
      "description": "The fast result size option in OAK-2926 should be configurable, for example over OSGi.\n\nThe resultFetchSize should be configurable as well. Currently it is hardcoded (PREFETCH_MAX = 100).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fast result size estimate: OSGi configuration"
   },
   {
      "_id": "12836776",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2015-06-10 09:18:44",
      "description": "http://jackrabbit.apache.org/oak/docs/command_line.html points to http://jackrabbit.apache.org/oak/docs/oak-mongo-js/oak.html, which doesn't exit. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Broken link on documentation site"
   },
   {
      "_id": "12836742",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-06-10 06:16:51",
      "description": "Depending on startup sequence it can happen that {{DocumentNodeStore}} gets initialized multiple times. \n\nSo far with Mongo {{DocumentNodeStoreService}}  was only dependent on one external reference of {{BlobStore}}. However with RDB there are two more external reference for {{DataSource}} one for nodes and other for blobs. \n\nSCR (Felix Service Component Runtime) would invoke both {{bindDataSource}} and {{bindBlobDataSource}} and currently there is no check to avoid re initialization. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting",
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore gets initialized multiple time with RDB persistence"
   },
   {
      "_id": "12836065",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-06-08 05:52:42",
      "description": "The logged number of blobs being deleted also includes blobs which could not be deleted because their last modification timestamp was recent than the configured max age to be deleted",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "[Blob GC]: Undeleted blobs also being logged in deleted count"
   },
   {
      "_id": "12835667",
      "assignee": "edivad",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-06-05 10:02:46",
      "description": "When running on a mongo cluster, in case of high activity the async index could fail with the following exception.\n\nReproduced with LucenePropertyIndex.\n\n{noformat}\n10:55:13.069 [oak-scheduled-executor-5] WARN  o.a.j.o.p.index.AsyncIndexUpdate - [async] The index update failed\norg.apache.jackrabbit.oak.api.CommitFailedException: OakState0001: Unresolved conflicts in /:async\n\tat org.apache.jackrabbit.oak.plugins.commit.ConflictValidator.failOnMergeConflict(ConflictValidator.java:84) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.commit.ConflictValidator.propertyAdded(ConflictValidator.java:54) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.propertyAdded(EditorDiff.java:82) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:378) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeChanged(EditorDiff.java:148) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:52) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.spi.commit.EditorHook.processCommit(EditorHook.java:55) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:61) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch$InMemory.merge(DocumentNodeStoreBranch.java:528) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:219) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:171) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:158) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1466) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.mergeWithConcurrencyCheck(AsyncIndexUpdate.java:467) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.access$4(AsyncIndexUpdate.java:445) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate$AsyncUpdateCallback.<init>(AsyncIndexUpdate.java:201) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.updateIndex(AsyncIndexUpdate.java:372) ~[classes/:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:320) ~[classes/:na]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_60]\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304) [na:1.7.0_60]\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_60]\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.7.0_60]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_60]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_60]\n\tat java.lang.Thread.run(Thread.java:745) [na:1.7.0_60]\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Async index fails with OakState0001: Unresolved conflicts in /:async"
   },
   {
      "_id": "12834989",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-06-03 10:06:37",
      "description": "Long running sessions limit the efficient of revision gc as they keep reference to old node states. \n\nWe should consider to add an MBean through which all sessions can be enforced to refresh. This would provide clients with means to fine tune revision gc by first calling that MBean and then triggering a gc cycle. IMO this is preferable to directly enforcing a refresh from the garbage collector. The latter is too invasive and also not required when there are no long running sessions. Offering this functionality to clients as an additional knob to turn is safer. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "doc-impacting",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add MBean to enforce session refresh on all open sessions"
   },
   {
      "_id": "12834948",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-06-03 06:46:39",
      "description": "It appears that WAS wraps Oracle JDBC connection objects and throws upon setReadOnly():\n{noformat}\njava.sql.SQLException: DSRA9010E: 'setReadOnly' is not supported on the WebSphere java.sql.Connection implementation.\nat com.ibm.ws.rsadapter.spi.InternalOracleDataStoreHelper.setReadOnly(InternalOracleDataStoreHelper.java:369)\nat com.ibm.ws.rsadapter.jdbc.WSJdbcConnection.setReadOnly(WSJdbcConnection.java:3626)\nat org.apache.jackrabbit.oak.plugins.document.rdb.RDBConnectionHandler.getROConnection(RDBConnectionHandler.java:61)\n{noformat}\n\n...which of course is a bug in WAS (setReadOnly() is documented as a hint, the implementation is not supposed to throw an exception here); see also <http://www-01.ibm.com/support/docview.wss?uid=swg1PM58588>",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RDBConnectionHandler: log failures on setReadOnly() only once"
   },
   {
      "_id": "12834514",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-02 08:07:48",
      "description": "The sampling rate feature introduced with OAK-2595 is not efficient. It only prevents uuids from being stored in the bloom filter while the visited set is not affected and thus keeps growing. \n\nI will remove the feature again for now. We should look for a better solution once this becomes a problem. Will follow up on OAK-2939 re. this. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Sampling rate feature CompactionGainEstimate is not efficient"
   },
   {
      "_id": "12834513",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-02 08:06:25",
      "description": "The sampling rate feature introduced with OAK-2595 is not efficient. It only prevents uuids from being stored in the bloom filter while the visited set is not affected and thus keeps growing. \n\nI will remove the feature again for now. We should look for a better solution once this becomes a problem. Will follow up on OAK-2939 re. this. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Sampling rate feature CompactionGainEstimate is not efficient"
   },
   {
      "_id": "12834487",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-06-02 06:16:05",
      "description": "Currently, any order by union queries (including optimized OR XPATH) scan a much larger set when returning the results even when the individual queries are sorted by the index itself. \nWe should have a merge iterator which would scan a much smaller set as the individual queries would be sorted.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support merge iterator for union order by queries"
   },
   {
      "_id": "12834195",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-01 09:27:08",
      "description": "Currently compaction will be skipped if some rough estimation determines that there is not  enough memory to run. That estimation however assumes that each compaction cycle requires as much space as the compaction map already takes up. This is too conservative. Instead the amount of memory taken up by the last compaction cycle should be a better estimate. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Estimation of required memory for compaction is off"
   },
   {
      "_id": "12834183",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-06-01 08:37:19",
      "description": "DocumentNodeStore has some code related to off heap which makes use of Apache Directmemory (OAK-891). This feature was not much used and PersistentCache made this feature obsolete.\n\nRecently it was mentioned on Directmemory that there is not much activity going on [1] in that project and it might be referred to attic. In light of that we should remove this feature from Oak\n\n[1] http://markmail.org/thread/atia2ecaa2mugmjx",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove code related to directmemory for off heap caching"
   },
   {
      "_id": "12833968",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-05-30 09:39:08",
      "description": "Certain search terms can get split into very small wildcard tokens that will match a huge amount of items from the index, finally resulting in a OOME.\n\nFor example\n{code}\n/jcr:root//*[jcr:contains(., 'U=1*')]\n{code}\nwill translate into the following lucene query\n{code}\n:fulltext:\"u ( [set of all index terms stating with '1'] )\"\n{code}\nthis will break down when lucene will try to compute the score for the huge set of tokens:\n{code}\njava.lang.OutOfMemoryError: Java heap space\n        at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexFile.<init>(OakDirectory.java:201)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexFile.<init>(OakDirectory.java:155)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.<init>(OakDirectory.java:340)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.clone(OakDirectory.java:345)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.clone(OakDirectory.java:329)\n        at org.apache.lucene.codecs.lucene41.Lucene41PostingsReader$BlockDocsAndPositionsEnum.<init>(Lucene41PostingsReader.java:613)\n        at org.apache.lucene.codecs.lucene41.Lucene41PostingsReader.docsAndPositions(Lucene41PostingsReader.java:252)\n        at org.apache.lucene.codecs.BlockTreeTermsReader$FieldReader$SegmentTermsEnum.docsAndPositions(BlockTreeTermsReader.java:2233)\n        at org.apache.lucene.search.UnionDocsAndPositionsEnum.<init>(MultiPhraseQuery.java:492)\n        at org.apache.lucene.search.MultiPhraseQuery$MultiPhraseWeight.scorer(MultiPhraseQuery.java:205)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:618)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:491)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:448)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:281)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:269)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndex$1.loadDocs(LuceneIndex.java:352)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndex$1.computeNext(LuceneIndex.java:289)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndex$1.computeNext(LuceneIndex.java:280)\n        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndex$LucenePathCursor$1.hasNext(LuceneIndex.java:1026)\n        at com.google.common.collect.Iterators$7.computeNext(Iterators.java:645)\n        at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n        at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n        at org.apache.jackrabbit.oak.spi.query.Cursors$PathCursor.hasNext(Cursors.java:198)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndex$LucenePathCursor.hasNext(LuceneIndex.java:1047)\n        at org.apache.jackrabbit.oak.plugins.index.aggregate.AggregationCursor.fetchNext(AggregationCursor.java:88)\n        at org.apache.jackrabbit.oak.plugins.index.aggregate.AggregationCursor.hasNext(AggregationCursor.java:75)\n        at org.apache.jackrabbit.oak.spi.query.Cursors$ConcatCursor.fetchNext(Cursors.java:474)\n        at org.apache.jackrabbit.oak.spi.query.Cursors$ConcatCursor.hasNext(Cursors.java:466)\n        at org.apache.jackrabbit.oak.spi.query.Cursors$ConcatCursor.fetchNext(Cursors.java:474)\n        at org.apache.jackrabbit.oak.spi.query.Cursors$ConcatCursor.hasNext(Cursors.java:466)\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Certain searches cause lucene index to hit OutOfMemoryError"
   },
   {
      "_id": "12833739",
      "assignee": "frm",
      "components": [],
      "created": "2015-05-29 10:20:53",
      "description": "Oak currently exports *a lot* of packages even though those are only used by Oak itself. We should probably leverage OSGi subsystems here and only export the bare minimum to the outside world. This will simplify evolution of Oak internal APIs as with the current approach changes to such APIs always leak to the outside world. \n\nThat is, we should have an Oak OSGi sub-system as an deployment option. Clients would then only need to deploy that into their OSGi container and would only see APIs actually meant to be exported for everyone (like e.g. the JCR API). At the same time Oak could go on leveraging OSGi inside this subsystem.\n\ncc [~bosschaert] as you introduced us to this idea. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "modularization",
         "osgi",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Limit the scope of exported packages"
   },
   {
      "_id": "12833694",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-29 06:58:18",
      "description": "With the DocumentStore query API, large result sets can happen; and these are returned as List<Document>, potentially causing large amounts of memory to be allocated.\r\n\r\nIn the current implementation, the result list is generated based on a list of internal row presentations (RDBRow). These are currently freed when the method finishes. They should be freed as early as possible.\r\n\r\nFurthermore, when the result set gets big, RDBDocumentStore should log an error containing the call chain, so that the component doing the excessive query can be identified (it should use paging instead).\r\n\r\n(For completeness: we could also change the code to lazily populate the list; but that would be a bigger change)\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RDBDocumentStore: mitigate effects of large query result sets"
   },
   {
      "_id": "12833670",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-29 04:59:11",
      "description": "With OAK-2673, it's now possible to have hidden intermediate nodes created concurrently.\nSo, a scenario like:\n{noformat}\nstart -> /:hidden\nN1 creates /:hiddent/parent/node1\nN2 creates /:hidden/parent/node2\n{noformat}\nis allowed.\n\nBut, if N2's creation of {{parent}} got persisted later than that on N1, then N2 is currently able to delete {{parent}} even though there's {{node1}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Parent of unseen children must not be removable"
   },
   {
      "_id": "12833421",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-05-28 13:35:03",
      "description": "In a large migration its seen that {{ReferenceEditor}} {{newIds}} can consume lots of memory as it records all the uuid property. This system has 33 million uuid index and the set was consuming ~1.5G of memory\n\nWe should look into ways such that it does not have to maintain such a big in memory state",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ReferenceEditor newIds consuming lots of memory during migration"
   },
   {
      "_id": "12833348",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-05-28 08:42:27",
      "description": "When asking for the correct result size of a query, the complete result needs to be read, so that access rights checks are made, and (unless the index is known to be up-to-date, and can process all conditions) so that the existence and all query conditions are checked.\n\nJackrabbit 2.x supports a fast way to get an estimate of the result size, without doing access rights checks. See also JCR-3858.\n\nPlease note that according to the JCR API, NodeIterator.getSize() may return -1 (for \"unknown\"), and in Oak this is currently done if counting is slow. This would also need to be disabled if a fast result size estimate is needed.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fast result size estimate"
   },
   {
      "_id": "12833338",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-28 07:40:06",
      "description": "Seen in a log file:\n\n{noformat}\n27.05.2015 11:34:48.130 *WARN* [DocumentNodeStore background update thread] org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore Background operation failed: org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: com.ibm.db2.jcc.am.SqlTransactionRollbackException: DB2 SQL Error: SQLCODE=-911, SQLSTATE=40001, SQLERRMC=68, DRIVER=3.65.77\norg.apache.jackrabbit.oak.plugins.document.DocumentStoreException: com.ibm.db2.jcc.am.SqlTransactionRollbackException: DB2 SQL Error: SQLCODE=-911, SQLSTATE=40001, SQLERRMC=68, DRIVER=3.65.77\n{noformat}\n\nWe need to decide whether these are harmless in that the operation will be repeated anyway. If the answer is yes, we may want to tune the log message. If the answer is no, we need to dig deeper.\n\n[~mreutegg] wdyt?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore background update thread handling of persistence exceptions"
   },
   {
      "_id": "12833327",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-05-28 07:17:19",
      "description": "Create scalability tests to test out the performance of the read/writes for RDB DocumentStore on a large repository.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Scalability tests for large read/write scenarios"
   },
   {
      "_id": "12833029",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2015-05-27 12:38:14",
      "description": "{{PermissionHook}} has in memory state in {{modified}} and {{deleted}} maps. In case of repository migration which is implemented as a large commit this can consume quite a bit of memory. In one of the migration it was taking ~1 GB of memory.\n\nIn a commit involving multiple commit hooks once {{PermissionHook}} has done the work it can clear that state so that memory is not held up untill all the hooks are applied. Specially as IndexingHook takes long time and also has some memory requirements",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Clear the modified and deleted map in PermissionHook after processing is complete"
   },
   {
      "_id": "12832953",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-05-27 04:44:07",
      "description": "Currently oak-jcr bundle needs to be embedded within some other bundle if the Oak needs to be properly configured in OSGi env. Need to revisit this aspect and see what needs to be done to enable Oak to be properly configured without requiring the oak-jcr bundle to be embedded in the repo",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization",
         "osgi",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-jcr bundle should be usable as a standalone bundle"
   },
   {
      "_id": "12832746",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-05-26 15:26:53",
      "description": "There is the {{Oak}} and {{Jcr}} builder classes for setting up Oak and Jcr repositories. Both builders don't have clear semantics regarding the life cycle of the individual components they register. On top of that the requirements regarding those life cycles differ depending on whether the individual components run within an OSGi container or not. In the former case the container would already manage the life cycle so the builder should not. \n\nIMO we should specify the builders to only be used for non OSGi deployments and have the manage the life cycles of the components they instantiate. OTOH for OSGi deployments we should leverage OSGi subsystems to properly set things up.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Review and improve Oak and Jcr repository setup"
   },
   {
      "_id": "12832736",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-05-26 15:00:08",
      "description": "The DocumentMK class is not directly used (when using the JCR API), but it is only really used by tests. So it should be moved to tests.\n\nThe DocumentMK.Builder class needs to be moved first (to a top level class for example).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move DocumentMK to test"
   },
   {
      "_id": "12832721",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         }
      ],
      "created": "2015-05-26 13:46:37",
      "description": "testAuthenticateValidateTrueFalse(org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest)  Time elapsed: 0.01 sec  <<< ERROR!\njava.io.IOException: Unable to delete file: target\\apacheds\\cache\\5c3940f5-2ddb-4d47-8254-8b2266c1a684\\ou=system.data\n        at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:2279)\n        at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1653)\n        at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1535)\n        at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:2270)\n        at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1653)\n        at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1535)\n        at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:2270)\n        at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1653)\n        at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1535)\n        at org.apache.jackrabbit.oak.security.authentication.ldap.AbstractServer.doDelete(AbstractServer.java:264)\n        at org.apache.jackrabbit.oak.security.authentication.ldap.AbstractServer.setUp(AbstractServer.java:183)\n        at org.apache.jackrabbit.oak.security.authentication.ldap.InternalLdapServer.setUp(InternalLdapServer.java:33)\n\n\netc...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "test failures for oak-auth-ldap on Windows"
   },
   {
      "_id": "12832683",
      "assignee": "tmueller",
      "components": [],
      "created": "2015-05-26 10:05:16",
      "description": "We should have automated code coverage results, and then decide upon minimum numbers we want to achieve (for example, initially 100% package or class coverage). Once we reached the goal, we can increase the minimum coverage on a module-by-module basis.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Code coverage"
   },
   {
      "_id": "12831690",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         }
      ],
      "created": "2015-05-21 10:35:42",
      "description": "OAK-2748 introduced a snapshot dependency to Jackrabbit 2.10.1-SNAPSHOT. Now that 2.10.1 is released, the snapshot dependency can be removed again.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update to Jackrabbit 2.10.1"
   },
   {
      "_id": "12831661",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-05-21 09:02:53",
      "description": "DataStoreBlobStore directly exposes the InputStream from the wrapped DataStore. In most cases underlying DataStore exposes a LazyFileInputStream [0] which is not buffered.\n\nFor performance reason the stream finally exposed at the BlobStore layer should be buffered one. See [1] for the discussion\n\n[1] http://markmail.org/thread/xi4isnzw57vphcsq\n[0]\nhttps://github.com/apache/jackrabbit/blob/trunk/jackrabbit-data/src/main/java/org/apache/jackrabbit/core/data/LazyFileInputStream.java#L102 \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DataStoreBlobStore should expose a buffer input stream for getInputStream call"
   },
   {
      "_id": "12831426",
      "assignee": "tripod",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         }
      ],
      "created": "2015-05-20 16:41:51",
      "description": "regression of OAK-2783....\n\nOn my local instance, I have tested the 4 combination of the new attributes in org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider\n@adminPool.lookupOnValidate (true)\n@userPool.lookupOnValidate (true)\nand found that only when both are set to true, I was able to login with credentials from LDAP server.  see table below for time stamps of the four tested combinations.\n\nI have setup a test harness at http://10.36.65.137:4502.  It is configured for LDAP server on my laptop, which provides user001 ... user010. All have same password, '1234'. \nNote: I have not repeated the above tests on the test harness due to time constraints.\n\n|| time || adminPool.lookupOnValidate || userPool.lookupOnValidate || logon user001 ||\n| 16.05.2015 11:14:59.066 | false | true  | NG @ 16.05.2015 11:16:37.431 (1) |\n| 16.05.2015 11:18:40.627 | false | false | NG @ 16.05.2015 11:19:54.971 (2) |\n| 16.05.2015 11:21:31.757 | true  | false | NG @ ??. No error in LDAP.log. But username and pwd not match |\n| 16.05.2015 11:24:16.277 | true | true | OK |\n\nExcerpts from ldap.log\n{code}\n(1) 16.05.2015 11:16:37.435 *ERROR* [qtp2069601494-1250] org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider Error while connecting to the ldap server.\njava.util.NoSuchElementException: Could not create a validated object, cause: ValidateObject failed\n\n(2) 16.05.2015 11:19:54.971 *ERROR* [qtp2069601494-1249] org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider Error while connecting to the ldap server.\njava.util.NoSuchElementException: Could not create a validated object, cause: ValidateObject failed\n\tat org.apache.commons.pool.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:1233)\n\tat org.apache.directory.ldap.client.api.LdapConnectionPool.getConnection(LdapConnectionPool.java:56)\n\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting",
         "regression",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Regression - lookupOnValidate does not work"
   },
   {
      "_id": "12831424",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-05-20 16:32:35",
      "description": "There is an issue with how the HAMT implementation ({{SegmentWriter.writeMap()}} interacts with the 256 segment references limit when putting many entries into the map: This limit gets regularly reached once the maps contains about 200k entries. At that points segments get prematurely flushed resulting in more segments, thus more references and thus even smaller segments. It is common for segments to be as small as 7k with a tar file containing up to 35k segments. This is problematic as at this point handling of the segment graph becomes expensive, both memory and CPU wise. I have seen persisted segment graphs as big as 35M where the usual size is a couple of ks. \n\nAs the HAMT map is used for storing children of a node this might have an advert effect on nodes with many child nodes. \n\nThe following code can be used to reproduce the issue: \n\n{code}\nSegmentWriter writer = new SegmentWriter(segmentStore, getTracker(), V_11);\nMapRecord baseMap = null;\n\nfor (;;) {\n    Map<String, RecordId> map = newHashMap();\n    for (int k = 0; k < 1000; k++) {\n        RecordId stringId = writer.writeString(String.valueOf(rnd.nextLong()));\n        map.put(String.valueOf(rnd.nextLong()), stringId);\n    }\n\n    Stopwatch w = Stopwatch.createStarted();\n    baseMap = writer.writeMap(baseMap, map);\n    System.out.println(baseMap.size() + \" \" + w.elapsed());\n}\n{code}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Putting many elements into a map results in many small segments. "
   },
   {
      "_id": "12831411",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-05-20 15:44:16",
      "description": "Currently the recommended way to exclude certain types of files from getting indexed is to add them to {{EmptyParser}} in Tika Config. However looking at how Tika works even if mimetype is provided as part metadata. \n\nTika Detector try to determine the mimetype by actually reading some bytes from InputStream [1] before looking up from passed MetaData. This would cause unnecessary IO in case large number of binaries are excluded.\n\nWe would need to look for way where any access to binary content which is not being indexed can be avoided. One option can to expose a multi value config property which takes a list of mimetypes to be excluded from indexing. If the mimeType provided as part of JCR data is part of that excluded list then call to Tika should be avoided\n\n[1] https://github.com/apache/tika/blob/trunk/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java#L446",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Avoid accessing binary content if the mimeType is excluded from indexing"
   },
   {
      "_id": "12831410",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-05-20 15:39:49",
      "description": "{{RepositoryImpl}} uses an instance of {{ContentRepository}} that is passed as an external dependency in its constructor.\n\n{{RepositoryImpl}} is not responsible for the creation of the {{ContentRepository}} instance and, as such, should not manage its lifecycle. In particular, the {{ContentRepository#close}} method should not be called when the {{RepositoryImpl#shutdown}} method is executed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "modularization",
         "resilience",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RepositoryImpl should not manage the lifecycle of ContentRepository"
   },
   {
      "_id": "12831407",
      "assignee": "baedke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-05-20 15:25:28",
      "description": "Currently RepositoryUpgrade.copy() fails on the first error. In practice this is very inconvenient, because any minor inconsistency in the source repository may cause the upgrade to fail.\nAn option to make best-effort copies is needed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RepositoryUpgrade.copy() should optionally continue on errors."
   },
   {
      "_id": "12831360",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-05-20 12:43:05",
      "description": "While migrating large repositories say having 3 M docs (250k PDF) Lucene indexing takes long time to complete (at time 4 days!). Currently the text extraction logic is coupled with Lucene indexing and hence is performed in a single threaded mode which slows down the indexing process. Further if the reindexing has to be triggered it has to be done all over again.\n\nTo speed up the Lucene indexing we can decouple the text extraction\nfrom actual indexing. It is partly based on discussion on OAK-2787\n\n# Introduce a new ExtractedTextProvider which can provide extracted text for a given Blob instance\n# In oak-run introduce a new indexer mode - This would take a path in repository and would then traverse the repository and look for existing binaries and extract text from that\n\nSo before or after migration is done one can run this oak-run tool to create this store which has the text already extracted. Then post startup we need to wire up the ExtractedTextProvider instance (which is backed by the BlobStore populated before) and indexing logic can just get content from that. This would avoid performing expensive text extraction in the indexing thread.\n\nSee discussion thread http://markmail.org/thread/ndlfpkwfgpey6o66",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Speed up lucene indexing post migration by pre extracting the text content from binaries"
   },
   {
      "_id": "12830964",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-19 09:45:28",
      "description": "{{SegmentBlob}} currently returns recordId for {{contentIdentity}} even when an external DataStore is configured. Given that recordId is not stable it would be better to return the blobId as part of  {{contentIdentity}} if external DataStore is configured",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentBlob does not return blobId for contentIdentity"
   },
   {
      "_id": "12830955",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-05-19 09:18:54",
      "description": "Currently, \"order by jcr:score desc\" is ignored in the Lucene index, however for \"union\" queries, this sort order is enforced in the query engine. This will cause queries to be slow if one of the sub-queries is slow.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Ignore \"order by jcr:score desc\" in the query engine (for \"union\" queries)"
   },
   {
      "_id": "12830954",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-19 09:14:14",
      "description": "In rare cases a commit may fail to update the pending changes on {{_lastRev}}    of documents. The stack trace is:\n\n{noformat}\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 0\n        at org.mapdb.BTreeMap.replace(BTreeMap.java:1174)\n        at org.apache.jackrabbit.oak.plugins.document.UnsavedModifications.put(UnsavedModifications.java:90)\n        at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore$10.track(DocumentNodeStore.java:1990)\n        at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.applyChanges(DocumentNodeStore.java:1056)\n        at org.apache.jackrabbit.oak.plugins.document.Commit.applyToCache(Commit.java:598)\n        at org.apache.jackrabbit.oak.plugins.document.CommitQueue.afterTrunkCommit(CommitQueue.java:127)\n        at org.apache.jackrabbit.oak.plugins.document.CommitQueue.done(CommitQueue.java:83)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "ArrayIndexOutOfBoundsException in UnsavedModifications.put()"
   },
   {
      "_id": "12830925",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-05-19 06:40:46",
      "description": "At time to analyse a issue with {{DocumentNodeStore}} running on Mongo we need a dump of various documents so as to recreate the scenario locally. In most case if issue is being observed for a specific path like /a/b then its sufficient to get Mongo documents for /, /a, /a/b and all the split documents for those paths.\n\nIt would be useful to have a function in oak-mongo which generates the required export command. For e.g. for path like /a/b following export command would dump all required info\n\n{noformat}\nmongoexport -h <mongo server> --port 27017 --db <db name> --collection nodes --out all-required-nodes.json --query '{$or:[{_id : /^4:p\\/a\\/b\\//},{_id : /^3:p\\/a\\//},{_id : /^2:p\\//},{_id:{$in:[\"2:/a/b\",\"1:/a\",\"0:/\"]}}]}'\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add support for generating mongo export command to oak-mongo"
   },
   {
      "_id": "12830668",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-18 12:43:30",
      "description": "{{SegmentNodeStoreService}} currently has no test coverage whatsoever. We should change that.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Tests for SegmentNodeStoreService"
   },
   {
      "_id": "12830649",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-05-18 10:46:35",
      "description": "Migration currently involves access to DataStore as its configured as part of repository.xml. However in complete migration actual binary content in DataStore is not accessed and migration logic only makes use of\n\n* Dataidentifier = id of the files\n* Length = As it gets encoded as part of blobId (OAK-1667)\n\nIt would be faster and beneficial to allow migration without actual access to the DataStore. It would serve two benefits\n\n# Allows one to test out migration on local setup by just copying the TarPM files. For e.g. one can only zip following files to get going with repository startup if we can somehow avoid having direct access to DataStore\n{noformat}\n>crx-quickstart# tar -zcvf repo-2.tar.gz repository --exclude=repository/repository/datastore --exclude=repository/repository/index --exclude=repository/workspaces/crx.default/index --exclude=repository/tarJournal\n{noformat}\n# Provides faster (repeatable) migration as access to DataStore can be avoided which in cases like S3 might be slow.  Given we solve how to get length\n\n*Proposal*\nHave a DataStore implementation which can be provided a mapping file having entries for blobId and length. This file would be used to answer queries regarding length and existing of blob and thus would avoid actual access to DataStore.\n\nGoing further this DataStore can be configured with a delegate which can be used as a fallback in case the required details is not present in pre computed data set (may be due to change in content after that data was computed)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "docs-impacting",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support migration without access to DataStore"
   },
   {
      "_id": "12830643",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-05-18 10:01:39",
      "description": "When running the consistency checker against a repository with a corrupt journal, it fails with an {{ISA}} instead of trying to skip over invalid revision identifiers:\n\n{noformat}\nException in thread \"main\" java.lang.IllegalArgumentException: Bad record identifier: foobar\nat org.apache.jackrabbit.oak.plugins.segment.RecordId.fromString(RecordId.java:57)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:227)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:178)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:156)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:166)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore$ReadOnlyStore.<init>(FileStore.java:805)\nat org.apache.jackrabbit.oak.plugins.segment.file.tooling.ConsistencyChecker.<init>(ConsistencyChecker.java:108)\nat org.apache.jackrabbit.oak.plugins.segment.file.tooling.ConsistencyChecker.checkConsistency(ConsistencyChecker.java:70)\nat org.apache.jackrabbit.oak.run.Main.check(Main.java:701)\nat org.apache.jackrabbit.oak.run.Main.main(Main.java:158)\n{noformat}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ConsistencyChecker#checkConsistency can't cope with inconsistent journal"
   },
   {
      "_id": "12830634",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-18 09:51:34",
      "description": "Under some rare conditions which are not entirely clear yet {{SegmentWriter.writeMap}} results in a {{NPE}}:\n\n{noformat}\njava.lang.NullPointerException\n\tat com.google.common.base.Preconditions.checkNotNull(Preconditions.java:192)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeRecordId(SegmentWriter.java:366)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapLeaf(SegmentWriter.java:417)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:475)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:511)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMap(SegmentWriter.java:711)\n{noformat}\n\nThis happens when the {{base}} passed to {{writeMap(MapRecord base, Map<String, RecordId> changes)}} is not null but doesn't contain some of the keys *removed* through the updates provided in the passed {{changes}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NPE in SegmentWriter.writeMap"
   },
   {
      "_id": "12830623",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-18 09:19:48",
      "description": "In the worst case compaction doubles the repository size while running. As this is somewhat unexpected we should check whether there is enough free disk space before running compaction and log a warning otherwise. This is to avoid a common source of running out of disk space and ending up with a corrupted repository. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "doc-impacting",
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction should check for required disk space before running"
   },
   {
      "_id": "12830621",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-18 09:14:21",
      "description": "{{org.apache.jackrabbit.oak.jcr.AutoCreatedItemsTest.autoCreatedItems}} fails on Jenkins: No default node type available for /testdata/property\n\n{noformat}\njavax.jcr.nodetype.ConstraintViolationException: No default node type available for /testdata/property\n\tat org.apache.jackrabbit.oak.util.TreeUtil.addChild(TreeUtil.java:186)\n\tat org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.addChild(NodeDelegate.java:692)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl$5.perform(NodeImpl.java:296)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl$5.perform(NodeImpl.java:262)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:202)\n\tat org.apache.jackrabbit.oak.jcr.session.ItemImpl.perform(ItemImpl.java:112)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.addNode(NodeImpl.java:262)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.addNode(NodeImpl.java:247)\n\tat org.apache.jackrabbit.oak.jcr.TestContentLoader.getOrAddNode(TestContentLoader.java:90)\n\tat org.apache.jackrabbit.oak.jcr.TestContentLoader.loadTestContent(TestContentLoader.java:58)\n\tat org.apache.jackrabbit.oak.jcr.AutoCreatedItemsTest.autoCreatedItems(AutoCreatedItemsTest.java:42)\n{noformat}\n\nFailure seen at builds: 130, 134, 138, 249, 292, 297\n\nSee https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/134/jdk=jdk-1.6u45,label=Ubuntu,nsfixtures=DOCUMENT_RDB,profile=unittesting/testReport/junit/org.apache.jackrabbit.oak.jcr/AutoCreatedItemsTest/autoCreatedItems_0_/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: AutoCreatedItemsTest.autoCreatedItems"
   },
   {
      "_id": "12830620",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-18 09:09:43",
      "description": "{{org.apache.jackrabbit.oak.jcr.OrderableNodesTest.setPrimaryType}} fails on Jenkins: No default node type available for /testdata\n\n{noformat}\njavax.jcr.nodetype.ConstraintViolationException: No default node type available for /testdata\n\tat org.apache.jackrabbit.oak.util.TreeUtil.addChild(TreeUtil.java:186)\n\tat org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.addChild(NodeDelegate.java:692)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl$5.perform(NodeImpl.java:296)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl$5.perform(NodeImpl.java:262)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:202)\n\tat org.apache.jackrabbit.oak.jcr.session.ItemImpl.perform(ItemImpl.java:112)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.addNode(NodeImpl.java:262)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.addNode(NodeImpl.java:247)\n\tat org.apache.jackrabbit.oak.jcr.TestContentLoader.getOrAddNode(TestContentLoader.java:90)\n\tat org.apache.jackrabbit.oak.jcr.TestContentLoader.loadTestContent(TestContentLoader.java:57)\n\tat org.apache.jackrabbit.oak.jcr.OrderableNodesTest.setPrimaryType(OrderableNodesTest.java:62)\n{noformat}\n\nFailure seen at builds: 132, 152, 176\n\nSee https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/132/jdk=jdk-1.6u45,label=Ubuntu,nsfixtures=DOCUMENT_RDB,profile=unittesting/testReport/junit/org.apache.jackrabbit.oak.jcr/OrderableNodesTest/setPrimaryType_0_/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: OrderableNodesTest.setPrimaryType"
   },
   {
      "_id": "12830615",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-05-18 08:51:53",
      "description": "{{org.apache.jackrabbit.oak.upgrade.RepositorySidegradeTest.verifyAsync}} fails on Jenkins with a {{NPE}}:\n\n{noformat}\nverifyAsync(org.apache.jackrabbit.oak.upgrade.RepositorySidegradeTest)  Time elapsed: 0.002 sec  <<< ERROR!\njava.lang.NullPointerException\n\tat org.apache.jackrabbit.oak.upgrade.RepositorySidegradeTest.verifyAsync(RepositorySidegradeTest.java:125)\n{noformat}\n\nFailure seen at builds: 133, 134\n\nSee https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/134/jdk=latest1.7,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=unittesting/console",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: RepositorySidegradeTest.verifyAsync (NPE)"
   },
   {
      "_id": "12830114",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-05-15 08:51:11",
      "description": "XPath queries with many \"or\" condition (around 3000) of the following form can result in a performance problem:\n\n{noformat}\ncontains(...) or x=1 or x=2 or x=3 ...\n{noformat}\n\nThis is somewhat similar to OAK-2738, but not quite the same.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "XPath: Performance problems with many \"or\" conditions"
   },
   {
      "_id": "12830089",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         }
      ],
      "created": "2015-05-15 06:50:18",
      "description": "As discussed in [1], it looks like the ExternalLoginModule ignores cleaning up its internal state when login was not successful.\n\nWhat I assume happens next is the old session (probably the initial one created on the very first login call) would be reused throughout the module's lifetime, which would in the end result in the SNFEs post compaction.\n\n[1] http://markmail.org/thread/pcmlz74ngxl7sqfy",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ExternalLoginModule should clear state when login was not successful"
   },
   {
      "_id": "12829503",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-13 09:55:35",
      "description": "Currently all commits go through the CommitQueue. This applies to commits that fit into memory, branch commits, merge commits and even reset commits.\n\nThe guarantee provided by the CommitQueue is only necessary for commits that affect the head revision of the store: commits that fit into memory and merge commits.\n\nBranch and reset commits should bypass the CommitQueue to avoid unnecessary delays of commits. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bypass CommitQueue for branch commits"
   },
   {
      "_id": "12829452",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-05-13 04:49:38",
      "description": "For issues like OAK-2787 it would helpful if we collect some stats around how much time is spent in extracting text from binaries.\n\nFor that purpose I would like add some logging around text extraction",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Log stats around time spent in extracting text from binaries"
   },
   {
      "_id": "12828838",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-11 14:59:47",
      "description": "I've seen {{CompactionMap#compress()}} take up most of the time spent in compaction. With 40M record ids in the compaction map compressing runs for hours. \n\nI will back this with numbers as soon as I have a better grip on the issue.  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "doc-impacting",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CompactionMap#compress() inefficient for large compaction maps"
   },
   {
      "_id": "12828818",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-11 13:54:51",
      "description": "In production, we've seen exceptions like this:\n\n{noformat}\n org.apache.jackrabbit.oak.plugins.document.rdb.RDBBlobStore insert document failed for id bd89b0745aa22429234f17dfc3e2a35b744dc6e86f5e8094a4153b2366c4d822 w\nith length 14691 (check max size of datastore_data.data)\ncom.ibm.db2.jcc.am.SqlIntegrityConstraintViolationException: DB2 SQL Error: SQLCODE=-803, SQLSTATE=23505, SQLERRMC=1;DB2INST1.DATASTORE_DATA, DRIVER=4.16.53\n        at com.ibm.db2.jcc.am.fd.a(fd.java:735)\n        at com.ibm.db2.jcc.am.fd.a(fd.java:60)\n        at com.ibm.db2.jcc.am.fd.a(fd.java:127)\n        at com.ibm.db2.jcc.am.to.b(to.java:2422)\n        at com.ibm.db2.jcc.am.to.c(to.java:2405)\n        at com.ibm.db2.jcc.t4.ab.l(ab.java:408)\n        at com.ibm.db2.jcc.t4.ab.a(ab.java:62)\n        at com.ibm.db2.jcc.t4.o.a(o.java:50)\n        at com.ibm.db2.jcc.t4.ub.b(ub.java:220)\n        at com.ibm.db2.jcc.am.uo.sc(uo.java:3526)\n        at com.ibm.db2.jcc.am.uo.b(uo.java:4489)\n        at com.ibm.db2.jcc.am.uo.mc(uo.java:2833)\n        at com.ibm.db2.jcc.am.uo.execute(uo.java:2808)\n        at sun.reflect.GeneratedMethodAccessor941.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:600)\n        at org.apache.tomcat.jdbc.pool.interceptor.AbstractQueryReport$StatementProxy.invoke(AbstractQueryReport.java:235)\n        at com.sun.proxy.$Proxy259.execute(Unknown Source)\n        at sun.reflect.GeneratedMethodAccessor941.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:600)\n        at org.apache.tomcat.jdbc.pool.interceptor.StatementDecoratorInterceptor$StatementProxy.invoke(StatementDecoratorInterceptor.java:252)\n        at com.sun.proxy.$Proxy259.execute(Unknown Source)\n        at org.apache.jackrabbit.oak.plugins.document.rdb.RDBBlobStore.storeBlockInDatabase(RDBBlobStore.java:374)\n        at org.apache.jackrabbit.oak.plugins.document.rdb.RDBBlobStore.storeBlock(RDBBlobStore.java:340)\n{noformat}\n\nThis seems to indicate that they key is present in _data but not in _meta. We need to find out whether that's caused by an earlier problem, or whether storeInBlock is supposed to handle this.\n\n(Note that the actual exception message about \"check max size of datastore_data.data\" is misleading; it's due to an earlier attempt to diagnose DB config problems)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RDBBlobStore: seen insert failures due to duplicate keys"
   },
   {
      "_id": "12828772",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-11 10:43:36",
      "description": "{{org.apache.jackrabbit.oak.jcr.OrderableNodesTest}} fails on Jenkins when running the {{DOCUMENT_RDB}} fixture.\n\n{noformat}\nTests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 12.572 sec <<< FAILURE!\norderableFolder[0](org.apache.jackrabbit.oak.jcr.OrderableNodesTest)  Time elapsed: 3.858 sec  <<< ERROR!\njavax.jcr.nodetype.ConstraintViolationException: No default node type available for /testdata\n\tat org.apache.jackrabbit.oak.util.TreeUtil.addChild(TreeUtil.java:186)\n\tat org.apache.jackrabbit.oak.jcr.delegate.NodeDelegate.addChild(NodeDelegate.java:692)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl$5.perform(NodeImpl.java:296)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl$5.perform(NodeImpl.java:262)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:202)\n\tat org.apache.jackrabbit.oak.jcr.session.ItemImpl.perform(ItemImpl.java:112)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.addNode(NodeImpl.java:262)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.addNode(NodeImpl.java:247)\n\tat org.apache.jackrabbit.oak.jcr.TestContentLoader.getOrAddNode(TestContentLoader.java:90)\n\tat org.apache.jackrabbit.oak.jcr.TestContentLoader.loadTestContent(TestContentLoader.java:57)\n\tat org.apache.jackrabbit.oak.jcr.OrderableNodesTest.orderableFolder(OrderableNodesTest.java:47)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\n\tat org.junit.runners.Suite.runChild(Suite.java:24)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\n\tat java.lang.Thread.run(Thread.java:662)\n{noformat}\n\nFailure seen at builds: 81, 87, 92, 95, 96, 114, 120, 128, 134, 186, 243, 272, 292\n\nSee e.g. https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/128/jdk=jdk-1.6u45,label=Ubuntu,nsfixtures=DOCUMENT_RDB,profile=unittesting/console",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: OrderableNodesTest"
   },
   {
      "_id": "12828771",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-11 10:39:08",
      "description": "{{org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest}} fails on Jenkins when running the {{DOCUMENT_RDB}} fixture.\n\n{noformat}\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 16.174 sec <<< FAILURE!\nobservation[0](org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest)  Time elapsed: 16.173 sec  <<< ERROR!\njavax.jcr.InvalidItemStateException: OakMerge0001: OakMerge0001: Failed to merge changes to the underlying store (retries 5, 5286 ms)\n\tat org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:239)\n\tat org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:212)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.newRepositoryException(SessionDelegate.java:664)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:489)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl$8.performVoid(SessionImpl.java:424)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.performVoid(SessionDelegate.java:268)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl.save(SessionImpl.java:421)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest.observation(ObservationRefreshTest.java:176)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\n\tat org.junit.runners.Suite.runChild(Suite.java:24)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\nCaused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakMerge0001: OakMerge0001: Failed to merge changes to the underlying store (retries 5, 5286 ms)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:242)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:179)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:158)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1451)\n\tat org.apache.jackrabbit.oak.core.MutableRoot.commit(MutableRoot.java:247)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:341)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:487)\n\t... 43 more\nCaused by: org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: The node 3:/oak:index/nodetype/:index was already added in revision\nr14d31a418d3-0-1, before\nr14d31a44656-0-1\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.checkConflicts(Commit.java:524)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.createOrUpdateNode(Commit.java:438)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:341)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:246)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyInternal(Commit.java:215)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.apply(Commit.java:200)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:323)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:293)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.access$200(DocumentNodeStoreBranch.java:52)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch$InMemory.merge(DocumentNodeStoreBranch.java:530)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:219)\n{noformat}\n\nFailure seen at builds: 48, 55, 115, 118, 123 , 127, 128, 130, 149, 152, 155, 164\n\nSee e.g. https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/128/jdk=latest1.7,label=Ubuntu,nsfixtures=DOCUMENT_RDB,profile=unittesting/console",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ObservationRefreshTest"
   },
   {
      "_id": "12828761",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-11 09:53:12",
      "description": "OAK-2624 decoupled the background read from the background write but the methods implementing the operations are synchronized. This means they cannot run at the same time and e.g. an expensive background write may unnecessarily block a background read.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Run background read and write operation concurrently"
   },
   {
      "_id": "12828389",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-08 15:16:44",
      "description": "It's essential that the database is configured with the proper charset and collation. After detecting the DB type, attempt to inspect the settings reported by the database. This will require custom code for each DB type, though.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "improve RDB diagnostics"
   },
   {
      "_id": "12828314",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-05-08 10:30:33",
      "description": "{{CopyOnReadDirectory}} currently deletes local files which are not found in remote upon close. The list of remote file is fixed for a given revision however list of local files may vary. \n\n{{IndexTracker}} opens a new {{IndexNode}} upon update before closing the older one. When CopyOnRead is enabled it can happen that same local directory might be in use by two wrapper directories at the same time. \n\nThis introduces a race condition in {{removeDeletedFiles}} method as by the time it is invoked a newer wrapped directory might have started adding new files so those files would get included in the listing done for local directory and hence cause them to be deleted as they would not be found in remote directory which is pinned to older revision. Leading to following exception\n\n{noformat}\nCaused by: java.io.FileNotFoundException: /path/to/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/4/_1r.cfe (No such file or directory)\n\tat java.io.RandomAccessFile.open(Native Method)\n\tat java.io.RandomAccessFile.<init>(RandomAccessFile.java:241)\n\tat org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:193)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier$CopyOnReadDirectory$FileReference.openLocalInput(IndexCopier.java:393)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier$CopyOnReadDirectory.openInput(IndexCopier.java:221)\n\tat org.apache.lucene.store.Directory.copy(Directory.java:185)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexMBeanImpl.dumpIndexContent(LuceneIndexMBeanImpl.java:104)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n{noformat}\n\nAs a fix the list of local file should be maintained as progress is made once the CopyOnRead instance gets created to ensure it does not pick up files which are added once the directory is closed",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CopyOnReadDirectory mode might delete a valid local file upon close"
   },
   {
      "_id": "12828025",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-05-07 14:42:22",
      "description": "If the traversing index is not available (by removing or renaming the node /oak:index/counter), the cost of traversing is relatively low. This can cause traversals, even thought using a property index (or another index) would be better.\n\nBy the way, disabling the counter index (setting the type to a 'disabled') alone does still use the estimation in the counter index. This may or may not be a good thing.\n\nExample costs:\n\n{noformat}\n/jcr:root/content//element(*, cq:Page)[@test='withCounter']\ncost for aggregate lucene is Infinity\ncost for lucene-property is Infinity\ncost for reference is Infinity\ncost for ordered is Infinity\ncost for nodeType is 138.0\ncost for property is Infinity\ncost for traverse is 27100.0\n\n/jcr:root/content//element(*, cq:Page)[@test='withoutCounter2']\ncost for aggregate lucene is Infinity\ncost for lucene-property is Infinity\ncost for reference is Infinity\ncost for ordered is Infinity\ncost for nodeType is 1504.0\ncost for property is Infinity\ncost for traverse is 2000.0\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Query engine: if counter index is not available, cost of traversing is too low"
   },
   {
      "_id": "12827982",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-05-07 10:40:07",
      "description": "This is a container issue for the ongoing effort to improve revision gc of the SegmentMK. \n\nI'm exploring \n* ways to make the reference graph as exact as possible and necessary: it should not contain segments that are not referenceable any more and but must contain all segments that are referenceable. \n* ways to segregate the reference graph reducing dependencies between certain set of segments as much as possible. \n* Reducing the number of in memory references and their impact on gc as much as possible.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve revision gc on SegmentMK"
   },
   {
      "_id": "12827969",
      "assignee": "catholicon",
      "components": [],
      "created": "2015-05-07 09:12:56",
      "description": "Early in the next release cycle we should go through the list of Oak's dependencies and decide whether we have candidates we want to upgrade and remove orphaned dependencies. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Dependency cleanup "
   },
   {
      "_id": "12827657",
      "assignee": "egli",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-06 13:14:26",
      "description": "When running discovery.impl on a mongoMk-backed jcr repository, there are risks of hitting problems such as described in \"SLING-3432 pseudo-network-partitioning\": this happens when a jcr-level heartbeat does not reach peers within the configured heartbeat timeout - it then treats that affected instance as dead, removes it from the topology, and continues with the remainings, potentially electing a new leader, running the risk of duplicate leaders. This happens when delays in mongoMk grow larger than the (configured) heartbeat timeout. These problems ultimately are due to the 'eventual consistency' nature of, not only mongoDB, but more so of mongoMk. The only alternative so far is to increase the heartbeat timeout to match the expected or measured delays that mongoMk can produce (under say given load/performance scenarios).\n\nAssuming that mongoMk will always carry a risk of certain delays and a maximum, reasonable (for discovery.impl timeout that is) maximum cannot be guaranteed, a better solution is to provide discovery with more 'real-time' like information and/or privileged access to mongoDb.\n\nHere's a summary of alternatives that have so far been floating around as a solution to circumvent eventual consistency:\n # expose existing (jmx) information about active 'clusterIds' - this has been proposed in SLING-4603. The pros: reuse of existing functionality. The cons: going via jmx, binding of exposed functionality as 'to be maintained API'\n # expose a plain mongo db/collection (via osgi injection) such that a higher (sling) level discovery could directly write heartbeats there. The pros: heartbeat latency would be minimal (assuming the collection is not sharded). The cons: exposes a mongo db/collection potentially also to anyone else, with the risk of opening up to unwanted possibilities\n # introduce a simple 'discovery-light' API to oak which solely provides information about which instances are active in a cluster. The implementation of this is not exposed. The pros: no need to expose a mongoDb/collection, allows any other jmx-functionality to remain unchanged. The cons: a new API that must be maintained\n\nThis ticket is about the 3rd option, about a new mongo-based discovery-light service that is introduced to oak. The functionality in short:\n * it defines a 'local instance id' that is non-persisted, ie can change at each bundle activation.\n * it defines a 'view id' that uniquely identifies a particular incarnation of a 'cluster view/state' (which is: a list of active instance ids)\n * and it defines a list of active instance ids\n * the above attributes are passed to interested components via a listener that can be registered. that listener is called whenever the discovery-light notices the cluster view has changed.\n\nWhile the actual implementation could in fact be based on the existing {{getActiveClusterNodes()}} {{getClusterId()}} of the {{DocumentNodeStoreMBean}}, the suggestion is to not fiddle with that part, as that has dependencies to other logic. But instead, the suggestion is to create a dedicated, other, collection ('discovery') where heartbeats as well as the currentView are stored.\n\nWill attach a suggestion for an initial version of this for review.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Introducing a simple document-based discovery-light service (to circumvent documentMk's eventual consistency delays)"
   },
   {
      "_id": "12827624",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-05-06 11:26:46",
      "description": "At times in migration following exception is seen\n\n{noformat}\nCaused by: java.lang.NullPointerException\nat org.apache.jackrabbit.oak.upgrade.JackrabbitNodeState.createProperties(JackrabbitNodeState.java:311)\nat org.apache.jackrabbit.oak.upgrade.JackrabbitNodeState.<init>(JackrabbitNodeState.java:149)\nat org.apache.jackrabbit.oak.upgrade.JackrabbitNodeState.getChildNodeEntries(JackrabbitNodeState.java:255)\nat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1014)\nat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1015)\nat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1015)\n{noformat}\n\nThis would happen if the NodePropBundle is null for a given id. It would be good to add a NPE check in loader itself",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Log NodePropBundle id for which no bundle is found"
   },
   {
      "_id": "12827602",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-05-06 09:42:44",
      "description": "The OSGiIT tests are failing silently, so not failing the build when the tests don't pass.\n\n{code}\nRunning org.apache.jackrabbit.oak.osgi.OSGiIT\n[main] INFO org.ops4j.pax.exam.spi.DefaultExamSystem - Pax Exam System (Version: 3.4.0) created.\n[main] INFO org.ops4j.pax.exam.junit.impl.ProbeRunner - creating PaxExam runner for class org.apache.jackrabbit.oak.osgi.OSGiIT\n[main] INFO org.ops4j.pax.exam.junit.impl.ProbeRunner - running test class org.apache.jackrabbit.oak.osgi.OSGiIT\nERROR: org.apache.jackrabbit.oak-lucene (23): [org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProviderService(1)] The activate method has thrown an exception\njava.lang.NullPointerException: Index directory cannot be determined as neither index directory path [localIndexDir] nor repository home [repository.home] defined\n\tat com.google.common.base.Preconditions.checkNotNull(Preconditions.java:236)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProviderService.createTracker(LuceneIndexProviderService.java:197)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProviderService.activate(LuceneIndexProviderService.java:125)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Test failure: OSGiIT"
   },
   {
      "_id": "12827592",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326717",
            "id": "12326717",
            "name": "cache"
         }
      ],
      "created": "2015-05-06 09:10:31",
      "description": "If the persistent cache is severely broken (after ouf memory for example), in some cases the store is closed, but there is still a risk to get many log message (mainly null pointer exceptions) saying \"Could not retrieve the map size\". This needs to be avoided. Possibly the cache files should be removed in such cases, and the cache re-created.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Persistent cache: avoid repeated log message after closing"
   },
   {
      "_id": "12827572",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2015-05-06 07:18:33",
      "description": "Following OAK-2817, it turns out that patching the data corruption issue revealed an inefficiency of the cleanup method. similar to the online compaction situation, the standby has issues clearing some of the in-memory references to old revisions.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "TARMK Cold Standby inefficient cleanup"
   },
   {
      "_id": "12827559",
      "assignee": "tmueller",
      "components": [],
      "created": "2015-05-06 06:47:57",
      "description": "Currently, the LIRS cache is always enabled when using the persistent cache. It should be possible to explicitly disable it in this case.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "considerFor1.2"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "LIRS cache: allow to disable it when using the persistent cache"
   },
   {
      "_id": "12827338",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-05-05 15:59:52",
      "description": "Container issue for refactoring the TarMK to make it more testable, maintainable, extensible and less entangled. \n\nFor example the segment format should be readable, writeable through standalone means so tests, tools and production code can share this code. Currently there is a lot of code duplication involved here. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor TarMK"
   },
   {
      "_id": "12827300",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-05-05 14:49:27",
      "description": "{{org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest.org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest}} fails on Jenkins.\n\nSee e.g. https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/123/jdk=latest1.7,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=unittesting/console\n\nSeen on {{DOCUMENT_RDB}} and {{SEGMENT_MK}} with Java 1.7. and 1.8. \n\n{noformat}\nTests run: 13, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 23.572 sec <<< FAILURE!\norg.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest  Time elapsed: 23.255 sec  <<< ERROR!\ncom.carrotsearch.randomizedtesting.ThreadLeakError: 21 threads leaked from SUITE scope at org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest: \n   1) Thread[id=32, name=oak-scheduled-executor-13, state=TIMED_WAITING, group=main]\n        at sun.misc.Unsafe.park(Native Method)\n        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:1125)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:807)\n        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n   2) Thread[id=25, name=oak-scheduled-executor-6, state=TIMED_WAITING, group=main]\n        at sun.misc.Unsafe.park(Native Method)\n        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:1125)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:807)\n        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n...\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: DefaultAnalyzersConfigurationTest"
   },
   {
      "_id": "12827231",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-05 09:33:07",
      "description": "Comparing node states for local changes has been improved already with OAK-2669. But in a clustered setup generating events for external changes cannot make use of the introduced cache and is therefore slower. This can result in a growing observation queue, eventually reaching the configured limit. See also OAK-2683.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Comparing node states for external changes is too slow"
   },
   {
      "_id": "12827202",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-05-05 09:14:19",
      "description": "The {{Jcr}} class is the entry point for configuring a JCR repository using an Oak backend. However, it always use a hardcoded set of dependencies ( IndexEditorProvider, SecurityProvider, etc )  which cannot be reset, as they are defined in the constructor and the builder {{with}} methods eagerly configure the backing {{Oak}} instance with those dependencies.\n\nAs an example\n\n{code:java|title=Jcr.java}\n    @Nonnull\n    public final Jcr with(@Nonnull SecurityProvider securityProvider) {\n        oak.with(checkNotNull(securityProvider));\n        this.securityProvider = securityProvider;\n        return this;\n    }\n{code}\n\ninjects the security provider which in turn starts configuring the Oak repository provider\n\n{code:java|title=Oak.java}\n    @Nonnull\n    public Oak with(@Nonnull SecurityProvider securityProvider) {\n        this.securityProvider = checkNotNull(securityProvider);\n        if (securityProvider instanceof WhiteboardAware) {\n            ((WhiteboardAware) securityProvider).setWhiteboard(whiteboard);\n        }\n        for (SecurityConfiguration sc : securityProvider.getConfigurations()) {\n            RepositoryInitializer ri = sc.getRepositoryInitializer();\n            if (ri != RepositoryInitializer.DEFAULT) {\n                initializers.add(ri);\n            }\n        }\n        return this;\n    }\n{code}\n\nInstead, the {{Jcr}} class should store the configured dependencies and only configure the {{Oak}} instance when {{createRepository}} is invoked.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Jcr builder class does not allow overriding most of its dependencies"
   },
   {
      "_id": "12827175",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-05-05 08:09:03",
      "description": "AWS sdk jar - com.amazonaws:aws-java-sdk-core has an open range dependency on joda-time [2.2,) which causes the build to fail.\n\n{noformat}\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-remote-resources-plugin:1.4:process (default) on project oak-blob-cloud: Failed to resolve dependencies for one or more projects in the reactor. Reason: No versions are present in the repository for the artifact with a range [2.2,)\n[ERROR] joda-time:joda-time:jar:null\n[ERROR]\n[ERROR] from the specified remote repositories:\n[ERROR] Nexus (http://repository.apache.org/snapshots, releases=false, snapshots=true),\n[ERROR] central (http://repo.maven.apache.org/maven2, releases=true, snapshots=false)\n[ERROR] Path to dependency:\n[ERROR] 1) org.apache.jackrabbit:oak-blob-cloud:bundle:1.4-SNAPSHOT\n[ERROR] 2) com.amazonaws:aws-java-sdk:jar:1.9.11\n[ERROR] 3) com.amazonaws:aws-java-sdk-support:jar:1.9.11\n[ERROR] 4) com.amazonaws:aws-java-sdk-core:jar:1.9.11\n[ERROR] -> [Help 1]\n[ERROR]\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n[ERROR]\n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <goals> -rf :oak-blob-cloud\nBuild step 'Invoke top-level Maven targets' marked build as failure\n[FINDBUGS] Skipping publisher since build result is FAILURE\nRecording test results\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "[oak-blob-cloud] Test Failures: Add joda-time dependency explicitly with definite version range"
   },
   {
      "_id": "12825863",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-29 08:56:22",
      "description": "The default multipler is currently 3, which translates into a lock try timeout of 6 seconds. This is rather low and may result in merge failures even when a commit acquired the merge lock exclusively. I would like to increase it to 30.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Change default for oak.maxLockTryTimeMultiplier"
   },
   {
      "_id": "12825846",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-29 07:54:45",
      "description": "The DocumentNodeStoreBranch retries merges in two phases. First it retries merges while holding the merge lock non-exclusive and performing sleeps between attempts. If those retries fail the next phase will acquire the merge lock exclusively and perform retries. In the first phase the merge lock is released when the commit goes to sleep, while in the second it is not and may block other commits while sleeping.\n\nDocumentNodeStoreBranch should be changed to release the exclusive lock when the commit goes to sleep.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release merge lock in retry loop"
   },
   {
      "_id": "12825462",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-28 09:02:22",
      "description": "It looks like the standby cleanup process could remove a lot more binary segments than permitted because of the order in which such segments are persisted. the sync will first persist the data segment referencing a binary, then the binary segment itself, this introduces problems when it spreads over multiple tar files and the #cleanup method expects them to be persisted the other way around (this is an implementation detail of the cleanup, but it is implemented this way for efficiency).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "docs-impacting",
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TARMK Cold Standby cleanup removes too many binary segments"
   },
   {
      "_id": "12824211",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-27 09:46:38",
      "description": "{{ObservationManagerImpl}} has a optimize method which process the list of includes and excludes and removes redundant clauses. That logic is now also being used in index filtering (OAK-2599) and is getting duplicated.\n\nGoing forward we need to refactor this logic so that both places can use it without copying. Possibly making it part of PathUtils\n\n[~mduerig] Also suggested to further optimize\nbq. Also PathFilter#optimise could be further optimised by removing entries that subsume each other (e.g. including /a/b, /a is the same as including (/a. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Refactor the optimize logic regarding path include and exclude to avoid duplication"
   },
   {
      "_id": "12823893",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-04-24 21:20:52",
      "description": "If we try to copy a node, in which we have full access, but with no access on the parent node, the copy operation will throw a PathNotFoundException when evaluating checkProtectedNode(getParentPath(\"sourceNodePath\")) on the copy() method from org.apache.jackrabbit.oak.jcr.session.WorkspaceImpl\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "easytest",
         "patch-available"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cannot copy a node if parent is not accessible"
   },
   {
      "_id": "12823779",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-24 15:30:59",
      "description": "OakDirectory has to at times perform directory listing specially at the time of opening of index. With DocumentNodeStore such listing of child nodes \"might\" be slow if there are lots more deleted nodes and GC has not cleared them so far (due to OAK-1557). \n\nAs seen in OAK-2808 Lucene might be creating and deleting lot more files. To speed up such lookup one OakDirectory can save the listing of child nodes as an array property once the writer is closed. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Save Lucene directory listing as array property"
   },
   {
      "_id": "12823773",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-24 15:17:40",
      "description": "With storing of Lucene index files within DataStore our usage pattern\nof DataStore has changed between JR2 and Oak.\n\nWith JR2 the writes were mostly application based i.e. if application\nstores a pdf/image file then that would be stored in DataStore. JR2 by\ndefault would not write stuff to DataStore. Further in deployment\nwhere large number of binary content is present then systems tend to\nshare the DataStore to avoid duplication of storage. In such cases\nrunning Blob GC is a non trivial task as it involves a manual step and\ncoordination across multiple deployments. Due to this systems tend to\ndelay frequency of GC\n\nNow with Oak apart from application the Oak system itself *actively*\nuses the DataStore to store the index files for Lucene and there the\nchurn might be much higher i.e. frequency of creation and deletion of\nindex file is lot higher. This would accelerate the rate of garbage\ngeneration and thus put lot more pressure on the DataStore storage\nrequirements.\n\nDiscussion thread http://markmail.org/thread/iybd3eq2bh372zrl",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "datastore",
         "doc-impacting",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Active deletion of 'deleted' Lucene index files from DataStore without relying on full scale Blob GC"
   },
   {
      "_id": "12823366",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-04-23 10:09:41",
      "description": "When starting up oak with oak-run the JMX beans are not registered, but it would be convenient for the registration to happen.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run: register JMX beans "
   },
   {
      "_id": "12823041",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-22 14:25:41",
      "description": "The DocumentStore API allows for conditional inserts (only add document if not present yet) and updates (using findAndModify() with a condition), but it doesn't allow you to remove a document given some conditions are met.\n\nThis feature is required to make sure the VersionGarbageCollector does not remove document that are modified concurrently. See OAK-2778.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Conditional remove on DocumentStore"
   },
   {
      "_id": "12822999",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-22 11:53:50",
      "description": "org.apache.jackrabbit.oak.plugins.nodetype.NodeTypeDefDiff copies a huge amount of code from org.apache.jackrabbit.spi.commons.nodetype.NodeTypeDefDiff (the latter working on QNodeTypeDefinitions, not NodeTypeDefinitions)\n\nFigure out how to avoid the code duplication.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "avoid NodeTypeDefDiff code duplication"
   },
   {
      "_id": "12822994",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-22 11:24:40",
      "description": "{{FileStore#cleanup}} would be more efficient when getting rid of as much references as possibly beforehand. Excess references are contributed by the current {{TarWriter}} instance and segment cache in {{SegmentTracker}}. \n\nThose excess references turn out to be especially harmful with many concurrent writers continuously writing to the repository. Starting with a certain write load clean up will become completely blocked. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clear excess references before cleanup"
   },
   {
      "_id": "12822976",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-22 10:26:56",
      "description": "{{TarWriter#cleanup}} currently adds all its references to the initial elements of the reference graph. It would be sufficient though to just add the references in the tar writer's own graph. \n\nAt the same time I'd like to rename that method from {{cleanup}} to {{collectReferences}}, which better reflects its semantics. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make contributions to reference graph from TarWriter less conservative "
   },
   {
      "_id": "12822956",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-22 09:28:53",
      "description": "Related to the inspections I was doing for OAK-2798 I also noticed that we don't fully comply with the {{IndexInput}}\u00a0javadoc [1]\u00a0as the cloned instances should throw the given exception if original is closed, but I also think that the original instance should close the cloned instances, see also [ByteBufferIndexInput#close|https://github.com/apache/lucene-solr/blob/lucene_solr_4_7_1/lucene/core/src/java/org/apache/lucene/store/ByteBufferIndexInput.java#L271].\n\n[1]\u00a0: {code}\n/** Abstract base class for input from a file in a {@link Directory}.  A\n * random-access input stream.  Used for all Lucene index input operations.\n *\n * <p>{@code IndexInput} may only be used from one thread, because it is not\n * thread safe (it keeps internal state like file position). To allow\n * multithreaded use, every {@code IndexInput} instance must be cloned before\n * used in another thread. Subclasses must therefore implement {@link #clone()},\n * returning a new {@code IndexInput} which operates on the same underlying\n * resource, but positioned independently. Lucene never closes cloned\n * {@code IndexInput}s, it will only do this on the original one.\n * The original instance must take care that cloned instances throw\n * {@link AlreadyClosedException} when the original one is closed.\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "OakIndexInput cloned instances are not closed"
   },
   {
      "_id": "12822650",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-21 11:42:18",
      "description": "This issue is related to OAK-2646. Every now and then I see reports of background reads with a cache invalidation that takes a rather long time. Sometimes minutes. It would be good to give the HierarchicalInvalidator an upper limit for the time it may take to perform the invalidation. When the time is up, the implementation should simply invalidate the remaining documents.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Time limit for HierarchicalInvalidator"
   },
   {
      "_id": "12822289",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-04-20 11:35:22",
      "description": "I have had issues in cases when the async Lucene index had gotten corrupted. With this index unusable the only option was to re-index.  The problem however was that there were ongoing queries relying on this index even during re-indexing. Because the original index was corrupted these queries led to further load on the system (traversals afair).\n\nI wonder if we could improve the system resilience in such situations.\nOne thing I could think of: could we maybe fallback to the last known non-corrupted index state while the re-index is running? This would at least take off the load due to new incoming queries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve system resilience in case of index corruption"
   },
   {
      "_id": "12821826",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-04-17 10:06:03",
      "description": "looking at queries executed in oak it seems that the vast majority doesn't set neither limit nor offset. Since there are not public constants available for NO_LIMIT and NO_OFFSET the corresponding values (i.e. Long.MAX_VALUE and 0 respectively) are repeatedly used. \n\nsince i found that i always have to look up how to indicated the NO_LIMIT, i would like to suggest that we either introduce constants for the 2 parameters or provide another {{executeQuery}} method that doesn't require to specify limit and offset (-> the constants might be kept private in this case).\n\ndiscussing with [~tmueller] it seemed that he would rather prefer the second approach.\n\nin any case it would allow us to make the various usages of {{QueryEngine.executeQuery}} more readable",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add QueryEngine.executeQuery without limit and offset"
   },
   {
      "_id": "12821795",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-17 07:50:32",
      "description": "{code}\n@Override\n            public int getLocalEventCount() {\n                return size(filter(queue, new Predicate<ContentChange>() {\n                    @Override\n                    public boolean apply(@Nullable ContentChange input) {\n                        return input.info != null;\n                    }\n                }));\n            }\n\n            @Override\n            public int getExternalEventCount() {\n                return size(filter(queue, new Predicate<ContentChange>() {\n                    @Override\n                    public boolean apply(@Nullable ContentChange input) {\n                        return input.info == null;\n                    }\n                }));\n            }\n{code}\n\nboth methods should probably check for {{input}} being null before accessing {{input.info}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove Nullable annotation in Predicates of BackgroundObserver"
   },
   {
      "_id": "12821620",
      "assignee": "tripod",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         }
      ],
      "created": "2015-04-16 18:28:46",
      "description": "Depending of the LDAP server configuration, it fails to connect as the server doesn't allow the connection validation query.\n\nIt fails on \n{quote}\nCaused by: java.util.NoSuchElementException: Could not create a validated object, cause: ValidateObject failed\nat org.apache.commons.pool.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:1233)\nat org.apache.directory.ldap.client.api.LdapConnectionPool.getConnection(LdapConnectionPool.java:56)\nat org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider.connect(LdapIdentityProvider.java:532)\n... 92 common frames omitted\n{quote}\n\nBased on customer analyze of Oak code this is the reason it fails:\n\n{quote}\n \tI think I have found a solution for the problem. While the system is initializing the connection it tries to validate the connection. This is the reason for the strange search request:\n\nSearchRequest\nbaseDn : ''\nfilter : '(objectClass=*)'\nscope : base object\n\nBecause such kind of requests are not allowed in the client's ldap system the connection is being rejected (as invalid). It is configurable if the connection should be validated. The class org.apache.jackrabbit.oak.security.authentication.ldap.impl.LdapIdentityProvider contains this code\n\nif (config.getAdminPoolConfig().getMaxActive() != 0) {\nadminPool = new LdapConnectionPool(adminConnectionFactory);\nadminPool.setTestOnBorrow(true);\nadminPool.setMaxActive(config.getAdminPoolConfig().getMaxActive());\nadminPool.setWhenExhaustedAction(GenericObjectPool.WHEN_EXHAUSTED_BLOCK);\n}\n\nA solution for our Problem would most probably be to change the connectionPool configuration adminPool.setTestOnBorrow(false);\nThis Parameter comes sadly not from the identity provider configuration.\n\nIs there a way to change this this parameter without creating an own implementation of the identity provider?\n{quote}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Make LDAP connection pool 'testOnBorrow' configurable"
   },
   {
      "_id": "12821214",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-04-15 15:55:37",
      "description": "According to the javadocs (QueryIndex) minimum cost for index is 1. Currently ReferenceIndex returns this minimum value, when it can be used for the query.\n\nBut even then cost for remaining indexes is still calculated. We could skip cost calculation of remaining indexes if we achieved the minimum cost already.\nIt will speed up all queries which can leverage the reference Index.\n\nExample query:\n\nSELECT * FROM [nt:base] WHERE PROPERTY([rep:members], 'WeakReference') = '345bef9b-ffa1-3e09-85df-1e03cfa0fb37'",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Minimize the cost calculation for queries using reference restrictions."
   },
   {
      "_id": "12821153",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-15 13:26:25",
      "description": "The {{Oak#createContentRepository()}} method changes the state of the builder at every invocation. In particular, it always adds a new {{CommitHook}}.\n\nThe observable behavior is that all the {{IndexEditor}} instances are executed twice when the {{Oak}} and {{Jcr}} builders are used together - i.e. when both an instance of {{Repository}} and {{ContentRepository}} are needed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak builder changes its state during repository creation"
   },
   {
      "_id": "12820818",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-14 13:42:39",
      "description": "The backgroundOperationLock in DocumentNodeStore uses the default non-fair acquisition order. According to JavaDoc of ReentrantReadWriteLock it is possible that a background operation task gets delayed for a long time when the system is under load. We should probably consider using the fair mode for the backgroundOperationLock to make sure background operation tasks do not get delayed excessively.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fair mode for backgroundOperationLock"
   },
   {
      "_id": "12820814",
      "assignee": "edivad",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-04-14 13:28:08",
      "description": "Create a matrix for the 1.2 branch as the one we have for trunk",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Enable a Jenkins matrix for the 1.2 branch"
   },
   {
      "_id": "12820786",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-14 11:04:36",
      "description": "OAK-2127 introduced a maxLockTryTimeMS to allow a writer to proceed with a merge even if the merge lock is currently acquired by another thread. The value is currently hardcoded.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Configurable maxLockTryTimeMS"
   },
   {
      "_id": "12820732",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326717",
            "id": "12326717",
            "name": "cache"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-14 06:59:21",
      "description": "The persistent cache usually stores data in a background thread, but sometimes (if a lot of data is added quickly) the foreground thread is blocked.\n\nEven worse, switching the cache file can happen in a foreground thread, with the following stack trace.\n\n{noformat}\n\"127.0.0.1 [1428931262206] POST /bin/replicate.json HTTP/1.1\" prio=5 tid=0x00007fe5df819800 nid=0x9907 runnable [0x0000000113fc4000]\n   java.lang.Thread.State: RUNNABLE\n        ...\n\tat org.h2.mvstore.MVStoreTool.compact(MVStoreTool.java:404)\n\tat org.apache.jackrabbit.oak.plugins.document.persistentCache.PersistentCache$1.closeStore(PersistentCache.java:213)\n\t- locked <0x0000000782483050> (a org.apache.jackrabbit.oak.plugins.document.persistentCache.PersistentCache$1)\n\tat org.apache.jackrabbit.oak.plugins.document.persistentCache.PersistentCache.switchGenerationIfNeeded(PersistentCache.java:350)\n\t- locked <0x0000000782455710> (a org.apache.jackrabbit.oak.plugins.document.persistentCache.PersistentCache)\n\tat org.apache.jackrabbit.oak.plugins.document.persistentCache.NodeCache.write(NodeCache.java:85)\n\tat org.apache.jackrabbit.oak.plugins.document.persistentCache.NodeCache.put(NodeCache.java:130)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.applyChanges(DocumentNodeStore.java:1060)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToCache(Commit.java:599)\n\tat org.apache.jackrabbit.oak.plugins.document.CommitQueue.afterTrunkCommit(CommitQueue.java:127)\n\t- locked <0x0000000781890788> (a org.apache.jackrabbit.oak.plugins.document.CommitQueue)\n\tat org.apache.jackrabbit.oak.plugins.document.CommitQueue.done(CommitQueue.java:83)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.done(DocumentNodeStore.java:637)\n{noformat}\n\nTo avoid blocking the foreground thread, one solution is to store all data in a separate thread. If there is too much data added, then some of the data is not stored. If possible, the data that was not referenced a lot, and / or old revisions of documents (if new revisions are available).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Persistent cache: add data in a different thread"
   },
   {
      "_id": "12820540",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-13 14:02:11",
      "description": "Under some rare circumstances there is a warning in the logs:\n\n{noformat}\n11:57:47.375 WARN  [pool-1-thread-24] FileStore.java:865    Failed to read from tar file target/SegmentCompactionIT1331315031754226278dir/data01460a.tar\njava.io.IOException: Stream Closed\n        at java.io.RandomAccessFile.seek(Native Method) ~[na:1.7.0_75]\n        at org.apache.jackrabbit.oak.plugins.segment.file.FileAccess$Random.read(FileAccess.java:105) ~[classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.file.TarReader.readEntry(TarReader.java:502) ~[classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:860) ~[classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.getSegment(SegmentTracker.java:128) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:108) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:348) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.readPropsV11(Segment.java:476) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.loadTemplate(Segment.java:449) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:402) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:396) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:79) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getChildNodeCount(SegmentNodeState.java:357) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomReader.readRandomTree(SegmentCompactionIT.java:410) [test-classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomPropertyReader.call(SegmentCompactionIT.java:446) [test-classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomPropertyReader.call(SegmentCompactionIT.java:439) [test-classes/:na]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_75]\n{noformat}\n\nThis happens due to a race between {{FileStore#readSegment}} reading from tar files and already removed by {{FileStore#flush}}. This isn't a problem as the tar file in question is still present at a newer generation and the {{FileStore}} will eventually read from that one. However the warning looks rather scaring and somewhat implies a defect. \n\nWe should either lower the log level or remove the race. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Failed to read from tar file "
   },
   {
      "_id": "12820397",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-12 14:45:45",
      "description": "Oak Observation support exposes a {{EventListenerMBean}} [1] which provide quite a bit of details around registered observation listeners. However in a typical application there would be multiple listeners registered. To simplify monitoring it would be helpful to have a _consolidated_ view of all listeners related statistics.\n\nFurther the stats can also include some more details which are Oak specific\n* Subtree paths to which the listener listens to - By default JCR Api allows single path however Oak allows a listener to register to multiple paths\n* If listener is enabled to listen to cluster local and cluster external changes\n* Size of queue in BackgroundObserver\n* Distribution of change types present in the queue - Local, External etc\n\n[1] https://github.com/apache/jackrabbit/blob/trunk/jackrabbit-api/src/main/java/org/apache/jackrabbit/api/jmx/EventListenerMBean.java",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring",
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Consolidated JMX view of all EventListener related statistics"
   },
   {
      "_id": "12820275",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-11 06:33:43",
      "description": "{{LucenePropertyIndex}} currently uses unique PathCursor [1] due to which the cursor would maintain an in memory set of visited path. This might grow big if result size is big and cursor is traversed completely.\n\nAs with current impl the path would not be duplicated we can avoid using unique cursor\n\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java#L1153-1154",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Use non unique PathCursor in LucenePropertyIndex"
   },
   {
      "_id": "12820040",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-10 12:03:08",
      "description": "In case of big repositories, asynchronous index like Lucene Property,\ncould lag behind as slow indexes, for example Full Text, are taken\ncare in the same thread pool.\n\nProvide a separate thread pool in which such indexes could be\nregistered.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide a \"different lane\" for slow indexers in async indexing"
   },
   {
      "_id": "12819969",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326717",
            "id": "12326717",
            "name": "cache"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-10 07:43:21",
      "description": "Currently the Cache invalidation logic used in MongoDocumentStore check for cache consistency for all the entries present in the cache. With use of persistent cache its possible that pressure on backend cache would be reduced and some of the cache entries are not being accessed for long time.\n\nCache invalidation logic should take into account such access statistics and not perform consistency check for cached instance which are not accessed for some long time (10 mins?). Such cache entries should be directly discarded.\n\nPS: Looking at [1] it appears that Guava cache does not enforces a global LRU eviction policy. The policy is maintained per segment table\n\n[1] http://stackoverflow.com/questions/10236057/guava-cache-eviction-policy",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Ignore lesser used old cache entries while invalidating cache entries in background read"
   },
   {
      "_id": "12819966",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-10 07:23:14",
      "description": "Currently when PersistentCache is enabled then any put results in addition of the entry to in memory cache and also to the backing persistent cache. While adding the entry to the persistent cache there is slight overhead of serialization of the entry to be paid.\n\nTo avoid such overheads at time of read/write to in memory cache it would be better to move the logic to separate thread. PersistentCache can make use of Guava cache eviction callback and then add the entry to the backend persistent store",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "PersistentCache should rely on eviction callback to add entry to the persistent cache"
   },
   {
      "_id": "12819945",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-04-10 05:17:25",
      "description": "By default the cache memory in DocumentNodeStore is distributed in following ratio\n\n* nodeCache - 25%\n* childrenCache - 10%\n* docChildrenCache - 3%\n* diffCache - 5%\n* documentCache - Is given the rest i.e. 57%\n\nHowever off late we have found that with persistent cache enabled we can lower the cache allocated to Document cache. That would reduce the time spent in invalidating cache entries in periodic reads. So far we are using following ration in few setup and that is turning out well\n\n* nodeCachePercentage=35\n* childrenCachePercentage=20\n* diffCachePercentage=30\n* docChildrenCachePercentage=10\n* documentCache - Is given the rest i.e. 5%\n\nWe should use the above distribution by default if the persistent cache is found to be enabled\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Change default cache distribution ratio if persistent cache is enabled"
   },
   {
      "_id": "12819682",
      "assignee": "egli",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-09 13:56:43",
      "description": "Currently, in an oak-cluster when (e.g.) one oak-client stops renewing its lease (ClusterNodeInfo.renewLease()), this will be eventually noticed by the others in the same oak-cluster. Those then mark this client as {{inactive}} and start recoverying and subsequently removing that node from any further merge etc operation.\n\nNow, whatever the reason was why that client stopped renewing the lease (could be an exception, deadlock, whatever) - that client itself still considers itself as {{active}} and continues to take part in the cluster action.\n\nThis will result in a unbalanced situation where that one client 'sees' everybody as {{active}} while the others see this one as {{inactive}}.\n\nIf this ClusterNodeInfo state should be something that can be built upon, and to avoid any inconsistency due to unbalanced handling, the inactive node should probably retire gracefully - or any other appropriate action should be taken, other than just continuing as today.\n\nThis ticket is to keep track of ideas and actions taken wrt this.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "take appropriate action when lease cannot be renewed (in time)"
   },
   {
      "_id": "12819638",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-09 11:23:41",
      "description": "Oak.createContentRepository does not closes the executors it creates upon close. It should close the executor if that is created by itself and not passed by outside\n\nAlso see recent [thread|http://markmail.org/thread/rryydj7vpua5qbub].",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Oak instance does not close the executors created upon ContentRepository creation"
   },
   {
      "_id": "12819623",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-09 10:06:23",
      "description": "The diff created by the test uses a lot of memory. Either test test should be changed or the implementation should ignore further changes once a threshold is reached.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MongoDiffCacheTest.sizeLimit() uses too much memory"
   },
   {
      "_id": "12819614",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-09 09:21:38",
      "description": "A repository with continuous writes can keep the compactor from completing causing the repository size to grow indefinitely. \n\nThis effect is caused by the compactor trying to catch up with changes that occurred while compacting. I.e. compacting them on top of the already compacted head. When there is a steady stream of incoming changes it can happen that the compactor never actually catches up. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "doc-impacting",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction does not finish on repository with continuous writes "
   },
   {
      "_id": "12819613",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-04-09 09:16:52",
      "description": "Queries with \"like\" conditions of the form \"x like 'abc%'\" are currently always converted to range queries. With Apache Lucene, using \"like\" in some cases is a bit faster (but not much, according to our tests).\n\nConverting \"like\" to range queries should be disabled by default.\n\nPotential patch:\n{noformat}\n--- src/main/java/org/apache/jackrabbit/oak/query/ast/ComparisonImpl.java\t(revision 1672070)\n+++ src/main/java/org/apache/jackrabbit/oak/query/ast/ComparisonImpl.java\t(working copy)\n@@ -31,11 +31,21 @@\n import org.apache.jackrabbit.oak.query.fulltext.LikePattern;\n import org.apache.jackrabbit.oak.query.index.FilterImpl;\n import org.apache.jackrabbit.oak.spi.query.PropertyValues;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n /**\n  * A comparison operation (including \"like\").\n  */\n public class ComparisonImpl extends ConstraintImpl {\n+    \n+    static final Logger LOG = LoggerFactory.getLogger(ComparisonImpl.class);\n+    \n+    private final static boolean CONVERT_LIKE_TO_RANGE = Boolean.getBoolean(\"oak.convertLikeToRange\");\n+    \n+    static {\n+        LOG.info(\"Converting like to range queries is \" + (CONVERT_LIKE_TO_RANGE ? \"enabled\" : \"disabled\"));\n+    }\n \n     private final DynamicOperandImpl operand1;\n     private final Operator operator;\n@@ -193,7 +203,7 @@\n                     if (lowerBound.equals(upperBound)) {\n                         // no wildcards\n                         operand1.restrict(f, Operator.EQUAL, v);\n-                    } else if (operand1.supportsRangeConditions()) {\n+                    } else if (operand1.supportsRangeConditions() && CONVERT_LIKE_TO_RANGE) {\n                         if (lowerBound != null) {\n                             PropertyValue pv = PropertyValues.newString(lowerBound);\n                             operand1.restrict(f, Operator.GREATER_OR_EQUAL, pv);\n@@ -203,7 +213,7 @@\n                             operand1.restrict(f, Operator.LESS_OR_EQUAL, pv);\n                         }\n                     } else {\n-                        // path conditions\n+                        // path conditions, or conversion is disabled\n                         operand1.restrict(f, operator, v);\n                     }\n                 } else {\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Option to convert \"like\" queries to range queries"
   },
   {
      "_id": "12819364",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-08 15:56:16",
      "description": "On a very busy site, we're observing an NPE in the code that should gather information about a JCR event for our custom event handler. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NPE when calling Event.getInfo()"
   },
   {
      "_id": "12818944",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-04-07 14:24:14",
      "description": "As discussed in OAK-2718 it'd be good to be able to selectively find Solr indexes by path, as done in Lucene index, see also OAK-2570.\nThis would avoid having to do full diffs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NodeStateSolrServersObserver should be filtering path selectively"
   },
   {
      "_id": "12818886",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-07 10:32:11",
      "description": "{{IndexCopier}} tries to remove the older index directory incase of reindex. This might fails on platform like Windows if the files are still memory mapped or are locked.\n\nFor deleting directories we would need to take similar approach like being done with deleting old index files i.e. do retries later.\n\nDue to this following test fails on Windows (Per [~julian.reschke@gmx.de] )\n\n{noformat}\nTests run: 9, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.07 sec <<< FAILURE!\ndeleteOldPostReindex(org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopierTest)  Time elapsed: 0.02 sec  <<< FAILURE!\njava.lang.AssertionError: Old index directory should have been removed\n        at org.junit.Assert.fail(Assert.java:93)\n        at org.junit.Assert.assertTrue(Assert.java:43)\n        at org.junit.Assert.assertFalse(Assert.java:68)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopierTest.deleteOldPostReindex(IndexCopierTest.java:160)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "IndexCopier fails to delete older index directory upon reindex"
   },
   {
      "_id": "12818550",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-06 07:05:18",
      "description": "At times following warning is seen in logs\n\n{noformat}\n31.03.2015 14:04:57.610 *WARN* [pool-6-thread-7] org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier Found local copy for _0.cfs in NIOFSDirectory@/path/to/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 lockFactory=NativeFSLockFactory@/path/to/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 but size of local 1040384 differs from remote 1958385. Content would be read from remote file only\n{noformat}\n\nThe file length check provides a weak check around index file consistency. In some cases this warning is misleading. For e.g. \n\n# Index version Rev1 - Task submitted to copy index file F1 \n# Index updated to Rev2 - Directory bound to Rev1 is closed\n# Read is performed with Rev2 for F1 - Here as the file would be locally created the size would be different as the copying is in progress\n\nIn such a case the logic should ensure that once copy is done the local file gets used",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Misleading warn message about local copy size different than remote copy in oak-lucene with copyOnRead enabled"
   },
   {
      "_id": "12787285",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-04-01 07:40:32",
      "description": "This issue is for tracking test failures seen at our Jenkins instance that might yet be transient. Once a failure happens too often we should remove it here and create a dedicated issue for it. \n\nh2. Current issues\n\n|| Test                                                                                       || Builds || Fixture      || JVM || Branch ||\n| org.apache.jackrabbit.oak.jcr.ConcurrentAddIT.addNodesSameParent | 427, 428, 758 | DOCUMENT_NS, SEGMENT_MK, DOCUMENT_RDB | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.jcr.ConcurrentAddIT.addNodes\\[DocumentNodeStore\\[RDB\\] on jdbc:h2:file:./target/oaktest\\] | 829, 846 | | | 1.4 |\n| org.apache.jackrabbit.oak.jcr.ConcurrentAddIT| 720, 818 | DOCUMENT_RDB | 1.7 | 1.5 |\n| org.apache.jackrabbit.oak.jcr.ConcurrentAddReferenceTest.addReferences[DocumentNodeStore\\[RDB] on jdbc:h2:file:./target/oaktest] |  778, 850 | RDB, NS | 1.7, 1.8 | 1.4 |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTest.testReorder\\[RDBDocumentStore on jdbc:h2:file:./target/oaktest] |  851 | | | 1.2 |\n| org.apache.jackrabbit.oak.osgi.OSGiIT.listServices | 851 | | | 1.2 |\n| org.apache.jackrabbit.oak.plugins.document.BulkCreateOrUpdateClusterTest.testConcurrentWithConflict\\[RDBFixture:RDB-Derby(embedded)] | 797, 823, 841, 842, 843, 847, 848, 850, 853 | | | 1.4, 1.5 |\n| org.apache.jackrabbit.oak.plugins.document.BulkCreateOrUpdateTest | 731, 732, 767 | DOCUMENT_RDB, DOCUMENT_NS | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.plugins.document.DocumentDiscoveryLiteServiceIT.testLargeStartStopFiesta | 803, 823, 849, 853 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.document.DocumentDiscoveryLiteServiceTest | 361, 608 | DOCUMENT_NS, SEGMENT_MK | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreTest.recoverBranchCommit | 805 | | | 1.0 |\n| org.apache.jackrabbit.oak.plugins.document.blob.RDBBlobStoreTest | 673, 674, 786, 787 | SEGMENT_MK, DOCUMENT_NS, DOCUMENT_RDB | 1.7, 1.8 |  |\n| org.apache.jackrabbit.oak.plugins.document.blob.RDBBlobStoreTest.testUpdateAndDelete[MyFixture: RDB-Derby(embedded)] | 780, 785, 786, 787 | RDB, NS, | 1.7, 1.8 | 1.5, 1.4 |\n| org.apache.jackrabbit.oak.plugins.document.persistentCache.BroadcastTest | 648, 679 | SEGMENT_MK, DOCUMENT_NS | 1.8 |  |\n| org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopierTest.reuseLocalDir                 | 81      | DOCUMENT_RDB | 1.7   | |\n| org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinitionTest | 770 | DOCUMENT_RDB, DOCUMENT_NS, SEGMENT_MK | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexEditorTest | 490, 623, 624, 656, 679 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexHookIT.testPropertyAddition | 775, 782, 783, 789, 821, 832 | Segment, rdb | 1.7, 1.8 | 1.5, 1.2, 1.0 |\n| org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTestIT.testNativeMLTQuery | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTestIT.testNativeMLTQueryWithStream | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.plugins.index.solr.query.SolrQueryIndexTest | 148, 151, 490, 656, 679 | SEGMENT_MK, DOCUMENT_NS, DOCUMENT_RDB | 1.5, 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.server.EmbeddedSolrServerProviderTest.testEmbeddedSolrServerInitialization | 490, 656, 679 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.util.NodeTypeIndexingUtilsTest | 663 | SEGMENT_MK | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.util.NodeTypeIndexingUtilsTest.testSynonymsFileCreation | 627 | DOCUMENT_RDB |1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.ExternalBlobIT.testDataStoreBlob | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.ExternalBlobIT.testNullBlobId | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.ExternalBlobIT.testSize | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.heavyWrite\\[usePersistedMap: false] | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.heavyWrite\\[usePersistedMap: true] | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest | 731, 766, 767, 773, 777, 815 | SEGMENT_MK | 1.7, 1.8 | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest.testProxyFlippedEndByte | 804 | | | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest.testProxyFlippedIntermediateByteSSL | 777 | Segment | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest.testProxyFlippedStartByteSSL | 773, 843 | Segment | 1.8 | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest.testProxySSLSkippedBytes | 788,806 | Segment | 1.7, 1.8 | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT | 722, 731, 733, 755, 759, 776, 812, 815, 816, 817 | SEGMENT_MK | 1.7, 1.8 | 1.4, 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxyFlippedIntermediateByte | 837, 848 | | | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxyFlippedIntermediateByte2 | 837 | | | | \n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxyFlippedIntermediateByteChange2 | 797, 837 | | | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxyFlippedStartByte | 794, 837, 848 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxySkippedBytes | 788, 837, 848 | Segment | 1.7, 1.8 | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxySkippedBytesIntermediateChange | 779, 776, 773 | Segment | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testSync | 837 | | | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT.testProxySkippedBytes | 788 | Segment | 1.7, 1.8 | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.FailoverSslTestIT | 759 | SEGMENT_MK | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.FailoverSslTestIT.testFailoverSecure | 794, 846 | | | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.StandbyTest.testSync | 839 | | | |\n| org.apache.jackrabbit.oak.remote.http.handler.RemoteServerIT | 643 | DOCUMNET_NS | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.run.osgi.DocumentNodeStoreConfigTest.testRDBDocumentStoreRestart | 621 | DOCUMENT_NS | 1.8 | |\n| org.apache.jackrabbit.oak.run.osgi.DocumentNodeStoreConfigTest.testRDBDocumentStore_CustomBlobStore | 52, 181, 399 |  SEGMENT_MK, DOCUMENT_NS | 1.7 | |\n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapDefaultLoginModuleTest | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest | 689 | SEGMENT_MK | 1.8 | |\n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testAuthenticate | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testAuthenticateCaseInsensitive | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testAuthenticateFail | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testAuthenticateValidateTrueTrue | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetGroups | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetMembers | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetUserByForeignRef | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetUserByRef | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetUserByUserId | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testListUsersWithMissingUid | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testSplitDNIntermediatePath | 833 | | | | \n| org.apache.jackrabbit.oak.spi.security.authorization.cug.impl.* | 648 | SEGMENT_MK, DOCUMENT_NS | 1.8 |  |\n| org.apache.jackrabbit.oak.standalone.RepositoryBootIT | 755 | DOCUMENT_NS | 1.7 | |\n| org.apache.jackrabbit.oak.standalone.RepositoryBootIT.repositoryLogin | 778, 781, 793 | RDB, NS | 1.7, 1.8 | 1.5, 1.4 |\n\nh2. fixed or not happening for a while\n\n|| Test                                                                                       || Builds || Fixture      || JVM || Branch ||\n| Build crashes: malloc(): memory corruption | 477 | DOCUMENT_NS | 1.5 | |\n| org.apache.jackrabbit.j2ee.TomcatIT | 589 | SEGMENT_MK | 1.8 | |\n| org.apache.jackrabbit.j2ee.TomcatIT.testTomcat | 489, 493, 597, 648, 801 | DOCUMENT_NS, SEGMENT_MK | 1.7 |  |\n| org.apache.jackrabbit.oak.jcr.ConcurrentFileOperationsTest.concurrent | 110, 382 | DOCUMENT_RDB | 1.5 | |\n| org.apache.jackrabbit.oak.jcr.MoveRemoveTest.removeExistingNode | 115 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.jcr.OrderedIndexIT.oak2035                                         | 76, 128 | SEGMENT_MK , DOCUMENT_RDB  | 1.5   | |\n| org.apache.jackrabbit.oak.jcr.RepositoryTest.addEmptyMultiValue | 115 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.jcr.cluster.NonLocalObservationIT | 731 | DOCUMENT_RDB | 1.8 | |\n| org.apache.jackrabbit.oak.jcr.nodetype.NodeTypeTest.updateNodeType | 243, 400 | DOCUMENT_RDB | 1.5, 1.8 | |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTest.disjunctPaths | 121, 157, 396 | DOCUMENT_RDB | 1.5, 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTest.removeSubtreeFilter | 94 | DOCUMENT_RDB | 1.5 | |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTest.testReorder | 155 | DOCUMENT_RDB | 1.8 | |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTesttestMove | 308 | DOCUMENT_RDB | 1.5 | |\n| org.apache.jackrabbit.oak.jcr.query.QueryPlanTest.nodeType | 272 | DOCUMENT_RDB | 1.8 | |\n| org.apache.jackrabbit.oak.jcr.query.QueryPlanTest.propertyIndexVersusNodeTypeIndex | 90 | DOCUMENT_RDB | 1.5 | |\n| org.apache.jackrabbit.oak.jcr.query.SuggestTest | 171 | SEGMENT_MK | 1.8 | |\n| org.apache.jackrabbit.oak.jcr.query.SuggestTest.testNoSuggestions | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.jcr.query.SuggestTest.testSuggestSql | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.jcr.query.SuggestTest.testSuggestXPath | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.jcr.version.VersionablePathNodeStoreTest.testVersionablePaths | 361 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.osgi.OSGiIT | 767, 770 | SEGMENT_MK, DOCUMENT_RDB, DOCUMENT_NS | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.osgi.OSGiIT.bundleStates | 163, 656 | SEGMENT_MK, DOCUMENT_RDB, DOCUMENT_NS | 1.5, 1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.StandbyTestIT.testSyncLoop                 | 64      | ?            | ?     | |\n| org.apache.jackrabbit.oak.run.osgi.JsonConfigRepFactoryTest.testRepositoryTar                | 41      | ?            | ?     | |\n| org.apache.jackrabbit.oak.run.osgi.PropertyIndexReindexingTest.propertyIndexState | 492 | DOCUMENT_NS | 1.5 | |\n| org.apache.jackrabbit.oak.stats.ClockTest.testClockDriftFast | 115, 142 | SEGMENT_MK, DOCUMENT_NS | 1.6, 1.8 | |\n| org.apache.jackrabbit.oak.upgrade.cli.SegmentToJdbcTest.validateMigration | 486 | DOCUMENT_NS | 1.7|  |\n| org.apache.jackrabbit.test.api.observation.PropertyAddedTest.testMultiPropertyAdded          | 29      | ?            | ?     | |\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failures on Jenkins"
   },
   {
      "_id": "12787040",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-31 14:26:33",
      "description": "In environments with a lot of volatile content the {{CompactionMap}} can end up eating a lot of memory. From {{CompactionStrategyMBean#getCompactionMapStats}}:\n\n{noformat}\n[Estimated Weight: 317,5 MB, Records: 39500094, Segments: 36698], \n[Estimated Weight: 316,4 MB, Records: 39374593, Segments: 36660], \n[Estimated Weight: 315,4 MB, Records: 39253205, Segments: 36620], \n[Estimated Weight: 315,1 MB, Records: 39221882, Segments: 36614], \n[Estimated Weight: 314,9 MB, Records: 39195490, Segments: 36604], \n[Estimated Weight: 315,0 MB, Records: 39182753, Segments: 36602], \n[Estimated Weight: 360 B, Records: 0, Segments: 0],\n{noformat}\n\n\nThis causes compaction to be skipped:\n\n{noformat}\n2015-03-30:30.03.2015 02:00:00.038 *INFO* [] [TarMK compaction thread [/foo/bar/crx-quickstart/repository/segmentstore], active since Mon Mar 30 02:00:00 CEST 2015, previous max duration 3854982ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore Not enough available memory 5,5 GB, needed 6,3 GB, last merge delta 1,3 GB, so skipping compaction for now\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "High memory usage of CompactionMap"
   },
   {
      "_id": "12787030",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-03-31 13:58:29",
      "description": "FindBugs complains about usages of ItemImpl#perform that is annotated with {{@CheckForNull}} but callers expecting a non-null return value.... most prominently in NodeImpl",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Possible null-dereference when calling ItemImpl#perform"
   },
   {
      "_id": "12787023",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-31 13:29:15",
      "description": "the default {{toString}} for all tree implementations calculates a string containing the path, the toString of all properties as well as the names of all child tree... this is prone to cause troubles in case for trees that have plenty of properties and children.\n\ni would strongly recommend to review this and make the toString of trees both meaningful and cheap.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Troublesome AbstractTree.toString"
   },
   {
      "_id": "12786731",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-03-30 14:00:56",
      "description": "When running Integration testing often the test fail with the following\n\n{noformat}\naddNodes[2](org.apache.jackrabbit.oak.jcr.ConcurrentAddIT)  Time elapsed: 9.88 sec  <<< ERROR!\njava.lang.RuntimeException: org.apache.jackrabbit.oak.api.CommitFailedException: OakMerge0001: OakMerge0001: Failed to merge changes to the underlying store (retries 5, 5240 ms)\n\tat org.apache.jackrabbit.oak.spi.lifecycle.OakInitializer.initialize(OakInitializer.java:64)\n\tat org.apache.jackrabbit.oak.Oak.createContentRepository(Oak.java:561)\n\tat org.apache.jackrabbit.oak.jcr.Jcr.createRepository(Jcr.java:202)\n\tat org.apache.jackrabbit.oak.jcr.AbstractRepositoryTest.createRepository(AbstractRepositoryTest.java:125)\n\tat org.apache.jackrabbit.oak.jcr.AbstractRepositoryTest.getRepository(AbstractRepositoryTest.java:115)\n\tat org.apache.jackrabbit.oak.jcr.AbstractRepositoryTest.createAdminSession(AbstractRepositoryTest.java:149)\n\tat org.apache.jackrabbit.oak.jcr.AbstractRepositoryTest.getAdminSession(AbstractRepositoryTest.java:136)\n\tat org.apache.jackrabbit.oak.jcr.ConcurrentAddIT.addNodes(ConcurrentAddIT.java:54)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\n\tat org.junit.runners.Suite.runChild(Suite.java:24)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakMerge0001: OakMerge0001: Failed to merge changes to the underlying store (retries 5, 5240 ms)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:257)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:191)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:159)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1434)\n\tat org.apache.jackrabbit.oak.spi.lifecycle.OakInitializer.initialize(OakInitializer.java:62)\n\t... 34 more\nCaused by: org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: update of 1:/jcr:system failed, race condition?\n\tat org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.internalCreateOrUpdate(RDBDocumentStore.java:914)\n\tat org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStore.createOrUpdate(RDBDocumentStore.java:256)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.createOrUpdateNode(Commit.java:437)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:341)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:246)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyInternal(Commit.java:215)\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.apply(Commit.java:200)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:311)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:281)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.access$200(DocumentNodeStoreBranch.java:52)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch$InMemory.merge(DocumentNodeStoreBranch.java:520)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge0(DocumentNodeStoreBranch.java:234)\n\t... 38 more\n{noformat}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ConcurrentAddIT occasionally fail with OakMerge0001"
   },
   {
      "_id": "12785952",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-26 17:33:32",
      "description": "{{org.apache.jackrabbit.core.query.QueryResultTest.testGetSize}} fails every couple of builds:\n\n{noformat}\njunit.framework.AssertionFailedError: Wrong size of NodeIterator in result expected:<48> but was:<-1>\n\tat junit.framework.Assert.fail(Assert.java:50)\n\tat junit.framework.Assert.failNotEquals(Assert.java:287)\n\tat junit.framework.Assert.assertEquals(Assert.java:67)\n\tat junit.framework.Assert.assertEquals(Assert.java:134)\n\tat org.apache.jackrabbit.core.query.QueryResultTest.testGetSize(QueryResultTest.java:47)\n{noformat}\n\nFailure seen at builds: 29, 39, 59, 61, 114, 117, 118, 120, 139, 142\n\nSee e.g. https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/59/jdk=jdk-1.6u45,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=unittesting/testReport/junit/org.apache.jackrabbit.core.query/QueryResultTest/testGetSize/\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: QueryResultTest.testGetSize"
   },
   {
      "_id": "12785898",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-26 14:57:06",
      "description": "The method Segment.readString is called a lot, and even a small optimization would improve performance for some use cases. Currently it uses a concurrent hash map to cache strings. It might be possible to speed up this cache.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Segment.readString optimization"
   },
   {
      "_id": "12785845",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-26 11:04:10",
      "description": "The persistent cache most likely reduce performance in some uses cases, but currently it's hard to find out if that's the case or not.\n\nActivity should be captured (and logged with debug level) if possible, for example writing, reading, writing in the foreground / background, opening and closing, switching the generation, moving entries from old to new generation.\n\nAdding entries to the cache could be completely decoupled from the foreground thread, if they are added to the persistent cache in a separate thread.\n\nIt might be better to only write entries if they were accessed often. To do this, entries could be put in the persistent cache once they are evicted from the in-memory cache, instead of when they are added to the cache. If that's done, we would maintain some data (for example access count) on which we can filter.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Persistent cache: log activity and timing data, and possible optimizations"
   },
   {
      "_id": "12785837",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-26 10:28:08",
      "description": "Currently the DocumentNodeState has two revisions:\n\n- {{getRevision()}} returns the read revision of this node state. This revision was used to read the node state from the underlying {{NodeDocument}}.\n- {{getLastRevision()}} returns the revision when this node state was last modified. This revision also reflects changes done further below the tree when the node state was not directly affected by a change.\n\nThe lastRevision of a state is then used as the read revision of the child node states. This avoids reading the entire tree again with a different revision after the head revision changed because of a commit.\n\nThis approach has at least two problems related to comparing node states:\n\n- It does not work well with the current DiffCache implementation and affects the hit rate of this cache. The DiffCache is pro-actively populated after a commit. The key for a diff is a combination of previous and current commit revision and the path. The value then tells what child nodes were added/removed/changed. As the comparison of node states proceeds and traverses the tree, the revision of a state may go back in time because the lastRevision is used as the read revision of the child nodes. This will cause misses in the diff cache, because the revisions do not match the previous and current commit revisions as used to create the cache entries. OAK-2562 tried to address this by keeping the read revision for child nodes at the read revision of the parent in calls of compareAgainstBaseState() when there is a diff cache hit. However, it turns out node state comparison does not always start at the root state. The {{EventQueue}} implementation in oak-jcr will start at the paths as indicated by the filter of the listener. This means, OAK-2562 is not effective in this case and the diff needs to be calculated again based on a set of revisions, which is different from the original commit.\n\n- When a diff is calculated for a parent with many child nodes, the {{DocumentNodeStore}} will perform a query on the underlying {{DocumentStore}} to get child nodes modified after a given timestamp. This timestamp is derived from the lower revision of the two lastRevisions of the parent node states to compare. The query gets problematic for the {{DocumentStore}} if the timestamp is too far in the past. This will happen when the parent node (and sub-tree) was not modified for some time. E.g. the {{MongoDocumentStore}} has an index on the _id and the _modified field. But if there are many child nodes the _id index will not be that helpful and if the timestamp is too far in the past, the _modified index is not selective either. This problem was already reported in OAK-1970 and linked issues.\n\nBoth of the above problems could be addressed by keeping track of the read revision of the root node state in each of the node states as the tree is traversed. The revision of the root state would then be used e.g. to derive the timestamp for the _modified constraint in the query. Because the revision of the root state is rather recent, the _modified constraint is very selective and the index on it would be the preferred choice.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Track root state revision when reading the tree"
   },
   {
      "_id": "12785591",
      "assignee": "egli",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-03-25 16:56:16",
      "description": "Currently the lease mechanism in DocumentNodeStore/mongoMk is based on the assumption that the clocks are in perfect sync between all nodes of the cluster. The lease is valid for 60sec with a timeout of 30sec. If clocks are off by too much, and background operations happen to take couple seconds, you run the risk of timing out a lease. So introducing a check which WARNs if the clocks in a cluster are off by too much (1st threshold, eg 5sec?) would help increase awareness. Further drastic measure could be to prevent a startup of Oak at all if the difference is for example higher than a 2nd threshold (optional I guess, but could be 20sec?).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Introduce time difference detection for DocumentNodeStore"
   },
   {
      "_id": "12785538",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-25 14:50:54",
      "description": "A lease update of the DocumentNodeStore on MongoDB will acquire a lock in MongoDocumentStore to perform the changes. The locking is only necessary for changes in the 'nodes' collection, because only those documents are cached and the locking makes sure the cache is consistent. The MongoDocumentStore must be changed to only acquire a lock when changes are done in the 'nodes' collection.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Update lease without holding lock"
   },
   {
      "_id": "12785512",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-03-25 13:16:01",
      "description": "If there are many indexes, preparing a query can take a long time, in relation to executing the query.\n\nThe query execution plans can be cached. The cache should be invalidated if there are new indexes, or indexes are changed; a simple solution might be to use a timeout, and / or a manual cache clean via JMX or so.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Query engine: faster cost calculation"
   },
   {
      "_id": "12785502",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-25 12:00:53",
      "description": "Currently the diff perf logs in {{NodeObserver}} does not indicate what type of change was processed i.e. was the change an internal one or an external one. \n\nHaving this information would allow us to determine how the cache is being used. For e.g. if we see slower number even for local changes then that would indicate that there is some issue with the diff cache and its not be being utilized effectively ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation",
         "performance",
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Include change type information in perf logs for diff logic"
   },
   {
      "_id": "12784761",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-03-23 08:25:35",
      "description": "Scripts and/or support should be added in oak-run console to support repair and recovery options as supported for Mongo.\nAlso, needed are options that are supported in the oak-mongo.js file specially sub-tree deletion which has been found useful to delete corrupted indexes.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RDB: Tool/scripts for repair, recovery and sub-tree deletion"
   },
   {
      "_id": "12783861",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-03-21 12:32:52",
      "description": "{{PropertyIndexEditor}} when configured for unique index maintains an in memory state of indexed property in {{keysToCheckForUniqueness}}. This set would accumulate all the unique values being indexed.\n\nIn case of upgrade where the complete upgrade is performed in single commit this state can become very large. Further later while exiting the editor validates that all such values are actually unique by iterating over all such values.\n\nWe should look into other possible ways to enforce uniqueness constraint",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Unique property index can trigger OOM during upgrade of large repository"
   },
   {
      "_id": "12783856",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-21 12:03:42",
      "description": "{noformat}\nheavyWrite(org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT)  Time elapsed: 96.384 sec  <<< ERROR!\norg.apache.jackrabbit.oak.plugins.segment.SegmentOverflowException: Segment cannot have more than 255 references 47a9dc3c-c6f9-4b5f-a61a-6711da8b68c2\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.getSegmentRef(SegmentWriter.java:353)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeRecordId(SegmentWriter.java:382)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapLeaf(SegmentWriter.java:426)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:484)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:511)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMap(SegmentWriter.java:720)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1108)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1091)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:396)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1082)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1110)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:97)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:83)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.updated(MemoryNodeBuilder.java:214)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:79)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setProperty(MemoryNodeBuilder.java:501)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setProperty(MemoryNodeBuilder.java:507)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createProperties(HeavyWriteIT.java:137)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createNodes(HeavyWriteIT.java:129)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createNodes(HeavyWriteIT.java:130)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.heavyWrite(HeavyWriteIT.java:110)\n{noformat}\n\nSee https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/35/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=integrationTesting/\n\ncc [~alex.parvulescu]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "SegmentOverflowException in HeavyWriteIT on Jenkins"
   },
   {
      "_id": "12783748",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-20 21:12:48",
      "description": "The following tests fail often on Jenkins:\n\n{noformat}\ntestGlobRestriction2(org.apache.jackrabbit.oak.jcr.security.authorization.ReadTest): Authorizable with ID group2 already exists\ntestGlobRestriction3(org.apache.jackrabbit.oak.jcr.security.authorization.ReadTest): Authorizable with ID group2 already exists\n{noformat}\n\nSee https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/33/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=unittesting/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Glob restriction test failures on Jenkins"
   },
   {
      "_id": "12783618",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2015-03-20 14:20:42",
      "description": "I see many similar test failures for {{FailoverMultipleClientsTestIT}} and {{RecoverTestIT}} on Jenkins. For example:\n\n{noformat}\ntestSyncLoop(org.apache.jackrabbit.oak.plugins.segment.standby.StandbyTestIT): expected:<{ checkpoints = { ... }, root = { ... } }> but was:<{ root : { } }>\n  testLocalChanges(org.apache.jackrabbit.oak.plugins.segment.standby.RecoverTestIT): expected: org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState<{ root = { ... } }> but was: org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState<{ root = { ... } }>\n{noformat}\n\nSee\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=integrationTesting/console\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=latest1.7,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=integrationTesting/console\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=latest1.7,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=integrationTesting/console",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Failed expectations in TarMK standby tests"
   },
   {
      "_id": "12783612",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2015-03-20 14:07:16",
      "description": "The following tests fail probably all for the same reason:\n\n{noformat}\ntestProxySkippedBytes(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxySkippedBytesIntermediateChange(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedStartByte(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedIntermediateByte(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedIntermediateByte2(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedIntermediateByteChange(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedIntermediateByteChange2(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\n{noformat}\n\nStacktraces always look something like:\n{noformat}\njava.lang.Exception: proxy not started\n\tat org.apache.jackrabbit.oak.plugins.segment.NetworkErrorProxy.reset(NetworkErrorProxy.java:87)\n\tat org.apache.jackrabbit.oak.plugins.segment.standby.DataStoreTestBase.useProxy(DataStoreTestBase.java:176)\n\tat org.apache.jackrabbit.oak.plugins.segment.standby.DataStoreTestBase.testProxySkippedBytes(DataStoreTestBase.java:118)\n{noformat}\n\nSee https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=latest1.7,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=integrationTesting/console",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failures in TarMK standby: Address already in use"
   },
   {
      "_id": "12783611",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-03-20 14:07:07",
      "description": "I noticed that during the upgrade we can distinguish 2 phases: first copying the data from the source, then applying all the Editors (indexes and co.).\nAfter phase 1 is done the repository upgrader could shut down the old repo to allow clearing some memory resources which might be used for the second phase.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Repository Upgrade could shut down the source repository early"
   },
   {
      "_id": "12783608",
      "assignee": "tripod",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         }
      ],
      "created": "2015-03-20 13:58:13",
      "description": "The following tests all fail with the same error message \"Failed to bind an LDAP service (1024) to the service registry.\". \n\n{noformat} \ntestAuthenticateFail(org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest): Failed to bind an LDAP service (1024) to the service registry.\ntestGetGroups2(org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest): Failed to bind an LDAP service (1024) to the service registry.\norg.apache.jackrabbit.oak.security.authentication.ldap.LdapDefaultLoginModuleTest: Failed to bind an LDAP service (1024) to the service registry.\ntestGetUserByUserId(org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest): Failed to bind an LDAP service (1024) to the service registry.\n{noformat} \n\nThe stacktrace is always similar:\n\n{noformat}\njava.net.BindException: Address already in use]\n\tat org.apache.directory.server.ldap.LdapServer.startNetwork(LdapServer.java:528)\n\tat org.apache.directory.server.ldap.LdapServer.start(LdapServer.java:394)\n\tat org.apache.directory.server.unit.AbstractServerTest.setUp(AbstractServerTest.java:273)\n\tat org.apache.jackrabbit.oak.security.authentication.ldap.InternalLdapServer.setUp(InternalLdapServer.java:37)\n\tat org.apache.jackrabbit.oak.security.authentication.ldap.LdapLoginTestBase.beforeClass(LdapLoginTestBase.java:86)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\nCaused by: java.net.BindException: Address already in use\n\tat sun.nio.ch.Net.bind0(Native Method)\n\tat sun.nio.ch.Net.bind(Net.java:444)\n\tat sun.nio.ch.Net.bind(Net.java:436)\n\tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)\n\tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\tat org.apache.mina.transport.socket.nio.NioSocketAcceptor.open(NioSocketAcceptor.java:198)\n\tat org.apache.mina.transport.socket.nio.NioSocketAcceptor.open(NioSocketAcceptor.java:51)\n\tat org.apache.mina.core.polling.AbstractPollingIoAcceptor.registerHandles(AbstractPollingIoAcceptor.java:547)\n\tat org.apache.mina.core.polling.AbstractPollingIoAcceptor.access$400(AbstractPollingIoAcceptor.java:68)\n\tat org.apache.mina.core.polling.AbstractPollingIoAcceptor$Acceptor.run(AbstractPollingIoAcceptor.java:422)\n\tat org.apache.mina.util.NamePreservingRunnable.run(NamePreservingRunnable.java:64)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat}\n\nFailure seen at builds: 31, 40, 52, 62, 63, 64, 72, 95, 103, 114, 126, 136, 145, 183\n\nSee \nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=latest1.7,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=unittesting/\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=unittesting/\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failures in LDAP authentication: Failed to bind an LDAP service"
   },
   {
      "_id": "12783588",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-03-20 12:37:35",
      "description": "{{org.apache.jackrabbit.oak.jcr.OrderableNodesTest.testAddNode}} fails on Jenkins when running the {{DOCUMENT_RDB}} fixture. \n\nFailure seen at builds: 30, 44, 57, 58, 69, 78, 115, 121, 130, 132, 142, 152\n\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/30/jdk=jdk-1.6u45,label=Ubuntu,nsfixtures=DOCUMENT_RDB,profile=unittesting/testReport/junit/org.apache.jackrabbit.oak.jcr/OrderableNodesTest/testAddNode_0_/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: OrderableNodesTest.testAddNode"
   },
   {
      "_id": "12782524",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-17 10:28:56",
      "description": "{{FilterImpl#getSupertypes}}, {{FilterImpl#getPrimaryTypes}} and {{FilterImpl#getMixinTypes}} might all return {{null}} although {{Filter}}'s contract mandates \\@Nonull.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "FilterImpl violates nullability contract "
   },
   {
      "_id": "12782216",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-16 14:53:21",
      "description": "The current implementation of TimeSeriesMax - which is what is backing eg the very important 'ObservationQueueMaxLength' statistics - has a very infamous behavior: it does very frequent, intermittent 'jumps back to 0'. This even though the queue-lengths are still at the previous highs, as can often be seen with subsequent measurements (which eg are still showing there are 1000 events in the observation queue).\n\nThe reason seems to be that\n* the value is increased via {{TimeSeriesMax.recordValue()}} during a 1 second interval\n* reset to 0 via {{TimeSeriesMax<init>.run()}} every second\n\nSo basically, every second the counter is reset, then during 1 second if any call to {{recordValue()}} happens, it is increased.\n\nThis in my view is rather unfortunate - as it can result in mentioned 'jumpy-0' behavior, but it can also jump to values in between if the largest queue does not reports its length during 1 second.\n\nIt sounds a bit like this was done this way intentionally? (perhaps to make it as inexpensive as possible) or could this be fixed?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TimeSeriesMax's frequent 'drops to 0'"
   },
   {
      "_id": "12782058",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-03-15 09:45:56",
      "description": "Lucene provides a buffered variants for {{IndexInput}} and {{IndexOutput}}. Currently Oak extends these classes directly. For better performance itshould extend the buffered variants.\n\nAs discussed [here|https://issues.apache.org/jira/browse/OAK-2222?focusedCommentId=14178265#comment-14178265]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use buffered variants for IndexInput and IndexOutput"
   },
   {
      "_id": "12781804",
      "assignee": "mduerig",
      "components": [],
      "created": "2015-03-13 13:28:04",
      "description": "Since we're moving towards Jenkins, let's remove the buildbot jobs for Oak.\nThe buildbot configuration is here: https://svn.apache.org/repos/infra/infrastructure/buildbot/aegis/buildmaster/master1/projects",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cleanup Oak jobs on buildbot"
   },
   {
      "_id": "12781803",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-03-13 13:27:19",
      "description": "Since we're moving toward Jenkins, let's remove the Travis jobs for Oak. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cleanup Oak Travis jobs"
   },
   {
      "_id": "12781712",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-13 04:03:00",
      "description": "As [noted|https://issues.apache.org/jira/browse/OAK-2557?focusedCommentId=14358704#comment-14358704] by [~tmueller] we do not have a test coverage for case when a deleted document has previous documents and Version GC should also remove those previous documents",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add test for GC of previous docs of a deleted document"
   },
   {
      "_id": "12781604",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-12 20:17:42",
      "description": "The DocumentNodeStore issues a lot of reads when sibling nodes are deleted, which are also index with a property index.\n\nThe following calls will become a hotspot:\n\n{noformat}\n\tat org.apache.jackrabbit.oak.plugins.document.mongo.MongoDocumentStore.query(MongoDocumentStore.java:406)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readChildDocs(DocumentNodeStore.java:846)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readChildren(DocumentNodeStore.java:788)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.getChildren(DocumentNodeStore.java:753)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeState.getChildNodeCount(DocumentNodeState.java:194)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.getChildNodeCount(ModifiedNodeState.java:198)\n\tat org.apache.jackrabbit.oak.plugins.memory.MutableNodeState.getChildNodeCount(MutableNodeState.java:265)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.getChildNodeCount(MemoryNodeBuilder.java:293)\n\tat org.apache.jackrabbit.oak.plugins.index.property.strategy.ContentMirrorStoreStrategy.prune(ContentMirrorStoreStrategy.java:456)\n{noformat}\n\nI think the code triggering this issue is in {{ModifiedNodeState.getChildNodeCount()}}. It keeps track of already deleted children and requests {{max += deleted}}. The actual {{max}} is always 1 as requested from {{ContentMirrorStoreStrategy.prune()}}, but as more nodes get deleted, the higher {{max}} gets passed to {{DocumentNodeState.getChildNodeCount()}}. The DocumentNodeStore then checks if it has the children in the cache, only to find out the cache entry has too few entries and it needs to fetch one more.\n\nIt would be best to have a minimum number of child nodes to fetch from MongoDB in this case. E.g. when NodeState.getChildNodeEntries() is called, the DocumentNodeState fetches 100 children.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Too many reads for child nodes"
   },
   {
      "_id": "12781593",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-12 19:40:10",
      "description": "MongoMK still holds the merge lock when it resets a persisted branch. Concurrency can be improved if the merge lock is released before the branch is reset.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release merge lock before branch is reset"
   },
   {
      "_id": "12781550",
      "assignee": "baedke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-03-12 16:47:54",
      "description": "When upgrading from Jackrabbit 2 to Oak there are several scenarios that could benefit from the ability to upgrade repeatedly into one target repository.\n\nE.g. a migration process might look as follows:\n\n# upgrade a backup of a large repository a week before go-live\n# run the upgrade again every night (commit-hooks only handle delta)\n# run the upgrade one final time before go-live (commit-hooks only handle delta)\n\nIn this scenario each upgrade would require a full traversal of the source repository. However, if done right, only the delta needs to be written and the commit-hooks also only need to process the delta.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Repeated upgrades"
   },
   {
      "_id": "12781511",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-03-12 14:21:24",
      "description": "When multiple OR constraints are specified in the XPATH query, itis broken up into union of multiple clauses. If query includes an order by clause, the sorting in this case is done by traversing the result set in memory leading to slow query performance.\n\nPossible improvements could include:\n* For indexes which can support multiple filters (like lucene, solr) such queries should be efficient and the query engine can pass-thru the query as is.\n** Possibly also needed for other cases also. So, we can have some sort of capability advertiser for indexes which can hint the query engine \n\nand/or\n* Batched merging of the sorted iterators returned for the multiple union queries (possible externally).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve performance of queries with ORDER BY and multiple OR filters"
   },
   {
      "_id": "12781432",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-12 08:17:33",
      "description": "Reading through a ValueMap can be very inefficient if the changes of a given\nproperty are distributed sparsely across the previous documents. The current\nimplementation has to scan through the entire set of previous documents to\ncollect the changes.\n\nIntermediate documents should have additional information about what properties\nare present on referenced previous documents. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Annotate intermediate docs with property names"
   },
   {
      "_id": "12781228",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2015-03-11 15:59:29",
      "description": "We have a sporadic problem with Sling's JCR installer 3.3.8 and Oak (tar mk). It seems to timing related: the JCR installer does a Thread#interrupt at one point and sometimes this brings the hole instance to stop. Nothing else is going on any more. \nWhile of course, a workaround is to remove the Thread.interrupt call in the JCR installer (which we did, see SLING-4477), I have the fear that this can happen with any code that is using the repository and gets interrupted.\nThis error is hard to reproduce, however with three people testing we could see this several times happening",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Thread.interrupt seems to stop repository"
   },
   {
      "_id": "12780726",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-03-10 06:17:29",
      "description": "Currently an {{IndexEditor}} gets to index all nodes under the tree where it is defined (post OAK-1980).  Due to this IndexEditor would traverse the whole repo (or subtree if configured in non root path) to perform reindex. Depending on the repo size this process can take quite a bit of time. It would be faster if an IndexEditor can exclude certain paths from traversal\n\nConsider an application like Adobe AEM and an index which only index dam:Asset or the default full text index. For a fulltext index it might make sense to avoid indexing the versionStore. So if the index editor skips such path then lots of redundant traversal can be avoided. \n\nAlso see http://markmail.org/thread/4cuuicakagi6av4v",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow excluding certain paths from getting indexed for particular index"
   },
   {
      "_id": "12780520",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-09 15:51:07",
      "description": "While debugging issues with the observation queue it would be handy to have more detailed information available. At the moment you can only see one value wrt length of the queue: that is the maximum of all queues. It is unclear if the queue is that long for only one or many listeners. And it is unclear from that if the listener is slow or the engine that produces the events for the listener.\n\nSo I'd suggest to add the following details - possible exposed via JMX? :\n# add queue length details to each of the observation listeners\n# have a history of the last, eg 1000 events per listener showing a) how long the event took to be created/generated and b) how long the listener took to process. Sometimes averages are not detailed enough so such a in-depth information might become useful. (Not sure about the feasibility of '1000' here - maybe that could be configurable though - just putting the idea out here).\n# have some information about whether a listener is currently 'reading events from the cache' or whether it has to go to eg mongo \n# maybe have a 'top 10' listeners that have the largest queue at the moment to easily allow navigation instead of having to go through all (eg 200) listeners manually each time.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring",
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "more (jmx) instrumentation for observation queue"
   },
   {
      "_id": "12780517",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-09 15:43:30",
      "description": "{{CompactionGainEstimate}} keeps a set for the visited record ids. Each entry in that set is represented by an instance of {{ThinRecordId}}. For big repositories the instance overhead lead to {{OOME}} while running the compaction estimator. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "High memory consumption of CompactionGainEstimate"
   },
   {
      "_id": "12780441",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-09 09:38:12",
      "description": "The MongoDocumentStore uses {{findAndModify()}} to commit a transaction. This operation does not allow an application specified write concern and always uses the MongoDB default write concern {{Acknowledged}}. This means a commit may not make it to a majority of a replica set when the primary fails. From a MongoDocumentStore perspective it may appear as if a write was successful and later reverted. See also the test in OAK-1641.\n\nTo fix this, we'd probably have to change the MongoDocumentStore to avoid {{findAndModify()}} and use {{update()}} instead.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Commit does not ensure w:majority"
   },
   {
      "_id": "12780152",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-06 19:34:26",
      "description": "The current implementation of oak's observation event processing is too eager and thus unfair under load scenarios. \n\nConsider having many (eg 200) Eventlisteners but only a relatively small threadpool (eg 5 as is the default in sling) backing them. When processing changes for a particular BackgroundObserver, that one (in BackgroundObserver.completionHandler.call) currently processes *all changes irrespective of how many there are* - ie it is *eager*. Only once that BackgroundObserver processed all changes will it let go and 'pass the thread' to the next BackgroundObserver. Now if for some reason changes (ie commits) are coming in while a BackgroundObserver is busy processing an earlier change, this will lengthen that while loop. As a result the remaining (eg 195) *EventListeners will have to wait for a potentially long time* until it's their turn - thus *unfair*.\n\nNow combine the above pattern with a scenario where mongo is used as the underlying store. In that case in order to remain highly performant it is important that the diffs (for compareAgainstBaseState) are served from the MongoDiffCache for as many cases as possible to avoid doing a round-trip to mongoD. The unfairness in the BackgroundObservers can now result in a large delay between the 'first' observers getting the event and the 'last' one (of those 200). When this delay increases due to a burst in the load, there is a risk of the diffs to no longer be in the cache - those last observers are basically kicked out of the (diff) cache. Once this happens, *the situation gets even worse*, since now you have yet new commits coming in and old changes still having to be processed - all of which are being processed through in 'stripes of 5 listeners' before the next one gets a chance. This at some point results in a totally inefficient cache behavior, or in other words, at some point all diffs have to be read from mongoD.\n\nTo avoid this there are probably a number of options - a few one that come to mind:\n* increase thread-pool to match or be closer to the number of listeners (but this has other disadvantages, eg cost of thread-switching)\n* make BackgroundObservers fairer by limiting the number of changes they process before they give others a chance to be served by the pool.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "observation processing too eager/unfair under load"
   },
   {
      "_id": "12780035",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-06 10:33:30",
      "description": "As we start seeing good results with the current approach to compaction I'd like to have it running per default. This allows us to gather more information while we are running up towards the 1.2 release. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Set pauseCompaction default to false"
   },
   {
      "_id": "12779689",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-03-05 05:08:53",
      "description": "{{org.apache.jackrabbit.oak.jcr.osgi.RepositoryManager}} currently registers the {{WhiteboardExecutor}} with Oak which internally again register with OSGi ServiceRegistry. This causes recursion as leading to stackoverflow.\n\nAs Oak creates an {{Executor}} in absence on explicitly provided one RepositoryManager should not set the {{Executor}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "RepositoryManager must not register WhiteboardExecutor with Oak"
   },
   {
      "_id": "12779007",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-03 10:25:15",
      "description": "The session auto refresh feature is implemented by marking sessions pending for refresh. The refresh operation itself however only happens on the next access to the session. \n\nIt would be helpful if {{SessionMBean}} could expose the information whether a session has a pending refresh. Additionally we could expose the current {{RefreshStrategy}} to make the auto refresh behaviour more transparent. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SessionMBean should provide information about pending refresh"
   },
   {
      "_id": "12778740",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-02 11:33:57",
      "description": "We've ran into a deadlock in the Oak SegmentNodeStore between\n_org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.deactivate(SegmentNodeStoreService.java:300)_ and _org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.getSegment(SegmentTracker.java:120)_\nThis was seen on Oak 1.0.11.\n\n{code}\nJava stack information for the threads listed above \n \n\"pool-9-thread-5\":\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:656)\n\t- waiting to lock <0x0000000680024468> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.getSegment(SegmentTracker.java:120)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:101)\n\t- locked <0x00000006b0b7ae28> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.size(MapRecord.java:128)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:462)\n\t- locked <0x0000000680c634a8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:460)\n\t- locked <0x0000000680c634a8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMap(SegmentWriter.java:660)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1020)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1022)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1003)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:396)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:994)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1003)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:396)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:994)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:91)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:77)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.updated(MemoryNodeBuilder.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:73)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setChildNode(MemoryNodeBuilder.java:331)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setChildNode(MemoryNodeBuilder.java:323)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.child(MemoryNodeBuilder.java:311)\n\tat org.apache.jackrabbit.oak.plugins.index.property.strategy.ContentMirrorStoreStrategy.insert(ContentMirrorStoreStrategy.java:112)\n\tat org.apache.jackrabbit.oak.plugins.index.property.strategy.ContentMirrorStoreStrategy.update(ContentMirrorStoreStrategy.java:81)\n\tat org.apache.jackrabbit.oak.plugins.index.property.PropertyIndexEditor.leave(PropertyIndexEditor.java:261)\n\tat org.apache.jackrabbit.oak.spi.commit.CompositeEditor.leave(CompositeEditor.java:74)\n\tat org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:63)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeAdded(EditorDiff.java:130)\n\tat org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:391)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeAdded(EditorDiff.java:125)\n\tat org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:391)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeAdded(EditorDiff.java:125)\n\tat org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:391)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeAdded(EditorDiff.java:125)\n\tat org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.compareAgainstEmptyState(EmptyNodeState.java:160)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:391)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeAdded(EditorDiff.java:125)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$2.childNodeAdded(MapRecord.java:383)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$3.childNodeAdded(MapRecord.java:425)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:483)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:422)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:380)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:540)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeChanged(EditorDiff.java:148)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$2.childNodeChanged(MapRecord.java:389)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$3.childNodeChanged(MapRecord.java:430)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:473)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:422)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:380)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:540)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeChanged(EditorDiff.java:148)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$2.childNodeChanged(MapRecord.java:389)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$3.childNodeChanged(MapRecord.java:430)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:473)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:422)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:380)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:540)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeChanged(EditorDiff.java:148)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$2.childNodeChanged(MapRecord.java:389)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:473)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:380)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:540)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:52)\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.updateIndex(AsyncIndexUpdate.java:354)\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:300)\n\t- locked <0x000000068afa00e8> (a org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate)\n\tat org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105)\n\tat org.quartz.core.JobRunShell.run(JobRunShell.java:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:744)\n \"FelixStartLevel\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.flush(SegmentWriter.java:167)\n\t- waiting to lock <0x0000000680c634a8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.flush(FileStore.java:431)\n\t- locked <0x000000068461ecb8> (a java.util.concurrent.atomic.AtomicReference)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.close(FileStore.java:582)\n\t- locked <0x0000000680024468> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.deactivate(SegmentNodeStoreService.java:300)\n\t- locked <0x00000006800243c8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invokeMethod(BaseMethod.java:231)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.access$500(BaseMethod.java:39)\n\tat org.apache.felix.scr.impl.helper.BaseMethod$Resolved.invoke(BaseMethod.java:624)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invoke(BaseMethod.java:508)\n\tat org.apache.felix.scr.impl.helper.ActivateMethod.invoke(ActivateMethod.java:149)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.disposeImplementationObject(SingleComponentManager.java:355)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.deleteComponent(SingleComponentManager.java:170)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.doDeactivate(AbstractComponentManager.java:908)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.deactivateInternal(AbstractComponentManager.java:883)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.dispose(AbstractComponentManager.java:580)\n\tat org.apache.felix.scr.impl.config.ConfigurableComponentHolder.disposeComponents(ConfigurableComponentHolder.java:406)\n\tat org.apache.felix.scr.impl.BundleComponentActivator.dispose(BundleComponentActivator.java:335)\n\tat org.apache.felix.scr.impl.Activator.disposeComponents(Activator.java:313)\n\tat org.apache.felix.scr.impl.Activator.access$300(Activator.java:45)\n\tat org.apache.felix.scr.impl.Activator$ScrExtension.destroy(Activator.java:198)\n\tat org.apache.felix.utils.extender.AbstractExtender$2.run(AbstractExtender.java:290)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat org.apache.felix.utils.extender.AbstractExtender.destroyExtension(AbstractExtender.java:312)\n\tat org.apache.felix.utils.extender.AbstractExtender.bundleChanged(AbstractExtender.java:186)\n\tat org.apache.felix.framework.util.EventDispatcher.invokeBundleListenerCallback(EventDispatcher.java:869)\n\tat org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:790)\n\tat org.apache.felix.framework.util.EventDispatcher.fireBundleEvent(EventDispatcher.java:515)\n\tat org.apache.felix.framework.Felix.fireBundleEvent(Felix.java:4409)\n\tat org.apache.felix.framework.Felix.stopBundle(Felix.java:2526)\n\tat org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1315)\n\tat org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:304)\n\tat java.lang.Thread.run(Thread.java:744)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentStore deadlock on shutdown"
   },
   {
      "_id": "12778255",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-02-27 17:34:43",
      "description": "A recent issue found at a customer unveils a potential issue with the async indexer. Reading the AsyncIndexUpdate.updateIndex it looks like it is doing the entire update of the async indexer *in one go*, ie in one commit.\n\nWhen there is - for some reason - however, a huge diff that the async indexer has to process, the 'one big commit' can become gigantic. There is no limit to the size of the commit in fact.\n\nSo the suggestion is to do intermediate commits while the async indexer is going on. The reason this is acceptable is the fact that by doing async indexing, that index is anyway not 100% up-to-date - so it would not make much of a difference if it would commit after every 100 or 1000 changes either.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Intermediate commit during async indexing"
   },
   {
      "_id": "12777494",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-02-25 11:23:29",
      "description": "Provide monitoring for the garbage collection process:\n* time series of repository size\n* time series of space reclaimed\n* time stamp of last clean up\n* time stamp of last compaction\n* last error\n* time stamp when next gc run is scheduled\n* ...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "compaction",
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement MBean monitoring garbage collection"
   },
   {
      "_id": "12776807",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-02-23 11:00:23",
      "description": "Seen on the 1.0 branch only so far when running ITs on my local machine, but travis reports the same:\n\nhttps://travis-ci.org/apache/jackrabbit-oak/builds/51589769\n\nIt doesn't necessarily mean the problem is with SegmentReferenceLimitTestIT even though the heap dump shows most of the memory consumed by Segments and SegmentWriter. A recent build on trunk was successful for me where we have the same test.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "CI",
         "travis"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentMk IT tests are too intensive"
   },
   {
      "_id": "12776197",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-02-19 16:00:50",
      "description": "Solr index is only able to do query time aggregation while that \"would not perform well for multi term searches as each term involves a separate call and with intersection cursor being used the operation might result in reading up all match terms even when user accesses only first page\", therefore it'd be good to implement index time aggregation like in Lucene index. (/cc [~chetanm])",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support index time aggregation in Solr index"
   },
   {
      "_id": "12774577",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-02-12 14:20:06",
      "description": "After off line compaction the repository contains a single revision. However the journal.log file will still contain the trail of all revisions that have been removed during the compaction process. I suggest we truncate the journal.log to only contain the latest revision created during compaction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Truncate journal.log after off line compaction"
   },
   {
      "_id": "12774256",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2015-02-11 16:34:37",
      "description": "To provide something that can be played with, and to verify the feasibility of the specification draft, an initial implementation of the HTTP API should be provided.\n\nThe API should follow the general behavior described [here|https://wiki.apache.org/jackrabbit/frm/RemoteOperations] and the HTTP semantics defined [here|https://wiki.apache.org/jackrabbit/frm/HttpOperations]. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "api",
         "remoting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Provide initial implementation of the Remote Operations specification"
   },
   {
      "_id": "12773875",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-02-10 15:50:46",
      "description": "According to the [documentation | http://jackrabbit.apache.org/oak/docs/nodestore/segmentmk.html] the root record references in a segment header provide enough context for parsing all records within this segment without any external information. \n\nTurns out this is not true: if a root record reference turns e.g. to a list record. The items in that list are record ids of unknown type. So even though those records might live in the same segment, we can't parse them as we don't know their type. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Root record references provide too little context for parsing a segment"
   },
   {
      "_id": "12773538",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-02-09 18:58:38",
      "description": "Current DocumentMK logic while performing a diff for child nodes works as below\n\n# Get children for _before_ revision upto MANY_CHILDREN_THRESHOLD (which defaults to 50). Further note that current logic of fetching children nodes also add children {{NodeDocument}} to {{Document}} cache and also reads the complete Document for those children\n# Get children for _after_ revision with limits as above\n# If the child list is complete then it does a direct diff on the fetched children\n# if the list is not complete i.e. number of children are more than the threshold then it for a query based diff (also see OAK-1970)\n\nSo in those cases where number of children are large then all work done in #1 above is wasted and should be avoided. To do that we can mark those parent nodes which have many children via special flag like {{_manyChildren}}. One such nodes are marked the diff logic can check for the flag and skip the work done in #1\n\nThis is kind of similar to way we mark nodes which have at least one child (OAK-1117)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Flag Document having many children"
   },
   {
      "_id": "12772648",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-02-05 10:06:57",
      "description": "Currently spellcheck configuration is controlled via properties defined on main config / props node but it'd be good if we would have its own place to configure the whole spellcheck feature to not mix up configuration of other features / parameters.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move spellcheck config to own configuration node"
   },
   {
      "_id": "12772647",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-02-05 10:06:13",
      "description": "Currently suggester configuration is controlled via properties defined on main config / props node but it'd be good if we would have its own place to configure the whole suggest feature to not mix up configuration of other features / parameters.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move suggester specific config to own configuration node"
   },
   {
      "_id": "12772397",
      "assignee": "mduerig",
      "components": [],
      "created": "2015-02-04 15:35:23",
      "description": "We should strive for stabilization of our CI setup, as of now we had Buildbot and Travis.\nIt seems ASF Jenkins can perform jobs on different environments (*nix, Windows and others) so we can evaluate that and check if it better address our needs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI",
         "build",
         "infrastructure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Move our CI to Jenkins"
   },
   {
      "_id": "12771991",
      "assignee": "edivad",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-02-03 10:02:47",
      "description": "As of OAK-2220 we added support for atomic counters in a non-clustered situation. \n\nThis ticket is about covering the clustered ones.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Add support for atomic counters on cluster solutions"
   },
   {
      "_id": "12771304",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-01-30 10:28:29",
      "description": "The blob store garbage collection (data store garbage collection) uses the chunk ids to identify binaries to be deleted. The blob ids contain the size now (<contentHash>#<size>), and the blob id is currently equal to the chunk id.\n\nIt would be more efficient to _not_ use the size, and instead just use the content hash, for the chunk ids. That way, enumerating the entries that are in the store is potentially faster. Also, it allows us to change the blob id in the future, for example add more information to it (for example the creation time, or the first few bytes of the content) if we ever want to.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "datastore",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DataStoreBlobStore: chunk ids should not contain the size"
   },
   {
      "_id": "12770899",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-01-29 03:30:18",
      "description": "Currently PersistentCache uses the directory path directly. Various other parts in Oak which need access to the filesystem currently make use of {{repository.home}} framework property in OSGi env [1]\n\nSame should also be used in PersistentCache\n\n[1] http://jackrabbit.apache.org/oak/docs/osgi_config.html#SegmentNodeStore ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Resolve the base directory path of persistent cache against repository home"
   },
   {
      "_id": "12768421",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-01-19 11:23:51",
      "description": "Implement support for continuable sessions to keeps state across multiple client/server interactions. Continuable sessions do not require any additional state on the server (i.e. Oak) apart form the apparent repository state. \n\nTo continue a session a client would obtain a continuation token from the current session. This token can be used on the next call to {{Repository.login}} to obtain a new {{Session}} instance that is based on the same repository revision that the session the token was obtained from. Additionally the token could contain information re. authentication so subsequent request can go through a simplified authentication procedure. ([~asanso]'s work on OAuth might be of help here.)\n\nTransient changes are not supported in continuable sessions. Obtaining a continuation token from a session with transient changes results in an error. \n\nContinuable sessions are typically short lived (i.e. the time of a single HTTP request). Specifically continuable session do not retain the underlying repository revision from being garbage collected. Clients need to be able to cope with respective exceptions. \n\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "api"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support continuable sessions "
   },
   {
      "_id": "12768418",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2015-01-19 11:10:06",
      "description": "Container issues for collecting tasks related to remoting the Oak API. Such a remoting should be:\n\n* stateless on the Oak side apart from the apparent persisted state in the content repository, \n\n* independent from {{oak-jcr}}, but reusing JCR related plugins from {{oak-core}} as required (e.g. for name space and node type handling),\n\n* agnostic of any protocol bindings,\n\n* ...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "api",
         "remoting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak API remoting"
   },
   {
      "_id": "12768365",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-01-19 06:08:56",
      "description": "The Sonar analysis for Oak [1] report shows some warnings for RDBDocumentStore [2]. The critical ones are related to not closing of statement and resultset instances. \n\n[1] https://analysis.apache.org/dashboard/index/org.apache.jackrabbit:jackrabbit-oak?did=2\n[2] https://analysis.apache.org/resource/index/179726?display_title=true&tab=violations",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "[sonar]Some statements not being closed in RDBDocumentStore"
   },
   {
      "_id": "12767764",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-01-15 15:58:05",
      "description": "Current approaches to revision garbage collection tend to be too conservative (too little space reclaimed, e.g. OAK-2045) or too aggressive (removing segments still being used, e.g. OAK-2384). \n\nThis issue is to explore ways to make revision gc on TarMk more precise. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Investigate ways to make revision gc more precise "
   },
   {
      "_id": "12767762",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-01-15 15:51:07",
      "description": "The approach to revision garbage collection taken in OAK-2192 assumes that long running background sessions call refresh once they become active again. Incidentally this is true as such background sessions usually are admin sessions and those are always auto-refreshed on access (see OAK-88, OAK-803, and OAK-960). However as soon as we move away from admin sessions this might not be true any more and we might start seeing {{SegmentNotFoundException}} s unless the user explicitly refreshes the session. \n\nTo prevent this we should make all sessions auto refresh once revision gc runs. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Auto-refresh sessions on revision gc"
   },
   {
      "_id": "12767745",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-01-15 15:08:42",
      "description": "We should add some monitoring that allows us to track \"old\" node states, which potentially block revision gc. \n\nPossible approaches:\n\n* Add monitoring too old revisions (root node states) along with the stack traces from where they have been acquired.\n\n* Include RecordId of root node state in the {{SessionMBean}}.\n\n* Add additional tooling on top of the {{SessionMBean}} to make it easier to make sense of the wealth of information provided. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "gc",
         "monitoring",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Monitoring to track old NodeStates"
   },
   {
      "_id": "12767742",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-01-15 15:05:49",
      "description": "There is currently no way to distinguish between a {{SegmentNotFoundException}} occurring because of a removed segment by gc or because of another corruption. Optimally we would tell in the exception why the segment is gone, how old it was when gc removed it and who/what was still referring to it at that time. In order to do that, we probably need some kind of log for the following data: When a segment was removed (because a new generation of the .tar file was made, or because the .tar file was removed), we should log the segment, the file name, and the date+time of the removal. If the segment was then not found because it was too old, then another type of exception should be thrown instead, for example \"ReadTimeoutException\", with a message that contains as much data as possible: the data+time of the segment, date+time of the removal of the segment, about when compaction was run, date+time of the session login and last refresh, the stack trace of where the session was acquired.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide more information in SegmentNotFoundException"
   },
   {
      "_id": "12767740",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-01-15 14:59:39",
      "description": "Container devoted to improving monitoring of the TarMk revision garbage collection process. The overall goal is to make it more transparent what revision gc does, how it performs, why it failed etc. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "gc",
         "monitoring",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve monitoring capabilities for TarMk revision gc"
   },
   {
      "_id": "12767690",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-01-15 09:29:50",
      "description": "The SegmentNodeStoreService is prone to deadlocks because of the way in which is synchronizes access to the _SegmentNodeStore_ delegate.\n\nThe issue can now be seen on #deactivate, when the deregistration is being synchronously broadcast and if a referring service calls #getNodeStore the deadlock happens.\n\n{code}\nFound one Java-level deadlock:\n=============================\n\"qtp844483043-936\":\n  waiting to lock monitor 0x000001d1aacc7208 (object 0x000001d231f52698, a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService),\n  which is held by \"CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\"\n\"CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\":\n  waiting to lock monitor 0x000001d4d0907c88 (object 0x000001d2334be930, a java.lang.Object),\n  which is held by \"pool-5-thread-4\"\n\"pool-5-thread-4\":\n  waiting to lock monitor 0x000001d1aacc7208 (object 0x000001d231f52698, a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService),\n  which is held by \"CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\"\n\nJava stack information for the threads listed above:\n===================================================\n\"qtp844483043-936\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.getNodeStore(SegmentNodeStoreService.java:144)\n\t- waiting to lock <0x000001d231f52698> (a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.getNodeStore(SegmentNodeStoreService.java:73)\n\tat org.apache.jackrabbit.oak.spi.state.ProxyNodeStore.getRoot(ProxyNodeStore.java:35)\n\tat org.apache.jackrabbit.oak.core.MutableRoot.<init>(MutableRoot.java:160)\n\tat org.apache.jackrabbit.oak.core.ContentSessionImpl.getLatestRoot(ContentSessionImpl.java:110)\n\tat org.apache.jackrabbit.oak.spi.security.authentication.AbstractLoginModule.getRoot(AbstractLoginModule.java:403)\n\tat org.apache.jackrabbit.oak.security.authentication.token.TokenLoginModule.getTokenProvider(TokenLoginModule.java:215)\n\tat org.apache.jackrabbit.oak.security.authentication.token.TokenLoginModule.login(TokenLoginModule.java:128)\n\tat org.apache.felix.jaas.boot.ProxyLoginModule.login(ProxyLoginModule.java:52)\n\tat sun.reflect.GeneratedMethodAccessor65.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat javax.security.auth.login.LoginContext.invoke(LoginContext.java:762)\n\tat javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)\n\tat javax.security.auth.login.LoginContext$4.run(LoginContext.java:690)\n\tat javax.security.auth.login.LoginContext$4.run(LoginContext.java:688)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:687)\n\tat javax.security.auth.login.LoginContext.login(LoginContext.java:595)\n\tat org.apache.jackrabbit.oak.core.ContentRepositoryImpl.login(ContentRepositoryImpl.java:161)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:256)\n\tat com.adobe.granite.repository.impl.CRX3RepositoryImpl.login(CRX3RepositoryImpl.java:92)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:197)\n\tat org.apache.sling.jcr.base.AbstractSlingRepository2.login(AbstractSlingRepository2.java:297)\n\tat org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProviderFactory.getResourceProviderInternal(JcrResourceProviderFactory.java:289)\n\tat org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProviderFactory.getResourceProvider(JcrResourceProviderFactory.java:201)\n\tat org.apache.sling.resourceresolver.impl.tree.ResourceProviderFactoryHandler.login(ResourceProviderFactoryHandler.java:164)\n\tat org.apache.sling.resourceresolver.impl.tree.RootResourceProviderEntry.loginToRequiredFactories(RootResourceProviderEntry.java:95)\n\tat org.apache.sling.resourceresolver.impl.CommonResourceResolverFactoryImpl.getResourceResolverInternal(CommonResourceResolverFactoryImpl.java:109)\n\tat org.apache.sling.resourceresolver.impl.CommonResourceResolverFactoryImpl.getResourceResolver(CommonResourceResolverFactoryImpl.java:90)\n\tat org.apache.sling.resourceresolver.impl.ResourceResolverFactoryImpl.getResourceResolver(ResourceResolverFactoryImpl.java:93)\n\tat org.apache.sling.auth.core.impl.SlingAuthenticator.getAnonymousResolver(SlingAuthenticator.java:839)\n\tat org.apache.sling.auth.core.impl.SlingAuthenticator.doHandleSecurity(SlingAuthenticator.java:478)\n\tat org.apache.sling.auth.core.impl.SlingAuthenticator.handleSecurity(SlingAuthenticator.java:438)\n\tat org.apache.sling.engine.impl.SlingHttpContext.handleSecurity(SlingHttpContext.java:121)\n\tat org.apache.felix.http.base.internal.context.ServletContextImpl.handleSecurity(ServletContextImpl.java:335)\n\tat org.apache.felix.http.base.internal.handler.ServletHandler.doHandle(ServletHandler.java:337)\n\tat org.apache.felix.http.base.internal.handler.ServletHandler.handle(ServletHandler.java:300)\n\tat org.apache.felix.http.base.internal.dispatch.ServletPipeline.handle(ServletPipeline.java:93)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:50)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.sling.i18n.impl.I18NFilter.doFilter(I18NFilter.java:128)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.felix.http.sslfilter.internal.SslFilter.doFilter(SslFilter.java:55)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.felix.http.sslfilter.internal.SslFilter.doFilter(SslFilter.java:89)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat com.adobe.granite.license.impl.LicenseCheckFilter.doFilter(LicenseCheckFilter.java:298)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.sling.security.impl.ReferrerFilter.doFilter(ReferrerFilter.java:290)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.sling.featureflags.impl.FeatureManager.doFilter(FeatureManager.java:115)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.sling.engine.impl.log.RequestLoggerFilter.doFilter(RequestLoggerFilter.java:75)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.felix.http.base.internal.dispatch.FilterPipeline.dispatch(FilterPipeline.java:76)\n\tat org.apache.felix.http.base.internal.dispatch.Dispatcher.dispatch(Dispatcher.java:49)\n\tat org.apache.felix.http.base.internal.DispatcherServlet.service(DispatcherServlet.java:67)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:722)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:501)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:229)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:255)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:370)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)\n\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)\n\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)\n\"CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\":\n\tat org.apache.sling.discovery.impl.DiscoveryServiceImpl.unbindTopologyEventListener(DiscoveryServiceImpl.java:242)\n\t- waiting to lock <0x000001d2334be930> (a java.lang.Object)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invokeMethod(BaseMethod.java:231)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.access$500(BaseMethod.java:39)\n\tat org.apache.felix.scr.impl.helper.BaseMethod$Resolved.invoke(BaseMethod.java:624)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invoke(BaseMethod.java:508)\n\tat org.apache.felix.scr.impl.helper.BindMethod.invoke(BindMethod.java:37)\n\tat org.apache.felix.scr.impl.manager.DependencyManager.invokeUnbindMethod(DependencyManager.java:1717)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.invokeUnbindMethod(SingleComponentManager.java:404)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$MultipleDynamicCustomizer.removedService(DependencyManager.java:376)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$MultipleDynamicCustomizer.removedService(DependencyManager.java:304)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1506)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1401)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$AbstractTracked.untrack(ServiceTracker.java:1261)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.serviceChanged(ServiceTracker.java:1440)\n\tat org.apache.felix.framework.util.EventDispatcher.invokeServiceListenerCallback(EventDispatcher.java:940)\n\tat org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:794)\n\tat org.apache.felix.framework.util.EventDispatcher.fireServiceEvent(EventDispatcher.java:544)\n\tat org.apache.felix.framework.Felix.fireServiceEvent(Felix.java:4425)\n\tat org.apache.felix.framework.Felix.access$000(Felix.java:75)\n\tat org.apache.felix.framework.Felix$1.serviceChanged(Felix.java:402)\n\tat org.apache.felix.framework.ServiceRegistry.unregisterService(ServiceRegistry.java:153)\n\tat org.apache.felix.framework.ServiceRegistrationImpl.unregister(ServiceRegistrationImpl.java:128)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager$3.unregister(AbstractComponentManager.java:1011)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager$3.unregister(AbstractComponentManager.java:992)\n\tat org.apache.felix.scr.impl.manager.RegistrationManager.changeRegistration(RegistrationManager.java:141)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.unregisterService(AbstractComponentManager.java:1054)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.doDeactivate(AbstractComponentManager.java:900)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.deactivateInternal(AbstractComponentManager.java:883)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$SingleStaticCustomizer.removedService(DependencyManager.java:974)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$SingleStaticCustomizer.removedService(DependencyManager.java:895)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1506)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1401)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$AbstractTracked.untrack(ServiceTracker.java:1261)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.serviceChanged(ServiceTracker.java:1440)\n\tat org.apache.felix.framework.util.EventDispatcher.invokeServiceListenerCallback(EventDispatcher.java:940)\n\tat org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:794)\n\tat org.apache.felix.framework.util.EventDispatcher.fireServiceEvent(EventDispatcher.java:544)\n\tat org.apache.felix.framework.Felix.fireServiceEvent(Felix.java:4425)\n\tat org.apache.felix.framework.Felix.access$000(Felix.java:75)\n\tat org.apache.felix.framework.Felix$1.serviceChanged(Felix.java:402)\n\tat org.apache.felix.framework.ServiceRegistry.unregisterService(ServiceRegistry.java:153)\n\tat org.apache.felix.framework.ServiceRegistrationImpl.unregister(ServiceRegistrationImpl.java:128)\n\tat org.apache.sling.jcr.base.AbstractSlingRepositoryManager.unregisterService(AbstractSlingRepositoryManager.java:258)\n\tat org.apache.sling.jcr.base.AbstractSlingRepositoryManager.stop(AbstractSlingRepositoryManager.java:345)\n\tat com.adobe.granite.repository.impl.SlingRepositoryManager.deactivate(SlingRepositoryManager.java:194)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invokeMethod(BaseMethod.java:231)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.access$500(BaseMethod.java:39)\n\tat org.apache.felix.scr.impl.helper.BaseMethod$Resolved.invoke(BaseMethod.java:624)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invoke(BaseMethod.java:508)\n\tat org.apache.felix.scr.impl.helper.ActivateMethod.invoke(ActivateMethod.java:149)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.disposeImplementationObject(SingleComponentManager.java:355)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.deleteComponent(SingleComponentManager.java:170)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.doDeactivate(AbstractComponentManager.java:908)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.deactivateInternal(AbstractComponentManager.java:883)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$SingleStaticCustomizer.removedService(DependencyManager.java:974)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$SingleStaticCustomizer.removedService(DependencyManager.java:895)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1506)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1401)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$AbstractTracked.untrack(ServiceTracker.java:1261)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.serviceChanged(ServiceTracker.java:1440)\n\tat org.apache.felix.framework.util.EventDispatcher.invokeServiceListenerCallback(EventDispatcher.java:940)\n\tat org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:794)\n\tat org.apache.felix.framework.util.EventDispatcher.fireServiceEvent(EventDispatcher.java:544)\n\tat org.apache.felix.framework.Felix.fireServiceEvent(Felix.java:4425)\n\tat org.apache.felix.framework.Felix.access$000(Felix.java:75)\n\tat org.apache.felix.framework.Felix$1.serviceChanged(Felix.java:402)\n\tat org.apache.felix.framework.ServiceRegistry.unregisterService(ServiceRegistry.java:153)\n\tat org.apache.felix.framework.ServiceRegistrationImpl.unregister(ServiceRegistrationImpl.java:128)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.unregisterNodeStore(SegmentNodeStoreService.java:320)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.deactivate(SegmentNodeStoreService.java:295)\n\t- locked <0x000001d231f52698> (a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invokeMethod(BaseMethod.java:231)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.access$500(BaseMethod.java:39)\n\tat org.apache.felix.scr.impl.helper.BaseMethod$Resolved.invoke(BaseMethod.java:624)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invoke(BaseMethod.java:508)\n\tat org.apache.felix.scr.impl.helper.ActivateMethod.invoke(ActivateMethod.java:149)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.disposeImplementationObject(SingleComponentManager.java:355)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.deleteComponent(SingleComponentManager.java:170)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.doDeactivate(AbstractComponentManager.java:908)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.deactivateInternal(AbstractComponentManager.java:883)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.reconfigure(SingleComponentManager.java:638)\n\tat org.apache.felix.scr.impl.config.ConfigurableComponentHolder.configurationUpdated(ConfigurableComponentHolder.java:328)\n\tat org.apache.felix.scr.impl.config.ConfigurationSupport.configurationEvent(ConfigurationSupport.java:290)\n\tat org.apache.felix.cm.impl.ConfigurationManager$FireConfigurationEvent.sendEvent(ConfigurationManager.java:2032)\n\tat org.apache.felix.cm.impl.ConfigurationManager$FireConfigurationEvent.run(ConfigurationManager.java:2002)\n\tat org.apache.felix.cm.impl.UpdateThread.run(UpdateThread.java:103)\n\tat java.lang.Thread.run(Thread.java:745)\n\"pool-5-thread-4\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.getNodeStore(SegmentNodeStoreService.java:144)\n\t- waiting to lock <0x000001d231f52698> (a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.getNodeStore(SegmentNodeStoreService.java:73)\n\tat org.apache.jackrabbit.oak.spi.state.ProxyNodeStore.getRoot(ProxyNodeStore.java:35)\n\tat org.apache.jackrabbit.oak.core.MutableRoot.<init>(MutableRoot.java:160)\n\tat org.apache.jackrabbit.oak.core.ContentSessionImpl.getLatestRoot(ContentSessionImpl.java:110)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.<init>(SessionDelegate.java:160)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl$1.<init>(RepositoryImpl.java:273)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.createSessionDelegate(RepositoryImpl.java:271)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:257)\n\tat com.adobe.granite.repository.impl.CRX3RepositoryImpl.login(CRX3RepositoryImpl.java:92)\n\tat com.adobe.granite.repository.impl.SlingRepositoryImpl$2.run(SlingRepositoryImpl.java:108)\n\tat com.adobe.granite.repository.impl.SlingRepositoryImpl$2.run(SlingRepositoryImpl.java:100)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAsPrivileged(Subject.java:536)\n\tat com.adobe.granite.repository.impl.SlingRepositoryImpl.createAdministrativeSession(SlingRepositoryImpl.java:100)\n\tat org.apache.sling.jcr.base.AbstractSlingRepository2.loginAdministrative(AbstractSlingRepository2.java:362)\n\tat org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProviderFactory.getResourceProviderInternal(JcrResourceProviderFactory.java:246)\n\tat org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProviderFactory.getAdministrativeResourceProvider(JcrResourceProviderFactory.java:209)\n\tat org.apache.sling.resourceresolver.impl.tree.ResourceProviderFactoryHandler.login(ResourceProviderFactoryHandler.java:162)\n\tat org.apache.sling.resourceresolver.impl.tree.RootResourceProviderEntry.loginToRequiredFactories(RootResourceProviderEntry.java:95)\n\tat org.apache.sling.resourceresolver.impl.CommonResourceResolverFactoryImpl.getResourceResolverInternal(CommonResourceResolverFactoryImpl.java:109)\n\tat org.apache.sling.resourceresolver.impl.CommonResourceResolverFactoryImpl.getAdministrativeResourceResolver(CommonResourceResolverFactoryImpl.java:76)\n\tat org.apache.sling.resourceresolver.impl.ResourceResolverFactoryImpl.getAdministrativeResourceResolver(ResourceResolverFactoryImpl.java:98)\n\tat org.apache.sling.discovery.impl.cluster.ClusterViewServiceImpl.getClusterView(ClusterViewServiceImpl.java:132)\n\tat org.apache.sling.discovery.impl.DiscoveryServiceImpl.getTopology(DiscoveryServiceImpl.java:418)\n\tat org.apache.sling.discovery.impl.DiscoveryServiceImpl.handlePotentialTopologyChange(DiscoveryServiceImpl.java:466)\n\tat org.apache.sling.discovery.impl.DiscoveryServiceImpl.handleTopologyChanged(DiscoveryServiceImpl.java:650)\n\t- locked <0x000001d2334be930> (a java.lang.Object)\n\tat org.apache.sling.discovery.impl.topology.TopologyChangeHandler.handleTopologyChanged(TopologyChangeHandler.java:134)\n\tat org.apache.sling.discovery.impl.topology.TopologyChangeHandler.handleEvent(TopologyChangeHandler.java:124)\n\tat org.apache.felix.eventadmin.impl.handler.EventHandlerProxy.sendEvent(EventHandlerProxy.java:412)\n\tat org.apache.felix.eventadmin.impl.tasks.SyncDeliverTasks.execute(SyncDeliverTasks.java:118)\n\tat org.apache.felix.eventadmin.impl.handler.EventAdminImpl.sendEvent(EventAdminImpl.java:114)\n\tat org.apache.felix.eventadmin.impl.security.EventAdminSecurityDecorator.sendEvent(EventAdminSecurityDecorator.java:96)\n\tat org.apache.sling.jcr.resource.internal.OakResourceListener.sendOsgiEvent(OakResourceListener.java:243)\n\tat org.apache.sling.jcr.resource.internal.OakResourceListener.changed(OakResourceListener.java:133)\n\tat org.apache.jackrabbit.oak.plugins.observation.NodeObserver$NodeEventHandler.leave(NodeObserver.java:208)\n\tat org.apache.jackrabbit.oak.plugins.observation.FilteredHandler.leave(FilteredHandler.java:51)\n\tat org.apache.jackrabbit.oak.plugins.observation.EventGenerator$Continuation.run(EventGenerator.java:175)\n\tat org.apache.jackrabbit.oak.plugins.observation.EventGenerator.generate(EventGenerator.java:118)\n\tat org.apache.jackrabbit.oak.plugins.observation.NodeObserver.contentChanged(NodeObserver.java:156)\n\tat org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1$1.call(BackgroundObserver.java:117)\n\tat org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1$1.call(BackgroundObserver.java:111)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nFound 1 deadlock.\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeStoreService prone to deadlocks"
   },
   {
      "_id": "12765997",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-01-09 11:21:56",
      "description": "With OAK-2192 revision gc started to remove segments older than a certain threshold. The underlying assumption was that old sessions would call refresh (i.e. auto refresh) anyway once they become active again. However, it turns out that refreshing a sessions does not affect JCR values as those are directly tied to the underlying record. Accessing those values after its segment has been gc'ed results in a {{SegmentNotFoundException}}. \n\nKeeping reference to JCR values is an important use case for Sling's {{JcrPropertyMap}}, which is widely used.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "SegmentNotFoundException when keeping JCR Value references"
   },
   {
      "_id": "12765321",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-01-07 08:20:57",
      "description": "There are many tests failing on http://ci.apache.org/builders/oak-trunk for the {{DOCUMENT_RDB}} fixture:\n\n{noformat}\n  addNodes[3](org.apache.jackrabbit.oak.jcr.ConcurrentAddIT): expected:<100> but was:<99>\n  testMVNameProperty[3](org.apache.jackrabbit.oak.jcr.NameAndPathPropertyTest): org.apache.jackrabbit.oak.api.CommitFailedException: OakMerge0001: OakMerge0001: Failed to merge changes to the underlying store (retries 5, 5432 ms)\n  testMVNameProperty[3](org.apache.jackrabbit.oak.jcr.NameAndPathPropertyTest): org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: java.sql.SQLException: Data source is closed\n  testMVPathProperty[3](org.apache.jackrabbit.oak.jcr.NameAndPathPropertyTest): Branch with failed reset\n  testMVPathProperty[3](org.apache.jackrabbit.oak.jcr.NameAndPathPropertyTest): java.sql.SQLException: Data source is closed\n  testInvalidPathProperty[3](org.apache.jackrabbit.oak.jcr.NameAndPathPropertyTest): initializing RDB blob store\n  orderableFolder[3](org.apache.jackrabbit.oak.jcr.OrderableNodesTest): java.sql.SQLException: Data source is closed\n  orderableFolder[3](org.apache.jackrabbit.oak.jcr.OrderableNodesTest): java.sql.SQLException: Data source is closed\n{noformat}\n\nAnd many more. See e.g. http://ci.apache.org/builders/oak-trunk/builds/890/steps/compile/logs/stdio\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "buildbot"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Regular CI failures for DOCUMENT_RDB on buildbot "
   },
   {
      "_id": "12762836",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2014-12-19 12:37:16",
      "description": "See http://markmail.org/message/idx2y2dwpkaxchsp for previous mention.\n\nI suggest to use the mechanism from OAK-2371 to exclude the tests on that CI environment for now. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "buildbot",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Sporadic test failure of OSGiIT.listBundles on Buildbot"
   },
   {
      "_id": "12762290",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-12-17 14:01:16",
      "description": "Following OAK-2323, I'd like to add a thin consistency check on startup to verify if the current rev is broken by some pending transaction or not.\n\nThe current startup check behavior is too lazy and it can miss some broken repos where the super root is only partly persisted.\n\n{code}\njava.lang.IllegalStateException: String is too long: 4531747125156176000\nat org.apache.jackrabbit.oak.plugins.segment.Segment.loadString(Segment.java:344)\nat org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:311)\nat org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:305)\nat org.apache.jackrabbit.oak.plugins.segment.Segment.loadTemplate(Segment.java:388)\nat org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:359)\nat org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:353)\nat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:74)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentMK thin consistency check on startup"
   },
   {
      "_id": "12760809",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-12-10 17:31:47",
      "description": "{{BackgroundThread}} catches {{InterruptedException}} but doesn't set the thread's interrupted status. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Wrong handling of InterruptedException in BackgroundThread"
   },
   {
      "_id": "12760088",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-12-08 08:54:05",
      "description": "We need a tool to check a SegmentMK repository for consistency. Such a tool should start at the most recent version in the journal and traverse back until it finds the latest good revision. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "offline",
         "production",
         "resilience",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentMK consistency check"
   },
   {
      "_id": "12759635",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-12-05 09:09:58",
      "description": "The original design of the compaction estimator was to only focus on binary segments when computing the amount of garbage that can be collected.\nThis has a flaw when it runs on systems with external data stores configured as there will be almost no binary segments and the estimation will always be _0_, no need for compaction.\n\nThe change to include all segments is not big, the _uuids_ bloomfilter is already initialized with the total number of segments, and the segment collection already loads everything in memory.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction estimation includes all data segments"
   },
   {
      "_id": "12758755",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-12-01 21:29:04",
      "description": "The Segment Explorer should be able to (more) gracefully print the info for external binaries when there's no BlobStore hooked in.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Better handling for external binaries in the segment explorer"
   },
   {
      "_id": "12757748",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-11-25 17:08:02",
      "description": "Performing version operations (checkin / checkout / addVersionLabel) concurrently can corrupt the repository. \n\nExecuting the following code in parallel from multiple threads demonstrates this:\n{code}\nVersion version = versionManager.checkin(vPath);\nversionManager.checkout(vPath);\nString label = version.getName() + \" \" + Thread.currentThread().getName();\nversion.getContainingHistory()\n    .addVersionLabel(version.getName(), label, true);\n{code}\n\nIn my tests this eventually lead to all sorts of exceptions:\n\n{noformat}\njava.lang.IllegalStateException: RefId '85' doesn't exist in data segment 0c5c0814-902c-429c-ad41-cd82aea276a2\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.getRefId(Segment.java:196)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.internalReadRecordId(Segment.java:307)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readRecordId(Segment.java:303)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getBucketList(MapRecord.java:134)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntries(MapRecord.java:347)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntries(MapRecord.java:325)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:474)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:394)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:544)\n...\n{noformat}\n\n{noformat}\njava.lang.IllegalStateException: String is too long: 2159501163930351661\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.loadString(Segment.java:352)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:319)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:313)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.loadTemplate(Segment.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:367)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:361)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:78)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:408)\n...\n{noformat}\n\n{noformat}\njava.lang.IllegalStateException\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:134)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.TarWriter.writeEntry(TarWriter.java:206)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.TarWriter.writeEntry(TarWriter.java:200)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.writeSegment(FileStore.java:682)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.flush(SegmentWriter.java:228)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.prepare(SegmentWriter.java:329)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeTemplate(SegmentWriter.java:969)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1039)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1062)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:395)\n...\n{noformat}\n\n{noformat}\nCaused by: java.lang.IllegalArgumentException: Invalid type tag: 81\n\tat org.apache.jackrabbit.oak.api.Type.fromTag(Type.java:202)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.loadTemplate(Segment.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:367)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:361)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:78)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getProperty(SegmentNodeState.java:122)\n...\n{noformat}\n\n{noformat}\nCaused by: java.lang.IllegalStateException\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:134)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.pos(Segment.java:178)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.loadString(Segment.java:326)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:319)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:313)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentPropertyState.getValue(SegmentPropertyState.java:174)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentPropertyState.getValue(SegmentPropertyState.java:147)\n\tat org.apache.jackrabbit.oak.plugins.memory.AbstractPropertyState.equal(AbstractPropertyState.java:53)\n...\n{noformat}\n\nWill attach a patch with a test case shortly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "corruption"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Corrupt repository after concurrent version operations"
   },
   {
      "_id": "12757647",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2014-11-25 08:55:34",
      "description": "OAK-2276 added support for {{IndexFormatVersion}} where {{V1}} is compatible with existing {{LuceneIndex}} while {{V2}} is compatible with newer index implemention being worked on OAK-2278.\n\nOnce implementation in OAK-2278 is stable enough we should switch the default version to be used for fresh index (unless overrided with {{compatMode}} ) from V1 to V2",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Switch default IndexFormatVersion to V2 "
   },
   {
      "_id": "12755383",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-11-14 15:06:39",
      "description": "Checkpoints can be seen as unix symlinks. The compaction estimation will blindly follow those links when computing the set of bulk segments that are in-use. \nFor example, when there are 1.9k checkpoints, the estimator will have to traverse the same repo 1.9k times to determine this set, even though it falls onto already traversed paths. \nThis is also misleading for debugging, it all looks like it's loading segments while estimating.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction estimation time should not depend on number of checkpoints"
   },
   {
      "_id": "12754445",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-11-11 11:27:33",
      "description": "When getting _PROPERTY_CHANGED_ events on non-multivalued properties only one value can have actually changed so that handlers of such events do not need any further information to process it and eventually work on the changed value; on the other hand _PROPERTY_CHANGED_ events on multivalued properties (e.g. String[]) may relate to any of the values and that brings a source of uncertainty on event handlers processing such changes because there's no mean to understand which property value had been changed and therefore to them to react accordingly.\nA workaround for that is to create Oak specific _Observers_ which can deal with the diff between before and after state and create a specific event containing the \"diff\", however this would add a non trivial load to the repository because of the _Observer_ itself and because of the additional events being generated while it'd be great if the 'default' events would have metadata e.g. of the changed value index or similar information that can help understanding which value has been changed (added, deleted, updated). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add metadata about the changed value to a PROPERTY_CHANGED event on a multivalued property"
   },
   {
      "_id": "12753708",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-11-07 14:45:39",
      "description": "It looks like the SegmentNodeState checks compaction in one direction [0], while the SegmentBlob checks in the other direction. This will not break anything as the fallback is to use byte comparison, but it will be terribly slow.\nI'm proposing to verify both directions in the #equals check, to make sure we don't miss out.\n\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeState.java#L401\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentBlob.java#L198\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentBlob equals check should verify compaction in both directions"
   },
   {
      "_id": "12753132",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-11-05 19:04:16",
      "description": "This is related to OAK-2000. I think the accessibility check needs to respect the session refresh settings when acquiring the root object.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation events accessibility check should respect session refresh settings"
   },
   {
      "_id": "12751650",
      "assignee": "edivad",
      "components": [],
      "created": "2014-10-30 10:22:53",
      "description": "When running the scalability suite even if not run the org.apache.jackrabbit.oak.scalability.ScalabilityNodeRelationshipSuite fails with \n\n{noformat}\nApache Jackrabbit Oak\nException in thread \"main\" java.lang.ExceptionInInitializerError\n\tat org.apache.jackrabbit.oak.scalability.ScalabilityRunner.main(ScalabilityRunner.java:143)\n\tat org.apache.jackrabbit.oak.run.Main.main(Main.java:162)\nCaused by: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3\n\tat java.util.ArrayList.RangeCheck(ArrayList.java:547)\n\tat java.util.ArrayList.get(ArrayList.java:322)\n\tat java.util.Collections$UnmodifiableList.get(Collections.java:1152)\n\tat org.apache.jackrabbit.oak.scalability.ScalabilityNodeRelationshipSuite.<clinit>(ScalabilityNodeRelationshipSuite.java:89)\n\t... 2 more\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "IndexOutOfBoundsException in o.a.j.o.scalability.ScalabilityNodeRelationshipSuite"
   },
   {
      "_id": "12751610",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2014-10-30 05:05:49",
      "description": "Currently a Lucene index when is written directly to OakDirectory. For reindex case it might happen that Lucene merge policy read the written index files again and then perform a sgement merge. This might have lower performance when OakDirectroy is writing to remote storage.\n\nInstead of that we can implement a CopyOnWriteDirectory on similar lines to  OAK-1724 where CopyOnReadDirectory support copies the  index locally for faster access. \n\nAt high level flow would be\n\n# While writing index the index file is first written to local directory\n# Any write is done locally and once a file is written its written asynchronously to OakDirectory\n# When IndexWriter is closed it would wait untill all the write is completed\n\nThis needs to be benchmarked with existing reindex timings to see it its actually beneficial",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "docs-impacting",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CopyOnWriteDirectory implementation for Lucene for use in indexing"
   },
   {
      "_id": "12751356",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-10-29 11:18:25",
      "description": "Both the MongoDocumentStore and the RDBDocumentStore maintain a \"_modCount\" property, which uniquely identifies a version of a document in the persistence.\n\nSometimes, we read data from the persistence although we already might have the document cached. This happens:\n\na) when the cached document is older than what the caller asked for\n\nb) when running a query (for instance when looking up children of a node)\n\nIn both cases, we currently replace the cache entry with a newly built NodeDocument.\n\nIt would make sense to re-use the existing document instead. (This would probably require modifying the \"created\" timestamp, but would avoid the trouble of having to update the cache at all) ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "provide a way to update the \"created\" timestamp of a NodeDocument"
   },
   {
      "_id": "12748072",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2014-10-14 16:33:07",
      "description": "When custom privileges are present {{jcr:all}} does not correctly reflect those via {{#getAggregatePrivileges}} and via its bit map. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "production",
         "upgrade"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Repository upgrade does not correctly update jcr:all aggregate privileges and bits"
   },
   {
      "_id": "12748070",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-10-14 16:18:35",
      "description": "I think it would be useful if the segment explorer could print the graph of a tar file along with its references. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Print tar file graph in segment explorer"
   },
   {
      "_id": "12748057",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-10-14 15:26:19",
      "description": "Tar garbage collection generates new generation of tar files once it determines a given file contains garbage. New generations will have the next lower case letter from the alphabet appended to its file name. When the letter 'z' is reached, no further garbage collection is done. \n\nI think we need to fix this as otherwise garbage collection just stops working arbitrarily. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "No garbage collection after reaching generation z"
   },
   {
      "_id": "12748055",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-10-14 15:10:26",
      "description": "Changes that are committed during a segment store compaction run will be compacted on top of the already compacted changes. However the compactor uses the wrong before state in this case. Instead of compacting against the compacted before state it uses the un-compacted before state. The resulting state will thus contain references to un-compacted state, making those not eligible for later clean up. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Concurrent commit during compaction results in mixed segments"
   },
   {
      "_id": "12747934",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2014-10-14 06:08:06",
      "description": "Intermittent failures on windows are observed in JaasConfigSpiTest with following exception\n\n{noformat}\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 3.841 sec <<< FAILURE!\ndefaultConfigSpiAuth(org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest)  Time elapsed: 3.835 sec  <<< ERROR!\njava.lang.reflect.UndeclaredThrowableException\n\tat $Proxy7.login(Unknown Source)\n\tat javax.jcr.Repository$login.call(Unknown Source)\n\tat org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:45)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:108)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:116)\n\tat org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest.defaultConfigSpiAuth(JaasConfigSpiTest.groovy:75)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.jackrabbit.oak.run.osgi.OakOSGiRepositoryFactory$RepositoryProxy.invoke(OakOSGiRepositoryFactory.java:325)\n\t... 37 more\nCaused by: javax.jcr.LoginException: No LoginModules configured for jackrabbit.oak\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:264)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:222)\n\t... 42 more\nCaused by: javax.security.auth.login.LoginException: No LoginModules configured for jackrabbit.oak\n\tat javax.security.auth.login.LoginContext.init(LoginContext.java:256)\n\tat javax.security.auth.login.LoginContext.<init>(LoginContext.java:499)\n\tat org.apache.jackrabbit.oak.spi.security.authentication.JaasLoginContext.<init>(JaasLoginContext.java:49)\n\tat org.apache.jackrabbit.oak.security.authentication.LoginContextProviderImpl.getLoginContext(LoginContextProviderImpl.java:85)\n\tat org.apache.jackrabbit.oak.core.ContentRepositoryImpl.login(ContentRepositoryImpl.java:161)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:256)\n\t... 43 more\n\nRunning org.apache.jackrabbit.oak.run.osgi.JsonConfigRepFactoryTest\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI",
         "buildbot",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Fix intermittent failure in JaasConfigSpiTest"
   },
   {
      "_id": "12747685",
      "assignee": "edivad",
      "components": [],
      "created": "2014-10-13 09:48:22",
      "description": "Issues for 1.1.1 https://issues.apache.org/jira/issues/?jql=project%20%3D%20OAK%20AND%20fixVersion%20%3D%201.1.1",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "release"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release 1.1.1"
   },
   {
      "_id": "12746165",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-10-06 15:17:11",
      "description": "{{JackrabbitNodeTest#testRenameEventHandling}} fails sporadically on the Apache buildbot with missing events (e.g. http://ci.apache.org/builders/oak-trunk-win7/builds/642). \n\nSame holds for other tests in the {{ObservationIT}} suite. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "buildbot",
         "observation",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation tests sporadically failing"
   },
   {
      "_id": "12744052",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-09-25 15:21:13",
      "description": "The compaction bit rely on the SegmentBlob#clone method in the case a binary is being processed but it looks like the #clone contract is not fully enforced for streams that are qualified as 'long values' (>16k if I read the code correctly). \nWhat happens is the stream is initially persisted as chunks in a ListRecord. When compaction calls #clone it will get back the original list of record ids, which will get referenced from the compacted node state [0], making compaction on large binaries ineffective as the bulk segments will never move from the original location where they were created, unless the reference node gets deleted.\n\nI think the original design was setup to prevent large binaries from being copied over but looking at the size problem we have now it might be a good time to reconsider this approach.\n\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentBlob.java#L75\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Segment Compactor will not compact binaries > 16k"
   },
   {
      "_id": "12744000",
      "assignee": "mreutegg",
      "components": [],
      "created": "2014-09-25 11:26:20",
      "description": "Issues for 1.0.7: https://issues.apache.org/jira/issues/?jql=project%20%3D%20OAK%20AND%20fixVersion%20%3D%201.0.7",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "Release"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release Oak 1.0.7"
   },
   {
      "_id": "12742399",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-09-18 09:27:09",
      "description": "When killing a node that is running the sync index update, then this async index update will not run for up to 15 minutes, because the lease time is set to 15 minutes.\n\nI think the lease time should be much smaller, for example 1 minute, or maybe even 10 seconds.\n\nAlso, we might need to better document this issue (in addition to the warning in the log file). For non cluster case we can do away with lease time out and this for such cases indexing would not get paused upon restart post abrupt shutdown",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Killing a node may stop async index update to to 30 minutes (Tar storage)"
   },
   {
      "_id": "12742379",
      "assignee": "tomek.rekawek",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-09-18 07:17:44",
      "description": "OAK-1645 introduced support for reads from secondaries under certain\nconditions. The current implementation checks the _lastRev on a potentially\ncached parent document and reads from a secondary if it has not been\nmodified in the last 6 hours. This timespan is somewhat arbitrary but\nreflects the assumption that the replication lag of a secondary shouldn't\nbe more than 6 hours.\n\nThis logic should be optimized to take the actual replication lag into\naccount. MongoDB provides information about the replication lag with\nthe command rs.status().\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize reads from secondaries"
   },
   {
      "_id": "12738281",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2014-09-01 15:04:34",
      "description": "The DocumentStore API currently has a call for creating many nodes at once.\n\nHowever, this will sometimes fail for large save operations in JCR, because in the DS persistence, JCR-deleted nodes are still present (with a deleted flag). This causes two subsequent sequences of\n\n1) create test container\n2) create many child nodes\n3) remove test container\n\nto behave very differently, depending on whether the test container is created for the first time or not.\n\n(see CreateManyChildNodesTest)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "DocumentStore API: batch create, but no batch update"
   },
   {
      "_id": "12738253",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2014-09-01 12:05:40",
      "description": "Currently DocumentStore performs various background operations like\n\n# Cache consistency check\n# Pushing the lastRev updates\n# Synchrnizing the root node version\n\nWe should capture some stats like time taken in various task and expose them over JMX to determine if those background operations are performing well or not. For example its important that all tasks performed in background task should be completed under 1 sec (default polling interval). If the time taken increases then it would be cause of concern\n\nSee http://markmail.org/thread/57fax4nyabbubbef",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JMX stats for operations being performed in DocumentNodeStore"
   },
   {
      "_id": "12738234",
      "assignee": "amitjain",
      "components": [],
      "created": "2014-09-01 10:18:11",
      "description": "Issues for 1.0.6: https://issues.apache.org/jira/issues/?jql=project%20%3D%20OAK%20AND%20fixVersion%20%3D%201.0.6",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "Release"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release Oak 1.0.6"
   },
   {
      "_id": "12737509",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-08-28 17:32:24",
      "description": "Currently DocumentNodeStore has 5 different types of caches and each register there own MBean. To get a better understanding of the overall cache usage it would be good to have a {{ConsolidatedCacheStatsMBean}} which depicts all the stats in tabular form",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MBean to provide consolidated cache stats "
   },
   {
      "_id": "12737059",
      "assignee": "edivad",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-08-27 09:34:55",
      "description": "Sorting by date fields is very slow in oak, especially if result set size is large.\n\nI'm running the following JCR-SQL2 query\n\n{code}\nSELECT * FROM [cq:PageContent] AS [c] WHERE ISDESCENDANTNODE('/content')\n{code}\n\nwhich returns 3270 results on my oak repo.\n\n{noformat}\nQuery execution times are as below\n---------------------------------------\nNo order clause \t\t|  0,147 sec\nORDER BY [jcr:title]\t        |  1,203 sec\nORDER BY [jcr:createdBy]\t|  1,018 sec\nORDER BY [jcr:created]\t\t| 25,229 sec\n{noformat}\n\nOrdering by date field adds extra 24 seconds overhead.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize orderings by date fields"
   },
   {
      "_id": "12735772",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-08-21 12:32:27",
      "description": "Cleanup operation in SegmentNodeStore detects the un referenced garbage and clean it up. To determine the reference validity it starts with an initial set of SegmentId which have a live java reference. \n\nThis works fine for simple setup but when Oak repository is used in an application (like Sling) where application code can create long running session (for observation) then such session are bound to old NodeState at time of startup. Such references prevent the cleanup logic to remove older revisions while system is running. Such revisions can only be removed via an offline compaction-> cleanup.\n\nNeed to find out a way where we can _migrate_ such old NodeState references to newer revisions",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Long running JCR session prevent live cleanup in Segment FileStore"
   },
   {
      "_id": "12734528",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-08-15 22:04:46",
      "description": "Currently, the syntax for the plan output is chaotic as it varies significantly from index to index. Whereas some of this is expected - each index type will have different data to output, Oak should provide some standards about how a plan will appear.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Define standards for plan output"
   },
   {
      "_id": "12733229",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-08-11 13:05:14",
      "description": "XPath queries with \"or\" are converted to union, even if there is an \"order by\" clause. In such cases, sorting is done in memory. See also OAK-2022.\n\nFor some queries, it might be better to not use union, but use an ordered index instead. This is tricky to decide up-front, but it would be possible to estimate the cost of both variants and pick the one that seems better.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimal index usage for XPath queries with \"order by\" combined with \"or\""
   },
   {
      "_id": "12732220",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-08-06 04:23:18",
      "description": "The blob gc max age setting is not configurable when using {{SegmentNodeStoreService}}. This can be made configurable and will be useful for testing.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "datastore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Make blob gc max age configurable in SegmentNodeStoreService"
   },
   {
      "_id": "12730767",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-07-30 11:56:22",
      "description": "Currently the maven baseline plugin only logs the package version mismatches, it doesn't fail the build. It would be beneficial to start looking at the output and possibly fix some of the warnings (increase the OSGi package versions).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "build",
         "modularization",
         "osgi",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Verify the maven baseline output and fix the warnings"
   },
   {
      "_id": "12730473",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-29 12:56:48",
      "description": "Before delivering an observation event it is checked whether the respective item is actually accessible through the associated session. However the check is currently done against the state of the session from the time the event listener was registered instead of from the time the event is being sent. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation events accessibility not checked correctly"
   },
   {
      "_id": "12729663",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-07-25 06:13:55",
      "description": "Oak Console 'ls' command currently lists down all the child node which cause issue for node have large no of children. As a fix ls command should dump max say 50 child node and allow user to change the limit as part of arguments",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "console"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Limit no of children listed with ls command in Oak Console"
   },
   {
      "_id": "12729658",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-07-25 05:13:09",
      "description": "Add a command in Oak Run Console to dump lucene index and also provide stats related to Lucene index\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "console"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add command to dump Lucene index in Oak Console"
   },
   {
      "_id": "12729095",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-07-23 06:54:24",
      "description": "So far we have implemented garbage collection in some form with OAK-1341. Those approaches help us remove quite a bit of garbage (mostly due to deleted nodes) but till some part is left\n\nHowever full GC is still not performed due to which some of the old revision related data cannot be GCed like\n* Revision info present in revision maps of various commit roots\n* Revision related to unmerged branches (OAK-1926)\n* Revision data created to property being modified by different cluster nodes\n\nSo having a tool which can perform above GC would be helpful. For start we can have an implementation which takes a brute force approach and scans whole repo (would take quite a bit of time) and later we can evolve it. Or allow system admins to determine to what level GC has to be done",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "resilience",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement full scale Revision GC for DocumentNodeStore"
   },
   {
      "_id": "12728484",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-21 07:20:33",
      "description": "Implement the new Jackrabbit API introduced with JCR-3797",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add path exclusion to JackrabbitEventFilter"
   },
   {
      "_id": "12727885",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-17 09:27:23",
      "description": "The value reported for the {{RepositoryStatistics.Type#OBSERVATION_EVENT_DURATION}} statistic is wrong. Instead of the total time spent *processing* observation events it reports the total time *producing* observation events. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "monitoring",
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Wrong values reported for OBSERVATION_EVENT_DURATION"
   },
   {
      "_id": "12727863",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-07-17 07:09:16",
      "description": "The current MongoMK implementation performs retries when it runs into merge\nconflicts caused by collisions. It may be possible to resolve a conflict by resetting\nthe branch back to the state as it was before the merge and re-run the commit hooks again.\nThis helps if the conflict was introduced by a commit hook. At the moment the retries\nalso happen when the conflict was introduced before the merge. In this case, a retry\nis useless and the commit should fail fast.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Fail fast on branch conflict"
   },
   {
      "_id": "12727342",
      "assignee": "catholicon",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-07-15 14:17:00",
      "description": "It appears that there are tests that have been rewritten exclusively for the Mongo persistence, but which really are specific to the DocumentMK (formerly MongoMK).\n\nThese should be rewritten to be useable for all implementations of the DocumentStore API.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "CI",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "generalize MongoDB-specific tests"
   },
   {
      "_id": "12727333",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-07-15 13:13:52",
      "description": "DocumentNodeStore currently makes use of query to determine child nodes which have changed after certain time. Query used is something like\n\n{noformat}\ndb.nodes.find({ _id: { $gt: \"3:/content/foo/01/\", $lt: \"3:/content/foo010\" }, _modified: { $gte: <start time> } }).sort({_id:1})\n{noformat}\n\nOAK-1966 tries to optimize the majority case where start times is recent and in that case it makes use of _modified index. However if the start time is quite old and a node has large number of children say 100k then it would involve scan of all those 100k nodes as _modified index would not be of much help. \n\nInstead of querying like this we can have a special handling for cases where large number of children are involved. It would involve following steps\n\nAfter analyzing the runtime queries in most case it is seen that even with old modified time the number of change nodes is < 50\n\n# Mark parent nodes which have large number of children say > 50\n# On such nodes we would keep an array of \\{modifiedtime, childName\\} ## Array would be bounded say keep last 50 updates. This can be done via splice and push operators [1]\n## Each entry in array would record modifiedtime and name of child node which was modified. \n## Array would be sorted on modifiedtime\n# Each updated to any child belonging to such parent would also involve update to above array\n# When we query for modified we check if the parent has such an array (if parent is in cache) and if that array has time entries from the required start time we directly make use of that and avoid the query\n\nThis should reduce needs for such queries in majority of cases\n\n[1] http://docs.mongodb.org/manual/reference/operator/update-array/\n ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize the diff logic for large number of children case "
   },
   {
      "_id": "12726576",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-10 12:46:38",
      "description": "In OAK-1703, we have added a new class WarningLock that internally uses an Exception to remember the stack trace. This seems to be used for every SessionDelegate object. With Java 6 and older, this is very problematic because it will cause \"java.lang.Throwable.fillInStackTrace(Native Method)\" to be called for almost every call to any of the Oak JCR methods, and \"fillInStackTrace(Native Method)\" is known to be be very slow. Java 7, I believe, will at some point give up and not fill in the stack trace any more. But with Java 6 and older, this is a big problem.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Performance degradation due to SessionDelegate.WarningLock"
   },
   {
      "_id": "12726532",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-07-10 09:23:04",
      "description": "In certain scenarios for performance reasons its desirable to have direct access to the Blob source. \n\nFor e.g. if using a FileDataStore having a direct access to the native file system path of the blob (if not stored in chunks) is more useful than repository path e.g. native tools don't understand repository path, instead file system path can be passed directly to native tools for processing binary.\n\nAnother usecase being ability exposed signed S3 url which would allow access to binary content directly",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "datastore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose URL for Blob source "
   },
   {
      "_id": "12726185",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-08 20:50:32",
      "description": "Problem:\nSession.logout was observed to take 14% of time in a performance test of a reasonably real-world load.\n\nMethod:\nUse the attached sling junit test case to run 8 concurrent instances of the test. profile with YourKit or  similar and see >50% time taken by logout.\n\nExpected:\nLogout should be practically free.\n\nSolution:\nThe attached patch avoids a bug in guava-15 (still present in guava-17 the latest) where the former use of addCallback triggered many CancellationExceptions when sessions were quickly created and logged out.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Session.logout performance poor"
   },
   {
      "_id": "12725972",
      "assignee": "mduerig",
      "components": [],
      "created": "2014-07-08 08:52:12",
      "description": "This issue serves as a reminder to set the correct OSGi package export versions before we release 1.2.\n\nOAK-1536 added support for the BND baseline feature: the baseline.xml files in the target directories should help us figuring out the correct versions. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "modularization",
         "osgi",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Set correct OSGi package export version"
   },
   {
      "_id": "12724756",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-07-01 15:50:06",
      "description": "Since OAK-1422 the  {{Continuation}} created in {{fullQueue()}} is put to the front of the List. This causes it to be taken right off the list again on the next call to {{generate()}} instead of first continuing with the rest of the list allowing it to shrink. As a result the list may grow up to 2 x {{MAX_QUEUED_CONTINUATIONS}} instead of 1 + {{MAX_QUEUED_CONTINUATIONS}} as anticipated. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MAX_QUEUED_CONTINUATIONS feature not working in EventGenerator class"
   },
   {
      "_id": "12717708",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-05-31 02:50:01",
      "description": "A significant part of the time in writing new SegmentMK records is spent in the {{SegmentWriter.prepare()}} method, especially in the part where the exact set of segment references is computed. In most cases that computation could be short-circuited to improve write performance.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize SegmentWriter.prepare()"
   },
   {
      "_id": "12717693",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-05-31 00:04:01",
      "description": "The SegmentMK has an optimization for the common case where only a single child node among many has been updated. For the most part this code works very well, but there's one code path where this optimization is currently not applied and as a result a node comparison ends up traversing the full list of child nodes.\n\nThe troublesome code path gets triggered when a single child node is updated in one commit and then another commit does some more complex changes (adds or removes a node and/or modifies more than a single node). \n\nUsually this isn't too big an issue since traversing even thousands of child node entries is very fast with the SegmentMK, but things slow down a lot when there are millions of children. Unfortunately that is exactly what happens with the UUID index in a large repository with millions of referenceable nodes...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentMK: Inefficient flat node comparisons"
   },
   {
      "_id": "12717071",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-05-28 16:01:06",
      "description": "The generic interface for operation management tasks added with OAK-1160 does so far not provide a way for specific tasks to return a value apart from a genetic status. With the consistency checking we are starting to add (OAK-1448) such a needs start to arise. \n\nTo address this I propose to change type of the tasks that can be passed to the constructor of {{ManagementOperation}}. The result type of the task (i.e. {{Callable}}) should change from {{Long}} to some generic container, which would carry the result of the task. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Generic operation tasks should be able to return specific results"
   },
   {
      "_id": "12716831",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2014-05-27 15:18:17",
      "description": "Add tests that exercise multiple DS instances accessing the same persistence.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "CI",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "unit tests for concurrent DocumentStore access"
   },
   {
      "_id": "12716811",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-05-27 13:45:28",
      "description": "I'm thinking about working on a desktop tool that would allow browsing the repository and would provide tarmk specific information: segment ids, tar files, sizes, checkpoints and so on.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Segment Explorer"
   },
   {
      "_id": "12715768",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2014-05-21 14:43:48",
      "description": "There are still a few places left where {{MicroKernelImpl}} is used for running tests. As {{SegementMK}} is the default for going forward I suggest we change those tests accordingly. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use SegmentMK for testing where possible"
   },
   {
      "_id": "12715514",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2014-05-20 15:43:31",
      "description": "The stacktrace of the call shows something like\n{code}\n20.05.2014 11:13:07.428 *ERROR* [OsgiInstallerImpl] com.adobe.granite.installer.factory.packages.impl.PackageTransformer Error while processing install task.\njava.lang.IllegalStateException: Unexpected value record type: f2\nat org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.length(SegmentBlob.java:101)\nat org.apache.jackrabbit.oak.plugins.value.BinaryImpl.getSize(BinaryImpl.java:74)\nat org.apache.jackrabbit.oak.jcr.session.PropertyImpl.getLength(PropertyImpl.java:435)\nat org.apache.jackrabbit.oak.jcr.session.PropertyImpl.getLength(PropertyImpl.java:376)\nat org.apache.jackrabbit.vault.packaging.impl.JcrPackageImpl.getPackage(JcrPackageImpl.java:324)\n{code}\n\nThe blob store was configured correctly and according to the log also correctly initialized\n{code}\n20.05.2014 11:11:07.029 *INFO* [FelixStartLevel] org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService Initializing SegmentNodeStore with BlobStore [org.apache.jackrabbit.oak.spi.blob.FileBlobStore@7e3dec43]\n20.05.2014 11:11:07.029 *INFO* [FelixStartLevel] org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService Component still not activated. Ignoring the initialization call\n20.05.2014 11:11:07.077 *INFO* [FelixStartLevel] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK opened: crx-quickstart/repository/segmentstore (mmap=true)\n{code}\n\nUnder which circumstances can the length within the SegmentBlob be invalid?\nThis only happens if a File Blob Store is configured (http://jackrabbit.apache.org/oak/docs/osgi_config.html). If a file datastore is used, there is no such exception.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ISE: \"Unexpected value record type: f2\" is thrown when FileBlobStore is used"
   },
   {
      "_id": "12715494",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2014-05-20 14:34:08",
      "description": "the 'clustering' page in our oak documentation is currently an empty placeholder and it would be great if there would be some initial pointers.\n\n[~chetanm], [~mreutegg], what do you think?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document Oak Clustering"
   },
   {
      "_id": "12714523",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-05-15 16:35:24",
      "description": "At about 1kLOC and dozens of methods, the SegmentWriter class currently a bit too complex for one of the key components of the TarMK. It also uses a somewhat non-obvious mix of synchronized and unsynchronized code to coordinate multiple concurrent threads that may be writing content at the same time. The synchronization blocks are also broader than what really would be needed, which in some cases causes unnecessary lock contention in concurrent write loads.\n\nTo improve the readability and maintainability of the code, and to increase performance of concurrent writes, it would be useful to split part of the SegmentWriter functionality to a separate RecordWriter class that would be responsible for writing individual records into a segment. The SegmentWriter.prepare() method would return a new RecordWriter instance, and the higher-level SegmentWriter methods would use the returned instance for all the work that's currently guarded in synchronization blocks.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improved SegmentWriter"
   },
   {
      "_id": "12714248",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2014-05-14 19:15:46",
      "description": "The following {{oak-solr-core}} test failures occur when building Oak with Java 8:\n\n{noformat}\nFailed tests:\n  testNativeMLTQuery(org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTest): expected:</test/[a]> but was:</test/[b]>\n  testNativeMLTQueryWithStream(org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTest): expected:</test/[a]> but was:</test/[b]>\n{noformat}\n\nThe cause of this might well be something as simple as the test case incorrectly expecting a specific ordering of search results.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "java8",
         "java9",
         "jenkins",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-solr-core test failures on Java 8 and later"
   },
   {
      "_id": "12713027",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-05-08 07:07:54",
      "description": "While running ConcurrentCreateNodesTest with 5 instances writing to same Mongo instance following exception is seen\n\n{noformat}\nException in thread \"Background job org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest$Writer@3f56e5ed\" java.lang.RuntimeException: javax.jcr.nodetype.ConstraintViolationException: OakConstraint0001: /: The primary type rep:root does not exist\n    at org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest$Writer.run(ConcurrentCreateNodesTest.java:111)\n    at org.apache.jackrabbit.oak.benchmark.AbstractTest$1.run(AbstractTest.java:481)\nCaused by: javax.jcr.nodetype.ConstraintViolationException: OakConstraint0001: /: The primary type rep:root does not exist\n    at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:225)\n    at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:212)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.newRepositoryException(SessionDelegate.java:679)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:553)\n    at org.apache.jackrabbit.oak.jcr.session.SessionImpl$8.perform(SessionImpl.java:417)\n    at org.apache.jackrabbit.oak.jcr.session.SessionImpl$8.perform(SessionImpl.java:414)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:308)\n    at org.apache.jackrabbit.oak.jcr.session.SessionImpl.perform(SessionImpl.java:127)\n    at org.apache.jackrabbit.oak.jcr.session.SessionImpl.save(SessionImpl.java:414)\n    at org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest$Writer.run(ConcurrentCreateNodesTest.java:100)\n    ... 1 more\nCaused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakConstraint0001: /: The primary type rep:root does not exist\n    at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.constraintViolation(TypeEditor.java:150)\n    at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.getEffectiveType(TypeEditor.java:286)\n    at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.<init>(TypeEditor.java:101)\n    at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditorProvider.getRootEditor(TypeEditorProvider.java:85)\n    at org.apache.jackrabbit.oak.spi.commit.CompositeEditorProvider.getRootEditor(CompositeEditorProvider.java:80)\n    at org.apache.jackrabbit.oak.spi.commit.EditorHook.processCommit(EditorHook.java:53)\n    at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:60)\n    at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:60)\n    at org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch$InMemory.merge(AbstractNodeStoreBranch.java:498)\n    at org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch.merge(AbstractNodeStoreBranch.java:300)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:129)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:159)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1275)\n    at org.apache.jackrabbit.oak.core.MutableRoot.commit(MutableRoot.java:247)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:405)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:551)\n    ... 7 more\n{noformat}\n\nThis has been reported by [~rogoz]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ConstraintViolationException seen with multiple Oak/Mongo with ConcurrentCreateNodesTest"
   },
   {
      "_id": "12713023",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-05-08 06:12:16",
      "description": "Have a longevity test which incrementally increases the load by adding blobs and then running full text search to measure the execution times and the performance degradation for increased loads.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "benchmark",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Benchmark for blob upload and search longevity"
   },
   {
      "_id": "12712931",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-05-07 20:21:02",
      "description": "It would be nice to for {{oak-run}} to come with a debugging console like the {{cli}} mode in {{jackrabbit-standalone}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "production",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Debugging console"
   },
   {
      "_id": "12712928",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-05-07 20:12:46",
      "description": "The TarMK would benefit from periodic \"compact\" operations that would traverse and recreate (parts of) the content tree in order to optimize the storage layout. More specifically, such compaction would:\n\n* Optimize performance by increasing locality and reducing duplication, both of which improve the effectiveness of caching.\n* Allow the garbage collector to release more unused disk space by removing references to segments where only a subset of content is reachable.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "production",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TarMK compaction"
   },
   {
      "_id": "12712793",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2014-05-07 09:20:24",
      "description": "As a follow up to OAK-1702 it'd be good to have a similar benchmark for the Solr indexer.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "benchmark",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Create a benchmark for Full text search with Solr"
   },
   {
      "_id": "12712602",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2014-05-06 15:31:41",
      "description": "oak-doc is missing documentation about the usage of the OrderedIndex.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Missing documentation around Ordered Index"
   },
   {
      "_id": "12711671",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-05-01 07:28:50",
      "description": "Occurs every now and then on buildbot. E.g.:\nhttp://ci.apache.org/builders/oak-trunk-win7/builds/16",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ConcurrentConflictTest fails occasionally"
   },
   {
      "_id": "12710305",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2014-04-24 12:59:37",
      "description": "Every now and then we see commit failures in a cluster when many sessions try to update the same property or perform some other conflicting update.\n\nThe current implementation will retry the merge after a delay, but chances are some session on another cluster node again changed the property in the meantime. This will lead to yet another retry until the limit is reached and the commit fails. The conflict logic is quite unfair, because it favors the winning session.\n\nThe implementation should be improved to show a more fair behavior across cluster nodes when there are conflicts caused by competing session.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Better cooperation for conflicting updates across cluster nodes"
   },
   {
      "_id": "12710287",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-04-24 10:51:34",
      "description": "This is a follow up from OAK-1757.\n\nThe accuracy of the values reported by {{RepositoryStatsMBean}} for {{SESSION_WRITE_DURATION}} and {{SESSION_READ_DURATION}} depend on the value of {{Clock#FAST_CLOCK_INTERVAL}}. \n\nThe 1s reset interval of the duration counters might be to small for the inaccuracies of the clock resolution to average out. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Inaccurate values reported by RepositoryStatsMBean"
   },
   {
      "_id": "12709986",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-04-23 09:30:36",
      "description": "Seeing the below IlegalStateException about tracker being null several times on a 4-node oak-mongo cluster. There were no log.warn 'Timed out waiting for change processor to stop' near those errors (but there was once hour(s) before in one case).\n\n{code}16.04.2014 05:34:50.908 *ERROR* [oak-executor-1619] org.apache.sling.extensions.threaddump.internal.Activator Uncaught exception in Thread Thread[oak-executor-1619,1,Configuration\n Admin Service]\njava.lang.IllegalStateException: null\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:134)\n        at org.apache.jackrabbit.oak.spi.whiteboard.AbstractServiceTracker.getServices(AbstractServiceTracker.java:60)\n        at org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardExecutor.execute(WhiteboardExecutor.java:40)\n        at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1.run(BackgroundObserver.java:130)\n        at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$ListenableFutureTask.run(BackgroundObserver.java:283)\n        at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$ListenableFutureTask.done(BackgroundObserver.java:278)\n        at java.util.concurrent.FutureTask$Sync.innerSet(FutureTask.java:281)\n        at java.util.concurrent.FutureTask.set(FutureTask.java:141)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:339)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Sporadic IllegalStateException in AbstractServiceTracker.getServices"
   },
   {
      "_id": "12709744",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-04-22 11:21:11",
      "description": "we should document how to use MongoMK when MongoDB requires credentials to connect to. According to [~chetanm] this would work as\n{quote}\nin OSGi config we can specify uri [1] to mongodb://admin:admin@localhost:27017\n\n[1] http://api.mongodb.org/java/current/com/mongodb/MongoURI.html \n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "add docu how to connect to Mongo w/ credentials"
   },
   {
      "_id": "12709720",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-04-22 09:15:40",
      "description": "The node name queries don't use any index currently, making them really slow and triggering a lot of traversal warnings.\n\nSimply adding node names to a property index would be too much content indexed, but as Lucene already indexes the node names, using this index would be one viable option.\n\n{code}\n/jcr:root//*[fn:name() = 'jcr:content']\n/jcr:root//*[jcr:like(fn:name(), 'jcr:con%')] \n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Node name queries should use an index"
   },
   {
      "_id": "12709036",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-04-17 12:26:45",
      "description": "The documentation of\n\n  Document.MOD_COUNT\n\n\"The modification count on the document. This is an long value incremented on every modification.\"\n\ngives the impression that this is a mechanism that is part of the DocumentStore API contract (which IMHO it is not)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cleanup documentation of _modCount"
   },
   {
      "_id": "12707672",
      "assignee": "edivad",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-04-10 09:33:17",
      "description": "In a clustered deployment with DocumentNodeStore on MongoDB it may happen that concurrent updates on the new ordered index fail because of conflicts.\n\nA common use case is maintaining an ordered index on a last modified date. When nodes with such a date are added concurrently on multiple cluster nodes, then all of them will try to update the ordered index at one end of the key list. The DocumentNodeStore will perform a couple of retries but there is no guarantee that the cluster nodes will sync within that time frame or some other session conflicts yet another time.\n\nA possible workaround is to declare the index as asynchronous.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Concurrent updates of ordered index in cluster may fail"
   },
   {
      "_id": "12707639",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         }
      ],
      "created": "2014-04-10 05:21:44",
      "description": "Benchmark runner has support for specifying concurrency levels to execute the test with varying level of concurrency. In most cases the test case would be operating on a JCR session. With multi threaded runs we need a way to have jcr session bound to that thread of execution.\n\nTo support that {{AbstractTest}} should provide a way for client to provide a executionContext object which sub classes can provide. That context would be managed per thread and passed to the runTest method if not null",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable passing of a execution context to runTest in multi threaded runs"
   },
   {
      "_id": "12707374",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-04-09 07:26:44",
      "description": "OAK-1601 introduced warnings that are logged when a session is accessed concurrently from different threads. The modalities however differ from those of Jackrabbit 2. The message \n\n{code}\nAttempt to perform \"sessionOperation\" while another thread is concurrently writing to \"session\". Blocking until the other thread is finished using this session. Please review your code to avoid concurrent use of a session.\n{code}\n\nis logged for the current thread\n\n* if the current threads attempts a write operation while another thread already executes a write operation in Jackrabbit 2,\n* if the current thread attempts a write operation while another thread already executes any operation. \n\nWe should make these warnings identical to those of Jackrabbit 2.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve warning logged on concurrent Session access"
   },
   {
      "_id": "12707136",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-04-08 08:48:51",
      "description": "As [noted | https://issues.apache.org/jira/browse/OAK-1414?focusedCommentId=13942016&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13942016] on OAK-1414 {{LargeOperationIT}} is somewhat inaccurate for the document node store fixture where the collected data tends to be noisy. We should look into ways to make  the tests results more accurate for this case.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve LargeOperationIT accuracy for document nodes store fixture"
   },
   {
      "_id": "12707129",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2014-04-08 08:04:42",
      "description": "Provide documentation about the Oak Solr index. That should contain information about the design and how to configure it.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document Solr index"
   },
   {
      "_id": "12706946",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-04-07 13:21:51",
      "description": "Please document (I'll assume it's similar to \"remove\", in that it is \"best effort\")?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "document atomicity of DS.update(collection, keys, update)"
   },
   {
      "_id": "12706594",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-04-04 09:14:11",
      "description": "[~mreutegg]\nI believe it's best effort (looking at the MongoDB impl), but it would be good to clarify.\n\nIn particular, should the operation abort then one removal failed, or keep going? What's the expectation when a document doesn't exist?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "document atomicity of DS.remove(collection, keys)"
   },
   {
      "_id": "12706187",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-04-02 15:03:21",
      "description": "OAK-1661 added node type information for {{NODE_ADDED}} and {{NODE_REMOVED}} events. We should consider adding this for all event types however.  Even property events would contain node type of the node the property is associated with (parent).\n\nAn implication of this is however that we also need to adapt the TCK as this will cause {{org.apache.jackrabbit.test.api.observation.GetInfoTest}} to fail, which expects the info map to be generally empty. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "JCR Event Info should contain NodeType for all Events "
   },
   {
      "_id": "12706142",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-04-02 11:17:55",
      "description": "JR2 FileDataStore#inUseMap [1] is currently a synchronized map and that at times causes contention concurrent env. This map is used for supporting the Blob GC logic for JR2. \n\nWith Oak this map content is not used. As a fix we can either\n\n# Set inUseMap to a Guava Cache Map which has weak keys and value\n# Set inUseMap to a no op map where all put calls are ignored\n# Modify FDS to disable use of inUseMap or make {{usesIdentifier}} protected\n\n#3 would be a proper fix and #2 can be used as temp workaround untill FDS gets fixed\n\n[1] https://github.com/apache/jackrabbit/blob/trunk/jackrabbit-data/src/main/java/org/apache/jackrabbit/core/data/FileDataStore.java#L118",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "FileDataStore inUse map causes contention in concurrent env"
   },
   {
      "_id": "12705591",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-31 07:13:16",
      "description": "Currently when a checkpoint is created in DocumentNodeStore then it is saved in form of currentHeadRev=>expiryTime. Now if multiple checkpoints are created where head revision has not changed then only the last one would be saved and previous entries would be overridden as revision is used as key\n\nOne fix would be to change the expiry time only if the new expiry time is greater than previous entry. However doing that safely in a cluster (check then save) is currently not possible with DocumentStore API as the modCount check if only supported for Nodes.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Creating multiple checkpoint on same head revision overwrites previous entries"
   },
   {
      "_id": "12703715",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-26 13:15:19",
      "description": "Implement the {{noInternal}} flag that will be added with JCR-3759. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Implement noInternal from JackrabbitEventFilter"
   },
   {
      "_id": "12703438",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-25 12:08:32",
      "description": "Currently we log a warning when calling {{Event.getUserID()}}, {{Event.getUserData()}} or {{Event.getDate()}} without first checking whether the event is not external. However we should inhibit such warnings for the case where the filter already excludes external events. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Omit warnings about accessing commit related info when external events are excluded"
   },
   {
      "_id": "12702892",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-21 16:03:50",
      "description": "Fails frequently on my W7 desktop:\n\ntestCacheInvalidationHierarchicalNotExist(org.apache.jackrabbit.oak.plugins.document.mongo.CacheInvalidationIT)  Time elapsed: 0.04 sec  <<< FAILURE!\njava.lang.AssertionError\n        at org.junit.Assert.fail(Assert.java:92)\n        at org.junit.Assert.assertTrue(Assert.java:43)\n        at org.junit.Assert.assertTrue(Assert.java:54)\n        at org.apache.jackrabbit.oak.plugins.document.mongo.CacheInvalidationIT.testCacheInvalidationHierarchicalNotExist(CacheInvalidationIT.java:171)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.plugins.document.mongo.CacheInvalidationIT fails"
   },
   {
      "_id": "12702870",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-21 13:43:01",
      "description": "Add tests that test DS implementations directly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentStore-specific test framework"
   },
   {
      "_id": "12702434",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-19 17:42:06",
      "description": "Implement refined conflict resolution for addExistingNode conflicts as defined in the parent issue for the document NS.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DocumentNS: Implement refined conflict resolution for addExistingNode conflicts"
   },
   {
      "_id": "12702353",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-03-19 10:24:41",
      "description": "In OAK-1395 we added limits for long running queries. The limits can be changed with system properties, now we should make the settings changeable using OSGi",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "configuration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "OSGi Configuration for Query Limits"
   },
   {
      "_id": "12702110",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-03-18 10:19:10",
      "description": "{{NodeStore}} implementations should expose the {{RevisionGCMBean}} in order to be interoperable with {{RepositoryManagementMBean}}. See OAK-1160.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose RevisionGCMBean for supported NodeStores "
   },
   {
      "_id": "12702108",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2014-03-18 10:16:05",
      "description": "{{NodeStore}} implementations should expose the {{FileStoreBackupRestoreMBean}} in order to be interoperable with {{RepositoryManagementMBean}}. See OAK-1160.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose FileStoreBackupRestoreMBean for supported NodeStores"
   },
   {
      "_id": "12702101",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-18 09:42:17",
      "description": "The original BlobStore implementations support an additional contract, which is tested, but so far the applications can't rely on. The contract is that concatenating multiple blobIds is a valid blobId, and means the binaries are concatenated. The use cases are to support partial and concurrent uploads / transfers. Depending on the backend, this can speed up transfers quite a bit. Also, it allows new use cases, for example \"resume upload\" without having to re-upload or stream the existing binary. \n\nThe DataStore implementations don't support those use cases. Now, with the DataStoreBlobStore compatibility wrapper, this contract can't be supported by all BlobStore implementations. That's fine. However, the tests against the other BlobStores should still test this contract.\n\nI will add a new marker interface \"ChunkingBlobStore\" so the unit tests can verify the contract.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "api",
         "documentation",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Document and test additional BlobStore contracts"
   },
   {
      "_id": "12701867",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-17 10:53:23",
      "description": "{{MicroKernel.rebase}} says: \"addExistingNode: node has been added that is different from a node of them same name that has been added to the trunk.\"\n\nHowever, the {{NodeStore}} implementation\n# throws a {{CommitFailedException}} itself instead of annotating the conflict,\n# also treats the equal childs with the same name as a conflict. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency",
         "observation",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Incorrect handling of addExistingNode conflict in NodeStore"
   },
   {
      "_id": "12700973",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-12 13:53:09",
      "description": "I'm seeing this test fail consistently on our internal CI builds.\n\n_org.apache.jackrabbit.core.observation.ShareableNodesTest.testAddShareableMixin_:\nbq. Change processor already stopped\n\nStacktrace\n{code}\njava.lang.IllegalStateException: Change processor already stopped\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:150)\n\tat org.apache.jackrabbit.oak.jcr.observation.ChangeProcessor$RunningGuard.stop(ChangeProcessor.java:259)\n\tat org.apache.jackrabbit.oak.jcr.observation.ChangeProcessor.stop(ChangeProcessor.java:192)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationManagerImpl.stop(ObservationManagerImpl.java:267)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationManagerImpl.dispose(ObservationManagerImpl.java:117)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionContext.dispose(SessionContext.java:387)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl$10.perform(SessionImpl.java:465)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl$10.perform(SessionImpl.java:462)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:263)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.safePerform(SessionDelegate.java:306)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl.safePerform(SessionImpl.java:129)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl.logout(SessionImpl.java:462)\n\tat org.apache.jackrabbit.test.AbstractJCRTest.cleanUp(AbstractJCRTest.java:439)\n\tat org.apache.jackrabbit.test.AbstractJCRTest.tearDown(AbstractJCRTest.java:448)\n\tat org.apache.jackrabbit.test.api.observation.AbstractObservationTest.tearDown(AbstractObservationTest.java:67)\n\tat junit.framework.TestCase.runBare(TestCase.java:140)\n\tat junit.framework.TestResult$1.protect(TestResult.java:110)\n\tat junit.framework.TestResult.runProtected(TestResult.java:128)\n\tat junit.framework.TestResult.run(TestResult.java:113)\n\tat junit.framework.TestCase.run(TestCase.java:124)\n\tat org.apache.jackrabbit.test.AbstractJCRTest.run(AbstractJCRTest.java:464)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:243)\n\tat junit.framework.TestSuite.run(TestSuite.java:238)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:243)\n\tat org.apache.jackrabbit.test.ConcurrentTestSuite.access$001(ConcurrentTestSuite.java:29)\n\tat org.apache.jackrabbit.test.ConcurrentTestSuite$2.run(ConcurrentTestSuite.java:67)\n\tat EDU.oswego.cs.dl.util.concurrent.PooledExecutor$Worker.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ShareableNodesTest.testAddShareableMixin failures"
   },
   {
      "_id": "12699169",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-06 15:03:55",
      "description": "We should implement these monitoring for those MKs where it makes sense. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Implement low disk space and low memory monitoring"
   },
   {
      "_id": "12699101",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-03-06 09:29:55",
      "description": "The benchmark test fails when run concurrently in a cluster. Setting up the test content fails with a conflict. I assume this happens because nodes in the permission store are populated concurrently and may conflict.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Concurrent FlatTreeWithAceForSamePrincipalTest fails on Oak-Mongo"
   },
   {
      "_id": "12698876",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-03-05 14:25:05",
      "description": "For queries of type, the property index on jcr:primaryType is used, even if only a subset of all node types are indexed:\n\n{noformat}\n/jcr:root//element(*,rep:User)[xyz/@jcr:primaryType]\n{noformat}\n\nThe problem is that this index returns the wrong cost. It should return \"infinity\", because the index doesn't have enough data if not all node types and mixins are indexed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Property index on \"jcr:primaryType\" returns the wrong cost"
   },
   {
      "_id": "12698873",
      "assignee": "amitjain",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-05 14:15:03",
      "description": "Following the discussion on OAK-1339, the backup will be controlled from Mongo directly, but we still need to verify 2 things:\n - ongoing transactions will be discarded on restore, the head has to point to the latest stable revision\n - as an added benefit, the restore could happen to an older revision (see the sharded setup where a node can get ahead of the others between the moment the backup starts and when it will finish across the board)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Verify restore to revision on MongoNS"
   },
   {
      "_id": "12698610",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-03-04 11:13:04",
      "description": "{{ObservationTest}} fails often on some Windows machines:\n\n{noformat}\npathFilter[3](org.apache.jackrabbit.oak.jcr.observation.ObservationTest)  Time elapsed: 0.864 sec  <<< FAILURE!\njava.lang.AssertionError: Missing events: [path = /events/only/here/below/this, type = 1]\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationTest.pathFilter(ObservationTest.java:315)\n{noformat}\n\nand\n\n{noformat}\nfilterPropertyOfParent[2](org.apache.jackrabbit.oak.jcr.observation.ObservationTest)  Time elapsed: 0.88 sec  <<< FAILURE!\njava.lang.AssertionError: Missing events: [path = /test_node/a/jcr:primaryType, type = 4, path = /test_node/a/foo, type = 4, path = /test_node/a/b, type = 1]\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationTest.filterPropertyOfParent(ObservationTest.java:614)\n{noformat}\n\nI have the suspicion this is an issue with the test similar to OAK-1486",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ObservationTest failure on Windows"
   },
   {
      "_id": "12698426",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-03 13:57:15",
      "description": "{{BackgroundObserverTest.concurrentObservers}} occasionally fails for the Windows 7 CI build:\n\n{noformat}\nconcurrentObservers(org.apache.jackrabbit.oak.spi.commit.BackgroundObs)  Time elapsed: 5.058 sec  <<< FAILURE!\njava.lang.AssertionError\n\tat org.junit.Assert.fail(Assert.java:92)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.junit.Assert.assertTrue(Assert.java:54)\n\tat org.apache.jackrabbit.oak.spi.commit.BackgroundObserverTest.concurrentObservers(BackgroundObserverTest.java:62)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "BackgroundObserverTest occasionally failing"
   },
   {
      "_id": "12697726",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-02-27 15:25:45",
      "description": "While running Oak in a two node clutser following exception is seen. It basically comes because the AsynchUpdate tries to update async-status concurrently\n\n{noformat}\n27.11.2013 17:56:35.507 *ERROR* [pool-5-thread-1] org.apache.sling.commons.scheduler.impl.QuartzScheduler Exception during job execution of org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate@fcf98c2 : com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\ncom.google.common.util.concurrent.UncheckedExecutionException: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199) ~[na:na]\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:3932) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diff(MongoMK.java:165) ~[na:na]\n\tat org.apache.jackrabbit.oak.kernel.KernelNodeState.compareAgainstBaseState(KernelNodeState.java:481) ~[na:na]\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:52) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:103) ~[na:na]\n\tat org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105) ~[org.apache.sling.commons.scheduler:2.4.2]\n\tat org.quartz.core.JobRunShell.run(JobRunShell.java:207) [org.apache.sling.commons.scheduler:2.4.2]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_40]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_40]\n\tat java.lang.Thread.run(Thread.java:724) [na:1.7.0_40]\nCaused by: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199) ~[na:na]\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:3932) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.getNode(MongoNodeStore.java:507) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diffFewChildren(MongoMK.java:313) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diffImpl(MongoMK.java:229) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK$1.call(MongoMK.java:168) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK$1.call(MongoMK.java:165) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) ~[na:na]\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) ~[na:na]\n\t... 11 common frames omitted\nCaused by: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat org.apache.jackrabbit.oak.plugins.mongomk.util.MergeSortedIterators.fetchNextIterator(MergeSortedIterators.java:103) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.util.MergeSortedIterators.next(MergeSortedIterators.java:85) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.NodeDocument.getLatestValue(NodeDocument.java:1041) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.NodeDocument.getNodeAtRevision(NodeDocument.java:456) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.readNode(MongoNodeStore.java:653) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.access$000(MongoNodeStore.java:80) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore$2.call(MongoNodeStore.java:510) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore$2.call(MongoNodeStore.java:507) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) ~[na:na]\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) ~[na:na]\n\t... 23 common frames omitted\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cluster"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Failing test for MergeSortedIterators"
   },
   {
      "_id": "12696542",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-02-21 14:10:42",
      "description": "When moving a node many extra events are dispatched in OAK in compared to other implementations\n\nOn Oak a node added and node remove events are dispatched for each node in the hierarchy being moved.  As well there is a property add and property remove event dispatched for each property in the node hierarchy.  \n\nThis compares to previous implementations where only a Node Moved, node added and node removed event is dispatched for the parentnode being moved.\n\nSee [0] for an example.\n\nFor me this is problematic for a couple of reasons:\n\n1) We are dispatching more events than we did previously.  In cases where nodes are frequently moved this will add extra load on the system. \n2) It is becoming increasingly difficult to ignore events related to a move without spending extra cycles to make that determination. \n3) Many pre-existing event listeners will be executing on events that they previously would not have.\n\nI know the JCR spec indicates that an implementation may choose to dispatch these events or not, but I suggest we change OAK to not throw these extra events.  If we do not many observation listeners will act on events they previously did not will likely cause problems.\n\nAlso, if we could add a simple marker in any event\u2019s info map which is related to a node move (ie: the node removed, node added etc) it would be very helpful when trying to ignore events caused by a move.  (which I believe to be the case in many situations).\n\n[0] \nMove \u201cc\u201d in the hierarchy below from /a/b to /a/z:\n\n/a/b/c/d/e\nto:\n/a/z/c/d/e\n\nResults in:\n\nCRX2:\n/a/b, type: {node removed}\n/a/z/b, type: {node added}\n/a/z/b, type: {node moved}\n\nOAK:\n/a/b/c, type: {node removed}\n/a/z/c, type: {node moved}\n/a/z/c, type: {node added}\n/a/b/c/jcr:primaryType, type: {property removed}\n/a/b/c/jcr:createdBy, type: {property removed}\n/a/b/c/jcr:created, type: {property removed}\n/a/b/c/d, type: {node removed}\n/a/z/c/jcr:primaryType, type: {property added}\n/a/z/c/jcr:createdBy, type: {property added}\n/a/z/c/jcr:created, type: {property added}\n/a/z/c/d, type: {node added}\n/a/b/c/d/jcr:primaryType, type: {property removed}\n/a/b/c/d/jcr:createdBy, type: {property removed}\n/a/b/c/d/jcr:created, type: {property removed}\n/a/b/c/d/e, type: {node removed}\n/a/z/c/d/jcr:primaryType, type: {property added}\n/a/z/c/d/jcr:createdBy, type: {property added}\n/a/z/c/d/jcr:created, type: {property added}\n/a/z/c/d/e, type: {node added}\n/a/b/c/d/e/jcr:primaryType, type: {property removed}\n/a/b/c/d/e/jcr:createdBy, type: {property removed}\n/a/b/c/d/e/jcr:created, type: {property removed}\n/a/z/c/d/e/jcr:primaryType, type: {property added}\n/a/z/c/d/e/jcr:createdBy, type: {property added}\n/a/z/c/d/e/jcr:created, type: {property added}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Many extra events are dispatched from a move event"
   },
   {
      "_id": "12696536",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-02-21 13:53:37",
      "description": "Expose capability to purge JCR versions so that higher level apps can start a clean up.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JCR version purge"
   },
   {
      "_id": "12696534",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-02-21 13:49:13",
      "description": "For huge Oak repos it will be essential to re-index some or all indexes in case they go out of sync in a non-blocking way (i.e. the repo is still operation while the re-indexing takes place).\n\nFor an asynchronous index this should not be much of a problem. One could drop it and recreate (as an added benefit it might be nice if the user could simply add a property \"reindex\" to the index definition node to trigger this).\n\nFor synchronous indexes, I suggest the mechanism creates an asynchronous index behind the scenes first and once it has caught up\n* blocks writes (?)\n* removes the existing synchronous index\n* moves asynchronous index in its place and makes it synchronous",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Non-blocking reindexing"
   },
   {
      "_id": "12696532",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-02-21 13:42:25",
      "description": "For long child node lists it is much better (in terms of performance) to use a non-ordered node type. Unfortunately, nt:unstructured is ordered.\nWe should have a \"performance hint\" on this in the docs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "document oak:unstructured performance advantages"
   },
   {
      "_id": "12696529",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-02-21 13:40:13",
      "description": "It is an explicit design non-goal of Oak to support huge amounts of values in multi-valued properties. If a user still tries to create these we should at least throw a WARN in the logs to indicate that usage of MVPs is wrong.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "Warn on huge multi-valued properties"
   },
   {
      "_id": "12696515",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-02-21 12:27:40",
      "description": "For debugging slow queries we need a way to analyze: which indexes where used and why (what were the cost responses of the non-used indexes).\nThis is related to OAK-1217",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Expose query plans"
   },
   {
      "_id": "12696504",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-02-21 12:08:02",
      "description": "I think we should prepare for cases where the permission store (managed as a tree mirrored to the content tree) goes out of sync with the content tree for whatever reason.\n\nIdeally, that would be an online tool (maybe exposed via JMX) that goes back the MVCC revisions to find the offending commit (so that have a chance to reduce the number of such occurences) and fixes the inconsistency on head.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "production",
         "resilience",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Tool to detect and possibly fix permission store inconsistencies"
   },
   {
      "_id": "12696503",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-02-21 12:03:16",
      "description": "For cases where the document semantics in Mongo that are created by Oak get corrupted to a point that Oak does not come up anymore (but MongoDB is still available), we should have a mechanism to fix those inconsistencies.\n\nOf course, one could use Mongo tools like cmdline or MongoHub to manually go in, but an automated approach would be preferable in the medium term.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Offline tool to repair MongoMK documents"
   },
   {
      "_id": "12696502",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-02-21 11:55:53",
      "description": "We should have a tool to inspect and repair TarMK files in case the repository does not come up due to a corruption in the tar files.\n\nIdeally, the tool could be pointed to an existing backup and use the backup to fix broken binaries (that might have been erroneously been deleted by the DS GC).\n\nOnce we have the tool, we could automatically run it after backups and on the failover instance (OAK-1161)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline tool to repair TarMK"
   },
   {
      "_id": "12693122",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-02-04 15:24:49",
      "description": "Most recent test failure on buildbot http://ci.apache.org/builders/oak-trunk/builds/4290/steps/compile/logs/stdio says:\n\n{noformat}\nconcurrent[2](org.apache.jackrabbit.oak.jcr.ConcurrentFileOperationsTest)  Time elapsed: 1.69 sec  <<< ERROR!\njavax.jcr.InvalidItemStateException: OakState0001: Unresolved conflicts in /test-node/session-6\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Occasional ConcurrentFileOperationsTest failure"
   },
   {
      "_id": "12692131",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-01-29 20:32:24",
      "description": "As mentioned in OAK-1332, a case where a single session registers multiple observation listeners can be troublesome if events are delivered concurrently to all of those listeners, since in such a case the {{NamePathMapper}} and other session internals will likely suffer from lock contention.\n\nA good way to avoid this would be to have all the listeners registered within a single session be tied to a single {{Observer}} and thus processed sequentially.\n\nDoing so would also improve performance as the listeners could leverage the same content diff. As the listeners come from a single session and thus presumably from a single client, there's no need to worry about one client blocking the work of another.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Only one Observer per session"
   },
   {
      "_id": "12691621",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-01-28 11:51:42",
      "description": "{{DocumentNodeState#compareAgainstBaseState}} usually falls back to the default implementation in {{AbstractNodeState#compareAgainstBaseState(NodeState, NodeStateDiff)}}, which is slow. See also the TODO in the code. This negatively affects performance when generation observation events. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeState#compareAgainstBaseState too slow"
   },
   {
      "_id": "12691096",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-01-24 19:08:34",
      "description": "The problem is that the different stores have different transient space characteristics. for example the MongoMK is very slow when handling large saves.\n\nsuggest to expose a repository descriptor that can be used to estimate the preferred transient space, for example when importing content.\n\nso either a boolean like: \n  {{option.infinite.transientspace}}\n\nor a number like:\n  {{option.transientspace.preferred.size}}\n\nthe later would denote the average number of modified node states that should be put in the transient space before the persistence starts to degrade.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "api"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose the preferred transient space size as repository descriptor "
   },
   {
      "_id": "12689805",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-01-20 12:35:07",
      "description": "Implement repository statistics (TimeSeries) for those values it makes sense on Oak.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement RepositoryStatistics from Jackrabbit API"
   },
   {
      "_id": "12689255",
      "assignee": "stefan@jira",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-01-16 14:56:26",
      "description": "the javadoc of {{MicroKernel#read}} currently states that \n\n{quote}\nAn attempt is made to read as many as {{length}} bytes, but a smaller number may be read.\n{quote}\n\nunder what conditions a smaller amount might be read is not specified. \n\nwith the current specification an api consumer would either have to know the length of the blob in advance (i.e. by calling  {{MicroKernel#getLength}}) or  would need to call the {{MicroKernel#read}} method twice to make sure that the blob content is fully read. \n\ni suggest to clarify the contract as follows:\n\nReads up to {{length}} bytes of data from the specified blob into the given array of bytes where the actual number of bytes read is {{min(length, max(0, blobLength - pos))}}.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MicroKernel API: clarify semantics of `read` method"
   },
   {
      "_id": "12688733",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-01-14 13:21:44",
      "description": "As discussed with Chetan offline we'd like to reduce the number of calls to MongoDB when content is added to the repository with a filevault package import.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce calls to MongoDB"
   },
   {
      "_id": "12688013",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2014-01-09 07:55:27",
      "description": "For very fine grained content with many nodes and only few properties per node it would be more efficient to bundle multiple nodes into a single MongoDB document. Mostly reading would benefit because there are less roundtrips to the backend. At the same time storage footprint would be lower because metadata overhead is per document.\n\nFeature branch - https://github.com/chetanmeh/jackrabbit-oak/compare/trunk...chetanmeh:OAK-1312\n\n*Feature Docs* - http://jackrabbit.apache.org/oak/docs/nodestore/document/node-bundling.html",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bundle nodes into a document"
   },
   {
      "_id": "12684964",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-12-16 14:30:35",
      "description": "This happened while running the maven build with {{-PintegrationTesting}}:\n\n{code}\nRunning org.apache.jackrabbit.oak.jcr.random.RandomizedReadTest\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.418 sec\norg.apache.maven.surefire.util.SurefireReflectionException: java.lang.reflect.InvocationTargetException; nested exception is java.lang.reflect.InvocationTargetException: null\njava.lang.reflect.InvocationTargetException\nException in thread \"main\" java.lang.OutOfMemoryError: PermGen space\n\nResults :\n\nTests run: 722, Failures: 0, Errors: 0, Skipped: 48\n{code}\n\nThe crucial point being Surefire silently ignoring the following tests such that the build happily succeeds making following failures. Note, that test suite consists of  2003 tests in contrast to the 722 reported by Surefire. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RandomizedReadTest fails with OutOfMemoryError: PermGen space"
   },
   {
      "_id": "12684921",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-12-16 11:03:06",
      "description": "The contract for {{ObservationManager#removeEventListener}} mandates: \"A listener may be deregistered while it is being executed. The deregistration method will block until the listener has completed executing.\"\n\nHowever a strict implementation of this contract is prone to deadlocks: clients unregistering event listeners need to take care not to hold a lock that is also acquired from the event listener being unregistered as this will lead to a deadlock\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ObservationManager#removeEventListener prone to deadlocks "
   },
   {
      "_id": "12684481",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-12-13 16:10:59",
      "description": "[~fmeschbe] had a look at the oak api and spotted the following problem:\n\nRoot#commit(String, CommitHook)\n\nBut the CommitHook interface is not part of the OAK API. we quickly searched for usages and found that this is only used for the Item#save case in oak-jcr to assert that the set of modifications is contained with the subtree defined by the specified target item.\n\nIMO we should get rid of the flavour of Root#commit again and solve the Item-save issue differently. For example we could change it to Root#commit(String, String absPath) where the absPath would be the path of the target item...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "api"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Root.commit(String, CommitHook) : CommitHook is not part of oak-api"
   },
   {
      "_id": "12684290",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-12-12 15:33:40",
      "description": "The tests take a very long time to complete on my machine. Most likely this is also the case on travis and the reason why recent builds time out.\n\nI'll attach a failsafe report.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TCK tests slow on SegmentMK+Mongo"
   },
   {
      "_id": "12684282",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-12-12 15:21:31",
      "description": "There are various overlapping RepositoryStub classes that need some clean up.\n\nA while ago we decided to switch to Oak+TarMK as default TCK setup. The TCK configuration still points to OakRepositoryStub, which is derived from OakRepositoryStubBase. In OAK-1207 we changed OakRepositoryStubBase to use the TarMK. This duplicates code in OakTarMKRepositoryStub.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Clean up RepositoryStub classes"
   },
   {
      "_id": "12682951",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-12-05 17:29:06",
      "description": "Failed tests:   observation[2](org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest): added nodes expected:<1000> but was:<442>\n\nTests run: 4, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 106.957 sec <<< FAILURE!\nobservation[3](org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest)  Time elapsed: 53.047 sec  <<< FAILURE!\njava.lang.AssertionError: added nodes expected:<1000> but was:<906>\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.failNotEquals(Assert.java:647)\n\tat org.junit.Assert.assertEquals(Assert.java:128)\n\tat org.junit.Assert.assertEquals(Assert.java:472)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest.observation(ObservationRefreshTest.java:119)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\n\tat org.junit.runners.Suite.runChild(Suite.java:24)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\n\tat java.lang.Thread.run(Thread.java:695)\nobservation[2](org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest)  Time elapsed: 58.379 sec  <<< FAILURE!\njava.lang.AssertionError: added nodes expected:<1000> but was:<396>\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.failNotEquals(Assert.java:647)\n\tat org.junit.Assert.assertEquals(Assert.java:128)\n\tat org.junit.Assert.assertEquals(Assert.java:472)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest.observation(ObservationRefreshTest.java:119)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\n\tat org.junit.runners.Suite.runChild(Suite.java:24)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\n\tat java.lang.Thread.run(Thread.java:695)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Failure in ObservationRefreshTest "
   },
   {
      "_id": "12682124",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-12-02 12:30:23",
      "description": "Currently the {{AsynchIndexUpdate }} job which performs the indexing in background is run on every node in a cluster. This at times causes commit failures when running Oak in a cluster using Mongo MK. As merging of indexed content say Lucene is tricky to implement it would be better to restrict this job to run as a singleton in a cluster\n\nSee http://markmail.org/thread/qff2fj7nqtbuhr4i for more discussion",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cluster"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make AsynchIndexUpdate task to run only on a single node in a cluster"
   },
   {
      "_id": "12681562",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2013-11-27 12:45:23",
      "description": "While running Oak in a two node clutser following exception is seen. It basically comes because the AsynchUpdate tries to update async-status concurrently\n\n{noformat}\n27.11.2013 17:56:35.507 *ERROR* [pool-5-thread-1] org.apache.sling.commons.scheduler.impl.QuartzScheduler Exception during job execution of org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate@fcf98c2 : com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\ncom.google.common.util.concurrent.UncheckedExecutionException: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199) ~[na:na]\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:3932) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diff(MongoMK.java:165) ~[na:na]\n\tat org.apache.jackrabbit.oak.kernel.KernelNodeState.compareAgainstBaseState(KernelNodeState.java:481) ~[na:na]\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:52) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:103) ~[na:na]\n\tat org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105) ~[org.apache.sling.commons.scheduler:2.4.2]\n\tat org.quartz.core.JobRunShell.run(JobRunShell.java:207) [org.apache.sling.commons.scheduler:2.4.2]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_40]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_40]\n\tat java.lang.Thread.run(Thread.java:724) [na:1.7.0_40]\nCaused by: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199) ~[na:na]\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:3932) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.getNode(MongoNodeStore.java:507) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diffFewChildren(MongoMK.java:313) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diffImpl(MongoMK.java:229) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK$1.call(MongoMK.java:168) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK$1.call(MongoMK.java:165) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) ~[na:na]\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) ~[na:na]\n\t... 11 common frames omitted\nCaused by: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat org.apache.jackrabbit.oak.plugins.mongomk.util.MergeSortedIterators.fetchNextIterator(MergeSortedIterators.java:103) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.util.MergeSortedIterators.next(MergeSortedIterators.java:85) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.NodeDocument.getLatestValue(NodeDocument.java:1041) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.NodeDocument.getNodeAtRevision(NodeDocument.java:456) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.readNode(MongoNodeStore.java:653) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.access$000(MongoNodeStore.java:80) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore$2.call(MongoNodeStore.java:510) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore$2.call(MongoNodeStore.java:507) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) ~[na:na]\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) ~[na:na]\n\t... 23 common frames omitted\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cluster"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "IllegalStateException in MergeSortedIterators"
   },
   {
      "_id": "12681420",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-11-26 21:39:31",
      "description": "Following up from OAK-928 and OAK-948 to clarify the interesting case of updates that set a property (or a broader subtree of content) to the exact same value that it used to have.\n\nSince such \"touching\" of content results in an empty content diff, the {{PermissionValidator}} doesn't get invoked and thus write access controls are not checked. Additionally (as reported in OAK-948) no observation events get sent for such updates. This seems like a reasonable thing to do, as if nothing changes there should be no need to check for write access or to inform observation listeners.\n\nHowever, OAK-928 makes this case trickier, as it opens a possibility to use brute force to circumvent read access controls for certain kinds of content. For example, if an attacker knows (or can guess) the existence of a certain read/write-protected property (e.g. some sensitive configuration setting), it's possible to repeatedly try to update that property with different likely values. Normally the update would fail with an exception because of the write protection, but when the attempted  update matches the stored value there would be no exception because no change gets detected. At that point the attacker would know what the stored value is!\n\nThe above scenario is somewhat artificial as it only works for highly specific cases, so I'm not sure how important it is for us to address this case at the repository level.\n\nIf we don't address this then a simple workaround for security-sensitive content would be to deny read access to the whole containing node and add a property containing a random value along the sensitive information. That would make it impossible for the attacker to use this mechanism to guess the sensitive bits, as they'd also need to guess what the random value is.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Write access control of \"touched\" content"
   },
   {
      "_id": "12680757",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2013-11-22 14:16:31",
      "description": "The JMX bindings for {{QueryStat}} are available in Jackrabbit, but not in Oak. Having support for this in Oak would make it easy to identify long running queries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "support for QueryStat MBean"
   },
   {
      "_id": "12679183",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2013-11-14 09:15:19",
      "description": "Conflict handling is mostly implemented in MongoMK but it does not yet annotate conflicts on rebase.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore: annotate conflicts"
   },
   {
      "_id": "12678986",
      "assignee": "anchela",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-11-13 10:34:12",
      "description": "see http://markmail.org/message/5ivmvhi7jbuo3jp6 for the initial request for discussion.\n\nbiggest pain points from a security perspective:\n\n- missing protection or concept for protection in a default setup\n- location of the index definitions\n- node types of the nodes associated with index definitions and index content",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "security"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Security Concerns wrt Index Definitions"
   },
   {
      "_id": "12678216",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2013-11-08 12:45:14",
      "description": "Could we add generic (i.e. MK independent) interfaces that can be used by higher levels to trigger certain ops tasks? The the application could decide when would be a good time to run them.\nI am thinking especially about backup/restore (OAK-1158), MVCC revision cleanup (OAK-1158) and DSGC (OAK-377)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Generic interfaces for operation tasks"
   },
   {
      "_id": "12676732",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-10-30 22:30:24",
      "description": "Oak should provide an *extended and efficient JCR observation listener* mechanism to support common use cases not handled well by the restricted options of the JCR observation (only base path, node types and raw events). Those cases require listeners to register much more broadly and then filter out their specific cases themselves, thus putting too many events into the observation system and creating a huge overhead due to asynchronous access to the modified JCR data to do the filtering. This easily is a big performance bottleneck with many writes and thus many events.\n\nPrevious discussions [on the list|http://markmail.org/message/oyq7fnfrveceemoh] and in OAK-1120, and [latest discussion on the list|http://markmail.org/message/x2l6tv4m7bxjzqqq].\n\nThe goals should be:\n* performance: handle filtering as early as possible, during the commit, where access to the modified data is already present\n* provide robust implementation for typical filtering cases\n* provide an asynchronous listener mechanism as in JCR\n* minimize effect on the lower levels on Oak (a visible addition in oak-commons or oak-jcr should be enough)\n* for delete events, allow filtering on the to-be-deleted data (currently not possible in jcr listeners that run after the fact)\n* ignore external cluster events by default; have an extra option if you really want to register for external events\n* if possible: design as an extension of the jcr observation to simplify migration for existing code\n* if possible: provide an intelligent listener that can work with pure JCR (aka Jackrabbit 2) as well, by falling back to in-listener-filtering\n* maybe: synchronous option using the same simple interface (instead of raw Oak plugins itself); however, not sure if there is a benefit if they can only read data and not change or block the session commit\n\nTypical filtering cases:\n- paths with globbing support (for example /content/foo/*/something)\n- check for property values (equal, not equal, contains etc.), most importantly\nsling:resourceType in Sling apps\n- allow to check properties on child nodes as well, typically jcr:content\n- check for any parent/ancestor as well (e.g. change deep inside a node type = foo structure should be triggered, even if the node with the type wasn't modified; very important to support efficiently)\n- node types (already in jcr observation)\n- created/modified/deleted events, separate from move/copy\n- and more... a custom filter should be possible to pass through (with similar access as the {{Observer}})",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation listener PLUS"
   },
   {
      "_id": "12675263",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-10-23 14:44:50",
      "description": "As discussed in http://markmail.org/message/otpckosnwfzjvqoj, it should be possible to deliver observation events from local commits immediately instead of waiting for the default one-second polling delay.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Immediate delivery of events from local commits "
   },
   {
      "_id": "12675262",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-10-23 14:42:53",
      "description": "With the new CommitInfo mechanism it should be possible to pass user data along with local commits.\n\nThe current user data implementation in ObservationManagerImpl is incorrect, as it just attaches the given user data to any events delivered to that session instead of attaching it to the commits done by that session.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support user data in local events"
   },
   {
      "_id": "12672808",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320828",
            "id": "12320828",
            "name": "security",
            "description": "Vulnerabilities and Security Issues"
         }
      ],
      "created": "2013-10-08 12:57:15",
      "description": "The scenario is bit complex. Running a query with following condition does not give any result\n\n*  Node path is like {{/home/users/geometrixx-outdoors/emily.andrews@mailinator.com/social/relationships/following/aaron.mcdonald@mailinator.com}}\n* It has a Glob jcr:read for everyone at {{\\*/social/relationships/following/\\*}}\n* The query is like \nbq. /jcr:root/home//social/relationships/following//*[id='aaron.mcdonald@mailinator.com']\n* The query is executed with anonymous session\n\nOn JR2 it returns expected result while on Oak it does not give any result",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compatibility"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Query with descendent node and access control fails to return result"
   },
   {
      "_id": "12671609",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-10-01 16:19:55",
      "description": "Currently external events are only reported along with local changes. That is, when local changes are persisted external changes are detected and reported along with the local changes. This might cause external events to be delayed indefinitely on cluster nodes without writes. \n\nWe might want to implement a solution that regularly polls for external events. \nSee OAK-1055 for why a previous implementation didn't work. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Periodically poll for external events"
   },
   {
      "_id": "12671374",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-09-30 14:49:11",
      "description": "The test occasionally fails with\n{code}\nFailed tests:\nobservation[1](org.apache.jackrabbit.oak.jcr.observation.ObservationTest):\nUnexpected events: [EventImpl{type=8, jcrPath='/test_node/property',\nuserID='oak:unknown', identifier='/test_node', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=16,\njcrPath='/test_node/n1/p1', userID='oak:unknown',\nidentifier='/test_node/n1', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=4, jcrPath='/test_node/n1/p2',\nuserID='oak:unknown', identifier='/test_node/n1', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=2, jcrPath='/test_node/n3',\nuserID='oak:unknown', identifier='/test_node/n3', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=8,\njcrPath='/test_node/n3/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/n3', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=8, jcrPath='/test_node/n3/p3',\nuserID='oak:unknown', identifier='/test_node/n3', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=2, jcrPath='/test_node/{4}',\nuserID='oak:unknown', identifier='/test_node/{4}', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=8,\njcrPath='/test_node/{4}/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/{4}', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=1, jcrPath='/test_node/n2',\nuserID='oak:unknown', identifier='/test_node/n2', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=4,\njcrPath='/test_node/n2/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/n2', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=4, jcrPath='/test_node/property',\nuserID='oak:unknown', identifier='/test_node', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=16,\njcrPath='/test_node/n1/p1', userID='oak:unknown',\nidentifier='/test_node/n1', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=8, jcrPath='/test_node/n1/p2',\nuserID='oak:unknown', identifier='/test_node/n1', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=2, jcrPath='/test_node/n2',\nuserID='oak:unknown', identifier='/test_node/n2', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=8,\njcrPath='/test_node/n2/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/n2', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=1, jcrPath='/test_node/n3',\nuserID='oak:unknown', identifier='/test_node/n3', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=4,\njcrPath='/test_node/n3/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/n3', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=4, jcrPath='/test_node/n3/p3',\nuserID='oak:unknown', identifier='/test_node/n3', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=1, jcrPath='/test_node/{4}',\nuserID='oak:unknown', identifier='/test_node/{4}', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=4,\njcrPath='/test_node/{4}/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/{4}', info={}, date=0, userData=null,\nexternal=true}]\n{code}\n\nAs [noted before | http://markmail.org/message/lk3vrrcn5edib73d]  having {{external=true}} and also the event types indicate that the events are being seen \"in reverse\" (i.e. reverse diffing of the node states involved). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Occasional test failure in ObservationTest.observation()"
   },
   {
      "_id": "12669503",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-09-19 18:14:28",
      "description": "Many places especially in the security code use String arrays as an intermediate representation for multivalued name and string properties. Unfortunately this practice leads to quite a bit of extra memory allocation and extra work in performance-critical places like AC evaluation.\n\nFor example, a significant percentage of the time in the SetProperty benchmark goes to PrivilegeUtil.readDefinitions(), just because of the array conversion that requires a number of extra object allocations and at least two extra iterations over the relevant value strings.\n\nThat extra work could be avoided in readDefinitions() and other similar places if the Iterable<String> return type of PropertyState.getValues() was used directly instead of a String array.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid turning multivalued properties to String arrays"
   },
   {
      "_id": "12668260",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-09-12 14:20:44",
      "description": "As Jukka [mentioned | https://issues.apache.org/jira/browse/OAK-978?focusedCommentId=13751242&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13751242] on OAK-978, is often on the critical path and the changes done there had a bad impact on performance:\n\n{code}\nApache Jackrabbit Oak\n# ReadPropertyTest               min     10%     50%     90%     max       N\nJackrabbit                         4       5       5       6      14   11287\nOak-Tar                           14      15      16      16      27    3855\n{code}\n\nUntil we are able to come up with a better solution that separates parsing from name mapping, I suggest to use the following heuristic to shortcut path parsing: shortcut iff the JCR path does not start with a dot, does not contain any of {}[]/ and if it contains a colon the session does not have local re-mappings.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimise path parsing"
   },
   {
      "_id": "12663170",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2013-08-12 08:49:06",
      "description": "Example query:\n{code}\nSELECT a.* \nFROM [nt:unstructured] AS a \nINNER JOIN [nt:unstructured] AS b \nON b.[jcr:uuid] = a.testref \nWHERE a.type = 'child' \nAND (CONTAINS(a.*, 'testJoinWithOR4') OR b.type = 'parent' AND CONTAINS(b.*, 'testJoinWithOR4'))\n{code}\n\nI'm not sure why this happens, but I noticed stepping through the code that the filter generated on the query doesn't contain any fulltext constraints. It does however contain the 'type' info which will trick the query engine into picking a property index, failing the test because is returns more results than it should.\n\nSee failing tests on the lucene module:\n - org.apache.jackrabbit.core.query.JoinTest#testJoinWithOR4\n - org.apache.jackrabbit.core.query.JoinTest#testJoinWithOR5",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Query: Filter doesn't contain fulltext constraints from joins "
   },
   {
      "_id": "12662067",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-08-06 08:31:18",
      "description": "Create JMX MBean to track Session and session related information:\n\n* stack trace from where the session has been acquired,\n* age of the session,\n* last (read/write) access to the session,\n* last refresh of the session,\n* conflict information (e.g. unresolved conflicts),\n* session attributes,\n* ...\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MBean to track sessions"
   },
   {
      "_id": "12660929",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2013-07-31 16:11:20",
      "description": "This issue covers 2 different changes related to the way the QueryEngine selects a query index:\n\n Firstly there could be a way to end the index selection process early via a known constant value: if an index returns a known value token (like -1000) then the query engine would effectively stop iterating through the existing index impls and use that index directly.\n\n Secondly it would be nice to be able to specify a desired index (if one is known to perform better) thus skipping the existing selection mechanism (cost calculation and comparison). This could be done via certain query hints [0].\n\n\n[0] http://en.wikipedia.org/wiki/Hint_(SQL)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_6",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Query engine index selection tweaks: shortcut and hint"
   },
   {
      "_id": "12659287",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-07-23 08:55:00",
      "description": "Chetan discovered that in some cases spurious observation events would be created when to sessions save concurrently. In a nutshell the problem occurs since the current implementation of observation expects a linear sequence of revisions (per cluster node). However on Root.commit there is a small race between rebasing and merging a branch: when another session saves inside this time frame, its branch will have the same base revision like that of the former session. In this case the sequence of revisions is effectively non linear.\n\nFull discussion: http://markmail.org/message/cbzrztagurplxo4r",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Concurrent commits may cause duplicate observation events"
   },
   {
      "_id": "12659063",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-07-22 11:13:31",
      "description": "The current namespace handling code does a lot of repetitive work, which shows up in hotspots like XML imports and Sling's namespace mapping code.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize namespace lookups"
   },
   {
      "_id": "12657954",
      "assignee": "alex.parvulescu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-07-16 09:06:17",
      "description": "Similar to OAK-237, I'd like to import the existing Observation tests from Jackrabbit and run them against an Oak repository",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Run Jackrabbit Observation tests"
   },
   {
      "_id": "12653704",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-06-19 13:45:39",
      "description": "Creating observation events is much more expensive when a transaction is broken down through intermediate save calls compared to only having a single save call. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Generating observation events takes too long when intermediate save calls are involved"
   },
   {
      "_id": "12653663",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-06-19 08:07:42",
      "description": "The TarMK fails to properly reopen a repository if its size is more than 256MB and the last entry in a data tar file isn't aligned at the end of the file. This can happen for example if a large transaction or binary is being persisted across tar file boundaries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentMK: File backend restart problem due to missing padding"
   },
   {
      "_id": "12652344",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-06-12 08:57:40",
      "description": "Observation listeners (OAK-144) might create backward compatibility issues. To ease the transition we should provide useful information about registered listeners e.g.:\n* Number of listeners\n* Session (user) a listener belongs to\n* Filter set for the listener\n* Number of events fired\n* Last couple of events fired\n* Size of pending queue\n* ...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Mangement info and statistics for observation listeners"
   },
   {
      "_id": "12652343",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-06-12 08:50:15",
      "description": "We should come up with a way to expose repository management information and statistics. See JCR-2936 plus subtasks and JCR-3243 for how this is done in Jackrabbit 2. See [this discussion | http://apache-sling.73963.n3.nabble.com/Monitoring-and-Statistics-td4021905.html] for an alternative proposal.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose repository management data and statistics"
   },
   {
      "_id": "12652187",
      "assignee": "chetanm",
      "components": [],
      "created": "2013-06-11 09:37:58",
      "description": "To get a better picture around the usage of cache it would be helpful to enable the [statistics|http://code.google.com/p/guava-libraries/wiki/CachesExplained#Statistics] for various caches used in Oak\n\n{code:java}\nnodeCache = CacheBuilder.newBuilder()\n                        .weigher(...)\n                        .maximumWeight(...)\n                        .recordStats()\n                        .build();\n{code}\n\nOnce enabled it allows to get stats like below\n{noformat}\nCacheStats{hitCount=763322, missCount=51333, loadSuccessCount=0, loadExceptionCount=0, totalLoadTime=0, evictionCount=3496}\n{noformat}\n\nAs stats collection adds a very minor overhead we can look into making this setting configurable. \n\nUntill we expose the stats via JMX one can extract the value in Sling env via approach mentioned in [this gist|https://gist.github.com/chetanmeh/5748650]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable stats for various caches used in Oak by default"
   },
   {
      "_id": "12645620",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-05-01 09:54:53",
      "description": "It would be useful to have a JMX MBean (or something similar) that kept track of and exposed information about all registered JCR observation listeners. The tracked information should include things like where the listener was registered (stack trace), what filter settings are used, and whether the listener is using methods like isExternal() or getUserID().",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MBean to track observation listeners"
   },
   {
      "_id": "12643898",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-04-22 09:20:26",
      "description": "The SegmentMK now has two backends: one in-memory and the other based on MongoDB. Since MongoDB isn't readily available everywhere and the in-memory backend obviously isn't suited for production use, it would be useful to have an additional SegmentMK backend based on just the local file system.\n\nInspired by, though not directly based on, the proprietary TarPM in CRX, I propose to implement such a backend using the tar file format as the basis.\n\nUnlike the MongoDB backend or the original TarPM, such a \"TarMK\" backend would be designed primarily for optimum performance on a *single-node* deployment, i.e. without support for clustering. A typical deployment could be replicated set of independent copies of a repository, designed for massively parallel read-only or mostly-read workloads.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "File backend for the SegmentMK"
   },
   {
      "_id": "12642260",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-04-12 15:44:22",
      "description": "As [discussed | http://markmail.org/message/6bqycmx6vbq7m25c] we might want look into implementing an alternative approach to observation, which trades some scalability for improved backward compatibility. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement backward compatible observation"
   },
   {
      "_id": "12639538",
      "assignee": "teofili",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2013-03-28 09:56:09",
      "description": "This patch fixes the errors occurred while executing the test",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "oak",
         "solr",
         "test",
         "unit-test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Fix sql2 test errors"
   },
   {
      "_id": "12637752",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-03-19 12:50:17",
      "description": "Many transient modifications require access to relevant node type information. These accesses should be optimized as they currently add significant overhead.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize access to node type information"
   },
   {
      "_id": "12637725",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-03-19 09:00:29",
      "description": "Apache Sling uses Session.getNamespacePrefixes() quite often. E.g. when reading content through a JcrPropertyMap:\n\n{code}\n   java.lang.Thread.State: RUNNABLE\n        at java.util.HashMap.put(HashMap.java:372)\n        at org.apache.jackrabbit.oak.plugins.name.Namespaces.getNamespaceMap(Namespaces.java:64)\n        at org.apache.jackrabbit.oak.plugins.name.ReadOnlyNamespaceRegistry.getPrefix(ReadOnlyNamespaceRegistry.java:116)\n        at org.apache.jackrabbit.oak.jcr.SessionImpl.getNamespacePrefix(SessionImpl.java:529)\n        - locked <0x00000007daf6c590> (a java.util.HashMap)\n        at org.apache.jackrabbit.oak.jcr.SessionImpl.getNamespacePrefixes(SessionImpl.java:495)\n        at org.apache.sling.jcr.resource.JcrPropertyMap.escapeKeyName(JcrPropertyMap.java:381)\n        at org.apache.sling.jcr.resource.JcrPropertyMap.read(JcrPropertyMap.java:344)\n        at org.apache.sling.jcr.resource.JcrPropertyMap.get(JcrPropertyMap.java:126)\n        at org.apache.sling.jcr.resource.JcrPropertyMap.get(JcrPropertyMap.java:147)\n{code}\n\nI'd like to optimize the case when there are not session re-mapped namespaces. In this case the prefixes can be returned from the namespace registry as is. This avoids the loop and reduces calls on the Oak API. Initial testing shows a performance improvement by a factor of 3.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimize Session.getNamespacePrefixes()"
   },
   {
      "_id": "12635546",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-03-06 10:46:34",
      "description": "Because there is no user id passed on to the events generated by the _ChangeProcessor_, the sling EventListener throws a bunch of NPEs when it receives the events.\n\n{code}\n06.03.2013 11:33:13.866 *ERROR* [pool-4-thread-1] org.apache.jackrabbit.oak.plugins.observation.ChangeProcessor Unable to generate or send events java.lang.NullPointerException\nat java.util.Hashtable.put(Hashtable.java:394)\nat org.apache.sling.jcr.resource.internal.JcrResourceListener.sendOsgiEvent(JcrResourceListener.java:298)\nat org.apache.sling.jcr.resource.internal.JcrResourceListener.onEvent(JcrResourceListener.java:218)\nat org.apache.jackrabbit.oak.plugins.observation.ChangeProcessor$EventGeneratingNodeStateDiff.sendEvents(ChangeProcessor.java:154)\nat org.apache.jackrabbit.oak.plugins.observation.ChangeProcessor.run(ChangeProcessor.java:117)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\nat java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:317)\nat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:150)\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:98)\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.runPeriodic(ScheduledThreadPoolExecutor.java:180)\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:204)\nat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\nat java.lang.Thread.run(Thread.java:662)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation generates NPE in an existing EventListener"
   },
   {
      "_id": "12635349",
      "assignee": "mduerig",
      "components": [],
      "created": "2013-03-05 15:00:56",
      "description": "Currently {{TreeImpl.getBaseState()}} calculates the base state of the tree on the fly on each call. As it turns out this method ends up being called by nearly every JCR method call. As recalculation is somewhat expensive since it recursively needs to calculate the base states of all parent trees, an optimisation would be to pre calculate the base state on instance creation.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimise TreeImpl.getBaseState() "
   },
   {
      "_id": "12624464",
      "assignee": "stefan@jira",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-12-18 13:25:36",
      "description": "As discussed on the list [1] the journal might be inconsistent when merges are involved. \n\n[1] http://markmail.org/message/4xwfwbax3kpoysbp",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Inconsistent journal with concurrent updates"
   },
   {
      "_id": "12616917",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2012-11-20 11:27:02",
      "description": "The oak-mongomk bundle currently exports couple of packages which are not required to be exported. These exports should be removed",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove exported packages from Mongo MK Bundle"
   },
   {
      "_id": "12613758",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2012-10-27 13:36:16",
      "description": "Currently the OSGi related dependencies org.osgi.core and org.osgi.compendium are marked as optional. Due to this packages under org.osgi.* are marked as optional which is not correct. \n\nAs such dependencies are already marked as provided scope they would not be included as part of transient dependencies. For more details refer to [1]\n\nFix: The optional flag should be removed\n\n[1] http://markmail.org/thread/njukyten6fdipts3",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "OSGi related dependencies should be set to provided scoped and not marked as optional"
   },
   {
      "_id": "12612238",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2012-10-17 15:23:31",
      "description": "Queries can potentially run for a very long time. I suggest we provide a way to list the running queries, and to cancel them using JMX.\n\nSee also http://java.net/jira/browse/JSR_333-49",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "JMX service to configure auto-cancel or long running queries"
   },
   {
      "_id": "12610547",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2012-10-05 11:55:43",
      "description": "Need to convert the oak-mongomk module to an OSGi bundle and expose the MongoMicroKernel as OSGi service",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MongoDB microkernal integration with OSGi"
   },
   {
      "_id": "12608413",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2012-09-20 09:44:35",
      "description": "Test class DerefTest.\n\nFor now there are just parse exceptions:\n{noformat}\njavax.jcr.query.InvalidQueryException: java.text.ParseException: Query:\ntestroot/people/jcr:deref((*)@worksfor, '*'); expected: <end>\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Deref (jcr:deref) support"
   },
   {
      "_id": "12607710",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2012-09-14 20:40:16",
      "description": "As discussed on oak-dev@ (http://markmail.org/message/e2pzcdtrxv7aqd6f), a designer at Adobe has contributed an updated site layout for us.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "Website",
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Updated Oak site layout"
   },
   {
      "_id": "12603988",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2012-08-19 17:33:25",
      "description": "At times Repository login fails because the LoginModule cannot be instantiated \n\n{noformat}\nCaused by: javax.jcr.LoginException: unable to find LoginModule class: org.apache.jackrabbit.oak.security.authentication.LoginModuleImpl\n\tat org.apache.jackrabbit.oak.jcr.RepositoryImpl.login(RepositoryImpl.java:139)\n\tat org.apache.jackrabbit.oak.jcr.SessionImpl.impersonate(SessionImpl.java:114)\n\tat org.apache.sling.jcr.base.SessionProxyHandler$SessionProxyInvocationHandler.invoke(SessionProxyHandler.java:101)\n\tat $Proxy9.impersonate(Unknown Source)\n\tat org.apache.sling.jcr.davex.impl.servlets.SlingDavExServlet$1.getLongLivedSession(SlingDavExServlet.java:206)\n\n{noformat}\n\nAs a fix LoginContextProviderImpl should switch the Thread's context classloader (TCCL) to oak-jcr bundle's classloader so that required loginmodule class can be instantiated",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "osgi",
         "sling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JAAS Authentication failing in OSGi env due to classloading issue"
   },
   {
      "_id": "12603584",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-08-15 13:42:24",
      "description": "MicroKernelService currently uses @Component annotation without enabling metatype. If metatype is enabled it would simply the configuration of home directory. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MicroKernelService should set metatype to true to easier configuration"
   },
   {
      "_id": "12603581",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-08-15 13:34:53",
      "description": "The oak-mk bundle depends on H2 database. It internally uses Class.forName('org.h2.Driver\") to load the H2 driver. Due to usage of Class.forName Bnd is not able to add org.h2 package to Import-Package list. So it should have an explicit entry in the maven-bundle-plugin config as shown below\n\n{code:xml}\n<Import-Package>\n  org.h2;resolution:=optional,\n  *\n</Import-Package>\n{code}\n\nWithout this MicroKernalService loading would fail with a CNFE",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add import for org.h2 in oak-mk bundle"
   },
   {
      "_id": "12601231",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2012-08-02 15:22:25",
      "description": "The Sling I18N component issues XPath queries like the following:\n\n{code:none}\n//element(*,mix:language)[fn:lower-case(@jcr:language)='en']//element(*,sling:Message)[@sling:message]/(@sling:key|@sling:message)\n{code}\n\nSuch queries currently fail with the following exception:\n\n{code:none}\njavax.jcr.query.InvalidQueryException: java.text.ParseException: Query: //element(*,mix:language)[fn:lower-(*)case(@jcr:language)='en']//element(*,sling:Message)[@sling:message]/(@sling:key|@sling:message); expected: (\n        at org.apache.jackrabbit.oak.jcr.query.QueryManagerImpl.executeQuery(QueryManagerImpl.java:115)\n        at org.apache.jackrabbit.oak.jcr.query.QueryImpl.execute(QueryImpl.java:85)\n        at org.apache.sling.jcr.resource.JcrResourceUtil.query(JcrResourceUtil.java:52)\n        at org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProvider.queryResources(JcrResourceProvider.java:262)\n        ... 54 more\nCaused by: java.text.ParseException: Query: //element(*,mix:language)[fn:lower-(*)case(@jcr:language)='en']//element(*,sling:Message)[@sling:message]/(@sling:key|@sling:message); expected: (\n        at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.getSyntaxError(XPathToSQL2Converter.java:704)\n        at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.read(XPathToSQL2Converter.java:410)\n        at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.parseExpression(XPathToSQL2Converter.java:336)\n        at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.parseCondition(XPathToSQL2Converter.java:279)\n        at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.parseAnd(XPathToSQL2Converter.java:252)\n        at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.parseConstraint(XPathToSQL2Converter.java:244)\n        at org.apache.jackrabbit.oak.query.XPathToSQL2Converter.convert(XPathToSQL2Converter.java:153)\n        at org.apache.jackrabbit.oak.query.QueryEngineImpl.parseQuery(QueryEngineImpl.java:86)\n        at org.apache.jackrabbit.oak.query.QueryEngineImpl.executeQuery(QueryEngineImpl.java:99)\n        at org.apache.jackrabbit.oak.query.QueryEngineImpl.executeQuery(QueryEngineImpl.java:39)\n        at org.apache.jackrabbit.oak.jcr.query.QueryManagerImpl.executeQuery(QueryManagerImpl.java:110)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "sling",
         "xpath"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Sling I18N queries not supported by Oak"
   },
   {
      "_id": "12598044",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-07-09 15:21:18",
      "description": "Since we're leveraging JSON quite a bit around the MicroKernel, it would be good if the syntax of the filter argument to getNodes was that of a proper JSON object. Currently the MicroKernel expects names in the filter to be raw tokens instead of quoted strings, as they should be in a normal JSON object.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "json"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MicroKernel filter syntax is not proper JSON"
   },
   {
      "_id": "12597232",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2012-07-03 13:00:17",
      "description": "In revision 1325811 the JCR TCK tests were moved from the integrationTesting profile to a normal build. However, since then the execution time of the TCK has grown to 3+ minutes, which is more than the rest of the Oak build combined. To keep the build time down to at most a couple of minutes, I'd like to move the TCK run back to the integrationTesting profile where it will get executed only when explicitly requested (typically manually before a commit or after one in a CI build).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tck"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move the JCR TCK back to the integrationTesting profile"
   },
   {
      "_id": "12595933",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2012-06-26 16:14:18",
      "description": "Oak should support full text search against content in the repository.\n\nAs a default implementation of such a feature I'd like to add a simple Lucene-based full text index, somewhat similar to the search index we have in Jackrabbit 2.x.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "lucene"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Full text search index"
   },
   {
      "_id": "12595785",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2012-06-25 12:44:58",
      "description": "Even though we currently don't (and perhaps never will) support full JCR locking functionality in Oak, it would still be good to have a basic LockManager implementation for clients that assume it's present and use it simply to access lock tokens and to ask whether a particular node is locked or not.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "locking"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Basic JCR LockManager support"
   },
   {
      "_id": "12558561",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         }
      ],
      "created": "2012-05-30 09:16:03",
      "description": "We need a performance test suite for benchmarking Oak against previous versions (to detect regressions) and other comparable repositories (to know where we stand). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak performance benchmark"
   },
   {
      "_id": "12557435",
      "assignee": "stefan@jira",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-05-24 13:16:12",
      "description": "the MicroKernel API javadoc should specify the minimal guaranteed retention period for old revisions. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "api"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MicroKernel API: specify retention policy for old revisions"
   },
   {
      "_id": "12549684",
      "assignee": "mduerig",
      "components": [],
      "created": "2012-04-05 12:01:30",
      "description": "For quick turn around cycles during development we should have a way to run the most important tests only during a build and exclude longer running tests. \n\nI propose to create a Maven profile \"smoke-test\" which excludes long running tests. This ensures all tests are run by default but smoke testing can be used during development. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Create smoke-test build profile"
   },
   {
      "_id": "12549631",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-04-05 06:54:58",
      "description": "As noted on oak-dev@ revision 1298366 broke the earlier ability to efficiently compare node states with large lists of child nodes. We should restore that feature to avoid introducing a major performance bottleneck for such cases.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Efficient diffing of large child node lists"
   },
   {
      "_id": "12546803",
      "assignee": "tmueller",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2012-03-16 15:24:40",
      "description": "A query engine needs to be implemented. \n\nA query parser in oak-core should be able to handle xpath, sql2 and optionally other query languages. The jcr component must generate a valid query in one of those languages from JQOM queries and pass that statement along with value bindings, limit, offset, and name space mappings to the oak-core. \n\nWe need to:\n* Define the oak-core API for handling queries. How are do we handle name space mappings, limit and offset\n* Implement a query builder in the jcr component which takes care of translating JQOM queries to statements in string form \n* Implement a query parser in oak-core and decide on a versatile AST representation which works with all query languages and which is extensible to future query languages.\n* Implement the actual query execution engine which interprets the query AST\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "query"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Query implementation"
   },
   {
      "_id": "12546795",
      "assignee": "mduerig",
      "components": [],
      "created": "2012-03-16 14:59:39",
      "description": "Trans-session isolation differs from Jackrabbit 2. Snapshot isolation can result in write skew. See http://wiki.apache.org/jackrabbit/Transactional%20model%20of%20the%20Microkernel%20based%20Jackrabbit%20prototype",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "documentation",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MVCC causes write skew"
   },
   {
      "_id": "12546374",
      "assignee": "stefan@jira",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-03-14 10:29:59",
      "description": "We should have a test suite which thourougly covers the contract of the MicroKernel API",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement a test suite for the MicroKernel"
   },
   {
      "_id": "12546219",
      "assignee": "reschke",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-03-13 11:40:53",
      "description": "We should do a review of the Microkernel API with the goal to clarify, disambiguate and document its contract.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "api",
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document and tighten contract of Microkernel API"
   },
   {
      "_id": "12545672",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2012-03-08 16:32:39",
      "description": "One of the proposed goals for the 0.1 release is at least a basic JCR binding for Oak. Most of that already exists in /jackrabbit/sandbox, we just need to decide where and how to place it in Oak. I think we should either put it all under o.a.j.oak.jcr in oak-core, or create a separate oak-jcr component for the JCR binding.\n\nAs for functionality, it would be nice if the JCR binding was able to do at least the following:\n\n{code}\nRepository repository = JcrUtils.getRepository(...);\n\nSession session = repository.login(...);\ntry {\n    // Create\n    session.getRootNode().addNode(\"hello\")\n        .setProperty(\"world\",  \"hello world\");\n    session.save();\n\n    // Read\n    assertEquals(\n        \"hello world\",\n        session.getProperty(\"/hello/world\").getString());\n\n    // Update\n    session.getNode(\"/hello\").setProperty(\"world\", \"Hello, World!\");\n    session.save();\n    assertEquals(\n        \"Hello, World!\",\n        session.getProperty(\"/hello/world\").getString());\n\n    // Delete\n    session.getNode(\"/hello\").delete();\n    session.save();\n    assertTrue(!session.propertyExists(\"/hello/world\"));\n} finally {\n    create.logout();\n}\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "jcr"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JCR bindings for Oak"
   },
   {
      "_id": "12545565",
      "assignee": "jukkaz",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2012-03-07 21:41:11",
      "description": "We should have a simple runnable jar version of Oak that can be started by double-clicking on the jar or by executing:\n\n{code}\n$ java -jar oak-run-0.1.jar\n{code}\n\nThe jar should start up an Oak repository, and keep running until killed. No specific shutdown sequence or command should be assumed or required; the repository *must* be in a stable state regardless of how the process terminates.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "packaging"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Runnable jar packaging"
   },
   {
      "_id": "12545335",
      "assignee": "jukkaz",
      "components": [],
      "created": "2012-03-06 12:48:50",
      "description": "As suggested on dev@:\n\n{quote}\nTo get us started, I'll set up a basic multimodule build in oak/trunk\nalong the lines of what we have in jackrabbit/trunk. As initial\ncomponents I propose the following:\n\n   * oak-core, for the main codebase (incl. unit tests)\n   * oak-run, for a runnable jar packaging\n   * oak-it, for integration tests\n   * oak-bench, for performance tests\n{quote}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "maven"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Setup basic build structure"
   }
]