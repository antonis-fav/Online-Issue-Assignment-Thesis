[
   {
      "_id": "13389392",
      "assignee": "dulceanu",
      "components": [],
      "created": "2021-07-13 13:15:55",
      "description": "{noformat}\r\nOne or more dependencies were identified with known vulnerabilities in Jackrabbit Oak:aggs-matrix-stats-client-7.1.1.jar (pkg:maven/org.elasticsearch.plugin/aggs-matrix-stats-client@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\nbcprov-jdk15on-1.65.jar (pkg:maven/org.bouncycastle/bcprov-jdk15on@1.65, cpe:2.3:a:bouncycastle:legion-of-the-bouncy-castle-java-crytography-api:1.65:*:*:*:*:*:*:*) : CVE-2020-28052\r\ncommons-io-2.6.jar (pkg:maven/commons-io/commons-io@2.6, cpe:2.3:a:apache:commons_io:2.6:*:*:*:*:*:*:*) : CVE-2021-29425\r\ncxf-core-3.3.6.jar (pkg:maven/org.apache.cxf/cxf-core@3.3.6, cpe:2.3:a:apache:cxf:3.3.6:*:*:*:*:*:*:*) : CVE-2020-13954, CVE-2021-22696, CVE-2021-30468\r\nelasticsearch-core-7.1.1.jar (pkg:maven/org.elasticsearch/elasticsearch-core@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\nfluent-hc-4.5.12.jar (pkg:maven/org.apache.httpcomponents/fluent-hc@4.5.12, cpe:2.3:a:apache:httpclient:4.5.12:*:*:*:*:*:*:*) : CVE-2020-13956\r\ngroovy-2.5.2.jar (pkg:maven/org.codehaus.groovy/groovy@2.5.2, cpe:2.3:a:apache:groovy:2.5.2:*:*:*:*:*:*:*) : CVE-2020-17521\r\ngroovy-all-2.4.17.jar (pkg:maven/org.codehaus.groovy/groovy-all@2.4.17, cpe:2.3:a:apache:groovy:2.4.17:*:*:*:*:*:*:*) : CVE-2020-17521\r\nguava-15.0.jar (pkg:maven/com.google.guava/guava@15.0, cpe:2.3:a:google:guava:15.0:*:*:*:*:*:*:*) : CVE-2018-10237, CVE-2020-8908\r\nguava-18.0.jar (pkg:maven/com.google.guava/guava@18.0, cpe:2.3:a:google:guava:18.0:*:*:*:*:*:*:*) : CVE-2018-10237, CVE-2020-8908\r\nhibernate-validator-5.3.6.Final.jar (pkg:maven/org.hibernate/hibernate-validator@5.3.6.Final, cpe:2.3:a:hibernate:hibernate-validator:5.3.6:*:*:*:*:*:*:*, cpe:2.3:a:redhat:hibernate_validator:5.3.6:*:*:*:*:*:*:*) : CVE-2020-10693\r\nhttp2-client-9.4.27.v20200227.jar (pkg:maven/org.eclipse.jetty.http2/http2-client@9.4.27.v20200227, cpe:2.3:a:eclipse:jetty:9.4.27:20200227:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.27:20200227:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.27:20200227:*:*:*:*:*:*) : CVE-2019-17638, CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\nhttpclient-4.5.12.jar (pkg:maven/org.apache.httpcomponents/httpclient@4.5.12, cpe:2.3:a:apache:httpclient:4.5.12:*:*:*:*:*:*:*) : CVE-2020-13956\r\nhttpclient-osgi-4.5.12.jar/META-INF/maven/org.apache.httpcomponents/httpclient-cache/pom.xml (pkg:maven/org.apache.httpcomponents/httpclient-cache@4.5.12, cpe:2.3:a:apache:httpclient:4.5.12:*:*:*:*:*:*:*) : CVE-2020-13956\r\njackson-databind-2.10.3.jar (pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.10.3, cpe:2.3:a:fasterxml:jackson-databind:2.10.3:*:*:*:*:*:*:*) : CVE-2020-25649\r\njava-xmlbuilder-1.1.jar (pkg:maven/com.jamesmurty.utils/java-xmlbuilder@1.1) : CWE-611: Improper Restriction of XML External Entity Reference ('XXE')\r\njavax-websocket-server-impl-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty.websocket/javax-websocket-server-impl@9.4.18.v20190429, cpe:2.3:a:eclipse:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:java-websocket_project:java-websocket:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*) : CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njavax.servlet-3.0.0.v201112011016.jar (pkg:maven/org.eclipse.jetty.orbit/javax.servlet@3.0.0.v201112011016, cpe:2.3:a:eclipse:jetty:3.0.0:201112011016:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:3.0.0:201112011016:*:*:*:*:*:*) : CVE-2009-5045, CVE-2009-5046, CVE-2017-7656, CVE-2017-7657, CVE-2017-7658, CVE-2020-27216, CVE-2021-28169, CVE-2021-34428\r\njavax.websocket-api-1.0.jar (pkg:maven/javax.websocket/javax.websocket-api@1.0, cpe:2.3:a:java-websocket_project:java-websocket:1.0:*:*:*:*:*:*:*) : CVE-2020-11050\r\njdom2-2.0.6.jar (pkg:maven/org.jdom/jdom2@2.0.6, cpe:2.3:a:jdom:jdom:2.0.6:*:*:*:*:*:*:*) : CVE-2021-33813\r\njetty-http-9.4.27.v20200227.jar (pkg:maven/org.eclipse.jetty/jetty-http@9.4.27.v20200227, cpe:2.3:a:eclipse:jetty:9.4.27:20200227:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.27:20200227:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.27:20200227:*:*:*:*:*:*) : CVE-2019-17638, CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njetty-io-8.2.0.v20160908.jar (pkg:maven/org.eclipse.jetty/jetty-io@8.2.0.v20160908, cpe:2.3:a:mortbay_jetty:jetty:8.2.0:20160908:*:*:*:*:*:*) : CVE-2021-28165\r\njetty-io-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty/jetty-io@9.4.18.v20190429, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*) : CVE-2021-28165\r\njetty-io-9.4.27.v20200227.jar (pkg:maven/org.eclipse.jetty/jetty-io@9.4.27.v20200227, cpe:2.3:a:mortbay_jetty:jetty:9.4.27:20200227:*:*:*:*:*:*) : CVE-2021-28165\r\njetty-server-8.2.0.v20160908.jar (pkg:maven/org.eclipse.jetty/jetty-server@8.2.0.v20160908, cpe:2.3:a:eclipse:jetty:8.2.0:20160908:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:8.2.0:20160908:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:8.2.0:20160908:*:*:*:*:*:*) : CVE-2017-7656, CVE-2017-7657, CVE-2017-7658, CVE-2017-9735, CVE-2019-10241, CVE-2019-10247, CVE-2020-27216, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njetty-server-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty/jetty-server@9.4.18.v20190429, cpe:2.3:a:eclipse:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*) : CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njetty-util-8.2.0.v20160908.jar (pkg:maven/org.eclipse.jetty/jetty-util@8.2.0.v20160908, cpe:2.3:a:eclipse:jetty:8.2.0:20160908:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:8.2.0:20160908:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:8.2.0:20160908:*:*:*:*:*:*) : CVE-2017-7656, CVE-2017-7657, CVE-2017-7658, CVE-2019-10247, CVE-2020-27216, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\njunit-4.12.jar (pkg:maven/junit/junit@4.12) : CVE-2020-15250\r\nlang-mustache-client-7.1.1.jar (pkg:maven/org.elasticsearch.plugin/lang-mustache-client@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\nlog4j-1.2.16.jar (pkg:maven/log4j/log4j@1.2.16, cpe:2.3:a:apache:log4j:1.2.16:*:*:*:*:*:*:*) : CVE-2019-17571, CVE-2020-9488\r\nlog4j-1.2.17.jar (pkg:maven/log4j/log4j@1.2.17, cpe:2.3:a:apache:log4j:1.2.17:*:*:*:*:*:*:*) : CVE-2019-17571, CVE-2020-9488\r\nlog4j-api-2.11.1.jar (pkg:maven/org.apache.logging.log4j/log4j-api@2.11.1, cpe:2.3:a:apache:log4j:2.11.1:*:*:*:*:*:*:*) : CVE-2020-9488\r\nlog4j-over-slf4j-1.7.30.jar (pkg:maven/org.slf4j/log4j-over-slf4j@1.7.30, cpe:2.3:a:apache:log4j:1.7.30:*:*:*:*:*:*:*) : CVE-2020-9488\r\nmongo-java-driver-3.12.7.jar (pkg:maven/org.mongodb/mongo-java-driver@3.12.7, cpe:2.3:a:mongodb:java_driver:3.12.7:*:*:*:*:*:*:*) : CVE-2021-20328\r\nnetty-3.7.0.Final.jar (pkg:maven/io.netty/netty@3.7.0.Final, cpe:2.3:a:netty:netty:3.7.0:*:*:*:*:*:*:*) : CVE-2014-0193, CVE-2014-3488, CVE-2015-2156, CVE-2019-16869, CVE-2019-20444, CVE-2019-20445, CVE-2021-21290, CVE-2021-21295, CVE-2021-21409, POODLE vulnerability in SSLv3.0 support\r\nnetty-transport-4.1.47.Final.jar (pkg:maven/io.netty/netty-transport@4.1.47.Final, cpe:2.3:a:netty:netty:4.1.47:*:*:*:*:*:*:*) : CVE-2021-21290, CVE-2021-21295, CVE-2021-21409\r\nnetty-transport-4.1.52.Final.jar (pkg:maven/io.netty/netty-transport@4.1.52.Final, cpe:2.3:a:netty:netty:4.1.52:*:*:*:*:*:*:*) : CVE-2021-21290, CVE-2021-21295, CVE-2021-21409\r\noak-jackrabbit-api-1.34.0.jar (pkg:maven/org.apache.jackrabbit/oak-jackrabbit-api@1.34.0, cpe:2.3:a:apache:jackrabbit:1.34.0:*:*:*:*:*:*:*, cpe:2.3:a:apache:jackrabbit_oak:1.34.0:*:*:*:*:*:*:*) : CVE-2015-1833\r\noak-segment-1.6.0.jar (pkg:maven/org.apache.jackrabbit/oak-segment@1.6.0, cpe:2.3:a:apache:jackrabbit:1.6.0:*:*:*:*:*:*:*, cpe:2.3:a:apache:jackrabbit_oak:1.6.0:*:*:*:*:*:*:*) : CVE-2015-1833, CVE-2020-1940\r\norg.apache.felix.webconsole-4.2.10-all.jar: jquery-1.8.3.js (pkg:javascript/jquery@1.8.3) : CVE-2012-6708, CVE-2015-9251, CVE-2019-11358, CVE-2020-11022, CVE-2020-11023\r\norg.apache.felix.webconsole-4.2.10-all.jar: jquery-ui-1.9.2.js (pkg:javascript/jquery-ui-dialog@1.9.2, pkg:javascript/jquery-ui-tooltip@1.9.2) : CVE-2010-5312, CVE-2012-6662, CVE-2016-7103\r\npom.xml (pkg:maven/org.apache.jackrabbit/oak-jackrabbit-api@1.22.8-SNAPSHOT, cpe:2.3:a:apache:jackrabbit:1.22.8:snapshot:*:*:*:*:*:*, cpe:2.3:a:apache:jackrabbit_oak:1.22.8:snapshot:*:*:*:*:*:*) : CVE-2015-1833\r\npom.xml (pkg:maven/org.apache.jackrabbit/oak-solr-core@1.22.8-SNAPSHOT, cpe:2.3:a:apache:jackrabbit_oak:1.22.8:snapshot:*:*:*:*:*:*, cpe:2.3:a:apache:solr:1.22.8:snapshot:*:*:*:*:*:*) : CVE-2012-6612, CVE-2013-6397, CVE-2013-6407, CVE-2013-6408, CVE-2015-8795, CVE-2015-8796, CVE-2015-8797, CVE-2017-3163, CVE-2017-3164, CVE-2018-11802, CVE-2018-1308, CVE-2019-0193, CVE-2020-13941, CVE-2021-27905, CVE-2021-29262, CVE-2021-29943\r\norg.apache.servicemix.bundles.dom4j-2.1.1_1.jar (pkg:maven/org.apache.servicemix.bundles/org.apache.servicemix.bundles.dom4j@2.1.1_1, cpe:2.3:a:dom4j_project:dom4j:2.1.1.1:*:*:*:*:*:*:*) : CVE-2020-10683\r\norg.apache.sling.commons.logservice-1.0.4.jar (pkg:maven/org.apache.sling/org.apache.sling.commons.logservice@1.0.4, cpe:2.3:a:apache:sling:1.0.4:*:*:*:*:*:*:*) : CVE-2016-5394, CVE-2016-6798\r\nparent-join-client-7.1.1.jar (pkg:maven/org.elasticsearch.plugin/parent-join-client@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\npdfbox-2.0.19.jar (pkg:maven/org.apache.pdfbox/pdfbox@2.0.19, cpe:2.3:a:apache:pdfbox:2.0.19:*:*:*:*:*:*:*) : CVE-2021-27807, CVE-2021-27906, CVE-2021-31811, CVE-2021-31812\r\npreflight-2.0.19.jar (pkg:maven/org.apache.pdfbox/preflight@2.0.19, cpe:2.3:a:apache:pdfbox:2.0.19:*:*:*:*:*:*:*) : CVE-2021-27807, CVE-2021-27906, CVE-2021-31811, CVE-2021-31812\r\nrank-eval-client-7.1.1.jar (pkg:maven/org.elasticsearch.plugin/rank-eval-client@7.1.1, cpe:2.3:a:elastic:elasticsearch:7.1.1:*:*:*:*:*:*:*, cpe:2.3:a:elasticsearch:elasticsearch:7.1.1:*:*:*:*:*:*:*) : CVE-2019-7614, CVE-2019-7619, CVE-2020-7009, CVE-2020-7014, CVE-2020-7019, CVE-2020-7020, CVE-2020-7021\r\nsentiment-analysis-parser-0.1.jar (pkg:maven/edu.usc.ir/sentiment-analysis-parser@0.1, cpe:2.3:a:data_tools_project:data_tools:0.1:*:*:*:*:*:*:*) : CVE-2018-18749\r\nsis-netcdf-1.0.jar (pkg:maven/org.apache.sis.storage/sis-netcdf@1.0, cpe:2.3:a:storage_project:storage:1.0:*:*:*:*:*:*:*) : CVE-2021-20291\r\nsnakeyaml-1.17.jar (pkg:maven/org.yaml/snakeyaml@1.17, cpe:2.3:a:snakeyaml_project:snakeyaml:1.17:*:*:*:*:*:*:*) : CVE-2017-18640\r\nsolr-solrj-8.6.3.jar (pkg:maven/org.apache.solr/solr-solrj@8.6.3, cpe:2.3:a:apache:solr:8.6.3:*:*:*:*:*:*:*) : CVE-2021-27905, CVE-2021-29262, CVE-2021-29943\r\nspring-core-4.3.24.RELEASE.jar (pkg:maven/org.springframework/spring-core@4.3.24.RELEASE, cpe:2.3:a:pivotal_software:spring_framework:4.3.24:release:*:*:*:*:*:*, cpe:2.3:a:springsource:spring_framework:4.3.24:release:*:*:*:*:*:*, cpe:2.3:a:vmware:spring_framework:4.3.24:release:*:*:*:*:*:*, cpe:2.3:a:vmware:springsource_spring_framework:4.3.24:release:*:*:*:*:*:*) : CVE-2020-5421\r\ntagsoup-1.2.1.jar (pkg:maven/org.ccil.cowan.tagsoup/tagsoup@1.2.1, cpe:2.3:a:tag_project:tag:1.2.1:*:*:*:*:*:*:*) : CVE-2020-29242, CVE-2020-29243, CVE-2020-29244, CVE-2020-29245\r\ntika-core-1.24.1.jar (pkg:maven/org.apache.tika/tika-core@1.24.1, cpe:2.3:a:apache:tika:1.24.1:*:*:*:*:*:*:*) : CVE-2021-28657\r\nvorbis-java-tika-0.8.jar (pkg:maven/org.gagravarr/vorbis-java-tika@0.8, cpe:2.3:a:flac_project:flac:0.8:*:*:*:*:*:*:*) : CVE-2017-6888\r\nwebsocket-common-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty.websocket/websocket-common@9.4.18.v20190429, cpe:2.3:a:eclipse:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:java-websocket_project:java-websocket:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:websocket-extensions_project:websocket-extensions:9.4.18:20190429:*:*:*:*:*:*) : CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\nwebsocket-server-9.4.18.v20190429.jar (pkg:maven/org.eclipse.jetty.websocket/websocket-server@9.4.18.v20190429, cpe:2.3:a:eclipse:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:java-websocket_project:java-websocket:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:jetty:jetty:9.4.18:20190429:*:*:*:*:*:*, cpe:2.3:a:mortbay_jetty:jetty:9.4.18:20190429:*:*:*:*:*:*) : CVE-2020-27216, CVE-2020-27218, CVE-2020-27223, CVE-2021-28165, CVE-2021-28169, CVE-2021-34428\r\nxmpbox-2.0.19.jar (pkg:maven/org.apache.pdfbox/xmpbox@2.0.19, cpe:2.3:a:apache:pdfbox:2.0.19:*:*:*:*:*:*:*) : CVE-2021-27807, CVE-2021-27906, CVE-2021-31811, CVE-2021-31812\r\nzookeeper-3.4.6.jar (pkg:maven/org.apache.zookeeper/zookeeper@3.4.6, cpe:2.3:a:apache:zookeeper:3.4.6:*:*:*:*:*:*:*) : CVE-2016-5017, CVE-2017-5637, CVE-2018-8012, CVE-2019-0201, CVE-2021-21409\r\nzookeeper-3.5.7.jar (pkg:maven/org.apache.zookeeper/zookeeper@3.5.7, cpe:2.3:a:apache:zookeeper:3.5.7:*:*:*:*:*:*:*) : CVE-2021-21409\r\n-1,548 {noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_22"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Address vulnerabilities found by dependency checker plugin"
   },
   {
      "_id": "13381686",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2021-06-02 12:03:13",
      "description": "The cold standby is able to do SSL connections to the primary, but currently only using on-the-fly generated certificates. This means that data is transferred over an encrypted connection but there is no protection against a man in the middle yet.\r\n\r\nWith this issue we want to:\r\n* make server and client certificates configurable\r\n* optionally validate the client certificate\r\n* optionally only allow matching subjects in client and server certificates ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cold Standby SSL certificates should be configurable"
   },
   {
      "_id": "13380389",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2021-05-25 16:50:29",
      "description": "The test fails consistently on Jenkins but succeeds on Travis and when running locally.\r\n{noformat}org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: Configured cluster node id 1 already in use: leaseEnd 1621945215196 > 1621945095197 - 119999ms in the future\r\n\tat org.apache.jackrabbit.oak.plugins.document.ClusterNodeInfo.createInstance(ClusterNodeInfo.java:628)\r\n\tat org.apache.jackrabbit.oak.plugins.document.ClusterNodeInfo.getInstance(ClusterNodeInfo.java:471)\r\n\tat org.apache.jackrabbit.oak.plugins.document.ClusterNodeInfo.getInstance(ClusterNodeInfo.java:440)\r\n\tat org.apache.jackrabbit.oak.plugins.document.mongo.LeaseUpdateSocketTimeoutIT.newClusterNodeInfo(LeaseUpdateSocketTimeoutIT.java:153)\r\n\tat org.apache.jackrabbit.oak.plugins.document.mongo.LeaseUpdateSocketTimeoutIT.leaseUpdateFailureOnSocketTimeout(LeaseUpdateSocketTimeoutIT.java:107)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\r\n\tat org.testcontainers.containers.FailureDetectingExternalResource$1.evaluate(FailureDetectingExternalResource.java:30)\r\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)\r\n\tat org.testcontainers.containers.FailureDetectingExternalResource$1.evaluate(FailureDetectingExternalResource.java:30)\r\n\tat org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)\r\n\tat org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\r\n\tat org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:413)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "continuous_integration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failure: LeaseUpdateSocketTimeoutIT.leaseUpdateFailureOnSocketTimeout"
   },
   {
      "_id": "13375040",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2021-04-26 10:45:42",
      "description": "Currently {{oak-run compact}} for Azure Segment Store always compacts the source container in place. It should be better to allow compacting the source container to a different container, allowing thus to skip source container cleanup. Moreover, in order to speed up compaction, Azure compaction should always employ a persistent disk cache, whose path for storing the segments and size should be configurable.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve oak-run compact to better support Azure compaction"
   },
   {
      "_id": "13372233",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2021-04-14 08:06:02",
      "description": "There won't be a leaseEndTime when the recovering clusterId, the one referred to in\u00a0{{recoveryBy}}, is not active anymore. The implementation of\u00a0{{RecoveryLock.tryBreakRecoveryLock()}}\u00a0should only call\u00a0{{getLeaseEndTime()}}\u00a0when\u00a0{{recovering.isActive()}}\u00a0is true.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_22",
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Breaking recovery lock issue"
   },
   {
      "_id": "13329558",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2020-09-26 21:14:22",
      "description": "{{oak-run explore}}\u00a0should accept Azure URIs for the segment store in order to\u00a0be able to browse azure segments.\u00a0\r\n\r\nThe Azure URI will be taken as argument and will have the following format:\u00a0{{az:[https://myaccount.blob.core.windows.net/container/repo]}}, where\u00a0_az_\u00a0identifies the cloud provider. The last missing piece is the secret key which will be supplied as an environment variable, i.e.\u00a0_AZURE_SECRET_KEY._",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run explore should support Azure Segment Store"
   },
   {
      "_id": "13328580",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2020-09-21 14:41:38",
      "description": "After netty update in OAK-9210,  {{OSGiIT}} fails with the following exception:\r\n\r\n{code}\r\nERROR: Bundle org.apache.jackrabbit.oak-segment-tar [41] Error starting file:/var/folders/jh/rvxkcm515dl3bksp1zlzdws80000gn/T/1600699057212-0/bundles/org.apache.jackrabbit.oak-segment-tar_1.35.0.SNAPSHOT.jar (org.osgi.framework.BundleException: Unable to resolve org.apache.jackrabbit.oak-segment-tar [41](R 41.0): missing requirement [org.apache.jackrabbit.oak-segment-tar [41](R 41.0)] osgi.wiring.package; (osgi.wiring.package=com.oracle.svm.core.annotate) Unresolved requirements: [[org.apache.jackrabbit.oak-segment-tar [41](R 41.0)] osgi.wiring.package; (osgi.wiring.package=com.oracle.svm.core.annotate)])\r\norg.osgi.framework.BundleException: Unable to resolve org.apache.jackrabbit.oak-segment-tar [41](R 41.0): missing requirement [org.apache.jackrabbit.oak-segment-tar [41](R 41.0)] osgi.wiring.package; (osgi.wiring.package=com.oracle.svm.core.annotate) Unresolved requirements: [[org.apache.jackrabbit.oak-segment-tar [41](R 41.0)] osgi.wiring.package; (osgi.wiring.package=com.oracle.svm.core.annotate)]\r\n\tat org.apache.felix.framework.Felix.resolveBundleRevision(Felix.java:4368)\r\n\tat org.apache.felix.framework.Felix.startBundle(Felix.java:2281)\r\n\tat org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1539)\r\n\tat org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:308)\r\n\tat java.base/java.lang.Thread.run(Thread.java:835)\r\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix OSGi wiring after netty update to 4.1.52.Final"
   },
   {
      "_id": "13327862",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2020-09-16 12:56:31",
      "description": "The current version presents several vulnerability issues:\u00a0\r\n\r\nBDSA-2018-4022,BDSA-2018-4482,BDSA-2019-2642,BDSA-2019-2643.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bump netty dependency from 4.1.17.Final to 4.1.52.Final"
   },
   {
      "_id": "13326424",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         }
      ],
      "created": "2020-09-08 09:23:23",
      "description": "Failure to write a segment to the redis cache results in an error level log message with a stack trace. However, this is expected behaviour: socket timeouts prevent the cache from effectively slowing down a request. OTOH too many socket timeouts make the cache ineffective, so it's good to have a way to log such errors when debugging. My suggestion is therefore to change the log level to \"debug\" and avoid the stack trace.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "patch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "PersistentRedisCache: failure to write segment is not an error"
   },
   {
      "_id": "13301237",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2020-04-27 11:21:56",
      "description": "During repository startup if archive directory is not closed properly, recovery will be performed. During that procedure, segents are copied to the backup directory and deleted from the source direcory, one by one.\r\n\r\nIt can create problems and negativelly impact other ongoing actiivties, which are accessing the same archive. This activity, for example, can be repository cloning in order to create new environment.\u00a0\r\n\r\nProposed patch, after creating backup is not deleting all segments from archive, but only segments which could not be recovered.\u00a0\r\n\r\n[^proposal.patch]\r\n\r\n\u00a0\r\n\r\n+API change+\r\n\r\nProposed patch is changing major version of exported SPI package, org.apache.jackrabbit.oak.segment.spi.persistence.split.\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Patch"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve azure archive recovery during startup"
   },
   {
      "_id": "13291031",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2020-03-11 09:31:47",
      "description": "While registering a resource change listener, we encountered the following exception :\u00a0\r\n\r\n\u00a0\r\n{code:java}\r\n05.03.2020 23:39:00.728 *ERROR* [FelixDispatchQueue] org.apache.sling.resourceresolver FrameworkEvent ERROR (java.lang.NullPointerException)\r\njava.lang.NullPointerException: null\r\nat org.apache.jackrabbit.oak.commons.PathUtils.unifyInExcludes(PathUtils.java:501) [org.apache.jackrabbit.oak-commons:1.8.17]\r\nat org.apache.jackrabbit.oak.jcr.observation.ObservationManagerImpl.addEventListener(ObservationManagerImpl.java:240) [org.apache.jackrabbit.oak-jcr:1.8.17]\r\nat org.apache.sling.jcr.resource.internal.JcrListenerBaseConfig.register(JcrListenerBaseConfig.java:136) [org.apache.sling.jcr.resource:3.0.16.1]\r\n{code}\r\n\u00a0\r\n\r\nOn further debugging, we found that issues lies in this snippet :\u00a0\r\n{code:java}\r\nif (exclude.equals(include) || isAncestor(exclude, include)) {\r\n includesRemoved.add(include);{code}\r\n'exclude' can be null if the getOakPath() method returns a null. This NPE causes listeners(ResourceChangeListener in our case) to fail at registration.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ObservationManager.addEventListener() throws NPE with invalid paths in filter"
   },
   {
      "_id": "13289743",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2020-03-05 09:03:15",
      "description": "When running oak run jar in recovery mode on a mongo replica set with auth enabled. it fails to pass the auth data for a findOne command called in\u00a0*GetRootRevisionsCallable*\r\n\r\n\u00a0\r\n{code:java}\r\nDBObject root = collection.findOne(new BasicDBObject(Document.ID, \"0:/\"));{code}\r\nStack Trace as below\r\n 07:07:27.790 [MongoDocumentStore replica set info provider] ERROR o.a.j.o.p.d.m.replica.ReplicaSetInfo - Can't connect to the Mongo instance07:07:27.790 [MongoDocumentStore replica set info provider] ERROR o.a.j.o.p.d.m.replica.ReplicaSetInfo - Can't connect to the Mongo instancejava.util.concurrent.ExecutionException: com.mongodb.MongoQueryException: Query failed with error code 13 and error message 'not authorized on dampro64tmp to execute command { find: \"nodes\", filter:\r\n\r\n{ _id: \"0:/\" }\r\n\r\n, limit: 1, singleBatch: true }' on server at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.getRootRevisions(ReplicaSetInfo.java:346) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.updateRevisions(ReplicaSetInfo.java:269) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.updateReplicaStatus(ReplicaSetInfo.java:181) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.updateLoop(ReplicaSetInfo.java:144) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.run(ReplicaSetInfo.java:133) at java.lang.Thread.run(Thread.java:745)Caused by: com.mongodb.MongoQueryException: Query failed with error code 13 and error message 'not authorized on DB to execute command { find: \"nodes\", filter:\r\n\r\n{ _id: \"0:/\" }\r\n\r\n, limit: 1, singleBatch: true }' on server at com.mongodb.operation.FindOperation$1.call(FindOperation.java:722) at com.mongodb.operation.FindOperation$1.call(FindOperation.java:711) at com.mongodb.operation.OperationHelper.withConnectionSource(OperationHelper.java:471) at com.mongodb.operation.OperationHelper.withConnection(OperationHelper.java:415) at com.mongodb.operation.FindOperation.execute(FindOperation.java:711) at com.mongodb.operation.FindOperation.execute(FindOperation.java:83) at com.mongodb.Mongo$3.execute(Mongo.java:826) at com.mongodb.Mongo$3.execute(Mongo.java:813) at com.mongodb.DBCursor.initializeCursor(DBCursor.java:877) at com.mongodb.DBCursor.hasNext(DBCursor.java:144) at com.mongodb.DBCursor.one(DBCursor.java:683) at com.mongodb.DBCollection.findOne(DBCollection.java:829) at com.mongodb.DBCollection.findOne(DBCollection.java:792) at com.mongodb.DBCollection.findOne(DBCollection.java:739) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.GetRootRevisionsCallable.call(GetRootRevisionsCallable.java:58) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.GetRootRevisionsCallable.call(GetRootRevisionsCallable.java:34) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) at org.apache.jackrabbit.oak.plugins.document.mongo.replica.ReplicaSetInfo.getRootRevisions(ReplicaSetInfo.java:340) ... 5 common frames omitted",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Oak run recovery fails when running on mongo replicaSet with auth enabled"
   },
   {
      "_id": "13281162",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         }
      ],
      "created": "2020-01-23 10:52:52",
      "description": "We use azcopy to copy segments from one azure blob container to another for testing. There is a bug in the current version of azcopy (10.3.3), which makes all metadata keys start with a capital letter -\u00a0\"type\" becomes \"Type\". As a consequence, the current implementation can not find the segments in the azure blob storage.\u00a0\r\n\u00a0\r\nThe azcopy\u00a0issue was already reported [1] in 2018.\u00a0I have little hope that azcopy will be fixed soon.\r\n\u00a0\r\nTherefore I suggest a patch to oak-segment-azure, that would be backward compatible and ignore the case of the keys when reading metadata.\u00a0We should be strict in what we write and tolerant in what we read.\u00a0\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "azureblob"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Access azure segments metadata in a case-insensitive way"
   },
   {
      "_id": "13264800",
      "assignee": "dulceanu",
      "components": [],
      "created": "2019-10-28 11:32:37",
      "description": "Currently the consistency check reports only if the command runs successfully (return code 0) or fails (return code 1).\r\nInto this logic will also add the status of repository consistency:\r\n- checking only the last revision: will return 0 if the revision is consistent and the command runs successfully OR will return 1 if the revision is inconsistent or job did not run successfully (some errors/exception were encountered during the run)\r\n- checking multiple revisions: will return 0 if at least one revision is consistent and the job runs successfully OR will return 1 if none of the revisions are consistent or the command did not run successfully (some errors/exception were encounter during the run) ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "oak-run",
         "segment-tar"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak run check command must return the status of repository consistency check"
   },
   {
      "_id": "13260246",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-10-03 07:16:14",
      "description": "Changing and merging descendant nodes of a bundled node fails when the commit root of the changes is located on a bundled node. The merge tries to apply the final commit changes on a document that does not exist (because the bundled node is located on an ancestor document).\r\n\r\nThe exception is misleading but looks like this:\r\n{noformat}\r\nCaused by: org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: Conflicting concurrent change. Update operation failed: key: 3:/foo/bar/baz update {_revisions.r16d8bf18282-0-1=SET_MAP_ENTRY c, _modified=MAX 1570010920}\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:398) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStoreWithTiming(Commit.java:278) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyToDocumentStore(Commit.java:262) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.applyInternal(Commit.java:230) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.Commit.apply(Commit.java:218) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:320) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.persist(DocumentNodeStoreBranch.java:282) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.access$500(DocumentNodeStoreBranch.java:56) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch$InMemory.merge(DocumentNodeStoreBranch.java:548) [org.apache.jackrabbit.oak-store-document:1.18.0]\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Merge may fail when commit root is a bundled node"
   },
   {
      "_id": "13257125",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-09-17 13:53:52",
      "description": "The DocumentNodeStore node bundling feature may expose a hidden internal property when a bundled node structure is deleted and re-created with a non-bundling nodetype.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Node bundling exposes hidden properties"
   },
   {
      "_id": "13251784",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-08-20 08:50:59",
      "description": "Backport OAK-8066 to 1.10 and 1.8.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Backport OAK-8066 to 1.10 and 1.8"
   },
   {
      "_id": "13240824",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-06-21 09:53:54",
      "description": "{{oak-run check}} should expose the head node and property counts for the last good revision. Currently these are only logged at the end of the check operation as\r\n{noformat}\r\nChecked X nodes and Y properties.{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run check should expose repository statistics for the last good revision"
   },
   {
      "_id": "13236196",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         }
      ],
      "created": "2019-05-29 09:11:13",
      "description": "Add remote store monitoring\r\nImplement the remote store monitoring for Azure Store.\u00a0This should include:\r\n- request_count : number of request to azure store\r\n- error_count : number of failed requests to azure store\r\n- duration : duration of a request to azure store in nanoseconds ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add remote store monitoring  for Azure"
   },
   {
      "_id": "13235965",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-05-28 10:16:13",
      "description": "{{oak-run check}}\u00a0currently uses memory mapping by default when building the {{FileStore}}. This setting should be configurable, to allow switching memory mapping off.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run check should have an option for specifying memory mapping"
   },
   {
      "_id": "13229853",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-04-24 12:06:17",
      "description": "The DocumentNodeStore does not clean up orphaned branch commit entries ({{_bc}}) after a restart. Cleanup for those entries happens while the DocumentNodeStore is running as well, but only when the branch is not referenceable anymore. In some cases it may happen that a branch is referenced right until the DocumentNodeStore is disposed and the cleanup must happen on startup.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Orphaned branch commit entries after restart"
   },
   {
      "_id": "13218575",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2019-02-28 09:13:13",
      "description": "If the standby client issues a request for a\u00a0binary ID larger than 8192 bytes, it will fail on the server side due to the current frame limitation, set to 8192 bytes:\r\n{noformat}\r\n28.02.2019 00:01:36.034 *WARN* [primary-32] org.apache.jackrabbit.oak.segment.standby.server.ExceptionHandler Exception caught on the server\r\nio.netty.handler.codec.TooLongFrameException: frame length (35029) exceeds the allowed maximum (8192)\r\n        at io.netty.handler.codec.LineBasedFrameDecoder.fail(LineBasedFrameDecoder.java:146) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.LineBasedFrameDecoder.fail(LineBasedFrameDecoder.java:142) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.LineBasedFrameDecoder.decode(LineBasedFrameDecoder.java:131) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.LineBasedFrameDecoder.decode(LineBasedFrameDecoder.java:75) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1342) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:934) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [org.apache.jackrabbit.oak-segment-tar:1.10.1]\r\n        at java.base/java.lang.Thread.run(Thread.java:834)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "The cold standby server cannot handle blob requests for long blob IDs"
   },
   {
      "_id": "13218371",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2019-02-27 15:12:39",
      "description": "The background update stats does not have timing information for refreshing the head revision.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add refresh head revision time to background update stats"
   },
   {
      "_id": "13217162",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-02-21 10:56:42",
      "description": "In a first step towards resolving OAK-8066, I want to add some logging regarding the number of transiently modified direct child nodes in {{DefaultSegmentWriter}} ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Log warning for too many transient modifications of direct child nodes"
   },
   {
      "_id": "13217128",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-02-21 08:35:49",
      "description": "{{DefaultSegmentWriter}} keeps a map of\u00a0[child nodes|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/DefaultSegmentWriter.java#L805] of a node being written. This can lead to high memory consumption in the case where many child nodes are added at the same time. The latter could happen in the case where a node needs to be rewritten because of an increase in the GC generation from a concurrently completed revision garbage collection.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Nodes with many direct children can lead to OOME when saving"
   },
   {
      "_id": "13216958",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2019-02-20 15:20:23",
      "description": "The logic from {{StandbyClientSyncExecution#copySegmentHierarchyFromPrimary}} has a flaw when it comes to \"backward references\". Suppose we have the following data segment graph to be transferred from primary: S1, which references \\{S2, S3} and S3 which references S2. Then, the correct transfer order should be S2, S3 and S1.\r\n\r\nGoing through the current logic employed by the method, here's what happens:\r\n{noformat}\r\nStep 0: batch={S1}\r\n\r\nStep 1: visited={S1}, data={S1}, batch={S2, S3}, queued={S2, S3}\r\n\r\nStep 2: visited={S1, S2}, data={S2, S1}, batch={S3}, queued={S2, S3}\r\n\r\nStep 3: visited={S1, S2, S3}, data={S3, S2, S1}, batch={}, queued={S2, S3}.{noformat}\r\nTherefore, at the end of the loop, the order of the segments to be transferred will be S3, S2, S1, which\u00a0might trigger a {{SegmentNotFoundException}} when S3 is further processed, because S2 is missing on standby (see OAK-8006).\r\n\r\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "The cold standby client doesn't correctly handle backward references"
   },
   {
      "_id": "13214937",
      "assignee": "mduerig",
      "components": [],
      "created": "2019-02-11 08:11:35",
      "description": "{{CompactionAndCleanupIT.testMixedSegments}} fails every 50-th build or so:\r\n{code:java}\r\n[ERROR] testMixedSegments(org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT)  Time elapsed: 1.064 s  <<< FAILURE!\r\njava.lang.AssertionError: Mixed segments found: 7395f14c-15dd-4224-ad53-ec981f46f5cd\r\n\tat org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT.testMixedSegments(CompactionAndCleanupIT.java:701)\r\n{code}\r\n\u00a0\r\n\r\nThis might have the same root cause as OAK-8033. But no causality found yet.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Intermittent test failure of CompactionAndCleanupIT.testMixedSegments"
   },
   {
      "_id": "13214414",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2019-02-07 16:09:53",
      "description": "Due to a regression introduced with OAK-7867 a full compaction can sometimes cause nodes that are written concurrently to reference segments from more than a single gc generation.\r\n\r\nThis happens when the {{borrowWriter}} method needs to [create a new writer|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentBufferWriterPool.java#L197-L201]. In this case the new writer will be of the generation of the current head state instead of the generation associated with the current write operation in progress.\r\n\r\n\u00a0\r\n\r\ncc [~frm], [~ahanikel]\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Node states sometimes refer to more than a single generation of segments after a full compaction"
   },
   {
      "_id": "13212224",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2019-01-28 12:24:15",
      "description": "When persisting a segment transferred from master, among others, the cold standby needs to read the binary references from the segment. While this usually doesn't involve any additional reads from any other segments,\u00a0there is a special case concerning binary IDs larger than 4092 bytes. These can live in other segments (which got transferred prior to the current segment and are already on the standby), but it might also be the case that the binary ID is stored in the same segment.\u00a0If this happens, the call to\u00a0{{blobId.getSegment()}}[0],\u00a0triggers a new read of the current, un-persisted segment\u00a0. Thus, a {{SegmentNotFoundException}} is thrown:\r\n{noformat}\r\n22.01.2019 09:35:59.345 *ERROR* [standby-run-1] org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSync Failed synchronizing state.\r\norg.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment d40a9da6-06a2-4dc0-ab91-5554a33c02b0 not found\r\n        at org.apache.jackrabbit.oak.segment.file.AbstractFileStore.readSegmentUncached(AbstractFileStore.java:284) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.lambda$readSegment$10(FileStore.java:498) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.SegmentCache$NonEmptyCache.lambda$getSegment$0(SegmentCache.java:163) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache.get(LocalCache.java:3932) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) [com.adobe.granite.osgi.wrapper.guava:15.0.0.0002]\r\n        at org.apache.jackrabbit.oak.segment.SegmentCache$NonEmptyCache.getSegment(SegmentCache.java:160) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:498) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:153) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.RecordId.getSegment(RecordId.java:98) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.SegmentBlob.readLongBlobId(SegmentBlob.java:206) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.SegmentBlob.readBlobId(SegmentBlob.java:163) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.AbstractFileStore$3.consume(AbstractFileStore.java:262) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.Segment.forEachRecord(Segment.java:601) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.AbstractFileStore.readBinaryReferences(AbstractFileStore.java:257) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.writeSegment(FileStore.java:533) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSyncExecution.copySegmentFromPrimary(StandbyClientSyncExecution.java:225) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSyncExecution.copySegmentHierarchyFromPrimary(StandbyClientSyncExecution.java:194) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSyncExecution.compareAgainstBaseState(StandbyClientSyncExecution.java:101) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSyncExecution.execute(StandbyClientSyncExecution.java:76) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.jackrabbit.oak.segment.standby.client.StandbyClientSync.run(StandbyClientSync.java:165) [org.apache.jackrabbit.oak-segment-tar:1.10.0]\r\n        at org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:347) [org.apache.sling.commons.scheduler:2.7.2]\r\n        at org.quartz.core.JobRunShell.run(JobRunShell.java:202) [org.apache.sling.commons.scheduler:2.7.2]\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n        at java.base/java.lang.Thread.run(Thread.java:834){noformat}\r\n\u00a0\r\n\r\n[0]\u00a0https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentBlob.java#L205",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentBlob#readLongBlobId might cause SegmentNotFoundException on standby"
   },
   {
      "_id": "13208546",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12334703",
            "id": "12334703",
            "name": "segment-azure"
         }
      ],
      "created": "2019-01-09 13:36:03",
      "description": "The transfer of segments between different persistence types when using {{oak-run segment-copy}} can be\u00a0sped up by employing multiple threads in the transfer. The idea is to try to load {{n}} segments from the source, which are then consumed by the writer on the target, keeping the ordering of the segments in the process.\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add multi-threaded segment transfer to oak-run segment-copy"
   },
   {
      "_id": "13185131",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-09-14 12:25:29",
      "description": "We are getting the following deadlock. Please help! (Production environment)\r\n\r\nI have already annotated possible locks and synchronized blocks in between:\r\n\r\n{noformat}\r\n\"TarMK flush [/opt/condat/epet9/sling/repository/segmentstore]\":\r\n\u00a0 waiting to lock Monitor@0x00007fedfc00cc28 (Object@0x00000004795519a8, a org/apache/jackrabbit/oak/segment/SegmentId),\r\n\u00a0 which is held by \"oak-lucene-14\"\r\n\"oak-lucene-14\":\r\n\u00a0waiting for ownable synchronizer 0x00000003c13818c0, (a java/util/concurrent/locks/ReentrantReadWriteLock$NonfairSync),\r\n\u00a0which is held by \"TarMK flush [/opt/condat/epet9/sling/repository/segmentstore]\"\r\n\r\nThread 28883: (state = BLOCKED)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentId.getSegment() @bci=12, line=121 (Compiled frame)\r\n\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0synchronized (this) \r\n\u00a0- org.apache.jackrabbit.oak.segment.Record.getSegment() @bci=4, line=70 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.BlockRecord.read(int, byte[], int, int) @bci=49, line=57 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentStream.read(byte[], int, int) @bci=314, line=189 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.read(java.io.InputStream, byte[], int, int) @bci=43, line=828 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.readFully(java.io.InputStream, byte[], int, int) @bci=4, line=695 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.readFully(java.io.InputStream, byte[]) @bci=5, line=676 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentStream.getString() @bci=93, line=103 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.Segment.readString(int) @bci=189, line=524 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBlob.readLongBlobId(org.apache.jackrabbit.oak.segment.Segment, int) @bci=15, line=212 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBlob.readBlobId(org.apache.jackrabbit.oak.segment.Segment, int) @bci=37, line=167 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.AbstractFileStore$4.consume(int, org.apache.jackrabbit.oak.segment.RecordType, int) @bci=24, line=354 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.Segment.forEachRecord(org.apache.jackrabbit.oak.segment.Segment$RecordConsumer) @bci=48, line=716 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.AbstractFileStore.populateTarBinaryReferences(org.apache.jackrabbit.oak.segment.Segment, org.apache.jackrabbit.oak.segment.file.TarWriter) @bci=25, line=349 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore.writeSegment(org.apache.jackrabbit.oak.segment.SegmentId, byte[], int, int) @bci=136, line=657 (Compiled frame)\r\n\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0fileStoreLock.writeLock().lock(); Zeile 639\r\n\u00a0\u00a0 \u00a0\u00a0\u00a0 \u00a0bis: populateTarBinaryReferences\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBufferWriter.flush() @bci=383, line=383 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBufferWriterPool.flush() @bci=165, line=148 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentWriter.flush() @bci=4, line=143 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$7.call() @bci=7, line=373 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$7.call() @bci=1, line=370 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.TarRevisions.doFlush(java.util.concurrent.Callable) @bci=25, line=224 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.TarRevisions.flush(java.util.concurrent.Callable) @bci=42, line=212 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore.flush() @bci=20, line=370 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$2.run() @bci=15, line=233 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.SafeRunnable.run() @bci=21, line=67 (Compiled frame)\r\n\u00a0- java.util.concurrent.Executors$RunnableAdapter.call() @bci=4, line=511 (Compiled frame)\r\n\u00a0- java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308 (Compiled frame)\r\n\u00a0- java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask) @bci=1, line=180 (Compiled frame)\r\n\u00a0- java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run() @bci=37, line=294 (Compiled frame)\r\n\u00a0- java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1142 (Compiled frame)\r\n\u00a0- java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=617 (Interpreted frame)\r\n\u00a0- java.lang.Thread.run() @bci=11, line=748 (Interpreted frame)\r\n\r\nLocked ownable synchronizers:\r\n\u00a0\u00a0\u00a0 - <0x00000003c1361228>, (a java/util/concurrent/locks/ReentrantLock$NonfairSync)\r\n\u00a0\u00a0\u00a0 - <0x00000003c13818c0>, (a java/util/concurrent/locks/ReentrantReadWriteLock$NonfairSync)\r\n\u00a0\u00a0\u00a0 - <0x00000003c1c3a0d8>, (a java/util/concurrent/ThreadPoolExecutor$Worker)\r\n\r\nThread 31035: (state = BLOCKED)\r\n\u00a0- sun.misc.Unsafe.park(boolean, long) @bci=0 (Compiled frame; information may be imprecise)\r\n\u00a0- java.util.concurrent.locks.LockSupport.park(java.lang.Object) @bci=14, line=175 (Compiled frame)\r\n\u00a0- java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt() @bci=1, line=836 (Compiled frame)\r\n\u00a0- java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(int) @bci=83, line=967 (Interpreted frame)\r\n\u00a0- java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(int) @bci=10, line=1283 (Compiled frame)\r\n\u00a0- java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock() @bci=5, line=727 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$8.call() @bci=158, line=567 (Compiled frame)\r\n\u00a0\u00a0 \u00a0fileStoreLock.readLock().lock();\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore$8.call() @bci=1, line=542 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentCache.getSegment(org.apache.jackrabbit.oak.segment.SegmentId, java.util.concurrent.Callable) @bci=1, line=95 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(org.apache.jackrabbit.oak.segment.SegmentId) @bci=14, line=542 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentId.getSegment() @bci=38, line=125 (Compiled frame)\r\n\u00a0\u00a0 \u00a0synchronized (this) \r\n\u00a0- org.apache.jackrabbit.oak.segment.Record.getSegment() @bci=4, line=70 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.BlockRecord.read(int, byte[], int, int) @bci=49, line=57 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentStream.read(byte[], int, int) @bci=314, line=189 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.read(java.io.InputStream, byte[], int, int) @bci=64, line=833 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.readFully(java.io.InputStream, byte[], int, int) @bci=4, line=695 (Compiled frame)\r\n\u00a0- com.google.common.io.ByteStreams.readFully(java.io.InputStream, byte[]) @bci=5, line=676 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentStream.getString() @bci=93, line=103 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.Segment.readString(int) @bci=189, line=524 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBlob.readLongBlobId(org.apache.jackrabbit.oak.segment.Segment, int) @bci=15, line=212 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentBlob.length() @bci=124, line=115 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexFile.<init>(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeBuilder, java.lang.String, org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$BlobFactory) @bci=204, line=409 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.<init>(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeBuilder, java.lang.String, org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$BlobFactory) @bci=25, line=589 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory.fileLength(java.lang.String) @bci=64, line=176 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.directory.CopyOnReadDirectory.copyFilesToLocal(org.apache.jackrabbit.oak.plugins.index.lucene.directory.CopyOnReadDirectory$CORFileReference, boolean, boolean) @bci=195, line=214 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.directory.CopyOnReadDirectory.prefetchIndexFiles() @bci=96, line=170 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.directory.CopyOnReadDirectory.<init>(org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier, org.apache.lucene.store.Directory, org.apache.lucene.store.Directory, boolean, java.lang.String, java.util.concurrent.Executor) @bci=85, line=81 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier.wrapForRead(java.lang.String, org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition, org.apache.lucene.store.Directory, java.lang.String) @bci=35, line=122 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.reader.DefaultIndexReaderFactory.createReader(org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition, org.apache.jackrabbit.oak.spi.state.NodeState, java.lang.String, java.lang.String, java.lang.String) @bci=61, line=102 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.reader.DefaultIndexReaderFactory.createReaders(org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinition, org.apache.jackrabbit.oak.spi.state.NodeState, java.lang.String) @bci=20, line=61 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexNode.open(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.plugins.index.lucene.reader.LuceneIndexReaderFactory, org.apache.jackrabbit.oak.plugins.index.lucene.hybrid.NRTIndexFactory) @bci=17, line=68 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker$1.leave(org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState) @bci=30, line=132 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeChanged(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState) @bci=66, line=153 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.MapRecord.compare(org.apache.jackrabbit.oak.segment.MapRecord, org.apache.jackrabbit.oak.spi.state.NodeStateDiff) @bci=197, line=415 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentNodeState.compareAgainstBaseState(org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeStateDiff) @bci=909, line=608 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.EditorDiff.childNodeChanged(java.lang.String, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState) @bci=43, line=148 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.MapRecord.compare(org.apache.jackrabbit.oak.segment.MapRecord, org.apache.jackrabbit.oak.spi.state.NodeStateDiff) @bci=400, line=457 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.segment.SegmentNodeState.compareAgainstBaseState(org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeStateDiff) @bci=909, line=608 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(org.apache.jackrabbit.oak.spi.commit.Editor, org.apache.jackrabbit.oak.spi.state.NodeState, org.apache.jackrabbit.oak.spi.state.NodeState) @bci=34, line=52 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker.diffAndUpdate(org.apache.jackrabbit.oak.spi.state.NodeState) @bci=140, line=142 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker.update(org.apache.jackrabbit.oak.spi.state.NodeState) @bci=36, line=113 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1$1.call() @bci=79, line=135 (Compiled frame)\r\n\u00a0- org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1$1.call() @bci=1, line=128 (Compiled frame)\r\n\u00a0- java.util.concurrent.FutureTask.run() @bci=42, line=266 (Compiled frame)\r\n\u00a0- java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1142 (Compiled frame)\r\n\u00a0- java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=617 (Compiled frame)\r\n\u00a0- java.lang.Thread.run() @bci=11, line=748 (Compiled frame)\r\n\r\nLocked ownable synchronizers:\r\n\u00a0\u00a0\u00a0 - <0x0000000476194f30>, (a java/util/concurrent/ThreadPoolExecutor$Worker)\u00a0\u00a0\u00a0\r\n\r\n{noformat}\r\n\r\n\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "deadlock"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "deadlock TarMK flush, lucene"
   },
   {
      "_id": "13184064",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-09-10 14:12:44",
      "description": "It's not entirely clear to me what behavior we expect if:\r\n\u00a0\r\n * node 1 creates a document\r\n * node 2 deletes it\r\n * node 1 tries to update it\r\n\r\n(and, related to that, whether the behavior really matters in practice)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clarify update semantics on deleted nodes"
   },
   {
      "_id": "13181865",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-08-29 10:12:04",
      "description": "Callers of the {{check}} command can specify an alternative journal with the {{\\-\\-journal}} option. This option instructs the {{ConsistencyChecker}} to check the revisions stored in that file instead of the ones stored in the default {{journal.log}}.\r\n\r\nI spotted at least two problems while using {{\\-\\-journal}} on a repository with a corrupted {{journal.log}} that didn't contain any valid revision.\r\n\r\nFirst, the path to the {{FileStore}} is validated by {{FileStoreHelper#isValidFileStoreOrFail}}, which checks for the existence of a {{journal.log}} in the specified folder. But if a {{journal.log}} doesn't exist and the user specified a different journal on the command line this check should be ignored.\r\n\r\nSecond, when opening the {{FileStore}} the default {{journal.log}} is scanned to determine the initial revision of the head state. If a user specifies an alternative journal on the command line, that journal should be used instead of the default {{journal.log}}. It might be that the default journal contains no valid revision, which would force the system to crash when opening a new instance of {{FileStore}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CheckCommand should consistently use an alternative journal if specified"
   },
   {
      "_id": "13181405",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2018-08-27 16:38:04",
      "description": "In the opening paragraph of the documentation on Direct Binary Access, reference is made to S3DataStore and AzureDataStore as blob stores that support this feature, but is is not clear whether they are mentioned as examples or as an exhaustive list of supporting blob stores.  It is only on further examination of the documentation that you are able to determine that the list was specific and not as examples.\r\nWe should change the documentation so it is more clear up front which blob stores support the feature.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Documentation for direct binary access is unclear"
   },
   {
      "_id": "13180468",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2018-08-22 13:09:41",
      "description": "Some SecurityProviderRegistrationTest.testRequiredUserAuthenticationFactoryNotAvailable() fails every now and then. The last occurrence on travis-ci was here: https://travis-ci.org/apache/jackrabbit-oak/jobs/414016611 but I've also seen the same test fail on other infrastructure.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "continuous_integration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failure: SecurityProviderRegistrationTest.testRequiredUserAuthenticationFactoryNotAvailable()"
   },
   {
      "_id": "13179095",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-08-15 14:05:52",
      "description": "We have seen instances were offline compaction did not clean up all reclaimable tar files on the first run but would reclaim them on subsequent runs. Apparently this is caused by OAK-6648, which fixes an issue where the file reaper is invoked without a prior call to {{System.gc}} reclaiming potential references.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "TarMK"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Backport OAK-6648 to Oak 1.6"
   },
   {
      "_id": "13177340",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333543",
            "id": "12333543",
            "name": "security-spi",
            "description": "Oak Security SPI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332557",
            "id": "12332557",
            "name": "store-spi",
            "description": "Oak NodeStore and Commit SPI"
         }
      ],
      "created": "2018-08-07 09:08:37",
      "description": "The ValueFactoryImpl has a few static methods that are used to create a {{Value}} from a {{PropertyState}} or {{PropertyValue}}. Those methods should be refactored to make it easier to  add a {{BlobAccessProvider}} for OAK-7569.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Replace usage of static ValueFactoryImpl methods"
   },
   {
      "_id": "13177087",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2018-08-06 12:01:27",
      "description": "Unfortunately, mocking varargs seems to work different in current mockito versions. With the 2:* default from the parent pom, I'm getting the test failure below:\r\n{noformat}\r\n[ERROR] Tests run: 12, Failures: 8, Errors: 0, Skipped: 0, Time elapsed: 0.828 s <<< FAILURE! - in org.apache.jackrabbit.oak.commons.PerfLoggerTest\r\n[ERROR] logAtDebugMessageStartWithInfoLog(org.apache.jackrabbit.oak.commons.PerfLoggerTest)  Time elapsed: 0.045 s  <<< FAILURE!\r\norg.mockito.exceptions.verification.junit.ArgumentsAreDifferent:\r\n\r\nArgument(s) are different! Wanted:\r\nlogger.debug(\r\n    <any string>,\r\n    <any java.lang.Object[]>\r\n);\r\n-> at org.apache.jackrabbit.oak.commons.PerfLoggerTest.verifyDebugInteractions(PerfLoggerTest.java:227)\r\nActual invocation has different arguments:\r\nlogger.debug(\r\n    \"message [took 0ms]\",\r\n    \"argument\"\r\n);\r\n-> at org.apache.jackrabbit.oak.commons.PerfLogger.end(PerfLogger.java:223)\r\n\r\n        at org.apache.jackrabbit.oak.commons.PerfLoggerTest.verifyDebugInteractions(PerfLoggerTest.java:227)\r\n        at org.apache.jackrabbit.oak.commons.PerfLoggerTest.logAtDebugMessageStartWithInfoLog(PerfLoggerTest.java:144)\r\n\r\n\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-commons: upgrade to project default mockito version"
   },
   {
      "_id": "13176090",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-08-01 11:34:04",
      "description": "Often there's the need to transform a type of {{SegmentStore}} (e.g. local TarMK) into *the exact same* counter-part, using another persistence type (e.g. Azure Segment Store). While {{oak-upgrade}} partially solves this through sidegrades (see OAK-7623), there's a gap in the final content because of the level at which {{oak-upgrade}} operates (node store level). Therefore, the resulting sidegraded repository doesn't contain all the (possibly stale, unreferenced) data from the original repository, but only the latest head state. A side effect of this is that the resulting repository is always compacted.\r\n\r\nIntroducing a new command in {{oak-run}}, namely {{segment-copy}}, would allow us to operate at a lower level (i.e. segment persistence), dealing only with constructs from {{org.apache.jackrabbit.oak.segment.spi.persistence}}: journal file, gc journal file, archives and archive entries. This way the only focus of this process would be to \"translate\" a segment between two persistence formats, without caring about the node logic stored inside (referenced/unreferenced node/property).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Introduce oak-run segment-copy for moving around segments in different storages"
   },
   {
      "_id": "13174984",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-07-26 20:31:35",
      "description": "{{AzureCompact}} in {{oak-segment-azure}} follows closely the structure and logic of {{Compact}} in {{oak-segment-tar}}. Since the only thing which differs is the underlying persistence used (remote in Azure vs. local in TAR files), the common logic should be extracted in a super-class, extended by both. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tech-debt",
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor AzureCompact and Compact"
   },
   {
      "_id": "13173120",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2018-07-19 07:26:21",
      "description": "OAK-3865 introduced a strategy to optimize reads from secondaries. This has been superseded by OAK-6087. This task is about removing the old strategy.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove strategy to optimize secondary reads"
   },
   {
      "_id": "13172835",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-07-18 06:05:59",
      "description": "With the changes from OAK-6770 applied, it seems that {{repository.home}} attribute is not correctly set, causing the repository to be written one level up in the directory hierarchy from where it was supposed to.\u00a0",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Revert changes done by OAK-6770"
   },
   {
      "_id": "13172627",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-07-17 11:49:32",
      "description": "This is similar to OAK-3883, but must prevent commits with revisions that are older than already present in the repository. At runtime, this is already taken care of with static fields in the Revision class, but on startup the clock may have jumped into the past since Oak was stopped.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Prevent commits in the past"
   },
   {
      "_id": "13172315",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-07-16 06:43:34",
      "description": "{{oak-run check}}\u00a0should accept Azure URIs for the segment store in order to\u00a0be able to check for data integrity. This will come handy in the light of remote compacted segment stores and/or sidegraded remote segment stores (see OAK-7623, OAK-7459).\r\n\r\nThe Azure URI will be taken as argument and will have the following format:\u00a0{{az:[https://myaccount.blob.core.windows.net/container/repo]}}, where\u00a0_az_\u00a0identifies the cloud provider. The last missing piece is the secret key which will be supplied as an environment variable, i.e.\u00a0_AZURE_SECRET_KEY._",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run check should support Azure Segment Store"
   },
   {
      "_id": "13171335",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2018-07-11 08:23:12",
      "description": "Azure support for segment-tar (OAK-6922) allowed us to plug another storage option for the segment store. Since sometimes there's the need to compare how local vs remote storage behaves, a sidegrade from local tar storage to remote azure storage must be implemented.\r\n\r\nThis would allow us to replicate the exact repository content, changing only the underlying storage mechanism. Analogous to OAK-7459, the Azure Segment Store\u00a0connection details\u00a0will be supplied in the following format:\r\n * an URI with the following format:\u00a0{{az:[https://myaccount.blob.core.windows.net/container/repo]}}, where\u00a0_az_\u00a0identifies the cloud provider\r\n * a secret key supplied as an environment variable, i.e.\u00a0_AZURE_SECRET_KEY._",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "azure",
         "migration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeStore - sidegrade support between TarPersistence and AzurePersistence"
   },
   {
      "_id": "13167181",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-06-20 14:43:15",
      "description": "OAK-3976 introduced a force push of of a journal entry during the commit when the accumulated changes reach 100'000 elements.\r\n\r\nCreating the journal entry however may fail with a DocumentStoreException and fail the commit even though all changes, including the one on the commit root, made it to the DocumentStore.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Commit fails when forced journal push throws exception"
   },
   {
      "_id": "13167093",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-06-20 07:36:41",
      "description": "The persistent cache has an async write mode enabled by default and the write queue is maintained by the CacheActionDispatcher. The queue has a fixed size of 16'384 and is not memory bound. It may happen that the queue retains a lot of memory (multiple GB of heap) when the pending write actions reference big cache values and cause OOME.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4",
         "candidate_oak_1_6",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CacheActionDispatcher not memory bound"
   },
   {
      "_id": "13166027",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2018-06-14 07:31:01",
      "description": "MissingLastRevSeekerTest actually does not run on MongoDB right now, but changing the test accordingly revealed an issue with the MongoDB specific implementation of MissingLastRevSeeker when running on a replica-set and secondary preferred read preference.\r\n\r\nThe class MongoMissingLastRevSeeker uses the configured read preference when checking for cluster node info entries that require recovery. This is inconsistent because the candidate nodes are read with primary read preference.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MissingLastRevSeekerTest fails on MongoDB with secondary preferred"
   },
   {
      "_id": "13155694",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-27 12:22:01",
      "description": "{{oak-run compact}}\u00a0should accept Azure URIs for the segment store in order to enable OffRC for Azure Segment Store.\r\n\r\n-Proposed options to add:-\r\n * -{{azure-connection}}: connection URL to to connect to the Azure Storage-\r\n * -{{azure-container}}: name of the container to use-\r\n * -{{azure-root-path}}: segment store directory-\r\n\r\nThe Azure URI will be taken as argument and will have the following format: {{az:[https://myaccount.blob.core.windows.net/container/repo]}}, where *az*\u00a0identifies the cloud provider. The last missing piece is the secret key which will be supplied as an environment variable, i.e. _AZURE_SECRET_KEY._",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run compact should support Azure Segment Store"
   },
   {
      "_id": "13154803",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-24 13:29:05",
      "description": "The IO tracing facility introduced with OAK-5655 should also be available during normal operation. The idea is to log IO reads intercepted via an {{IOMonitor}} instance to a logger. If {{DEBUG}} logging is not enabled for that logger at the time when the {{FileStore}} is instantiated, then no tracing would take place.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "monitoring",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow collection of IOTraces during normal operation"
   },
   {
      "_id": "13154787",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-04-24 12:26:14",
      "description": "The module oak-store-document currently only uses a single utility method from commons-codec. It shouldn't be too difficult to remove this dependency.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove dependency to commons-codec"
   },
   {
      "_id": "13153315",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-18 10:46:59",
      "description": "It would be useful to expose\u00a0{{writerGroups}} in\u00a0{{SegmentNodeStoreStats}} through an OSGi config property. Since this is a low level configuration related to monitoring, it shouldn't be added to {{SegmentNodeStoreService}}, but to a newly created service, {{SegmentNodeStoreMonitorService}} that would handle exposing monitoring related stuff. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Introduce SegmentNodeStoreMonitorService for exposing writerGroups as an OSGi config property"
   },
   {
      "_id": "13152910",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-17 06:53:58",
      "description": "With guidance from [~mduerig], I recently developed a way to expose Segment Node Store's internal information through the NodeState API. \r\n\r\nThe concept is similar in spirit to the proc file system in Linux: the proc subtree exposes internal information in a straightforward manner, enabling consumers to rely on a well-understood API to access the data. This proc subtree shelters tooling from variations of the internal APIs of the Segment Store. As long as the data exported through the proc subtree is stable, the same tools are going to work across different versions of the Segment Store with minimal to no modifications.\r\n\r\nThe proc subtree has been developed in [this branch on GitHub|https://github.com/francescomari/jackrabbit-oak/tree/proc]. I created this issue in order to review the work done so far, and to track the contribution of the proc subtree in Oak.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Contribute a 'proc' subtree for the Segment Node Store"
   },
   {
      "_id": "13151579",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-11 08:05:29",
      "description": "[http://svn.apache.org/viewvc?view=revision&revision=1827841] introduced utility classes to collect IO traces. See e.g. https://issues.apache.org/jira/browse/OAK-5655?focusedCommentId=16415730&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16415730. Currently the only way to run such traces is via code or JUnit (see {{IOTracerRunner}}).\r\n\r\nGoing forward we should wire this functionality to {{oak-run}} to make it more generally useful. \r\n\r\n\u00a0\r\n\r\n[~frm], FYI.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose UI for collecting IO traces"
   },
   {
      "_id": "13151561",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-04-11 06:30:29",
      "description": "In some cases no persisted branch is created by the DocumentNodeStore when the number of changes hit the update limit. This happens when the current branch state is in-memory and the commit hook contributes changes that reach the update limit. The implementation keeps those changes in memory, which may lead to a commit way bigger than specified by the update limit.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6",
         "candidate_oak_1_8"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Changes kept in memory when update limit is hit in commit hook"
   },
   {
      "_id": "13149438",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-04-02 08:55:03",
      "description": "The current \"CommitsCountPerWriter\" stats exposed by {{SegmentNodeStoreStats}} are hard to follow since there can be too many writers at a time. To improve this, a more coarse-grained version of this metric should be added, in which commits are recorded for groups of threads. The groups should be configurable and represent regexes to be matched by individual thread names. An additional group (i.e. \"other\") will group all threads not matching any of the defined group regexes. \r\n\r\nThe current behaviour will be split in two:\r\n* \"CommitsCountOtherThreads\" will expose a snapshot of threads currently in \"other\" group\r\n* \"CommitsCountPerGroup\" will expose an aggregate of commits count per thread group for the previous minute.\r\n\r\nBoth metrics will be reset each minute.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeStoreStats should expose stats for previous minute per thread group"
   },
   {
      "_id": "13146525",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2018-03-20 12:09:46",
      "description": "The {{MongoDocumentStore}} currently uses the old API in {{com.mongodb}}. Starting with MongoDB Java driver 3.0 a new client API was introduced in {{com.mongodb.client}}. New features like client sessions are only available in the new API and MongoDB may remove some deprecated methods/classes/interfaces in the future. The implementation should be migrated to the new client API.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Migrate to the MongoDB Java driver API 3.0"
   },
   {
      "_id": "13144981",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-03-14 10:02:29",
      "description": "Due to duplicate registration of {{SegmentNodeStoreStats}} in both {{SegmentNodeStore}}  and {{LockBasedScheduler}}, we end up with two instances of this MBean. The former gets exposed via JMX and always returns empty tables for CommitsCountPerWriter and QueuedWriters, while the latter correctly tracks these data, but is not exposed. To address this, we should stick to only one instance of {{SegmentNodeStoreStats}}, used in both {{SegmentNodeStore}} and {{LockBasedScheduler}}.\r\n\r\nWhile at this, two additional points to be addressed:\r\n# {{CommitsTracker}} needs to be unit tested\r\n# commits count map size needs to be configurable via {{SegmentNodeStoreStats}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CommitsTracker data is always empty when exposed via JMX"
   },
   {
      "_id": "13144371",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-03-12 16:51:18",
      "description": "We should transform {{CacheWeightEstimator}} from a stand-alone utility into a unit test such that we can regularly run in on a CI.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Transform CacheWeightEstimator into a unit test"
   },
   {
      "_id": "13143234",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-03-07 14:40:04",
      "description": "Support for long ids of external blobs where introduces with OAK-3107.\u00a0{{SegmentParser.parseBlob()}} is still oblivious about them.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentParser#parseBlob does not long ids of external blobs"
   },
   {
      "_id": "13141749",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-03-01 10:00:43",
      "description": "OAK-4707 introduced logging at debug logging to the system console for sorting out test failures on Jenkins. Since we haveen't seen these failures for a while and that issue is fixed I would like to remove the extra logging again to avoid cluttering the console unnecessarily.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove debug logging to the console during tests"
   },
   {
      "_id": "13137875",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-02-12 14:22:03",
      "description": "When investigating the performance of\u00a0 {{segment-tar}}, the source of the writes (commits) is a very useful indicator of the cause.\r\n\r\nTo better understand which threads are currently writing in the repository and which are blocked on the semaphore, we need to improve {{SegmentNodeStoreStats}} to:\r\n * expose the number of commits executed per thread\r\n * expose threads currently waiting on the semaphore",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve SegmentNodeStoreStats to include number of commits per thread and threads currently waiting on the semaphore"
   },
   {
      "_id": "13136571",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-02-06 14:14:57",
      "description": "With OAK-5595 we have enabled deep traversals by default when using the check command. At the same time we have deprecated the --{{deep}}\u00a0option.\r\n\r\nSince all these happened for {{1.8}}, the next logical step to do for {{1.10}} is to remove this option altogether.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove deprecated deep option from check command"
   },
   {
      "_id": "13135379",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-02-01 10:52:00",
      "description": "Analyze and further reduce calls to the DocumentStore when content is written to the repository. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce calls to DocumentStore"
   },
   {
      "_id": "13135038",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-31 10:29:01",
      "description": "{{oak-run check}}\u00a0does currently\u00a0*not*\u00a0check the checksums of the segments. As a consequence, there is no quick way of determining the\u00a0state of the repository (corrupt/valid), after corrupting some random node record, as we currently do in {{CheckRepositoryTestBase#corruptRecord}}. To determine that, there needs to be an attempt to read the corrupt record as part of a traversal.\r\n\r\nAn easier way would be to have a new dedicated option for this (i.e., {{--segments}}) which checks by default the content of segments against the checksums from all the tar files in the specified location. Additionally, it could accept as an argument a list of tar files, the segments of which to be checked.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run check should have an option to check the segments checksums"
   },
   {
      "_id": "13134479",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-01-29 15:46:48",
      "description": "The persistent cache currently stores binaries up to one MB by default. However most of the BlobStore implementations already provide some form of caching. E.g. for S3 a cache on the local filesystem is maintained and when using a Jackrabbit FileDataStore the persistent cache is actually unnecessary.\r\n\r\nSupport for documents in the persistent cache should also be removed. In contrast to other cache entries, documents are mutable and may cause consistency issues when enabled with the persistent cache. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove support for binaries and documents in persistent cache"
   },
   {
      "_id": "13134438",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-29 12:39:03",
      "description": "{{SegmentOverflowExceptionIT}} potentially consumes a lot of disk space. Running it for 10 minutes on a AWS m4.4xlarge instance with 900 / 3000 IOPS resulted in 80GB being taken up. \r\nCurrently the test can be time boxed but not size boxed. I suggest to add another option to cap the repository size in addition to the existing {{-Dtimeout}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add configurable repository size cap to SegmentOverflowExceptionIT"
   },
   {
      "_id": "13134388",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2018-01-29 08:48:43",
      "description": "When nodes are bundled in a document, the DocumentNodeStore keeps track of whether all children are included in a document. The presence of the hidden {{:doc-has-child-non-bundled}} property indicates there are non bundled child nodes. For the case when a document contains all children in the bundle, the DocumentNodeStore still does a find call on the DocumentStore when asked for an unknown child node.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bundling",
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Avoid call for child node when bundle contains all children"
   },
   {
      "_id": "13133362",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2018-01-24 13:37:15",
      "description": "In some cases a call to {{Node.getMixinNodeTypes()}} may result in a check whether there is a child node named {{jcr:mixinTypes}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Node.getMixinNodeTypes() may check for child node named jcr:mixinTypes"
   },
   {
      "_id": "13132712",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-22 13:40:37",
      "description": "See https://google.github.io/guava/releases/19.0/api/docs/com/google/common/util/concurrent/Futures.html#transform(com.google.common.util.concurrent.ListenableFuture,%20com.google.common.util.concurrent.AsyncFunction)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "guava: ListenableFuture.transform() changes to transformAsync in version 20"
   },
   {
      "_id": "13131603",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12333607",
            "id": "12333607",
            "name": "oak-run"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-17 15:05:40",
      "description": "We should review and update the documentation of [{{oak-run check}}|http://jackrabbit.apache.org/oak/docs/nodestore/segment/overview.html#check]. E.g. to include the new options from OAK-6373.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Update documentation for oak-run check"
   },
   {
      "_id": "13131600",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-17 15:01:58",
      "description": "Currently the [TarMK documentation|http://jackrabbit.apache.org/oak/docs/nodestore/segment/overview.html#monitoring-via-jmx] only mentions {{SegmentRevisionGarbageCollection}}. We should review that paragraph and also include documentation for all other relevant JMX endpoints.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document TarMK specific MBeans"
   },
   {
      "_id": "13131220",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-16 12:17:50",
      "description": "There is a race condition on {{TarRevisions#head}} between a running compaction trying to set the new head [0] and the scheduler doing the same after executing a specific commit [1]. If the compaction thread is first, then the head assignment in the scheduler will fail and not be re-attempted. \r\n\r\nIMO, the simple if statement should be changed to a while loop in which the head is refreshed and the commit is re-applied against the new head, before attempting again to set a new head in {{TarRevisions}}. This is somehow similar to what we previously had [2], but without the unneeded optimistic/pessimistic strategies involving tokens.\r\n\r\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/FileStore.java#L764\r\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/scheduler/LockBasedScheduler.java#L253\r\n[2] https://github.com/apache/jackrabbit-oak/blob/1.6/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentNodeStore.java#L686",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Race condition on revisions head between compaction and scheduler could result in skipped commit"
   },
   {
      "_id": "13129793",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2018-01-10 09:44:03",
      "description": "In some cases we observed a {{SNFE}} right after a the cleanup following a full compaction:\r\n\r\n{noformat}\r\n31.12.2017 04:25:19.816 *ERROR* [pool-17-thread-22] org.apache.jackrabbit.oak.segment.SegmentNotFoundExceptionListener Segment not found: a82a99a3-f1e9-49b7-a1e0-55e7fec80c41. SegmentId age=609487478ms,segment-generation=GCGeneration{generation=4,fullGeneration=2,isCompacted=true}\r\norg.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment a82a99a3-f1e9-49b7-a1e0-55e7fec80c41 not found\r\n        at org.apache.jackrabbit.oak.segment.file.AbstractFileStore.readSegmentUncached(AbstractFileStore.java:276)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.lambda$readSegment$5(FileStore.java:478)\r\n        at org.apache.jackrabbit.oak.segment.SegmentCache.lambda$getSegment$0(SegmentCache.java:116)\r\n        at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724)\r\n        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522)\r\n        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315)\r\n        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278)\r\n        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193)\r\n        at com.google.common.cache.LocalCache.get(LocalCache.java:3932)\r\n        at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721)\r\n        at org.apache.jackrabbit.oak.segment.SegmentCache.getSegment(SegmentCache.java:113)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:478)\r\n        at org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:154)\r\n        at org.apache.jackrabbit.oak.segment.CachingSegmentReader$1.apply(CachingSegmentReader.java:94)\r\n        at org.apache.jackrabbit.oak.segment.CachingSegmentReader$1.apply(CachingSegmentReader.java:90)\r\n        at org.apache.jackrabbit.oak.segment.ReaderCache.get(ReaderCache.java:118)\r\n        at org.apache.jackrabbit.oak.segment.CachingSegmentReader.readString(CachingSegmentReader.java:90)\r\n        at org.apache.jackrabbit.oak.segment.MapRecord.getEntry(MapRecord.java:220)\r\n        at org.apache.jackrabbit.oak.segment.MapRecord.getEntry(MapRecord.java:173)\r\n        at org.apache.jackrabbit.oak.segment.SegmentNodeState.getChildNode(SegmentNodeState.java:423)\r\n        at org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.<init>(MemoryNodeBuilder.java:143)\r\n        at org.apache.jackrabbit.oak.segment.SegmentNodeBuilder.<init>(SegmentNodeBuilder.java:93)\r\n        at org.apache.jackrabbit.oak.segment.SegmentNodeBuilder.createChildBuilder(SegmentNodeBuilder.java:148)\r\n        at org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.getChildNode(MemoryNodeBuilder.java:331)\r\n        at org.apache.jackrabbit.oak.core.SecureNodeBuilder.<init>(SecureNodeBuilder.java:112)\r\n        at org.apache.jackrabbit.oak.core.SecureNodeBuilder.getChildNode(SecureNodeBuilder.java:329)\r\n        at org.apache.jackrabbit.oak.core.MutableTree.getTree(MutableTree.java:290)\r\n        at org.apache.jackrabbit.oak.core.MutableRoot.getTree(MutableRoot.java:220)\r\n        at org.apache.jackrabbit.oak.core.MutableRoot.getTree(MutableRoot.java:69)\r\n        at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.getItem(SessionDelegate.java:442)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl.getItemInternal(SessionImpl.java:167)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl.access$400(SessionImpl.java:82)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl$3.performNullable(SessionImpl.java:229)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl$3.performNullable(SessionImpl.java:226)\r\n        at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.performNullable(SessionDelegate.java:243)\r\n        at org.apache.jackrabbit.oak.jcr.session.SessionImpl.getItemOrNull(SessionImpl.java:226)\r\n{noformat}\r\n\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "SNFE after full compaction"
   },
   {
      "_id": "13126821",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-12-22 14:17:46",
      "description": "Improve monitoring section of cold standby in {{oak-doc}} to include missing MBean screenshots.\r\n\r\n-[~mduerig], [~frm]: How about adding a *Benchmarking* section to the cold standby page covering a bit ways to use the new {{Oak-Segment-Tar-Cold}} fixture and also running {{ScalabilityStandbySuite}} on top of it?-",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Update documentation for cold standby"
   },
   {
      "_id": "13126227",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-20 09:24:53",
      "description": "When compaction starts it should also log the current gc generation and the new gc generation it is going to create. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Compaction should log generation info"
   },
   {
      "_id": "13125964",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-19 16:41:02",
      "description": "When starting on an Oak 1.6 repository and the {{gc.log}} file is present the TarMK fails with:\r\n{noformat}\r\njava.lang.ArrayIndexOutOfBoundsException: 5\r\n        at org.apache.jackrabbit.oak.segment.file.GCJournal$GCJournalEntry.parseString(GCJournal.java:217)\r\n        at org.apache.jackrabbit.oak.segment.file.GCJournal$GCJournalEntry.fromString(GCJournal.java:204)\r\n        at org.apache.jackrabbit.oak.segment.file.GCJournal.read(GCJournal.java:115)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.compact(FileStore.java:750)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.compactFull(FileStore.java:731)\r\n        at org.apache.jackrabbit.oak.segment.file.FileStore.compactFull(FileStore.java:385)\r\n        at org.apache.jackrabbit.oak.segment.tool.Compact.run(Compact.java:273)\r\n        at org.apache.jackrabbit.oak.run.CompactCommand.execute(CompactCommand.java:72)\r\n        at org.apache.jackrabbit.oak.run.Main.main(Main.java:49)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "migration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "ArrayIndexOutOfBoundsException when upgrading from Oak 1.6"
   },
   {
      "_id": "13125830",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-12-19 09:07:54",
      "description": "The newly introduced {{Segment-Tar-Cold}} fixture should support secure communication between primary and standby via a {{--secure}} option. Moreover, the current implementation allows only for continuous sync between primary and standby. It should be possible to allow a \"one-shot run\" of the sync to easily measure and compare specific metrics ({{--oneShotRun}} option).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Segment-Tar-Cold fixture should have options for secure communication and one shot runs"
   },
   {
      "_id": "13125593",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-18 10:47:03",
      "description": "Ensure {{oak-doc}} is up to date with the current version of {{oak-run compact}}, its current command line arguments and system properties. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document oak-run compact arguments and system properties"
   },
   {
      "_id": "13124683",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-13 14:09:31",
      "description": "When {{oak-run compact}} gets cancelled because running out of disk space it will send a corresponding warning to the logs and bail out. However on the console it will still report success. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "production",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run compact reports success even when it was cancelled"
   },
   {
      "_id": "13124679",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-13 14:05:42",
      "description": "Currently the Segment dump created in {{Segment.toString}} includes a list of records with their offsets. However these offsets do no match the ones in the subsequent raw byte dump of the segment. We should add a raw offsets to the list of records so finding the actual data that belongs to a record doesn't involve manually fiddling with logical / physical offset translation. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Segment.toString: Record table should include an index into the hexdump"
   },
   {
      "_id": "13124359",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2017-12-12 13:02:53",
      "description": "{{oak-doc/src/site/markdown/command_line.md}} refers to the {{compress-interval}} system property, which does not exist any more. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove dangling reference to compress-interval system property from oak-run documentation"
   },
   {
      "_id": "13124338",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-12-12 11:00:34",
      "description": "Offline compaction can corrupt the repository in some cases: when offline compaction is cancelled by the {{CancelCompactionSupplier}} the corresponding return value is not correctly passed up the call chain resulting in a incomplete compacted head state being set as the compacted head state (instead of being discarded). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "corruption",
         "data-corruption"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Offline compaction corrupts repository"
   },
   {
      "_id": "13122808",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-12-05 08:52:10",
      "description": "Seen on an internal Windows Jenkins node:\r\n\r\nh3. Regression\r\n\r\norg.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT.testSyncFailingDueToTooShortTimeout\r\n\r\nh3. Error Message\r\n\r\n{noformat}\r\nValues should be different. Actual: { root = { ... } }\r\n{noformat}\r\n\r\nh3. Stacktrace\r\n\r\n{noformat}\r\njava.lang.AssertionError: Values should be different. Actual: { root = { ... } }\r\n\tat org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT.testSyncFailingDueToTooShortTimeout(ExternalPrivateStoreIT.java:87)\r\n{noformat}\r\n\r\nh3. Standard Output\r\n\r\n{noformat}\r\n22:41:13.646 INFO  [main] FileStoreBuilder.java:340         Creating file store FileStoreBuilder{version=1.8-SNAPSHOT, directory=target\\junit2834122541179880349\\junit3041268421527563090, blobStore=DataStore backed BlobStore [org.apache.jackrabbit.core.data.FileDataStore], maxFileSize=1, segmentCacheSize=0, stringCacheSize=0, templateCacheSize=0, stringDeduplicationCacheSize=15000, templateDeduplicationCacheSize=3000, nodeDeduplicationCacheSize=1, memoryMapping=false, gcOptions=SegmentGCOptions{paused=false, estimationDisabled=false, gcSizeDeltaEstimation=1073741824, retryCount=5, forceTimeout=60, retainedGenerations=2, gcType=FULL}}\r\n22:41:13.646 INFO  [main] FileStore.java:241                TarMK opened at target\\junit2834122541179880349\\junit3041268421527563090, mmap=false, size=0 B (0 bytes)\r\n22:41:13.646 DEBUG [main] FileStore.java:247                TAR files: TarFiles{readers=[],writer=target\\junit2834122541179880349\\junit3041268421527563090\\data00000a.tar}\r\n22:41:13.646 DEBUG [main] TarWriter.java:185                Writing segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a to target\\junit2834122541179880349\\junit3041268421527563090\\data00000a.tar\r\n22:41:13.646 INFO  [main] FileStoreBuilder.java:340         Creating file store FileStoreBuilder{version=1.8-SNAPSHOT, directory=target\\junit2834122541179880349\\junit4470899745425503556, blobStore=DataStore backed BlobStore [org.apache.jackrabbit.core.data.FileDataStore], maxFileSize=1, segmentCacheSize=0, stringCacheSize=0, templateCacheSize=0, stringDeduplicationCacheSize=15000, templateDeduplicationCacheSize=3000, nodeDeduplicationCacheSize=1, memoryMapping=false, gcOptions=SegmentGCOptions{paused=false, estimationDisabled=false, gcSizeDeltaEstimation=1073741824, retryCount=5, forceTimeout=60, retainedGenerations=2, gcType=FULL}}\r\n22:41:13.646 INFO  [main] FileStore.java:241                TarMK opened at target\\junit2834122541179880349\\junit4470899745425503556, mmap=false, size=0 B (0 bytes)\r\n22:41:13.646 DEBUG [main] FileStore.java:247                TAR files: TarFiles{readers=[],writer=target\\junit2834122541179880349\\junit4470899745425503556\\data00000a.tar}\r\n22:41:13.646 DEBUG [main] TarWriter.java:185                Writing segment 8d19c7dc-8b48-4e10-a58d-31c15c93f2fe to target\\junit2834122541179880349\\junit4470899745425503556\\data00000a.tar\r\n22:41:13.646 INFO  [main] DataStoreTestBase.java:127        Test begin: testSyncFailingDueToTooShortTimeout\r\n22:41:13.646 INFO  [main] SegmentNodeStore.java:120         Creating segment node store SegmentNodeStoreBuilder{blobStore=DataStore backed BlobStore [org.apache.jackrabbit.core.data.FileDataStore]}\r\n22:41:13.646 INFO  [main] LockBasedScheduler.java:155       Initializing SegmentNodeStore with the commitFairLock option enabled.\r\n22:41:13.708 DEBUG [main] StandbyServer.java:248            Binding was successful\r\n22:41:13.708 DEBUG [main] TarWriter.java:185                Writing segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to target\\junit2834122541179880349\\junit3041268421527563090\\data00000a.tar\r\n22:41:13.739 DEBUG [main] TarRevisions.java:240             TarMK journal update null -> 4a5183bd-bcdf-41ab-a557-6f19143bbc91.0000000c\r\n22:41:13.755 DEBUG [standby-1] GetHeadRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for current head\r\n22:41:13.755 DEBUG [primary-1] ClientFilterHandler.java:53  Client /127.0.0.1:65480 is allowed\r\n22:41:13.755 DEBUG [primary-1] RequestDecoder.java:42       Parsed 'get head' message\r\n22:41:13.755 DEBUG [primary-1] CommunicationObserver.java:120 Message 'get head' received from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.755 DEBUG [primary-1] GetHeadRequestHandler.java:43 Reading head for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.755 DEBUG [primary-1] GetHeadResponseEncoder.java:36 Sending head 4a5183bd-bcdf-41ab-a557-6f19143bbc91.0000000c to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.755 DEBUG [standby-1] ResponseDecoder.java:82      Decoding 'get head' response\r\n22:41:13.755 DEBUG [standby-run-23] StandbyClientSyncExecution.java:103 Found missing segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91\r\n22:41:13.755 DEBUG [standby-run-23] StandbyClientSyncExecution.java:124 Inspecting segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91\r\n22:41:13.755 DEBUG [standby-1] GetReferencesRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for references of segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91\r\n22:41:13.755 DEBUG [primary-1] RequestDecoder.java:48       Parsed 'get references' message\r\n22:41:13.771 DEBUG [primary-1] GetReferencesRequestHandler.java:39 Reading references of segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetReferencesResponseEncoder.java:34 Sending references of segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [standby-1] ResponseDecoder.java:94      Decoding 'get references' response\r\n22:41:13.771 DEBUG [standby-run-23] StandbyClientSyncExecution.java:184 Found reference from 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to 4cea1684-ef05-44f5-a869-3ef2df6e0c9a\r\n22:41:13.771 DEBUG [standby-run-23] StandbyClientSyncExecution.java:124 Inspecting segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a\r\n22:41:13.771 DEBUG [standby-1] GetReferencesRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for references of segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a\r\n22:41:13.771 DEBUG [primary-1] RequestDecoder.java:48       Parsed 'get references' message\r\n22:41:13.771 DEBUG [primary-1] GetReferencesRequestHandler.java:39 Reading references of segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetReferencesResponseEncoder.java:34 Sending references of segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [standby-1] ResponseDecoder.java:94      Decoding 'get references' response\r\n22:41:13.771 INFO  [standby-run-23] StandbyClientSyncExecution.java:196 Copying data segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a from primary\r\n22:41:13.771 DEBUG [standby-1] GetSegmentRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a\r\n22:41:13.771 DEBUG [primary-1] RequestDecoder.java:45       Parsed 'get segment' message\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:120 Message 'get segment' received from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetSegmentRequestHandler.java:39 Reading segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:125 Segment with size 192 sent to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetSegmentResponseEncoder.java:43 Sending segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [standby-1] ResponseDecoder.java:86      Decoding 'get segment' response\r\n22:41:13.771 DEBUG [standby-run-23] TarWriter.java:185      Writing segment 4cea1684-ef05-44f5-a869-3ef2df6e0c9a to target\\junit2834122541179880349\\junit4470899745425503556\\data00000a.tar\r\n22:41:13.771 INFO  [standby-run-23] StandbyClientSyncExecution.java:196 Copying data segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 from primary\r\n22:41:13.771 DEBUG [standby-1] GetSegmentRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91\r\n22:41:13.771 DEBUG [primary-1] RequestDecoder.java:45       Parsed 'get segment' message\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:120 Message 'get segment' received from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetSegmentRequestHandler.java:39 Reading segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:125 Segment with size 448 sent to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetSegmentResponseEncoder.java:43 Sending segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [standby-1] ResponseDecoder.java:86      Decoding 'get segment' response\r\n22:41:13.771 DEBUG [standby-run-23] TarWriter.java:185      Writing segment 4a5183bd-bcdf-41ab-a557-6f19143bbc91 to target\\junit2834122541179880349\\junit4470899745425503556\\data00000a.tar\r\n22:41:13.771 DEBUG [standby-1] GetBlobRequestEncoder.java:33 Sending request from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90 for blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.771 DEBUG [primary-1] RequestDecoder.java:39       Parsed 'get blob' request\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:120 Message 'get blob id' received from client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetBlobRequestHandler.java:41 Reading blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 for client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] CommunicationObserver.java:130 Binary with size 5242880 sent to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.771 DEBUG [primary-1] GetBlobResponseEncoder.java:41 Sending blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.786 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 1/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.802 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 2/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.802 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.802 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 1/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.802 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.802 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 3/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.802 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 2/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.818 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 4/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 3/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.818 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.818 DEBUG [primary-1] ChunkedBlobStream.java:128   Sending chunk 5/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880 to client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 4/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:90      Decoding 'get blob' response\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:150     Received chunk 5/5 of size 1048576 from blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:159     All checks OK. Appending chunk to disk to C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp \r\n22:41:13.833 DEBUG [standby-1] ResponseDecoder.java:167     Received entire blob c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880\r\n22:41:13.880 DEBUG [standby-run-23] ResponseDecoder.java:66 Processing input stream finished! Deleting file C:\\Windows\\TEMP\\c3ac16ad0c8bc3a3ff30cef8e296af92d53058c13a8930406d3f08e271b4b57b#5242880.tmp\r\n22:41:13.896 DEBUG [standby-run-23] TarRevisions.java:240   TarMK journal update null -> 4a5183bd-bcdf-41ab-a557-6f19143bbc91.0000000c\r\n22:41:13.911 WARN  [standby-1] ExceptionHandler.java:37     Exception caught on client 9aa63ed8-347b-4f00-ae7c-f984e0623e90\r\nio.netty.handler.timeout.ReadTimeoutException: null\r\n22:41:13.911 INFO  [standby-run-23] StandbyClientSyncExecution.java:82 updated head state successfully: true in 156ms.\r\n22:41:13.911 DEBUG [standby-run-23] StandbyClient.java:157  Channel closed\r\n22:41:16.137 DEBUG [main] StandbyClientSync.java:277        Group shut down\r\n22:41:16.137 DEBUG [main] StandbyServer.java:219            Channel disconnected\r\n22:41:16.137 DEBUG [main] StandbyServer.java:219            Channel disconnected\r\n22:41:16.137 DEBUG [main] StandbyServer.java:230            Boss group shut down\r\n22:41:16.137 DEBUG [main] StandbyServer.java:236            Worker group shut down\r\n22:41:16.137 INFO  [main] DataStoreTestBase.java:132        Test end: testSyncFailingDueToTooShortTimeout\r\n22:41:16.137 DEBUG [main] Scheduler.java:134                The scheduler FileStore background tasks was successfully shut down\r\n22:41:16.137 DEBUG [main] TarRevisions.java:236             Head state did not change, skipping flush\r\n22:41:16.184 INFO  [main] FileStore.java:480                TarMK closed: target\\junit2834122541179880349\\junit4470899745425503556\r\n22:41:16.184 DEBUG [main] Scheduler.java:134                The scheduler FileStore background tasks was successfully shut down\r\n22:41:16.184 DEBUG [main] TarRevisions.java:236             Head state did not change, skipping flush\r\n22:41:16.199 INFO  [main] FileStore.java:480                TarMK closed: target\\junit2834122541179880349\\junit3041268421527563090\r\n{noformat}\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ExternalPrivateStoreIT.testSyncFailingDueToTooShortTimeout"
   },
   {
      "_id": "13121939",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-30 15:23:28",
      "description": "Since OAK-6883, FULL estimation compares segmentstore size with the previous FULL. There can be cases where the current segmentstore is smaller than the previous FULL (i.e. due to TAIL cleaning up more). This leads to FULL being skipped for much more than anticipated.\r\n\r\nA case to illustrate this scenario:\r\n\r\n    Start Oak with a 10 GB repo\r\n    GC #1: run FULL results in segmenstore of 20GB\r\n    GC #2: run TAIL results in segmentstore of 11GB\r\n    GC #3: run FULL (saturday) - skipped because the reference is 20GB from the previous FULL\r\n\r\nFULL be executed again only when the segmentstore grows back above 20GB, which might be too late.\r\n\r\nEstimation should take this situation into account this and take a better decision.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Estimation for FULL can be off sometimes"
   },
   {
      "_id": "13120892",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-27 11:00:15",
      "description": "We have seen unusual high read IO in compaction retry cycles in our longevity tests at Adobe.\r\n\r\n!cpu.png|width=1000!\r\n\r\nAbove picture shows the CPU utilisation during an online compaction run, which starts at 03:00. At about 03:22 CPU user time drops and CPU waiting for IO time increases. This point in time coincides with the start of the first retry cycle of compaction. \r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "High read IO in compaction retry cycles"
   },
   {
      "_id": "13120406",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-23 08:10:31",
      "description": "{noformat}\r\nINFO] Running org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\r\n[WARNING] Corrupted STDOUT by directly writing to native stream in forked JVM 1. See FAQ web page and the dump file C:\\projects\\apache\\oak\\trunk\\oak-segment-tar\\target\\failsafe-reports\\2017-11-23T08-48-55_999-jvmRun1.dumpstream\r\n[ERROR] Tests run: 4, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 17.984 s <<< FAILURE! - in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\r\n[ERROR] offRCUpgradesSegments(org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT)  Time elapsed: 5.024 s  <<< FAILURE!\r\njava.lang.AssertionError: Segment version mismatch. Expected V_13, found V_12 expected:<V_13> but was:<V_12>\r\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.checkSegmentVersion(UpgradeIT.java:143)\r\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.offRCUpgradesSegments(UpgradeIT.java:108)\r\n\r\n{noformat}\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "test failure seen in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT"
   },
   {
      "_id": "13119685",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-20 15:17:59",
      "description": "We need to add documentation of tail compaction:\r\n* What is it, how does it work?\r\n* How is it configured and scheduled?\r\n* How can it be monitored, what are the related log entries?\r\n* What are its limitations?\r\n* What if it fails?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document tail compaction"
   },
   {
      "_id": "13117925",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-13 12:49:01",
      "description": "The {{-Dcache}} option currently has no effect when used in conjunction with the {{compact}} run mode of {{oak-run}}. However we should enable users to configure the segment cache size through this option if necessary. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Enable the -Dcache of offline compaction"
   },
   {
      "_id": "13116641",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-11-07 11:47:37",
      "description": "The changes to the segment cache introduced in r1793527 [0] introduced a performance regression on the primary for the case in which a standby is attached to it. Below a benchmark duration comparison between primary w/o and w/ standby for r1793527 (after the segment cache changes) and r1793526 (before the changes) :\r\n\r\n|Oak 1.6 r1793527 (20170502)|{noformat}\r\n# BasicWriteTest                   C     min     10%     50%     90%     max       N\r\nOak-Segment-Tar                    1      19      21      22      26     160    2491\r\nOak-Segment-Tar-DS                 1      56      59      63      70     181     919\r\nOak-Segment-Tar-Cold(Shared DS)    1      58      66     159     177     372     302\r\n{noformat}|\r\n|Oak 1.6 r1793526 (20170502)|{noformat}\r\n# BasicWriteTest                   C     min     10%     50%     90%     max       N\r\nOak-Segment-Tar                    1      19      21      22      25      52    2584\r\nOak-Segment-Tar-DS                 1      56      60      63      69     158     925\r\nOak-Segment-Tar-Cold(Shared DS)    1      57      60      64      70     122     915\r\n{noformat}|\r\n\r\n[0] https://github.com/apache/jackrabbit-oak/commit/efafa4e1710621b7f3b8e92d0b2681669185fcd4",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby",
         "performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cold standby performance regression due to segment caching"
   },
   {
      "_id": "13116579",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-07 04:55:40",
      "description": "SegmentNodeStore currently inlines binaries of size less that 16KB (Segment.MEDIUM_LIMIT) even if external BlobStore is configured. \r\n\r\nDue to this behaviour quite a bit of segment tar storage consist of blob data. In one setup out of 370 GB segmentstore size 290GB is due to inlined binary. If most of this binary content is moved to BlobStore then it would allow same repository to work better in lesser RAM\r\n\r\nSo it would be useful if some way is provided to disable this default behaviour and let BlobStore take control of inline size i.e. in presence of BlobStore no inlining is attempted by SegmentWriter.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide a way to tune inline size while storing binaries"
   },
   {
      "_id": "13116445",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-06 16:38:38",
      "description": "The offline compaction tool should do an effort to detect whether it is being run on windows and disable memory mapping if so. Rational: with memory mapping enabled it might fail to remove the old tar files (see OAK-4274 and [JDK-4724038|http://bugs.java.com/view_bug.do?bug_id=4724038]).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction should not use mmap on Windows"
   },
   {
      "_id": "13116443",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-06 16:32:51",
      "description": "When {{FileStore.compact()}} returns the {{journal.log}} does not necessarily contain the head created by the compactor. This can lead to problems downstream like e.g. in OAK-6894 where the compactor tool wrote the wrong (i.e. uncompacted) head to the {{journal.log}}. \r\n\r\nProposed fix is to call on of the {{FileStore.flush()}} methods after compaction and add a test case that verifies the {{journal.log}} contains the correct head state. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "FileStore.compact does not persist compacted head to journal"
   },
   {
      "_id": "13115677",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-11-02 16:58:12",
      "description": "After the netty upgrade in OAK-6564, there's a recurring warning appearing in the server thread:\r\n{noformat}\r\n18:54:44.691 [main] WARN  io.netty.bootstrap.ServerBootstrap - Unknown channel option 'TCP_NODELAY' for channel '[id: 0xa64bc5c4]'\r\n{noformat}\r\n\r\nWe need to see what's causing it (i.e. was that option removed in the latest version? if yes, is there a substitute/change needed?).\r\n\r\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Unknown channel option 'TCP_NODELAY' for channel warning in cold standby"
   },
   {
      "_id": "13115540",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-11-02 04:32:10",
      "description": "It would be useful if we can log the segmentstore size at time of startup. FileStore already computes the size to initialize the FileStoreStats so we just need to log it\r\n\r\nThis size often help when customer report issues and provide log files",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Log SegmentStore size at startup"
   },
   {
      "_id": "13113327",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-31 15:28:15",
      "description": "The background threads used in {{FileStore}} are implemented by wrapping {{Runnable}} instances in {{SafeRunnable}}, and by handing the {{SafeRunnable}} instances over to a {{ScheduledExecutorService}}. \r\n\r\nThe documentation of {{ScheduledExecutorService#scheduleAtFixedRate}} states that \"if any execution of a task takes longer than its period, then subsequent executions may start late, but will not concurrently execute\". This means that if an execution is delayed, the piled up executions might fire in rapid succession.\r\n\r\nThis way of running the periodic background threads might not be ideal. For example, it doesn't make much sense to flush the File Store five times in a row. On the other hand, if the background tasks are coded with this caveat in mind, this issue might not be a problem at all. For example, flushing the File Store five times in a row might not be a problem if many of those executions don't do much and return quickly.\r\n\r\nTasks piling up might be a problem when it comes to release the resource associated with the {{FileStore}} in a responsive way. Since the {{ScheduledExecutorService}} is gracefully shut down, it might take some time before all the scheduled background tasks are processed and the {{ScheduledExecutorService}} is ready to be terminated.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Executions of background threads might pile up"
   },
   {
      "_id": "13113323",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-31 15:13:59",
      "description": "The background threads used in {{FileStore}} are implemented by wrapping {{Runnable}} instances in {{SafeRunnable}}, and by handing the {{SafeRunnable}} instances over to a {{ScheduledExecutorService}}. \r\n\r\nThe documentation of {{ScheduledExecutorService#scheduleAtFixedRate}} states that \"if any execution of the task encounters an exception, subsequent executions are suppressed\". But a {{SafeRunnable}} always re-throws any {{Throwable}} that it catches, effectively preventing itself from executing again in the future.\r\n\r\nThere is more than one solution to this problem. One of these is to never re-throw any exception. Even if it doesn't always make sense, e.g. in case of an {{OutOfMemoryError}}, never re-throwing an exception would better fulfil the assumption that background threads should always be up and running even in case of error.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Background threads might not be automatically restarted"
   },
   {
      "_id": "13113277",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-31 10:57:49",
      "description": "After an offline compaction the {{gc.log}} always contains 0 for the number of compacted nodes. This is caused by {{org.apache.jackrabbit.oak.segment.tool.Compact.compact()}} instantiating a new {{FileStore}} to run cleanup. That file store has new {{GCMonitor}} instance, which did no see any of the nodes written by the compaction that was run on the previous {{FileStore}} instance. \r\n\r\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "OffRC always logs 0 for the number of compacted nodes in gc.log"
   },
   {
      "_id": "13113047",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-10-30 14:50:45",
      "description": "It seems that the disk space check is not properly synchronized with {{FileStore}} as I revealed a race condition while using oak-upgrade during migration to {{segment-tar}}.\r\n\r\nThe {{FileStore}} instance is closed while TarMK disk check tries to execute and it seems it is dependent on the state of segment ({{org.apache.jackrabbit.oak.segment.file.FileStore.checkDiskSpace(FileStore.java:541)}} that needs to be opened. \r\n\r\n{noformat}\r\n30.10.2017 11:26:05.834 WARN   o.a.j.o.s.f.Scheduler: The scheduler FileStore background tasks takes too long to shut down\r\n30.10.2017 11:26:11.674 INFO   o.a.j.o.s.f.FileStore: TarMK closed: /data/cq/crx-quickstart/repository-segment-tar-20171030-112401/segmentstore\r\n30.10.2017 11:26:11.676 ERROR  o.a.j.o.s.f.SafeRunnable: Uncaught exception in TarMK disk space check [/data/cq/crx-quickstart/repository-segment-tar-20171030-112401/segmentstore]\r\njava.lang.IllegalStateException: already shut down\r\n    at org.apache.jackrabbit.oak.segment.file.ShutDown.keepAlive(ShutDown.java:42)\r\n    at org.apache.jackrabbit.oak.segment.file.FileStore.size(FileStore.java:302)\r\n    at org.apache.jackrabbit.oak.segment.file.FileStore.checkDiskSpace(FileStore.java:541)\r\n    at org.apache.jackrabbit.oak.segment.file.FileStore.access$300(FileStore.java:102)\r\n    at org.apache.jackrabbit.oak.segment.file.FileStore$3.run(FileStore.java:237)\r\n    at org.apache.jackrabbit.oak.segment.file.SafeRunnable.run(SafeRunnable.java:67)\r\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\r\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n    at java.lang.Thread.run(Thread.java:745)\r\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "TarMK disk space check is not synchronized with FileStore opened state"
   },
   {
      "_id": "13113043",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-30 14:46:56",
      "description": "Currently the compaction estimator unconditionally looks at the growth of the repository since the last compaction run. This turn out to be not optimal when interleaving tail and full compaction. It would be better to have the estimator look at the growth of the repository since last full compaction when running full compaction. \r\n\r\ncc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "The compaction estimator should take the compaction type (tail vs. full) into consideration"
   },
   {
      "_id": "13112267",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-10-26 12:27:31",
      "description": "When {{--shareDataStore}} option is used for {{Segment-Tar-Cold}}, the standby instance ends up without a blob store configured.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Segment-Tar-Cold fixture doesn't correctly set up standby blob store"
   },
   {
      "_id": "13110217",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-18 08:10:43",
      "description": "{{FileStore.close}} should take better advantage of the {{Closer}} instance to close its resources (including the file store lock). Also the order of the close calls should be aligned with their dependencies. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor FileStore.close"
   },
   {
      "_id": "13108896",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2017-10-12 11:59:08",
      "description": "For upgrade case in many applications older index type is set to {{disabled}} when new index is provisioned. If the new index is async then it would take some time for reindex and till then any query which used to make use of old index would end up traversing the repository\r\n\r\nTo avoid such a scenario we should only mark older index as \"disabled\" only if the newer index is reindex. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement support for disabling indexes which are replaced with newer index"
   },
   {
      "_id": "13107951",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-10-09 11:18:10",
      "description": "Currently persistent cache if enabled for nodes caches all nodes accessed on the system. It would be better if it can be configured to only cache those nodes which are not volatile so that caching can be effective\r\n\r\nPurpose of this issue is to\r\n* Provide an extension point in PersistentCache logic to check if a node is to be cached\r\n* Provide an impl which relies on some static OSGi config to determine that\r\n\r\nLater we can make this impl dynamic i.e. rely on access pattern to cache imp stuff",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Provide a way to for persistent cache to determine which all nodes can be cached"
   },
   {
      "_id": "13107238",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-10-05 14:16:27",
      "description": "Exceptions thrown by {{oak-run compact}} are inhibited so the exit code of the command is not correct in case of error. \n\nExample: \n{code}\n$ java -jar oak-run-1.7.8-R1809845.jar compact test-oak-run/\nApache Jackrabbit Oak 1.7.8-R1809845\nCompacting test-oak-run-6.3.0\nWith default access mode\n    before\n        Thu Oct 05 15:14:22 CEST 2017, journal.log\n        Thu Oct 05 15:14:23 CEST 2017, data00000a.tar\n        Thu Oct 05 15:14:23 CEST 2017, manifest\n        Thu Oct 05 15:14:23 CEST 2017, repo.lock\n    size 119.1 MB (119133142 bytes)\n    -> compacting\norg.apache.jackrabbit.oak.segment.file.InvalidFileStoreVersionException: Using a too recent version of oak-segment-tar\n\tat org.apache.jackrabbit.oak.segment.file.ManifestChecker.checkStoreVersion(ManifestChecker.java:81)\n\tat org.apache.jackrabbit.oak.segment.file.ManifestChecker.checkManifest(ManifestChecker.java:70)\n\tat org.apache.jackrabbit.oak.segment.file.ManifestChecker.checkAndUpdateManifest(ManifestChecker.java:51)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore.<init>(FileStore.java:191)\n\tat org.apache.jackrabbit.oak.segment.file.FileStoreBuilder.build(FileStoreBuilder.java:343)\n\tat org.apache.jackrabbit.oak.segment.tool.Compact.newFileStore(Compact.java:165)\n\tat org.apache.jackrabbit.oak.segment.tool.Compact.compact(Compact.java:135)\n\tat org.apache.jackrabbit.oak.segment.tool.Compact.run(Compact.java:128)\n\tat org.apache.jackrabbit.oak.run.SegmentTarUtils.compact(SegmentTarUtils.java:183)\n\tat org.apache.jackrabbit.oak.run.CompactCommand.execute(CompactCommand.java:93)\n\tat org.apache.jackrabbit.oak.run.Main.main(Main.java:49)\n    after\n        Thu Oct 05 15:14:22 CEST 2017, journal.log\n        Thu Oct 05 15:14:23 CEST 2017, data00000a.tar\n        Thu Oct 05 15:14:23 CEST 2017, manifest\n        Thu Oct 05 15:14:23 CEST 2017, repo.lock\n    size 119.1 MB (119133142 bytes)\n    removed files []\n    added files []\nCompaction succeeded in 211.9 ms (0s).\n{code}\n\nA quick fix would be to wrap the exception into a {{RuntimeException}}:\n{code}\n--- a/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/tool/Compact.java\n+++ b/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/tool/Compact.java\n@@ -127,7 +127,7 @@ public class Compact implements Runnable {\n         try {\n             compact();\n         } catch (Exception e) {\n-            e.printStackTrace();\n+            throw new RuntimeException(\"Failed to run compact\", e);\n         }\n     }\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Exceptions are inhibited in oak-run compact"
   },
   {
      "_id": "13105674",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-28 06:55:40",
      "description": "Currently all the {{GetXXXRequestHandler}} (where XXX stands for Blob, Head, References and Segment), on the server discard client requests which cannot be satisfied (i.e. the requested object does not exist (yet) on the server). A more transparent approach would be to timely respond to all client requests, clearly stating that the object was not found. This would improve a lot debugging for example, because all requests and their responses could be easily followed from the client log, without needing to know what actually happened on the server.\n\nBelow, a possible implementation for {{GetHeadRequestHandler}}, suggested by [~frm] in a comment on OAK-6678:\n\n{noformat}\nString id = reader.readHeadRecordId();\n\nif (id == null) {\n    ctx.writeAndFlush(new NotFoundGetHeadResponse(msg.getClientId(), id));\n    return;\n}\n\nctx.writeAndFlush(new GetHeadResponse(msg.getClientId(), id));\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Standby server should send timely responses to all client requests"
   },
   {
      "_id": "13104303",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-22 14:34:25",
      "description": "Invoking TarWriter.close() on an already closed writer throws an {{ISE}}. According to the general contract this is not allowed:\n\n{code}\n* Closes this stream and releases any system resources associated\n* with it. If the stream is already closed then invoking this\n* method has no effect.\n{code}\n\nWe should adjust the behvaviour of that method accordingly. \n\nFailing to comply with that general contract causes {{TarWriter}} instances to fail in try-resource statements when multiple wrapped streams are involved.\n\nConsider \n\n{code}\ntry (\n    StringWriter string = new StringWriter();\n    PrintWriter writer = new PrintWriter(string);\n    WriterOutputStream out = new WriterOutputStream(writer, Charsets.UTF_8))\n{\n    dumpHeader(out);\n    writer.println(\"----------------------------------------\");\n    dumpHex(out);\n    writer.println(\"----------------------------------------\");\n    return string.toString();\n}\n{code}\n\nThis code would cause exceptions to be thrown if e.g. the {{PrintWriter.close}} method would not be idempotent. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "TarWriter.close() must not throw an exception on subsequent invocations"
   },
   {
      "_id": "13104227",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-22 09:11:35",
      "description": "In order to correctly configure cold standby there are two OSGi configurations that need to be provided. Among other settings, {{org.apache.jackrabbit.oak.segment.SegmentNodeStoreService.config}} needs {{standby=B\"true\"}} and {{org.apache.jackrabbit.oak.segment.standby.store.StandbyStoreService.config}} needs {{mode=\"standby\"}}. The problem is that sometimes we have {{mode=\"standby\"}} in {{StandbyStoreService}} and {{standby=B\"false\"}} in {{SegmentNodeStoreService}} which leads to starting a problematic standby instance (with primary behaviour enabled, e.g. indexing, etc.). This problem stems from the fact that there are two components whose configuration should be coordinated. Proposals to mitigate this:\n\n# Keep the {{mode=\"standby\"}}, but merge the configuration of {{StandbyStoreService}} in the one for {{SegmentNodeStoreService}} and eliminate {{StandbyStoreService}} altogether\n# {{StandbyStoreService}} should derive {{mode=\"standby\"}} from {{\"standby=B\"true\"}} in {{SegmentNodeStoreService}}\n# {{SegmentNodeStoreService}} should derive {{\"standby=B\"true\"}} from {{mode=\"standby\"}} in {{StandbyStoreService}} even if this is backwards when compared to how the synchronization currently happens, with {{StandbyStoreService}} waiting for for a proper initialisation of {{SegmentNodeStoreService}}\n# Make {{StandbyStoreService}} configuration mandatory, but require a {{mode=\"off\"}} setting. This way the removal of {{standby=B\"true\"}} from {{SegmentNodeStoreService}} would be guaranteed and any synchronization between the two components would be avoided.\n\n/cc  [~frm], [~volteanu], [~mduerig]\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve cold standby resiliency to incoherent configs"
   },
   {
      "_id": "13103614",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-20 14:20:00",
      "description": "Started a server with Oak version 1.7.7 and tried to connect oak-run-1.7.7 to same setup. This resulted in following exception\n\n{noformat}\n2017-09-20 19:47:22,213 INFO  [main] o.a.j.o.segment.file.FileStore - Creating file store FileStoreBuilder{version=1.7.7, directory=/path/to/repository/segmentstore, blobStore=DataStore backed BlobStore [org.apache.jackrabbit.oak.plugins.blob.datastore.OakFileDataStore], maxFileSize=256, segmentCacheSize=256, stringCacheSize=256, templateCacheSize=64, stringDeduplicationCacheSize=15000, templateDeduplicationCacheSize=3000, nodeDeduplicationCacheSize=1048576, memoryMapping=true, gcOptions=SegmentGCOptions{paused=false, estimationDisabled=false, gcSizeDeltaEstimation=1073741824, retryCount=5, forceTimeout=60, retainedGenerations=2, gcType=FULL}} \n2017-09-20 19:47:22,243 WARN  [main] o.a.j.o.s.file.tar.TarReader - Unable to load index of file data00000a.tar: Unrecognized magic number \n2017-09-20 19:47:22,243 INFO  [main] o.a.j.o.s.file.tar.TarReader - No index found in tar file data00000a.tar, skipping... \n2017-09-20 19:47:22,243 WARN  [main] o.a.j.o.s.file.tar.TarReader - Could not find a valid tar index in /path/to/repository/segmentstore/data00000a.tar, recovering read-only \n2017-09-20 19:47:22,243 INFO  [main] o.a.j.o.s.file.tar.TarReader - Recovering segments from tar file /path/to/repository/segmentstore/data00000a.tar \n2017-09-20 19:47:22,315 INFO  [main] o.a.j.o.s.file.tar.TarReader - Regenerating tar file/path/to/repository/segmentstore/data00000a.tar.ro.bak \n2017-09-20 19:47:22,460 ERROR [main] o.a.j.oak.index.IndexCommand - Error occurred while performing index tasks \njava.lang.IllegalArgumentException: invalid segment buffer\n\tat org.apache.jackrabbit.oak.segment.data.SegmentDataLoader.newSegmentData(SegmentDataLoader.java:37) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.data.SegmentData.newSegmentData(SegmentData.java:66) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.AbstractFileStore.writeSegment(AbstractFileStore.java:212) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.AbstractFileStore.access$000(AbstractFileStore.java:66) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.AbstractFileStore$1.recoverEntry(AbstractFileStore.java:125) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarReader.generateTarFile(TarReader.java:213) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarReader.openRO(TarReader.java:162) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarFiles.<init>(TarFiles.java:298) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarFiles.<init>(TarFiles.java:58) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.tar.TarFiles$Builder.build(TarFiles.java:167) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.ReadOnlyFileStore.<init>(ReadOnlyFileStore.java:74) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.segment.file.FileStoreBuilder.buildReadOnly(FileStoreBuilder.java:383) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.run.cli.SegmentTarFixtureProvider.configureSegment(SegmentTarFixtureProvider.java:63) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.run.cli.NodeStoreFixtureProvider.create(NodeStoreFixtureProvider.java:71) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.run.cli.NodeStoreFixtureProvider.create(NodeStoreFixtureProvider.java:47) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.index.IndexCommand.execute(IndexCommand.java:98) ~[oak-run-1.7.7.jar:1.7.7]\n\tat org.apache.jackrabbit.oak.run.Main.main(Main.java:49) [oak-run-1.7.7.jar:1.7.7]\n\n{noformat}\n\nPost restart of server oak-run was able to connect fine. So looks like issue with very fresh setup only\n\nCommand used for oak-run\n{noformat}\njava -jar oak-run-1.7.7.jar index --fds-path=/path/to/repository/datastore --checkpoint head --reindex --index-paths=/oak:index/lucene /path/to/repository/segmentstore --metrics\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ReadOnly connection to fresh SegmentNodeStore setup failing"
   },
   {
      "_id": "13102961",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-09-18 14:00:09",
      "description": "{{DocumentNodeStoreTest.disabledBranchesWithBackgroundWrite}} fails when I try a clean build on Windows, as per r1808698.\n\n{noformat}\n[ERROR] Failures:\n[ERROR]   DocumentNodeStoreTest.disabledBranchesWithBackgroundWrite:3199 expected:<1> but was:<0>\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: DocumentNodeStoreTest.disabledBranchesWithBackgroundWrite"
   },
   {
      "_id": "13102805",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-17 05:53:00",
      "description": "With changes for OAK-6653 in place, {{ExternalPrivateStoreIT#testSyncBigBlog}} and sometimes {{ExternalSharedStoreIT#testSyncBigBlob}} are failing on CI:\n\n{noformat}\norg.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT\ntestSyncBigBlob(org.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT)  Time elapsed: 96.82 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n...\ntestSyncBigBlob(org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT)  Time elapsed: 95.254 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n{noformat}\n\nPartial stacktrace:\n{noformat}\n14:09:08.355 DEBUG [main] StandbyServer.java:242            Binding was successful\n14:09:08.358 DEBUG [standby-1] GetHeadRequestEncoder.java:33 Sending request from client Bar for current head\n14:09:08.359 DEBUG [primary-1] ClientFilterHandler.java:53  Client /127.0.0.1:52988 is allowed\n14:09:08.360 DEBUG [primary-1] RequestDecoder.java:42       Parsed 'get head' message\n14:09:08.360 DEBUG [primary-1] CommunicationObserver.java:79 Message 'get head' received from client Bar\n14:09:08.362 DEBUG [primary-1] GetHeadRequestHandler.java:43 Reading head for client Bar\n14:09:08.363 WARN  [primary-1] ExceptionHandler.java:31     Exception caught on the server\njava.lang.NullPointerException: null\n\tat org.apache.jackrabbit.oak.segment.standby.server.DefaultStandbyHeadReader.readHeadRecordId(DefaultStandbyHeadReader.java:32) ~[oak-segment-tar-1.8-SNAPSHOT.jar:1.8-SNAPSHOT]\n\tat org.apache.jackrabbit.oak.segment.standby.server.GetHeadRequestHandler.channelRead0(GetHeadRequestHandler.java:45) ~[oak-segment-tar-1.8-SNAPSHOT.jar:1.8-SNAPSHOT]\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Syncing big blobs fails since StandbyServer sends persisted head"
   },
   {
      "_id": "13102497",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-15 08:10:43",
      "description": "At the moment all integration tests for cold standby are using the same scenario in their tests: some content is created on the server (including binaries), a standby sync cycle is started and then the content is checked on the client. The only twist here is using/not using a data store for storing binaries.\n\nAlthough good, this model could be extended to cover many more cases. For example, {{StandbyDiff}} covers the following 6 cases node/property added/changed/deleted. From these, with the scenario described, the removal part is never tested (and the change part is covered in only one test). \n\nIt would be nice to have an IT which would add content on the server, do a sync, remove some of the content, do a sync and then call OnRC. This way all cases will be covered, including if cleanup works as expected on the client.\n\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby",
         "technical_debt",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Create a more complex IT for cold standby"
   },
   {
      "_id": "13102494",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-15 08:00:45",
      "description": "With the new feature which allows chunking in blob transfer between server and client, there are various places in which more meaningful log messages could be used. For example, on the server, there's a tally of the no. of chunks sent/total no. of chunks, but this part is missing on the client, i.e. no. of chunks received/total no. of chunks. \n\nAnother case which would benefit from improved logging is when a big blob can't be sent fully from the server to the client in {{readTimeoutMs}}. The current exception message is a bit scarce in details (e.g. {{\"Unable to load remote blob \" + blobId + \" at \" + path + \"#\" + pName}}). This could also mean that the remote blob doesn't exist on the server in the first place. A better option would be to advise about increasing {{readTimeoutMs}}.\n\nFinally, the same log level should be used everywhere, since currently {{DEBUG}} and {{INFO}} are  interchangeably mixed.\n\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve cold standby logging"
   },
   {
      "_id": "13102284",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-14 15:14:12",
      "description": "{{StandbyDiff}} still makes use of the {{logOnly}} property for deciding when to act upon node/property changes. The official documentation of {{logOnly}} states that it helps for\n\n{quote}\n/**\n     * read-only traversal of the diff that has 2 properties: one is to log all\n     * the content changes, second is to drill down to properly level, so that\n     * missing binaries can be sync'ed if needed\n     */\n{quote}\n\nbut it's use is a bit misleading. The first call to {{StandbyDiff}} is always with {{logOnly==false}}, while subsequent calls are done with {{logOnly==true}}. Implementing {{StandbyDiff}} without this mechanism would result in better clarity and maintainability.\n\nAnother minor improvement is to rename {{#binaryCheck}} methods and {{#readBinary}} to {{#fetchBinary}} and {{#fetchAndStoreBlob}} which is more appropriate to their purpose.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Refactor StandbyDiff for better clarity and understandability"
   },
   {
      "_id": "13102249",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-09-14 13:06:16",
      "description": "Move the DocumentNodeStore implementation and the two backends (MongoDB, RDB) into its own bundle. This will make it possible to release oak-core and the NodeStore implementation independently.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move DocumentNodeStore into its own bundle"
   },
   {
      "_id": "13101964",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-13 13:40:25",
      "description": "As already explained in OAK-6659, there can be cases in which deleting the previous spool file fails (Windows) and new (duplicate) content is added under the hood to the old file. This way the persisted blob doesn't match in content and id with the original sent by the server.\n\nA first improvement here is to not allow the decoding to continue if the old spool file cannot be deleted. For this, the call to {{File#delete}} needs to be replaced with {{java.nio.file.Files#delete}} which would throw an exception if something wrong happens.\n\nBy ensuring that the spool file has the same size as the original blob we solve this problem. This check is sufficient, since all the chunks received are individually checked by hash, before appending them to the spool file. Moreover, the single threaded nature of the client ensures that races in which a new thread starts appending new content, after the length check has just passed can never happen.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ResponseDecoder should check that the length of the received blob matches the length of the sent blob"
   },
   {
      "_id": "13101940",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-13 12:12:40",
      "description": "Due to changes done in OAK-4969, currently there are two 'sync blob' cycles triggered by {{StandbyDiff#childNodeChanged}}. The test scenario is the same as the one in {{DataStoreTestBase#testSyncBigBlob}}: on the primary file store, a new big blob (1GB) is added and then a standby sync is triggered to sync this content to the secondary file store. \n\nThe first 'sync blob' cycle happens as a result of {{#process}} being called in {{StandbyDiff#childNodeChanged}}. Therefore, a new 'get blob' request is created on the client and the server starts sending chunks from the big blob. Now, if the time needed for transferring the entire blob from server to client exceeds {{readTimeoutMs}} an {{IllegalStateException}} will be correctly thrown by {{StandbyDiff#readBlob}}, but will be swallowed by the {{StandbyDiff#childNodeChanged}} in its catch clause. A second 'sync blob' cycle will be triggered and, -this might succeed with the same {{readTimeoutMs}} for which it was failing before-, if {{readTimeoutMs * 2}} is enough, the blob will be synced on the standby. This happens because the server will continue sending the remaining chunks after {{IllegalStateException}} was thrown (first 'sync blob' cycle).\n\nThe consequence of these two 'sync blob' cycles is that sometimes, deleting the temporary file to which chunks are spooled to on the client fails (see Windows for example and OAK-6641 specifically). This way, instead of deleting the previous incomplete transfer, new chunks from the second 'sync blob' cycle are added. The blob persisted in the blob store on the client won't have the same size and id as the initial blob sent by the server.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Cold standby should fail loudly when a big blob can't be timely transferred"
   },
   {
      "_id": "13101632",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-12 12:46:53",
      "description": "Currently the standby server sends an un-persisted head record to clients. Under normal circumstances, the TarMK flush thread is able to persist it and its corresponding segment at a 5 seconds interval.\nHowever, there are cases (uploading a very large blob > 10 GB) in which the flush thread writes the segment too late, and the 20s allowed by {{FileStoreUtil#readSegmentWithRetry}} are not enough. Therefore the server can't read the segment containing the head record and a timeout occurs on the client.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Standby server must always send the persisted head to clients"
   },
   {
      "_id": "13101295",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-11 15:03:38",
      "description": "{noformat}\nRunning org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@6bb75258\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@5b04476e\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@5b04476e\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@5b04476e\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nTests run: 4, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 18.543 sec <<< FAILURE! - in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\noffRCUpgradesSegments(org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT)  Time elapsed: 5.578 sec  <<< FAILURE!\njava.lang.AssertionError: Segment version mismatch. Expected V_13, found V_12 expected:<V_13> but was:<V_12>\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.checkSegmentVersion(UpgradeIT.java:143)\n        at org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT.offRCUpgradesSegments(UpgradeIT.java:109)\n\n\nResults :\n\nFailed tests:\n  UpgradeIT.offRCUpgradesSegments:109->checkSegmentVersion:143 Segment version mismatch. Expected V_13, found V_12 expected:<V_13> but was:<V_12>\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "test failure seen in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT"
   },
   {
      "_id": "13101189",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-11 08:00:52",
      "description": "Backport the fix from OAK-6110 to the 1.6 branch.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc",
         "memory",
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Backport OAK-6110 to 1.6 (Offline compaction uses too much memory)"
   },
   {
      "_id": "13100831",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-08 14:38:13",
      "description": "{noformat}\nTests run: 10, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 99.858 sec <<< FAILURE! - in org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT\ntestSyncBigBlob(org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT)  Time elapsed: 71.122 sec  <<< ERROR!\njava.lang.RuntimeException: Error occurred while obtaining InputStream for blobId [8098b6ac1491be80b7e58a85767ede178c432866d90caf6726f556406ecc84a4#1073741824]\nCaused by: java.io.IOException: org.apache.jackrabbit.core.data.DataStoreException: Record 8098b6ac1491be80b7e58a85767ede178c432866d90caf6726f556406ecc84a4 does not exist\nCaused by: org.apache.jackrabbit.core.data.DataStoreException: Record 8098b6ac1491be80b7e58a85767ede178c432866d90caf6726f556406ecc84a4 does not exist\n\n{noformat}\n\n(might be specific to Windows)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "test failure in org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT"
   },
   {
      "_id": "13100451",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-07 12:57:33",
      "description": "When the memory requirements for running OnRC are not met before the estimation phase the estimator will run nevertheless. The process will only be cancelled at the beginning of the compaction phase. The entries in the log file reflect this:\n\n{code}\nTarMK GC #1: canceling compaction because available memory level 306.4 MB (306395472 bytes) is too low...\nTarMK GC #1: estimation started\nTarMK GC #1: estimation completed in 343.5 ms (343 ms). Estimation skipped because of missing gc journal data (expected on first run)\nTarMK GC #1: running full compaction\nTarMK GC #1: compaction started ...\nTarMK GC #1: unable to estimate number of nodes for compaction, missing gc history.\nTarMK GC #1: compaction cancelled: Not enough memory.\nTarMK GC #1: cleaning up after failed compaction\n{code}\n\nHowever they can easily be (mis-)read as compaction being re-triggered after having been cancelled and then being cancelled again. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Confusing log entries when memory requirements are not met at start of OnRC"
   },
   {
      "_id": "13100179",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-09-06 15:20:58",
      "description": "The backup command in oak-run should not accidentally perform a transparent upgrade of the FileStore. Instead, it should use a strict version check to fail fast if the code is run on an outdated version of the FileStore.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "production",
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "The backup command should not silently upgrade the FileStore"
   },
   {
      "_id": "13100178",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-09-06 15:16:36",
      "description": "We should remove the {{StandbyStoreService#BLOB_CHUNK_SIZE}} OSGi configuration and replace it with a feature flag. Rational: we expect customer to rarely change this thus not justifying the additional configuration complexity and testing overhead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby",
         "configuration"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Replace standby blob chunk size configuration with feature flag"
   },
   {
      "_id": "13100175",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-06 15:09:40",
      "description": "The transparent upgrade feature for segments from version 12 to 13 should not cause \"accidental upgrades\". That is, running Oak 1.8 oak-run compact on a store with segment version 12 should bail out unless a special option was specified on the command line. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid oak-run compact inadvertently upgrading the segment format "
   },
   {
      "_id": "13099813",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-09-05 11:47:22",
      "description": "If this fixture is chosen, a cold standby instance will be started, syncing with the primary every {{n}} seconds. All the benchmarks specified via {{[testcases]}} argument will be run on primary instance, and all statistics and reports will be linked to primary.\n\nThis could work similarly to {{Oak-Segment-Tar-DS}} and have dedicated options like {{--no-data-store}}, {{--private-data-store}} or {{--shared-data-store}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add new segment-tar fixture for attaching a cold-standby to benchmarked primary"
   },
   {
      "_id": "13099592",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-09-04 11:50:59",
      "description": "For OAK-6353 we need to know all bundled nodestate in a given parent. For this purpose we should provide following method in DocumentNodeState\n\n{code}\npublic Iterable<DocumentNodeState> getBundledNodesStates() {\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Provide list of all bundled nodes within a given DocumentNodeState"
   },
   {
      "_id": "13098847",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-31 11:45:38",
      "description": "{{BulkTransferBenchmark}} should be moved from {{oak-segment-tar}} to {{oak-benchmarks}} to allow standard run of this cold standby related benchmark.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move BulkTransferBenchmark to oak-benchmarks module"
   },
   {
      "_id": "13098793",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-31 07:52:15",
      "description": "BulkTransferBenchmark might improperly dispose of test resources if error conditions occur. This is mostly due to improper resource tracking and finalization in BenchmarkBase, but similar mistakes have been made in BulkTransferBenchmark too.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve resource management in BulkTransferBenchmark"
   },
   {
      "_id": "13098752",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-31 07:00:26",
      "description": "The {{SegmentWriteOperation.isOldGeneration()}} predicate includes some segments that are not \"old\". This leads to more deferred compaction operations than strictly necessary. The affected segments are those generated by tail compaction. Tail compaction created segments should only be included in the predicate once they are from another full compaction operation. Otherwise referencing such segments is fine as they will not be reclaimed in a cleanup following a tail compaction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentWriteOperation.isOldGeneration() too eager"
   },
   {
      "_id": "13098388",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-08-29 20:58:32",
      "description": "I mentioned that properties that got indexed due to an aggregation are not considered for excerpts (highlighting) as they are not indexed as stored fields.\r\n\r\nSee the attached patch that implements a test for excerpts in {{LuceneIndexAggregationTest2}}.\r\n\r\nIt creates the following structure:\r\n\r\n{code}\r\n/content/foo [test:Page]\r\n + bar (String)\r\n - jcr:content [test:PageContent]\r\n  + bar (String)\r\n{code}\r\n\r\nwhere both strings (the _bar_ property at _foo_ and the _bar_ property at _jcr:content_) contain different text. \r\n\r\nAfterwards it queries for 2 terms (\"tinc*\" and \"aliq*\") that either exist in _/content/foo/bar_ or _/content/foo/jcr:content/bar_ but not in both. For the former one the excerpt is properly provided for the later one it isn't.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "excerpt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "rep:excerpt not working for content indexed by aggregation in lucene"
   },
   {
      "_id": "13097912",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-28 08:48:54",
      "description": "When {{UpgradeIT}} is executed, the following output is produced.\n\n{noformat}\nRunning org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@75e01201\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@75e01201\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nApache Jackrabbit Oak 1.6.1\n===> true\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook\n===> org.apache.jackrabbit.oak.plugins.document.*, org.apache.jackrabbit.oak.plugins.segment.*, org.apache.jackrabbit.oak.segment.SegmentNodeBuilder, org.apache.jackrabbit.oak.spi.commit.EmptyHook, org.apache.jackrabbit.oak.spi.commit.CommitInfo\n===> true\n===> org.apache.jackrabbit.oak.segment.SegmentNodeStore@75e01201\n===> SegmentNodeBuilder{path=/}\n===> null\n===> { property-name-5-0 = property-value-5-0, property-name-5-1 = property-value-5-1, property-name-5-2 = property-value-5-2, property-name-5-3 = property-value-5-3, property-name-5-4 = property-value-5-4, property-name-5-5 = property-value-5-5, property-name-5-6 = property-value-5-6, property-name-5-7 = property-value-5-7, property-name-5-8 = property-value-5-8, property-name-5-9 = property-value-5-9, node-5-3 = { ... }, node-5-4 = { ... }, node-5-9 = { ... }, node-5-1 = { ... }, node-5-2 = { ... }, node-5-7 = { ... }, node-5-8 = { ... }, node-5-5 = { ... }, node-5-0 = { ... }, node-5-6 = { ... } }\nTests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.17 sec - in org.apache.jackrabbit.oak.segment.upgrade.UpgradeIT\n{noformat}\n\nThe test should not produce any output, especially such a useless one.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "UpgradeIT produces unwanted output"
   },
   {
      "_id": "13097268",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-24 08:49:36",
      "description": "h3. Current situation\nCurrent segment store related tools are implemented ad-hoc by potentially relying on internal implementation details of Oak Segment Tar. This makes those tools less useful, portable, stable and potentially applicable than they should be.\n\nh3. Goal\nProvide a common and sufficiently stable Oak Tooling API for implementing segment store related tools. The API should be independent of Oak and not available for normal production use of Oak. Specifically it should not be possible to it to implement production features and production features must not rely on it. It must be possible to implement the Oak Tooling API in Oak 1.8 and it should be possible for Oak 1.6.\n\nh3. Typical use cases\n* Query the number of nodes / properties / values in a given path satisfying some criteria\n* Aggregate a certain value on queries like the above\n* Calculate size of the content / size on disk\n* Analyse changes. E.g. how many binaries bigger than a certain threshold were added / removed between two given revisions. What is the sum of their sizes?\n* Analyse locality: measure of locality of node states. Incident plots (See https://issues.apache.org/jira/browse/OAK-5655?focusedCommentId=15865973&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15865973).\n* Analyse level of deduplication (e.g. of checkpoint) \n\nh3. Validation\nReimplement [Script Oak|https://github.com/mduerig/script-oak] on top of the tooling API. \n\nh3. API draft\n* Whiteboard shot of the [API entities|https://wiki.apache.org/jackrabbit/Oakathon%20August%202017?action=AttachFile&do=view&target=IMG_20170822_163256.jpg] identified initially.\n* Further [drafting of the API|https://github.com/mduerig/oak-tooling-api] takes place on Github for now. We'll move to the Apache SVN as soon as considered mature enough and have a consensus of where to best move it. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add tooling API"
   },
   {
      "_id": "13096992",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-08-23 11:04:18",
      "description": "Similar to OAK-4637 but for lucene indexes\n\nIn some cases, property indexes contain many nodes, and updating them can be slow. Right now we have filters for node and mixin types, path (include and exclude). \n\nAn include and exclude list of values (patterns) would be useful. For example the property \"status\", if we only ever run queries with the condition \"status = 'ACTIVE'\", then nodes with status INACTIVE and DONE don't need to be indexed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Lucene index: include/exclude key pattern list"
   },
   {
      "_id": "13096362",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-21 08:07:14",
      "description": "After netty update in OAK-6564, {{OSGiIT}} fails with the following exception:\n\n{code}\nRunning org.apache.jackrabbit.oak.osgi.OSGiIT\nERROR: Bundle org.apache.jackrabbit.oak-segment-tar [36] Error starting file:/oak-it-osgi/target/test-bundles/oak-segment-tar.jar (org.osgi.framework.BundleException: Unresolved constraint in bundle org.apache.jackrabbit.oak-segment-tar [36]: Unable to resolve 36.0: missing requirement [36.0] osgi.wiring.package; (osgi.wiring.package=com.ning.compress))\norg.osgi.framework.BundleException: Unresolved constraint in bundle org.apache.jackrabbit.oak-segment-tar [36]: Unable to resolve 36.0: missing requirement [36.0] osgi.wiring.package; (osgi.wiring.package=com.ning.compress)\n\tat org.apache.felix.framework.Felix.resolveBundleRevision(Felix.java:3974)\n\tat org.apache.felix.framework.Felix.startBundle(Felix.java:2037)\n\tat org.apache.felix.framework.Felix.setActiveStartLevel(Felix.java:1291)\n\tat org.apache.felix.framework.FrameworkStartLevelImpl.run(FrameworkStartLevelImpl.java:304)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix OSGi wiring after netty update to 4.1.x"
   },
   {
      "_id": "13095635",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-18 13:31:33",
      "description": "{{GetBlobResponseEncoder}} writes too fast all the chunks, leaving the channel in a not-writable state, after the first write. The problem is not visible at a first glance, especially when using small blobs for testing. Increasing the blobs size, as done for OAK-6538, revealed the problem. Not only this triggers hidden {{OutOfMemory}} errors on either server or client, but sometimes incomplete blobs are sent along, which are interpreted by the client as valid.\n\nA more elegant solution, which also solves the memory consumption problem, would be to use {{ChunkedWriteHandler}} which employs complex logic on how and when to write the chunks. {{ChunkedWriteHandler}} must be used in conjunction with a custom {{ChunkedInput<ByteBuf>}} implementation to generate {{header}} + {{payload}} chunks from an {{InputStream}}, as done currently. This way the server will send more chunks only when the previous one was consumed by the client.\n\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "GetBlobResponseEncoder should not write all chunks at once"
   },
   {
      "_id": "13095632",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-18 13:16:06",
      "description": "Taking into account the improvements listed at [0], and also the individual issues solved since our current netty version (4.0.41.Final) was released, I propose to bump up netty version to latest 4.1.14.Final.\n\n/cc [~frm]\n\n[0] http://netty.io/wiki/new-and-noteworthy-in-4.1.html ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update netty dependency to 4.1.x"
   },
   {
      "_id": "13094761",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-15 13:41:37",
      "description": "Running offline gc currently adds an entry to the {{gc.log}} with a {{NULL}} record id. We should improve this and record the record id of the compacted root node state. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "gc.log should contain recordId of compacted root after offline compaction"
   },
   {
      "_id": "13094728",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-15 10:23:24",
      "description": "We need basic IT coverage for the rolling upgrade scenario from Oak 1.6. to Oak 1.8. See OAK-6531.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "IT",
         "migration",
         "test",
         "upgrade"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement ITs for rolling upgrade"
   },
   {
      "_id": "13094458",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-14 12:53:07",
      "description": "We should implement a basic progress indicator for compaction displaying percent completed. This could be done by estimating the number of nodes from the entries in the {{gc.log}} and the timestamp of the last entry in the {{journal.log}}. Such a feature would explicitly *not* give an ETA as too many factors have an impact here (concurrent activity, IO bandwidth, quota, etc.).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc",
         "operation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Progress indicator for compaction "
   },
   {
      "_id": "13094046",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-11 08:28:48",
      "description": "The {{gcType}} property should move from the {{FileStore}} class to the {{SegmentGCOptions}} along with all other GC related properties. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move gcType to SegmentGCOptions"
   },
   {
      "_id": "13093446",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-09 12:03:56",
      "description": "In an investigation from some time ago, 4GB of heap were needed for transferring 1GB blob and 6GB for 2GB blob. This was in part due to using {{addTestContent}} [0] in the investigation, which allocates a huge {{byte[]}} on the heap. \n\nOAK-5902 introduced chunking for transferring blobs between primary and standby. This way, the memory needed for syncing a big blob should be around the chunk size used. Solving the way test data is created, it should be possible to transfer a big blob (e.g. 2.5 GB) with less memory.\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/test/java/org/apache/jackrabbit/oak/segment/standby/DataStoreTestBase.java#L96",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Investigate cold standby memory consumption "
   },
   {
      "_id": "13093176",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-08 14:18:38",
      "description": "The segment format changes introduced for tail compaction (OAK-3349) must not require an explicit migration step. Instead there should be a rolling migration during normal operation. \n\nThings to consider:\n* Segments from Oak 1.6\n* Changes in tar index formats induced by the segment format changes\n* Changes in gc.log induced by the segment format changes\n* Required changes in the repository manifest and its interpretation\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "migration",
         "upgrade"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement rolling upgrade from Oak 1.6"
   },
   {
      "_id": "13092410",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-04 08:35:16",
      "description": "{{OnlineCompactor}} needs more unit test coverage going forward. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement unit tests for OnlineCompactor"
   },
   {
      "_id": "13092407",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-04 08:31:38",
      "description": "This is a follow up to OAK-3349: in tail compaction the {{FileStore.GarbageCollector.getBase()}} might fail to determine the base state to rebase onto. In this case we should fall back to full compaction and report (log, JMX) the problem and its exact cause. \n\nFailing to determine the base state might be caused by a missing or invalid {{gc.log}} file or a invalid or missing record id for the base state being recorded in {{gc.log}}. None of these cases should impact system stability. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve tail compactions resilience when base state cannot be determined"
   },
   {
      "_id": "13092402",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-08-04 08:20:22",
      "description": "This is a follow up to OAK-3349, which introduced tail compactions:\n\nThe deduplication caches currently only take the full generations into account and ignore the tail generations. Cache generations need to be a monotonically increasing, ordered sequence consisting of the full and tail part of the gc generation. See {{FileStoreBuilder.EvictingWriteCacheManager.evictOldGeneration}}. Optimally we find a way to decouple the segment generation from the cache generations as these are really separate concerns. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Properly handle tail compactions in deduplication caches"
   },
   {
      "_id": "13085141",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-07-06 09:17:41",
      "description": "In OAK-4732 the 50th percentile of the last 1000 commits is used as wait time before returning the current root. In order to parametrise the value of the percentile, it would be nice to have a new feature flag, e.g. {{oak.scheduler.head.lockWaitPercentile}}. Setting it to {{0}} would basically disable this. Setting it to a different value might be interesting in future experiments.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add flag for controlling percentile of commit time used in scheduler"
   },
   {
      "_id": "13083418",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-29 10:24:16",
      "description": "Some of the constants in the {{Segment}} class still refer to the old 255 segment references limit. We should fix the comments, the constants and their usage to reflect the current situation where that limit has been lifted. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cleanup constants in Segment class"
   },
   {
      "_id": "13082516",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-26 14:20:44",
      "description": "Currently monitoring is of the deduplication caches is hard wired into the cache manager. It would be cleaner (and is in fact a pre-requisite for OAK-5790) to decouple the monitoring from the caches. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor monitoring of deduplication caches"
   },
   {
      "_id": "13081072",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-20 10:18:03",
      "description": "{{oak-run check}} does currently *not* traverse and check the items in the checkpoint. I think we should change this and add an option to traverse all, some or none of the checkpoints. When doing this we need to keep in mind the interaction of this new feature with the {{filter}} option: the paths passed through this option need then be prefixed with {{/root}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "oak-run check should also check checkpoints "
   },
   {
      "_id": "13079958",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2017-06-15 04:47:45",
      "description": "Currently if multiple indexes compete for same query i.e. they report cost > 0 and less than infinity then the log output is confusing. For e.g. for a query like\n\n{noformat}\nQueryEngineImpl Parsing xpath statement: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')]\nQueryEngineImpl XPath > SQL2: select [jcr:path], [jcr:score], * from [dam:Asset] as a where contains(*, 'foo.png') and isdescendantnode(a, '/content/dam') /* xpath: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')] */\nQueryImpl cost using filter Filter(query=select [jcr:path], [jcr:score], * from [dam:Asset] as a where contains(*, 'foo.png') and isdescendantnode(a, '/content/dam') /* xpath: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')] */ fullText=\"foo.png\", path=/content/dam//*)\nQueryImpl cost for aggregate lucene is 2.2424751E7\nQueryImpl cost for lucene-property[/oak:index/index-a][/oak:index/index-b] is 146914.0\nQueryImpl cost for reference is Infinity\nQueryImpl cost for ordered is Infinity\nQueryImpl cost for nodeType is Infinity\nQueryImpl cost for property is Infinity\nQueryImpl cost for traverse is Infinity\nQueryImpl query execute select [jcr:path], [jcr:score], * from [dam:Asset] as a where contains(*, 'foo.png') and isdescendantnode(a, '/content/dam') /* xpath: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')] */\nQueryImpl query plan [dam:Asset] as [a] /* lucene:index-b(/oak:index/index-b) +(((...) +:ancestors:/content/dam ft:(\"foo.png\") where (contains([a].[*], 'foo.png')) and (isdescendantnode([a], [/content/dam])) */\nQueryImpl query execute select [jcr:path], [jcr:score], * from [dam:Asset] as a where contains(*, 'foo.png') and isdescendantnode(a, '/content/dam') /* xpath: /jcr:root/content/dam//element(*, dam:Asset)[jcr:contains(., 'foo.png')] */\nQueryImpl query plan [dam:Asset] as [a] /* lucene:index-b(/oak:index/index-b) +(((...)) +:ancestors:/content/dam ft:(\"foo.png\") where (contains([a].[*], 'foo.png')) and (isdescendantnode([a], [/content/dam])) */\n{noformat}\n\nHere both index-a and index-b satisfy the query. However from logs it appears that both have same cost. While actually the reported cost is the lowest one which in this case would be for index-b\n\n{noformat}\nQueryImpl cost for lucene-property[/oak:index/index-a][/oak:index/index-b] is 146914.0\n{noformat}\n\nSo as a fix\n* Report cost for multiple plans returned by same index type separately\n* If cost is less than infinity and that plan is eventually not selected then also log its plan. This would help to see why specific plan lost\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve log reporting if multiple indexes compete for same query"
   },
   {
      "_id": "13079441",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-13 10:19:56",
      "description": "Recently we saw OutOfMemory using [oakRepoStats|https://github.com/chetanmeh/oak-console-scripts/tree/master/src/main/groovy/repostats] script with a SegmentNodeStore setup where uuid index has 16M+ entries and thus creating a very flat hierarchy. This happened while computing Tree#getChildren iterator which internally invokes MapRecord#getKeys to obtain an iterable for child node names.\n\nThis happened because code in getKeys computes the key list eagerly by calling bucket.getKeys() which recursivly calls same for each child bucket and thus resulting in eager evaluation.\n{code}\n        if (isBranch(size, level)) {\n            List<MapRecord> buckets = getBucketList(segment);\n            List<Iterable<String>> keys =\n                    newArrayListWithCapacity(buckets.size());\n            for (MapRecord bucket : buckets) {\n                keys.add(bucket.getKeys());\n            }\n            return concat(keys);\n        }\n{code}\n\nInstead here we should use same approach as used in MapRecord#getEntries i.e. evalate the iterable for child buckets lazily\n{code}\n        if (isBranch(size, level)) {\n            List<MapRecord> buckets = getBucketList(segment);\n            List<Iterable<MapEntry>> entries =\n                    newArrayListWithCapacity(buckets.size());\n            for (final MapRecord bucket : buckets) {\n                entries.add(new Iterable<MapEntry>() {\n                    @Override\n                    public Iterator<MapEntry> iterator() {\n                        return bucket.getEntries(diffKey, diffValue).iterator();\n                    }\n                });\n            }\n            return concat(entries);\n        }\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MapRecord#getKeys should should initialize child iterables lazily"
   },
   {
      "_id": "13078419",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 20:07:22",
      "description": "There is a few places where this annotation is missing and should be added.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add missing @Nonnull annotations"
   },
   {
      "_id": "13078418",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 20:05:32",
      "description": "Remove the throws clause for the {{IOException}}, which never thrown.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Closeable.close in StandbyStoreService declares exception that is never thrown"
   },
   {
      "_id": "13078417",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 20:03:08",
      "description": "Remove the throws clause for the {{InterruptedException}}, which never thrown.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "LockBasedScheduler.execute declares exception that is never thrown"
   },
   {
      "_id": "13078414",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 20:00:12",
      "description": "Immutable fields should be final",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Declare immutable field of FileStore.CompactionResult final"
   },
   {
      "_id": "13078413",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 19:57:31",
      "description": "The field is immutable and should thus be declared final.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Declare StandbyStoreService.closer final"
   },
   {
      "_id": "13078412",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 19:55:13",
      "description": "That field is only used in the constructor an can thus be converted to a local variable. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Convert FileStore.maxFileSize fiels into local variable"
   },
   {
      "_id": "13078411",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-06-08 19:52:30",
      "description": "That field is not used any more since the explicit commit queue was introduced. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove unused field SegmentNodeStore.reader"
   },
   {
      "_id": "13076144",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-05-31 09:34:10",
      "description": "This is a leftover from when we switched from record ids to record numbers as at that point it became unnecessary to track such references. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Unreferenced argument reference in method SegmentBufferWriter.writeRecordId"
   },
   {
      "_id": "13074194",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-05-23 13:10:44",
      "description": "Regression\n\norg.apache.jackrabbit.oak.plugins.document.VersionGCTest.gcMonitorInfoMessages\nFailing for the past 1 build (Since Failed#330 )\nTook 28 ms.\nError Message\n\nexpected:<3> but was:<7>\n\nStacktrace\n\njava.lang.AssertionError: expected:<3> but was:<7>\n\tat org.apache.jackrabbit.oak.plugins.document.VersionGCTest.gcMonitorInfoMessages(VersionGCTest.java:224)\n\nFailed run: [Jackrabbit Oak #330|https://builds.apache.org/job/Jackrabbit%20Oak/330/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/330/console]\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: VersionGCTest.gcMonitorInfoMessages"
   },
   {
      "_id": "13074117",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-05-23 08:50:07",
      "description": "OAK-5956 improved the statistics collected for the segment cache. As I expected this had an impact on performance as measured by our micro benchmarks. An impact is visible for {{ConcurrentReadTest}}, {{ConcurrentReadWriteTest}} and {{ConcurrentWriteTest}}. Impact on full stack operation is yet to be determined (I assume it is neglectable though). \n\n{noformat}\n# ConcurrentReadTest               C     min     10%     50%     90%     max       N \nOak-Segment-Tar (base)             1      43     101     112     129     219     525\nOak-Segment-Tar (OAK-5956)         1      45     104     118     138     264     496\n{noformat}\n\nThe impact seems to be mostly caused by the {{SegmentId.onAccess}} callback. \n\nPossible solutions:\n* Replace the {{SegmentId.onAccess}} callback with a direct reference to the underlying counter. \n* Allow disabling of the cache statistics. \n* Do nothing and accept the performance impact. \n\nThe first approach is least attractive as it breaks encapsulation. Depending on the impact of this on full stack operations I'd either go with the 2nd or 3rd option.  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Minor performance impact by collecting data for SegmentCache statistics "
   },
   {
      "_id": "13070838",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-05-10 14:52:02",
      "description": "Before 1.6 {{oak-run compact}} had a way to explicitly enable/disable memory mapping of the tar files. Somehow this got lost in {{oak-segment-tar}}. \n\nWe need to add this back as e.g. on Windows memory mapping does not work well and we need to be able to explicitly disable it. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run compact should have an option to disable/enable memory mapping"
   },
   {
      "_id": "13070389",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-05-09 11:52:33",
      "description": "When the file store is shut down during gc compaction is properly aborted. Afterwards it will trigger a cleanup cycle though, which runs concurrently to the proceeding shutdown potentially causing an {{ISE}}:\n\n{noformat}\nat com.google.common.base.Preconditions.checkState(Preconditions.java:134)\nat org.apache.jackrabbit.oak.segment.file.TarWriter.close(TarWriter.java:333)\nat org.apache.jackrabbit.oak.segment.file.TarWriter.createNextGeneration(TarWriter.java:376)\nat org.apache.jackrabbit.oak.segment.file.FileStore.newWriter(FileStore.java:682)\nat org.apache.jackrabbit.oak.segment.file.FileStore.access$1700(FileStore.java:100)\nat org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.cleanup(FileStore.java:1069)\nat org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.cleanupGeneration(FileStore.java:1195)\nat org.apache.jackrabbit.oak.segment.file.FileStore$GarbageCollector.run(FileStore.java:803)\nat org.apache.jackrabbit.oak.segment.file.FileStore.gc(FileStore.java:387)\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "IllegalStateException when closing the FileStore during garbage collection"
   },
   {
      "_id": "13069938",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2017-05-08 10:17:29",
      "description": "The set returned by {{MongoMissingLastRevSeeker.getCandidates()}} may be incomplete. See also discussion in OAK-4535 and on [oak-dev|https://lists.apache.org/thread.html/36ade745b7f6a0417aab578c21ca9fb072a7d6e5c43c724b85a153bf@%3Coak-dev.jackrabbit.apache.org%3E].",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MongoMissingLastRevSeeker may return incomplete candidate set"
   },
   {
      "_id": "13069223",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2017-05-04 17:44:42",
      "description": "There is no unit test coverage for {{IOUtils.humanReadableByteCount}} in {{oak-commons}}.\n\nI will add a patch shortly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "unit-test-missing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add unit test coverage for IOUtils.humanReadableByteCount"
   },
   {
      "_id": "13069198",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-05-04 16:30:46",
      "description": "Jenkins CI failure: https://builds.apache.org/view/J/job/Jackrabbit%20Oak/\n\nThe build Jackrabbit Oak #253 has failed.\nFirst failed run: [Jackrabbit Oak #253|https://builds.apache.org/job/Jackrabbit%20Oak/253/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/253/console]\n\n{code}\njava.lang.AssertionError: expected:<[INITIALIZING, COLLECTING, UPDATING, SPLITS_CLEANUP, IDLE]> but was:<[INITIALIZING, COLLECTING, CHECKING, COLLECTING, DELETING, SORTING, DELETING, UPDATING, SPLITS_CLEANUP, IDLE]>\n\tat org.apache.jackrabbit.oak.plugins.document.VersionGCTest.gcMonitorStatusUpdates(VersionGCTest.java:207)\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: VersionGCTest.gcMonitorStatusUpdates"
   },
   {
      "_id": "13069197",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2017-05-04 16:30:26",
      "description": "There is no unit test coverage for {{IOUtils.copy}} in {{oak-commons}}.\n\nI will add a patch shortly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "unit-test-missing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add unit test coverage for IOUtils.copy"
   },
   {
      "_id": "13068885",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2017-05-03 19:04:05",
      "description": "There is no unit test coverage for IOUtils.writeInt(), IOUtils.writeLong(), IOUtils.readInt(), and IOUtils.readLong() in oak-commons.\n\nI am working on a patch and will have one to submit shortly.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "easyfix",
         "patch",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add unit test coverage for IOUtils.writeInt/writeLong and IOUtils.readInt/readLong"
   },
   {
      "_id": "13065492",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-20 11:36:17",
      "description": "Using offline compaction on a repository with nodes having many direct child node I observed a steady increase of heap usage. This is cause by using a {{MemoryNodeBuilder}} in {{CompactDiff.childNodeAdded()}}, which causes all those child nodes to be cached in memory. \n\nChanging the line\n\n{code}\nchild = EMPTY_NODE.builder();\n{code}\n\nto \n\n{code}\nchild = writer.writeNode(EMPTY_NODE).builder();\n{code}\n\nfixes the problem as the latter returns a {{SegmentNodeBuilder}} where the former returns a {{MemoryNodeBuilder}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "memory",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction uses too much memory "
   },
   {
      "_id": "13065446",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-20 08:59:43",
      "description": "The references of a segment to other segments are cached within {{Segment.readReferencedSegments()}}. However caching the {{SegmentId}} instances themselves leads to excessive heap usage as each id also keeps a reference to its underlying segment. \n\nI suggest to cache those references as msb, lsb pairs instead and create the {{SegmentId}} instance on the fly when required. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Excessive memory usage by the cached segment references"
   },
   {
      "_id": "13064720",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-04-18 14:17:43",
      "description": "See OAK-6020.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.management.ManagementOperation should use TimeDurationFormatter"
   },
   {
      "_id": "13064699",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2017-04-18 13:32:49",
      "description": "With OAK-2106 Oak now attempts to read from a MongoDB secondary when it detects the requested data is available on the secondary.\n\nWhen multiple Oak cluster nodes are deployed on a MongoDB replica set, many reads are still directed to the primary. One of the reasons why this is seen in practice, are observers and JCR event listeners that are triggered rather soon after a change happens and therefore read recently modified documents. This makes it difficult for Oak to direct calls to a nearby secondary, because changes may not yet be available there.\n\nA rather simple solution for the observers may be to delay processing of changes until they are available on the near secondary.\n\nA more sophisticated solution discussed offline could hide the replica set entirely and always read from the nearest secondary. Writes would obviously still go to the primary, but only return when the write is available also on the nearest secondary. This guarantees that any subsequent read is able to see the preceding write.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid reads from MongoDB primary"
   },
   {
      "_id": "13063204",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-11 14:06:13",
      "description": "For easier understanding of the cold standby behaviour, threads used by the cold standby implementations should be assigned more human readable names.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Assign meaningful names to cold standby threads"
   },
   {
      "_id": "13062916",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-10 14:41:34",
      "description": "Jenkins CI failure: https://builds.apache.org/view/J/job/Jackrabbit%20Oak/\n\nThe build Jackrabbit Oak #144 has failed.\nFirst failed run: [Jackrabbit Oak #144|https://builds.apache.org/job/Jackrabbit%20Oak/144/] [console log|https://builds.apache.org/job/Jackrabbit%20Oak/144/console]\n\nError Message\n\n{code}\nexpected: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }> but was: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }>\n{code}\n\nStacktrace\n\n{code}\njava.lang.AssertionError: expected: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }> but was: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }>\n    at org.apache.jackrabbit.oak.segment.standby.StandbyTestIT.testSyncLoop(StandbyTestIT.java:126)\n{code}\n\nStandard Output\n\n[^stdout.log]\n\nAlso failed at https://builds.apache.org/job/Jackrabbit%20Oak/394/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "flaky-test",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: StandbyTestIT.testSyncLoop"
   },
   {
      "_id": "13062144",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-06 15:38:54",
      "description": "The refactoring from OAK-6002 moved the cleanup of the tar readers into the read lock, which blocks concurrent writers from progressing. This was a problem with {{oak-segment}} before and fixed with OAK-3329.\nAs cleanup can take up to a couple of minutes on busy system we should re-establish the former behaviour. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cleanup blocks writers"
   },
   {
      "_id": "13061466",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-04 16:05:05",
      "description": "That test fails for me on every 2nd run or so. This seems to be a regression introduced with OAK-6002. \n\n{code}\norg.junit.ComparisonFailure: Expected nothing to be cleaned but generation 'b' for file data00002b.tar indicates otherwise. \nExpected :a\nActual   :b\n\n\nat org.junit.Assert.assertEquals(Assert.java:115)\norg.apache.jackrabbit.oak.segment.CompactionAndCleanupIT.concurrentCleanup(CompactionAndCleanupIT.java:1252)\n{code}\n\n[~frm], could you have a look?\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: CompactionAndCleanupIT.concurrentCleanup"
   },
   {
      "_id": "13061396",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-04 09:56:35",
      "description": "The newly created {{TarFiles}} should be added to the architecture diagram for oak-segment-tar.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add TarFiles to the architecture diagram"
   },
   {
      "_id": "13061085",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-04-03 10:31:54",
      "description": "We could probably remove the segment graph functionality from oak-run. This has been implemented mainly (and solely?) for the purpose of analysing the problems around OAK-3348 and I assume it would quickly start falling behind as we move forward. Also for this kind of analysis I have switched to [oak-script|https://github.com/mduerig/script-oak], which is far more flexible. \n\nLet's decide closer to cutting 1.8 how to go forward here.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove segment graph functionality from oak-run"
   },
   {
      "_id": "13061054",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-04-03 08:02:55",
      "description": "Comparing node states in read-only mode may fail with an IllegalStateException when the journal is used to perform a diff.\n\n{noformat}\njava.lang.IllegalStateException: Root document does not have a lastRev entry for local clusterId 0\n    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199)\n    at com.google.common.cache.LocalCache.get(LocalCache.java:3932)\n    at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721)\n    at org.apache.jackrabbit.oak.plugins.document.MemoryDiffCache.getChanges(MemoryDiffCache.java:83)\n    at org.apache.jackrabbit.oak.plugins.document.TieredDiffCache.getChanges(TieredDiffCache.java:50)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.compare(DocumentNodeStore.java:1632)\n[...]\nCaused by: java.lang.IllegalStateException: Root document does not have a lastRev entry for local clusterId 0\n    at org.apache.jackrabbit.oak.plugins.document.JournalDiffLoader.call(JournalDiffLoader.java:82)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.diffImpl(DocumentNodeStore.java:2428)\n{noformat}\n\nSee also OAK-6011.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_6"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore.compare() fails with IllegalStateException in read-only mode"
   },
   {
      "_id": "13060292",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-30 08:08:45",
      "description": "Cancellation of (force) compaction by timeout is currently implemented on top of the {{CancelCompactionSupplier}}. It should better be implemented within though to simplify the implementation of OAK-3349. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "refactoring",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Simplify cancellation of compaction by timeout "
   },
   {
      "_id": "13060282",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-03-30 07:50:05",
      "description": "Introduce a DocumentStore wrapper that can be instructed to fail after some number of operations or with some probability.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Introduce a FailingDocumentStore"
   },
   {
      "_id": "13060276",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-30 07:22:31",
      "description": "We should also add the record id of the root node resulting from compaction to the gc log. This would have been helpful a couple of times already in the past for testing and post mortems. It will likely also be a requirement to implement the tail compaction approach form OAK-3349. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add record id of the compacted root to the GC journal"
   },
   {
      "_id": "13059956",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-29 07:53:41",
      "description": "Currently {{Revisions.setHead(Function, Option)}} returns a {{boolean}} to indicate success or failure. The caller has no access to the head resulting from this call. I would thus like to change this into the record id of the new head in case of success and {{null}} otherwise. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Revisions.setHead(Function) should return the new head or null instead of boolean"
   },
   {
      "_id": "13058163",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-03-22 09:34:03",
      "description": "Secondary NodeStore feature (OAK-4180) for now currently supports path inclusion. It would be useful to have support for path exclusion also.\n\nUsing this a user can can include all content  under / but exclude /oak:index/uuid/:index entries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support path exclusion in secondary nodestore"
   },
   {
      "_id": "13057878",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-03-21 12:40:44",
      "description": "The Metrics related classes and interfaces in {{org.apache.jackrabbit.oak.stats}} and {{org.apache.jackrabbit.oak.plugins.metric}} are largely undocumented. Specifically it is not immediately how they should be used, how a new {{Stats}} instance should be added, what the effect this would have and how it would (or would) not be exposed (e.g. via JMX). \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document Metrics related classes and interfaces"
   },
   {
      "_id": "13057868",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-21 12:19:04",
      "description": "The statistics provided by the segment cache are off due to the fact it serves as 2nd level cache: as it doesn't see all the hits in the 1st level cache ({{SegmentId.getSegment()}}), it reports a hit/miss rate that is to low. \n\nWe should look into how we could expose better statistics wrt. caching of segments. Possible consolidated over 1st and 2nd level caches. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve cache statistics of the segment cache"
   },
   {
      "_id": "13057842",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-21 10:12:38",
      "description": "As a preparation to enable better monitoring and add more precise monitoring probes to the deduplication caches I would like to unify their interfaces and simplify their setup. \n* Don't expose the cache statistics via the {{FileStore}} and leverage the the {{FileStoreBuilder}} instead for this.\n* All deduplication caches should implement a unified {{Cache}} interface to simplify wrapping them (e.g. for additional access statistics collection). \n* Replace the ad-hoc collection of cache statistics in the {{NodeWriteStats}} inner class of the {{SegmentWriter}} and replace it with a more structured approach. \n* Expose additional cache access statistics via Metrics. \n* The additional statistics should discriminate caches access occurring as regular writes from such occurring during compaction. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring",
         "refactoring",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Unify and simplify the deduplication caches "
   },
   {
      "_id": "13057836",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-21 09:46:03",
      "description": "Currently {{CacheStats.loadExceptionCount()}} always returns 0 on a cache statistics retrieved from the {{PriorityCache}}. I would like to implement this statistics by returning the number of times a {{put()}} failed on that cache because it did not find an empty slot. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "PriorityCache statistics should support load exception count"
   },
   {
      "_id": "13056362",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-03-15 17:22:25",
      "description": "The CachedNodeDocument interface was introduced with OAK-891 but then the feature was later removed with OAK-2937. The interface is not used anywhere and should be removed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove CachedNodeDocument"
   },
   {
      "_id": "13056257",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-15 11:06:36",
      "description": "That depth parameter is a leftover from when the node de-duplication cache used the depth of a node in the tree for its eviction strategy. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove unused depth parameter SegmentWriteOperation#writeNode and related methods"
   },
   {
      "_id": "13049537",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-09 09:07:43",
      "description": "Running that IT (with 4g heap) currently results in an {{OOME}}. We need to check whether the expectations are still valid for Segment Tar and either adapt the test or look into the memory consumption. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "OOM in SegmentReferenceLimitTestIT"
   },
   {
      "_id": "13048893",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-07 13:54:09",
      "description": "Currently there is a limitation for the maximum binary size (in bytes) to be synced between primary and standby instances. This matches {{Integer.MAX_VALUE}} (2,147,483,647) bytes and no binaries bigger than this limit can be synced between the instances.\n\nPer comment at [1], the current protocol needs to be changed to allow sending of binaries in chunks, to surpass this limitation.\n\n[1] https://github.com/apache/jackrabbit-oak/blob/1.6/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/standby/client/StandbyClient.java#L125",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cold standby should allow syncing of blobs bigger than 2.2 GB"
   },
   {
      "_id": "13047970",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-03 10:07:49",
      "description": "{{oak-segment}} had a {{tarmkrecovery}} command responsible with listing candidates for head journal entries. We should re-enable this also for {{oak-segment-tar}}.\n\n/cc [~mduerig] [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "segment-tar should have a tarmkrecovery command"
   },
   {
      "_id": "13047961",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-03-03 09:51:37",
      "description": "{{RepositoryGrowthTest}} is a benchmark which makes use of the deprecated {{SegmentFixture}}. Since OAK-5834 removes the old {{oak-segment}} module and the code associated with it, {{RepositoryGrowthTest}} was also removed. If there's value in it, we can adapt it to work with the new {{SegmentTarFixture}}.\n\n/cc [~chetanm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "benchmark"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Evaluate utility of RepositoryGrowthTest benchmark"
   },
   {
      "_id": "13047677",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2017-03-02 13:34:03",
      "description": "Running {{java -jar oak-upgrade*.jar}}\u00a0prints \n\n{noformat}\nUsage: java -jar oak-run-*-jr2.jar upgrade [options] jcr2_source [destination]\n       (to upgrade a JCR 2 repository)\n\n       java -jar oak-run-*-jr2.jar upgrade [options] source destination\n       (to migrate an Oak repository)\n{noformat}\n\nWhich incorrectly refers to {{oak-run upgrade}}. The latter will send me back to {{oak-run}}: \"This command was moved to the oak-upgrade module\". ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "production",
         "tooling",
         "usability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Oak upgrade usage note refers to oak-run"
   },
   {
      "_id": "13046916",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-28 09:47:04",
      "description": "It would be interesting to see the effect of compressing the segments within the tar files with a sufficiently effective and performant compression algorithm:\n\n* Can we increase overall throughput by trading CPU for IO?\n* Can we scale to bigger repositories (in number of nodes) by squeezing in more segments per MB and thus pushing out onset of thrashing?\n* What would be a good compression algorithm/library?\n* Can/should we make this optional? \n* Migration and compatibility issues?\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compressed segments"
   },
   {
      "_id": "13046660",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-27 15:04:13",
      "description": "On of the {{Template}} constructors (the one used when writing templates) performs a call to {{NodeState.getChildNodeCount()}} to determine the value of {{Template.childName}}. I have seen this call comping up in performance traces on various occasions, which leads me to believe there is room for improvement here. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Potential expensive call to NodeState.getChildNodeCount() in constructor of Template"
   },
   {
      "_id": "13046007",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2017-02-24 12:46:27",
      "description": "The {{oak-segment}} module has been deprecated for 1.6 with OAK-4247. We should remove it entirely now:\n\n* Remove the module\n* Remove fixtures and ITs pertaining to it\n* Remove references from documentation where not needed any more\n\nAn open question is how we should deal with the tooling for {{oak-segment}}. Should we still maintain this in trunk and keep the required classes (which very much might be all) or should we maintain the tooling on the branches? What about new features in tooling? \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "deprecation",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove the deprecated oak-segment module"
   },
   {
      "_id": "13045682",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-23 17:07:20",
      "description": "With {{oak-run check}} we can determine the last good revision of a repository and use it to manually roll back a corrupted segment store. \n\nComplementary to this we should implement a tool to roll forward a broken revision to a fixed new revision. Such a tool needs to detect which items are affected by a corruption and replace these items with markers. With this the repository could brought back online and the markers could be used to identify the locations in the tree where further manual action might be needed. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "production",
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TarMK: Implement tooling to repair broken nodes"
   },
   {
      "_id": "13045662",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-23 16:00:16",
      "description": "Currently the compactor does just a rewrite of the super root node without any special handling of the checkpoints. It just relies on the node de-duplication cache to avoid fully exploding the checkpoints. \nI think this can be improved by subsequently rebasing checkpoints on top of each other during compaction. (Very much like checkpoints are handled in migration). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Chronologically rebase checkpoints on top of each other during compaction"
   },
   {
      "_id": "13045626",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-02-23 13:56:27",
      "description": "If a single node is modified in a commit then currently it performs 2 remote calls\n\n# The actual update\n# Update of commit root\n\nas for single node update commitRoot == node being updated we can optimize this case to see if both operations can be done in same call",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Perform update of single node in one remote call if possible"
   },
   {
      "_id": "13045336",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-22 18:54:25",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=integrationTesting #472 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=integrationTesting #472|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=integrationTesting/472/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=integrationTesting/472/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: segment.standby.MBeanIT.testClientAndServerEmptyConfig"
   },
   {
      "_id": "13045164",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-22 09:40:34",
      "description": "To better explain the bug I'll describe the content of the revisions:\n# Valid Revision\nAdds child nodes {{a}}, {{b}}, {{c}}, {{d}}, {{e}}, {{f}} with various properties (blobs included)\n# Invalid Revision\nAdds child node {{z}} with some blob properties and then corrupts the {{NODE}} record holding {{z}}.\nNow when the consistency check is run, it correctly detects that the second revision is broken, *marks the path {{/z}} as corrupt* and then continues checking the first valid revision. Because of a check introduced for OAK-5556 [1], which tries to validate the user provided absolute paths before checking them, the checker tries to check {{/z}} in the first revision, where of course it can't find it. Therefore the check incorrectly fails for this revision, although it shouldn't have to.\n\n/cc [~mduerig], [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Consistency check incorrectly fails for broken partial paths "
   },
   {
      "_id": "13045162",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-02-22 09:36:32",
      "description": "There are multiple places in DocumentNodeStore where background operations log timing. This should be consolidated.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove duplicate code for background operation timing log"
   },
   {
      "_id": "13044658",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2017-02-20 21:59:47",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=unittesting #465 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=unittesting #465|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=unittesting/465/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=unittesting/465/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: org.apache.jackrabbit.oak.run.osgi.SegmentNodeStoreConfigTest.testDeadlock"
   },
   {
      "_id": "13042975",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2017-02-14 15:29:45",
      "description": "[~chetanm], in the light of OAK-4975 a dependency to the document nodestore code got introduced in {{org.apache.jackrabbit.oak.plugins.nodetype.write.InitialContent}} by adding the following line:\n{code}\n        BundlingConfigInitializer.INSTANCE.initialize(builder);\n{code}\n\nthe {{BundlingConfigInitializer}} is defined in the {{org.apache.jackrabbit.oak.plugins.document.bundlor}}.\n\nTo me that looks quite troublesome and I don't think the generic JCR-InitialContent should have any dependency on the document nodestore code base.\n\nWhy not defining a dedicated {{RepositoryInitializer}} for that kind of init an making sure it is listed in the (default) setup scenarios (or at least in those that actually have a document store and thus require this)?\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "modularization",
         "tech-debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "InitialContent depends on document.bundlor.BundlingConfigInitializer"
   },
   {
      "_id": "13042569",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-13 13:06:28",
      "description": "This is a bigger refactoring item to revisit the format of the exposed data, moving towards having it in a more machine consumable friendly format.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Revisit FileStoreStats mbean stats format"
   },
   {
      "_id": "13042568",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-13 13:04:48",
      "description": "Followup of OAK-5632 and OAK-5631, to expose the collected data via JMX for external use.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Expose IOMonitor stats via JMX"
   },
   {
      "_id": "13041683",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-09 12:26:23",
      "description": "The current implementation of the consistency check ({{ConsistencyChecker}},{{CheckCommand}})\nis cluttered with unnecessary checks regarding deprecated arguments of the {{check}} command. \nWith OAK-5595, deep traversals are enabled by default, therefore the code needs to be revised to take this into account. The same applies to the argument taken by {{--bin}} option, which was removed in OAK-5604.\n\nMoreover, {{ConsistencyChecker}} could be refactored in order to better distinguish when:\n* a full path at the given revision is checked\n* a node and its properties are checked\n* a node and its descendants are checked",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Simplify consistency check"
   },
   {
      "_id": "13041595",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2017-02-09 05:54:16",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_MK,profile=integrationTesting #443 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.7 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_MK,profile=integrationTesting #443|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_MK,profile=integrationTesting/443/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.7%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_MK,profile=integrationTesting/443/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: segment.standby.ExternalSharedStoreIT.testProxyFlippedIntermediateByteChange2"
   },
   {
      "_id": "13041582",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-02-09 04:04:42",
      "description": "Jenkins Windows CI failure: https://builds.apache.org/job/Oak-Win/\n\nThe build Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=integrationTesting #443 has failed.\nFirst failed run: [Oak-Win/Windows slaves=Windows,jdk=JDK 1.8 (unlimited security) 64-bit Windows only,nsfixtures=SEGMENT_TAR,profile=integrationTesting #443|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=integrationTesting/443/] [console log|https://builds.apache.org/job/Oak-Win/Windows%20slaves=Windows,jdk=JDK%201.8%20(unlimited%20security)%2064-bit%20Windows%20only,nsfixtures=SEGMENT_TAR,profile=integrationTesting/443/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: org.apache.jackrabbit.mk.util.CommitGateIT.test"
   },
   {
      "_id": "13041411",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-08 15:25:25",
      "description": "Currently the {{--bin}} option expects a {{Long}} argument, as the {{LENGTH}} up to which to scan the content of binary properties. The {{--bin}} option should be simplified so that it doesn't take any arguments. Running {{check}} without the {{--bin}} flag won't scan any binary properties, while including {{--bin}} option will scan all binaries, no matter their size.\n\nIf an argument is given with {{--bin}}, there will be a failure and a warning will be displayed.\n\nThe message displayed at the end of the consistency check will be changed to take into account whether binary properties were traversed or not.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command should accept a non-argument \"bin\" option for checking binaries"
   },
   {
      "_id": "13041330",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-08 09:39:12",
      "description": "We should add tests for {{o.a.j.o.r.CheckCommand}} in order to validate recent changes introduced by adding/removing options and their arguments (see OAK-5275, OAK-5276, OAK-5277, OAK-5595). There is also a new feature introduced by OAK-5556 (filter paths) and a refactoring in OAK-5620 which must be thoroughly tested in order to avoid regressions.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test coverage for CheckCommand"
   },
   {
      "_id": "13040675",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-06 16:08:57",
      "description": "Only checking accessibility of the root nodes doesn't make much sense. Even more so because the file store automatically rolls back on startup if a root revision is not accessible. In terms of not doing full traversals, it is more interesting to restrict by path (aka OAK-5556).\n\nThe {{--deep}} option will still be accepted, but there will be a failure when it is specified. An explanation that full traversal is now done regardless of that option will be printed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command should do deep traversals by default"
   },
   {
      "_id": "13040625",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-06 12:51:21",
      "description": "When the {{check}} command is used without {{--deep}} option, there is no check/traversal being done against the repository.\n\nFirst relevant line in code is [1], where a check is supposed to happen, but due to a mismatch between argument expected/argument provided, {{null}} is always returned without checking anything. The method which should do the actual check [2] expects a set of paths to be traversed, but this set is always empty. Therefore, relevant code for running the check is never executed [3].\n\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/tooling/ConsistencyChecker.java#L120\n[2] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/tooling/ConsistencyChecker.java#L183\n[3] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/tooling/ConsistencyChecker.java#L194",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "The check command doesn't do any check when \"deep\" option is not provided"
   },
   {
      "_id": "13040030",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-02-03 04:10:23",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_MK,profile=integrationTesting #1399 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_MK,profile=integrationTesting #1399|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_MK,profile=integrationTesting/1399/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_MK,profile=integrationTesting/1399/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cold-standby",
         "test-failure",
         "ubuntu",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.segment.standby.StandbyTestIT.testSyncLoop"
   },
   {
      "_id": "13039435",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-02-01 11:19:24",
      "description": "Reading a node state in a past revision can become expensive when the change history in the previous documents have overlapping changes. In this case, the changes in the previous documents must be merge sorted to find the correct value for the properties on the node. The more overlapping ranges there are, the more sorting is needed.\n\nThere is a prominent node in the repository that seems to create quite many of those previous documents. The {{/:async}} nodes gets frequent updates and is therefore split on a regular basis. Because the properties on this node are not all updated at the same time, it is quite likely that previous document ranges overlap.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce reads with overlapping previous documents"
   },
   {
      "_id": "13039208",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2017-01-31 15:01:09",
      "description": "It would be good if the {{check}} command would allow for filtering on content path. This would help in quickly identifying what is the good revision of a specific broken node in cases of very large repos.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow filter paths for Check command"
   },
   {
      "_id": "13038925",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-30 16:13:41",
      "description": "We should improve our documentation of the internal design of the the TarMK. There is currently a [single section|http://jackrabbit.apache.org/oak/docs/nodestore/segment/overview.html#design]. \n\n* Add a high level class diagram and description of the overall structure of the TarMK. \n* Decide what to do with {{segmentmk.md}}. My preference would be to incorporate everything from it we didn't cover so far into {{segment/overview.md}}, {{segment/records.md}} and {{segment/tar.md}}. \n* Rewrite, clarify the design section in {{segment/overview.md}}. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document TarMK design"
   },
   {
      "_id": "13038747",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-01-29 12:22:52",
      "description": "grouping the improvements for indexer resilience in this issue for easier tracking",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Improve indexing resilience"
   },
   {
      "_id": "13038623",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-01-28 06:53:48",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting #1390 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting #1390|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting/1390/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_TAR,profile=integrationTesting/1390/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: security.authentication.ldap.LdapProviderTest (Address already in use)"
   },
   {
      "_id": "13038418",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-01-27 11:19:23",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_RDB,profile=unittesting #1386 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_RDB,profile=unittesting #1386|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_RDB,profile=unittesting/1386/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_RDB,profile=unittesting/1386/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: standalone.RepositoryBootIT.repositoryLogin"
   },
   {
      "_id": "13038374",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2017-01-27 06:57:47",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1384 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1384|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1384/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1384/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: segment.standby.ExternalSharedStoreIT/BrokenNetworkTest.test..."
   },
   {
      "_id": "13037770",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-25 17:16:16",
      "description": "When a gc run is cancelled the subsequent run (compaction phase to be precise) can result in a {{SNFE}}. The reason for this is the node deduplication cache not being purged in the cancellation case. This causes the subsequent compaction to reference node states from that cache that have been cleaned. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "SNFE when running compaction after a cancelled gc"
   },
   {
      "_id": "13037624",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-25 09:06:49",
      "description": "The OSGi setting controlling standby automatic cleanup, {{standby.autoclean}}, should be set to {{true}} by default. When the automatic cleanup is on, the {{cleanup()}} method will be called on standby, provided the size of the store increases over 25% on a sync cycle.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cold-standby"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Standby Automatic Cleanup should be on by default"
   },
   {
      "_id": "13037570",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         }
      ],
      "created": "2017-01-25 04:10:07",
      "description": "Currently {{IndexUpdate}} does a lookup for {{oak:index}} node under each changed node. This is done to pickup index definitions and create IndexEditor based on those so as to index content under that subtree. \n\nThis lookup results in extra remote calls on DocumentNodeStore based setup as for non leaf nodes NodeStore has to check from remote storage to determine if {{oak:index}} node is present or not.\n\nThis lookup can be avoided by\n# Having an {{Editor}} which adds a hidden property {{:oak-index-present}} in parent node upon addition of {{oak:index}} as a child node\n# IndexUpdate would then does a lookup for {{oak:index}} node only if such a hidden property is found\n\nFor upgrade we would have some logic which would make use of Nodetype index to identify all such nodes and mark them\n\nDiscussion [thread|https://lists.apache.org/thread.html/70d5ffff0f950d7fc25bc1bbb41527f5672825f8cf2b238f54df2966@%3Coak-dev.jackrabbit.apache.org%3E] on oak-dev",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce lookup for oak:index node under each changed node"
   },
   {
      "_id": "13036145",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324387",
            "id": "12324387",
            "name": "auth-ldap",
            "description": "Oak LDAP Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2017-01-19 09:12:56",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1375 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_TAR,profile=unittesting #1375|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1375/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_TAR,profile=unittesting/1375/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu",
         "windows"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: LdapDefaultLoginModuleTest address already in use"
   },
   {
      "_id": "13035890",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2017-01-18 14:36:33",
      "description": "There are cases where a document split is overdue and it continues to grow until it hits the MongoDB limit of 16MB.\n\nIt gets more likely, the more cluster nodes are running and when they all update the same property with a somewhat larger value. E.g. the :childOrder property of a node with many children.\n\nThe current split logic has multiple triggers that will result in creating a previous document.\n\n- There are 100 old changes for a cluster node that can be moved\n- A node was recreated with a binary bigger than 4k\n- The main document is bigger than 256k and 30% of its size can be moved to a previous document\n\nThe last condition may cause the uncontrolled growth of the document when there are many cluster nodes. If all cluster nodes continuously change a property on a node, then none of the cluster nodes will be able to move 30% of the document.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Overdue document split with many cluster nodes"
   },
   {
      "_id": "13035466",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-17 10:45:57",
      "description": "The TarMK's write throughput is limited by the way concurrent commits are processed: rebasing and running the commit hooks happen within a lock without any explicit scheduling. This epic covers improving the overall transaction rate. The proposed approach would roughly be to first make scheduling of transactions explicit, then add monitoring on transaction to gather a better understanding and then experiment and implement explicit scheduling strategies to optimise particular aspects. \n\nh2. Summary of ideas mentioned in an offline sessions\n\nh3. Advantages of explicit scheduling:\n* Control over (order) of commits\n* Sophisticated monitoring (commit statistics, e.g. commit rate, time in queue, etc.) \n* Favour certain commits (e.g. checkpoints)\n* Reorder commits to simplify rebasing\n* Suspend the compactor on concurrent commits and have it resume where it left off afterwards\n* Parallelise certain commits (e.g. by piggy backing)\n* Implement a concurrent commit editor. we'd need to take care of proper access to the shared state; [~frm] maybe introduce the idea of a common context to enforce concurrent access semantics.\n\nh3. Scheduler Implementation\n* Expedite\n* Prioritise\n* Defer\n* Collapse\n* Coalesce\n* Parallelise\n* Piggy back: can we piggy back commits on top of each other? The idea would be while processing the changes of one commit to also check them for conflicts with the changes of other commits waiting to commit. If a conflict is detected there, that other commit can immediately be failed (given the current commit doesn't fail).\n* Merging non conflicting commits. Given multiple transactions ready to commit at the same time. Can we process them as one (given they don't conflict) instead of one after each other, which requires rebasing the later transaction to be rebase on the former.\n* Shield the file store from {{InterruptedException}} because of thread boundaries introduced\n* Implement tests, benchmarks and fixtures for verification\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve the transaction rate of the TarMK"
   },
   {
      "_id": "13035392",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328326",
            "id": "12328326",
            "name": "examples"
         }
      ],
      "created": "2017-01-17 04:01:49",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_MK,profile=integrationTesting #1369 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=SEGMENT_MK,profile=integrationTesting #1369|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_MK,profile=integrationTesting/1369/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=SEGMENT_MK,profile=integrationTesting/1369/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: RepositoryBootIT.repositoryLogin"
   },
   {
      "_id": "13033612",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-01-11 06:43:51",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=unittesting #1363 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_RDB,profile=unittesting #1363|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=unittesting/1363/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_RDB,profile=unittesting/1363/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: BasicServerTest.testServerOk() Address already in use"
   },
   {
      "_id": "13033423",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2017-01-10 15:45:25",
      "description": "Commands in oak-run currently live in a flat namespace. If a command is specific to only one implementation, it will leave along other implementation-specific commands without any means of distinguishing what belongs where.\n\nI would like to add a layer of indirection to the oak-run command line interface, so to parse commands in the following fashion:\n\n{noformat}\noak-run segment debug /path/to/folder\noak-run mongo debug mongodb://host:12345\noak-run rdb debug jdbc:oracle:oci8:scott/tiger@myhost\n{noformat}\n\nIn this scenario, oak-run would become a simple entry point that would delegate to implementation-specific command line utilities based on the first argument. In the previous example, {{segment}}, {{mongo}} and {{rdb}} would delegate to three different implementation specific CLI utilities. Each of these CLI utilities will understand the {{debug}} command and will collect command-line parameters as it sees fit.\n\nIf the code for a command is so generic that can be reused from different commands, it can be parameterised and reused from different implementation-specific commands.\n\nThe benefit of this approach is that we can start moving commands closer to the implementations. This approach would benefit oak-run as well, which is overloaded with many commands from many different implementations.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add a persistence-dependent namespace when running CLI commands"
   },
   {
      "_id": "13033355",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2017-01-10 12:00:48",
      "description": "ExternalIndexObserver is currently backed by a queue (its wrapped in BackgroundObserver). Currently it processed the changes one by one as received from the queue. If this processing takes long time then its possible that it would lag behind the async indexing cycle.\n\nSo ExternalIndexObserver may be busy indexing changes from [r1-r2] but async indexing is already done indexing changes upto r3 (r3 > r2) and IndexTracker would move to newer index version. In such case work done by ExternalIndexObserver is wasted. \n\nThis can be optimized by ensuring that ExternalIndexObserver can see the lastIndexTo of :async as per latest entry in queue. If that is newer than one its processing then it can skip processing the queue entry and thus free up space in queue",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Skip processing of queued changes if async index update is detected in ExternalIndexObserver"
   },
   {
      "_id": "13033276",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2017-01-10 05:38:07",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting #1360 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.8 (latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting #1360|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting/1360/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.8%20(latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting/1360/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test Failure: org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT.compactionNoBinaryClone"
   },
   {
      "_id": "13032769",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328326",
            "id": "12328326",
            "name": "examples"
         }
      ],
      "created": "2017-01-07 04:04:59",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1357 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1357|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1357/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1357/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "test-failure",
         "ubuntu"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: TomcatIT.testTomcat()"
   },
   {
      "_id": "13032183",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2017-01-05 07:42:26",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_MK,profile=unittesting #1355 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=SEGMENT_MK,profile=unittesting #1355|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_MK,profile=unittesting/1355/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=SEGMENT_MK,profile=unittesting/1355/console]\n\nInitially reported test failure: testProxyFlippedStartByte()\nAdditional test failure reported via OAK-5476: testProxySSLSkippedBytes()\nAdditional test failure reported via OAK-5477: testProxyFlippedStartByteSSL()\nAdditional test failures reported via OAK-5478: all tests failed",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: segment.standby.BrokenNetworkTest"
   },
   {
      "_id": "13030476",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         }
      ],
      "created": "2016-12-24 07:30:44",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1351 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=unittesting #1351|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1351/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=unittesting/1351/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ...stats.ClockTest.testClockDrift"
   },
   {
      "_id": "13029783",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-21 15:19:49",
      "description": "When revision garbage collection is cancelled because one of the conditions in {{CancelCompactionSupplier}} then this should be reported to {{GCMonitor.skipped}}. Currently it is not. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc",
         "monitoring",
         "production",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cancelled garbage collection not reported to GCMonitor"
   },
   {
      "_id": "13029507",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-20 16:49:36",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting #1338 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/Ubuntu Slaves=ubuntu,jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting #1338|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting/1338/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/Ubuntu%20Slaves=ubuntu,jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_NS,profile=integrationTesting/1338/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: CompactionAndCleanupIT"
   },
   {
      "_id": "13029400",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-20 09:57:22",
      "description": "Improve code coverage of oak-segment-tar.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve code coverage of oak-segment-tar"
   },
   {
      "_id": "13029134",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-19 13:27:31",
      "description": "In {{SegmentNodeStoreService}} there is {{repository.home}}, {{DIRECTORY}}, {{getRootDirectory()}}, {{getDirectory()}} and {{getBaseDirectory()}} mostly without documentation about their intention. I think we should clarify, document and consolidate them. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clarify the various directories and their usages in SegmentNodeStoreService"
   },
   {
      "_id": "13028399",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-15 14:46:13",
      "description": "{{org.apache.jackrabbit.oak.segment.file.ReversedLinesFileReaderTestParamBlockSize}} should actually have been removed with OAK-4467, where we replaced our {{ReversedLinesFileReader}} implementation with the one from {{commons-io}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove ReversedLinesFileReaderTestParamBlockSize"
   },
   {
      "_id": "13028126",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-14 15:34:03",
      "description": "{{AbstractFileStore.collectFiles()}} contains legacy upgrade code dating back to special handling of binaries in older version of {{oak-segment}} (bulkFiles). We should remove this code. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove legacy upgrade code from AbstractFileStore.collectFiles"
   },
   {
      "_id": "13028123",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-14 15:22:44",
      "description": "{{MapEntry.compareTo()}} passes possibly {{null}} {{MapEntry.value}} to {{ComparisonChain.compare(Comparable, Comparable)}}, which does not accept {{null}} values. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Possible null dereference in MapRecord"
   },
   {
      "_id": "13027751",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-13 10:28:28",
      "description": "We should run some static analysis (i.e. sonar, find bugs, etc.) on our code base and fix the most sever issues. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Static code analysis and code cleanup"
   },
   {
      "_id": "13027713",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-13 08:01:58",
      "description": "The {{tarmkdiff}} command is actually the combination of two commands. \n\nThe first command, activated when the {{\\-\\-list}} flag is specified, list available revisions in the Segment Store. For this command, only the {{\\-\\-output}} option is relevant. If other options are specified, they are ignored.\n\nThe second command is the proper logic of {{tarmkdiff}}. This logic is activated only if the {{\\-\\-list}} flag is not specified. For this command, every option on the command line is relevant.\n\nThe logic listing available revisions in the Segment Store should be encapsulated in its own command, without cluttering the CLI of {{tarmkdiff}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The tarmkdiff command does too many things"
   },
   {
      "_id": "13027472",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-12 14:59:27",
      "description": "The {{check}} command enables the traversal of binary properties via the {{--bin}} option. The user could provide a value for this option to specify the amount of bytes that should be traversed for every binary value. The default value for the {{--bin}} option is zero, effectively disabling the traversal of binary properties. Instead, if a value for this property is not specified, the tools should traverse the binary properties in their entirety. A value should be specified only to restrict the amount of bytes to traverse.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command defines a useless default value for the \"bin\" option"
   },
   {
      "_id": "13027471",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-12 14:52:58",
      "description": "The {{--deep}} option accepted by the {{check}} command is semantically overloaded. It is used both as a flag to enable deep content traversal and as a way to specify the frequency of debug messages printed by the tool. \n\nThis option should be split in two. In particular, {{--deep}} should retain its behaviour of on/off flag for deep traversal, and a new command line option should be introduced to specify the interval of debug messages.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command overloads the meaning of the \"deep\" option"
   },
   {
      "_id": "13027470",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-12 14:48:33",
      "description": "The {{check}} tool requires the path to the store to be specified. The path is passed to the tool via a required option {{--path}}. This way of specifying the path to the store is verbose for no good reason. It would be nicer if the path to the Segment Store would be specified via a positional argument instead.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "The check command should accept the path to the store as a positional argument"
   },
   {
      "_id": "13027002",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-09 13:47:59",
      "description": "The default value for the size delta estimation used during garbage collection should be changed to 1GB.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Better default for size delta estimation "
   },
   {
      "_id": "13026547",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12331094",
            "id": "12331094",
            "name": "continuous integration",
            "description": "Issues auto reported by CI"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-12-08 03:50:37",
      "description": "Jenkins CI failure: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/\n\nThe build Apache Jackrabbit Oak matrix/jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1320 has failed.\nFirst failed run: [Apache Jackrabbit Oak matrix/jdk=JDK 1.7 (latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting #1320|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1320/] [console log|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/jdk=JDK%201.7%20(latest),nsfixtures=DOCUMENT_RDB,profile=integrationTesting/1320/console]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ExternalPrivateStoreIT. testSyncUpdatedBinaryProperty()"
   },
   {
      "_id": "13025018",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-12-02 08:59:46",
      "description": "As noted in OAK-5211 directory listing was getting modified (due to reorder) even if no change happens in index. \n\nAnother place where we update state post index close is at \":status\" node where we store {{lastUpdated}} and {{indexedNodes}} post index close. In normal cases LuceneIndexEditor avoids initializing the IndexWriter if there is no change. However it can happen that when any node gets deleted the editor performs a delete operation. It can happen that tree being deleted is not indexed but still editor would do this as it cannot determine that easily. And in doing that IndexWriter would be initialized.\n\nCurrently IndexWriter being initialized is considered same as index updated. Due to this index status nodes gets unnecessarily updated even if there is no change in index which causes the IndexTracker to reopen the index even when it has not changed. \n\nWe should make this more explicit and find a way to determine if index has been updated or not",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Avoid updating the index nodestate if no change is done in index"
   },
   {
      "_id": "13025009",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-12-02 08:09:35",
      "description": "[~alex.parvulescu] noted that OakDirectory saves the directory listing even if no actual change happened in the directory. Only change that happens is the order of entries in set. \n\nIn normal cases LuceneIndexEditor avoids initializing the IndexWriter if there is no change. However it can happen that when any node gets deleted the editor performs a delete operation. It can happen that tree being deleted is not indexed but still editor would do this as it cannot determine that easily. This would lead to OakDirectory being closed without any change and thus can lead save of dir listing with just change in order of entries",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "OakDirectory should not save dir listing if no change is done"
   },
   {
      "_id": "13024389",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2016-11-30 10:46:41",
      "description": "I would like to deprecate the various fixtures and stubs for {{oak-segment}} and replace them where possible with its corresponding variants of {{oak-segment-tar}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "deprecation",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Deprecate stubs and fixtures related to oak-segment"
   },
   {
      "_id": "13023967",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-11-29 05:30:04",
      "description": "{{IndexUpdate}} allows passing in a custom {{MissingIndexProviderStrategy}}. However the custom provider is only stored as instance variable in {{IndexUpdate}} and does not get passed to child IndexUpadate instance.\n\nAs a fix it should be stored in IndexUpdateRootState and accessed from that",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Non default MissingIndexProviderStrategy is not being passed to child editor"
   },
   {
      "_id": "13023742",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2016-11-28 14:16:12",
      "description": "See <http://mail-archives.apache.org/mod_mbox/www-legal-discuss/201611.mbox/%3C0CE2E8C9-D9B7-404D-93EF-A1F8B07189BF%40apache.org%3E>\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "legal"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Get rid of test dependency to json.org JSON parser"
   },
   {
      "_id": "13023222",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-11-24 15:49:21",
      "description": "To mitigate problems when hitting the observation queue limit (OAK-2683) we should bump the default size from 1000 to 10000.\r\n\r\ncc [~stefanegli]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Increase default size of the observation queue from 1000 to 10000"
   },
   {
      "_id": "13022465",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-11-22 10:32:23",
      "description": "At times we see very long time in async index update cycle\n\n{noformat}\n06.11.2016 18:16:18.703 *INFO* [aysnc-index-update-async] org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate [async] AsyncIndex update run completed in 25.58 min. Indexed 7498 nodes\n06.11.2016 18:41:43.088 *INFO* [aysnc-index-update-async] org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate [async] AsyncIndex update run completed in 24.79 min. Indexed 28335 nodes\n{noformat}\n\nIt would be good to also include the number of nodes traversed in that diff. For the record such high times were seen on a setup which did not had persistent cache enabled which probably caused slow diff",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Collect stats around number of nodes traversed by AsyncIndexer"
   },
   {
      "_id": "13020824",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-15 15:16:07",
      "description": "The current default of the node deduplication cache is 8M. We should consider changing this to a smaller value still resulting in effective compactions. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Change default size of the node deduplication cache"
   },
   {
      "_id": "13020468",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-14 10:26:15",
      "description": "Performing two backups via {{RepositoryManagementMBean.startBackup}}, directory size increases not only with the delta, but also again with the size of existing tar files. This lead me to the conclusion that backup is not incremental.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "operations",
         "production",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Backup is not incremental i.e. previous tar files are duplicated"
   },
   {
      "_id": "13018193",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-11-04 18:23:37",
      "description": "For changes in bundled nodes diff is not reporting change in properties of bundled node",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Journal diff not working for changes in bundled node"
   },
   {
      "_id": "13017636",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-03 13:40:55",
      "description": "This issue is about making TarMK gc more scalable: \n* how to deal with huge repositories.\n* how to deal with massive concurrent writes.\n* how can we improve monitoring to determine gc health. \n** Monitor deduplication caches (e.g. deduplication of checkpoints)\n\nPossible avenues to explore:\n* Can we partition gc? (e.g. along sub-trees, along volatile vs. static content)\n* Can we pause and resume gc? (e.g. to give precedence to concurrent writes) \n* Can we make gc a real background process not contending with foreground operations? \n\nThis issue is a follow up to OAK-2849, which was about efficacy of gc.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "gc",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve GC scalability on TarMK"
   },
   {
      "_id": "13017275",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-02 15:14:31",
      "description": "{{ImmutableRecordNumbers}} is based on a map. This turns to be expensive as the items in the map are accessed very frequently. I would like to look into way of optimising this using a linear storage model instead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimise ImmutableRecordNumbers"
   },
   {
      "_id": "13017273",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-02 15:13:14",
      "description": "The methods in {{RepositoryManagementMBean}} do not provide any description to the end user and might seem unclear for someone trying to trigger them via JMX.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "osgi-config"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "Add @Description annotations to methods in RepositoryManagementMBean"
   },
   {
      "_id": "13017185",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-11-02 11:50:17",
      "description": "Oak Lucene index is currently using Tika 1.5 version while current latest release of Apache Tika is 1.14, I think there are lots of \"interesting\" bugs fixed, and possibly improvements (performance, more accurate text extraction, etc.) we could get at almost 0 cost by just bumping the version number.\r\n\r\nRelease notes https://tika.apache.org/1.15/index.html",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Upgrade to Tika 1.15 version"
   },
   {
      "_id": "13017154",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-02 10:19:33",
      "description": "Currently, there are two implementations for finding out the gain in repository size after running compaction: the old one, {{CompactionGainEstimate}} and the new one, {{SizeDeltaGcEstimation}}. Similarly, there are also two configurations for customising them, in {{SegmentNodeStoreService}}, {{compaction.gainThreshold}} and {{compaction.sizeDeltaEstimation}}.\n\nAt the moment both of them are exposed as OSGi configurations, but only the new one should be exposed (e.g. {{compaction.sizeDeltaEstimation}}). \n\nIt must be evaluated whether it makes sense to keep the logic associated with the old implementation.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "osgi-config"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove the old estimation OSGi setting (compaction.gainThreshold)"
   },
   {
      "_id": "13017105",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-11-02 06:47:31",
      "description": "Bundling logic would not work for node structures which are present in versionstore i.e. nodes stored under /jcr:system/jcr:versionStorage as the nodes there always have type {{nt:frozenNode}}. So any node structure which gets version would not get benefit of bundling\n\nCurrently bundling logic looks for {{jcr:primaryType}} and {{jcr:mixinTypes}} for determining type information. To support bundling for nodes stored in version store we should also look for \n\n* jcr:frozenPrimaryType\n* jcr:frozenMixinTypes\n\nThese properties contains the type information of original node stored which got versioned",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support bundling of nodes present in version store"
   },
   {
      "_id": "13016843",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-11-01 09:35:34",
      "description": "Various aspects of how Segment Tar caches segments could possibly improved. The current cache is a result of replacing the former ad-hoc cache with a proper one in OAK-3055. While the former was prone to contention under concurrent load the current cache is too oblivious about reads: read accesses are always served through {{SegmentId.segment}} and never actually hit the cache. This results in frequently accessed segments not to be seen as such by the cache and potentially being prematurely evicted. \n\nPossibly approaches to address this problem include: \n* Reinstantiating the cache we had pre OAK-3055 but making in fully concurrent. \n* Convey the information about read accesses to the current cache. \n* In either of the above cases avoid bulk segments from being placed into the cache. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve caching of segments"
   },
   {
      "_id": "13015847",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2016-10-27 14:41:54",
      "description": "OAK-3018 removed the single production usage of DocumentStore.update(). I propose we remove the method to reduce maintenance.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove DocumentStore.update()"
   },
   {
      "_id": "13015762",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-27 10:13:52",
      "description": "I would like to improve how the {{SegmentWriter}} is used for compaction. In particular I dislike how the {{SegmentBufferWriter}} needs to be looped into {{SegmentWriter.writeNode()}}.\nFurthermore creating a {{SegmentWriter}} for offline compaction with its own cache (instead of using the caches we have) is a bit wasteful wrt. to memory. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve the usage of the SegmentWriter for compaction"
   },
   {
      "_id": "13015707",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-27 07:27:57",
      "description": "I've recently seen a couple of the standby tests fail. E.g. on Jenkins: https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/1245/\n\n{noformat}\njava.lang.AssertionError: expected: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }> but was: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }>\n\tat org.apache.jackrabbit.oak.segment.standby.StandbyTestIT.testSyncLoop(StandbyTestIT.java:122)\n{noformat}\n\n{noformat}\njava.lang.AssertionError: expected: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }> but was: org.apache.jackrabbit.oak.segment.SegmentNodeState<{ checkpoints = { ... }, root = { ... } }>\n\tat org.apache.jackrabbit.oak.segment.standby.StandbyTestIT.testSyncLoop(StandbyTestIT.java:122)\n{noformat}\n\n{{org.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT.testProxySkippedBytes}}:\n{noformat}\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n{noformat}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Standby test failures"
   },
   {
      "_id": "13015240",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-25 21:30:07",
      "description": "Running offline compaction on a repository with checkpoints will explode those into full copies. Observed e.g. with OAK-5001. \n\nI think we should consider improving this by compacting checkpoints on top of each other in the proper order ({{oak-upgrade}} does this successfully). \n\n[~alex.parvulescu], WDYT? What was our take on this in the previous Oak versions? ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction explodes checkpoints "
   },
   {
      "_id": "13014980",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-25 04:50:53",
      "description": "With OAK-4180 its possible to use a SegmentNodeStore as secondary store and thus like a cache for certain set of path. In such kind of setup persistent cache should not cache those NodeStates which are covered by DocumentNodeStateCache",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Persistent cache should not cache those paths which are covered by DocumentNodeStateCache"
   },
   {
      "_id": "13014773",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-24 16:00:36",
      "description": "The former depends on the latter only for generation sequence numbers of segments, which are subsequently used to generate the segment meta information. I suggest to replace that dependency with a generalised one. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentBufferWriter should not depend on SegmentTracker"
   },
   {
      "_id": "13014772",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-24 15:56:02",
      "description": "We should simplify {{GCListener}} to minimise the boilerplate necessary in {{FileStoreBuilder}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Simplify GCListener"
   },
   {
      "_id": "13014670",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-10-24 09:59:25",
      "description": "The MongoDocumentStore gets the current server time with the {{serverStatus}} command. When MongoDB is configured with authentication, the command may fail because it requires the [clusterMonitor|https://docs.mongodb.com/manual/reference/built-in-roles/#clusterMonitor] role.\n\nThe method will then simply log a WARN message and assume no time difference. Maybe there is a different command we can use to get the time on the server?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Server time unavailable with authenticated connection to MongoDB"
   },
   {
      "_id": "13014649",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-24 07:53:54",
      "description": "With OAK-4975 Oak would be shipping some default bundling config. An application might want to disable such bundling and for those cases we need to support some config option to disable bundling for specific nodetypes.\n\n*Proposal*\n\nHave a boolean property {{disabled}} on bundling config for specific nodetype to indication that this bundling config is not to be used\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "bundling",
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Config option to disable specific bundling config"
   },
   {
      "_id": "13014175",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-10-21 09:26:39",
      "description": "Oak QueryEngine exposes few settings options via {{QueryEngineSettings}}. Currently they can be configured via\n\n# System properties\n# JMX - The settings are not persistent \n\nWe should have a way to configure them via OSGi also. A simple option can be to have a OSGi component which obtains a reference to {{QueryEngineSettingsMBean}} and then modifies the config upon activation",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable configuring QueryEngineSettings via OSGi config"
   },
   {
      "_id": "13013781",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-20 08:02:49",
      "description": "SegmentDataStoreBlobGCIT seems to crash the JVM on Java 7. Following is the relevant part of the build output.\n\n{noformat}\n[INFO] --- maven-failsafe-plugin:2.19.1:integration-test (default) @ oak-segment-tar ---\n\n-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.jackrabbit.oak.segment.file.FileStoreIT\nTests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.301 sec - in org.apache.jackrabbit.oak.segment.file.FileStoreIT\nRunning org.apache.jackrabbit.oak.segment.file.SegmentReferenceLimitTestIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 sec - in org.apache.jackrabbit.oak.segment.file.SegmentReferenceLimitTestIT\nRunning org.apache.jackrabbit.oak.segment.file.LargeNumberOfPropertiesTestIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.001 sec - in org.apache.jackrabbit.oak.segment.file.LargeNumberOfPropertiesTestIT\nRunning org.apache.jackrabbit.oak.segment.SegmentOverflowExceptionIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 sec - in org.apache.jackrabbit.oak.segment.SegmentOverflowExceptionIT\nRunning org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 45.78 sec - in org.apache.jackrabbit.oak.segment.standby.ExternalPrivateStoreIT\nRunning org.apache.jackrabbit.oak.segment.standby.FailoverSslTestIT\nTests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.202 sec - in org.apache.jackrabbit.oak.segment.standby.FailoverSslTestIT\nRunning org.apache.jackrabbit.oak.segment.standby.BrokenNetworkIT\nTests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 63.024 sec - in org.apache.jackrabbit.oak.segment.standby.BrokenNetworkIT\nRunning org.apache.jackrabbit.oak.segment.standby.FailoverMultipleClientsTestIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.052 sec - in org.apache.jackrabbit.oak.segment.standby.FailoverMultipleClientsTestIT\nRunning org.apache.jackrabbit.oak.segment.standby.MBeanIT\nTests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.287 sec - in org.apache.jackrabbit.oak.segment.standby.MBeanIT\nRunning org.apache.jackrabbit.oak.segment.standby.FailoverIPRangeIT\nTests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.691 sec - in org.apache.jackrabbit.oak.segment.standby.FailoverIPRangeIT\nRunning org.apache.jackrabbit.oak.segment.standby.StandbyTestIT\nTests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.303 sec - in org.apache.jackrabbit.oak.segment.standby.StandbyTestIT\nRunning org.apache.jackrabbit.oak.segment.standby.RecoverTestIT\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.415 sec - in org.apache.jackrabbit.oak.segment.standby.RecoverTestIT\nRunning org.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT\nTests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.002 sec - in org.apache.jackrabbit.oak.segment.standby.ExternalSharedStoreIT\nRunning org.apache.jackrabbit.oak.segment.SegmentDataStoreBlobGCIT\n\nResults :\n\nTests run: 65, Failures: 0, Errors: 0, Skipped: 3\n\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 10:17 min\n[INFO] Finished at: 2016-10-19T20:45:40+00:00\n[INFO] Final Memory: 63M/553M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.19.1:integration-test (default) on project oak-segment-tar: Execution default of goal org.apache.maven.plugins:maven-failsafe-plugin:2.19.1:integration-test failed: The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\n[ERROR] Command was /bin/sh -c cd /apps/jenkins/workspace/oak-segment-tar && /opt/jdk-7/jre/bin/java -Xmx512m -XX:MaxPermSize=64m -XX:+HeapDumpOnOutOfMemoryError -Dupdate.limit=100 -Djava.awt.headless=true -jar /apps/jenkins/workspace/oak-segment-tar/target/surefire/surefirebooter4283069132546797078.jar /apps/jenkins/workspace/oak-segment-tar/target/surefire/surefire8963659563100379656tmp /apps/jenkins/workspace/oak-segment-tar/target/surefire/surefire_03767892930481742588tmp\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: SegmentDataStoreBlobGCIT"
   },
   {
      "_id": "13013555",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-19 14:52:47",
      "description": "Currently there is no easy way to run the tools provided by {{oak-run}} against a snapshot version of Segment Tar. In order to have better CI coverage (e.g. benchmarks) of Segment Tar, we need to introduce a way for running such tools independently of {{oak-run}}. Eventually {{oak-run}} should even be using that tooling front-end instead of directly depending on {{oak-segment-tar}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Standalone tooling for segment tar"
   },
   {
      "_id": "13013458",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-19 10:01:25",
      "description": "Bundling pattern currently supports wild card pattern. This makes it powerful but at same time can cause issue if it misconfigured. \n\nWe should review this aspect before 1.6 release to determine if this feature needs to be exposed or not. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Review the support for wildcards in bundling pattern"
   },
   {
      "_id": "13013457",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-19 09:59:05",
      "description": "The config for node bundling feature in DocumentNodeStore is currently stored under {{jcr:system/rep:documentStore/bundlor}}. This task is meant to \n\n* Review the access control aspect - This config should be only updatetable by system admin\n* Config under here should be writeable via JCR api",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "bundling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Review the security aspect of bundling configuration"
   },
   {
      "_id": "13013452",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-19 09:40:37",
      "description": "On some machines the {{BrokenNetworkTest}} fails:\n\n{noformat}\nFailed tests:\n  BrokenNetworkTest.testProxyFlippedEndByteSSL:103->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxyFlippedIntermediateByte:88->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxyFlippedIntermediateByteSSL:93->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxyFlippedStartByte:78->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxySSLSkippedBytes:63->useProxy:113->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxySSLSkippedBytesIntermediateChange:73->useProxy:113->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n  BrokenNetworkTest.testProxySkippedBytesIntermediateChange:68->useProxy:113->useProxy:146 expected:<{ root = { ... } }> but was:<{ root : { } }>\n{noformat}\n\nStack traces are all similar to \n{noformat}\ntestProxySkippedBytesIntermediateChange(org.apache.jackrabbit.oak.segment.standby.BrokenNetworkTest)  Time elapsed: 5.577 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n\tat org.apache.jackrabbit.oak.segment.standby.BrokenNetworkTest.useProxy(BrokenNetworkTest.java:146)\n\tat org.apache.jackrabbit.oak.segment.standby.BrokenNetworkTest.useProxy(BrokenNetworkTest.java:113)\n\tat org.apache.jackrabbit.oak.segment.standby.BrokenNetworkTest.testProxySkippedBytesIntermediateChange(BrokenNetworkTest.java:68)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: BrokenNetworkTest"
   },
   {
      "_id": "13013446",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-19 09:09:55",
      "description": "Regarding this, the current \"Status\" is showing the last log info. This is useful, but it would also be interesting to expose the real-time status. For monitoring it would be useful to know exactly in which phase we are, e.g. a field showing on of the following:\n- idle\n- estimation\n- compaction\n- compaction-retry-1\n- compaction-retry-2\n- compaction-forcecompact\n- cleanup\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentRevisionGC MBean should report more detailed gc status information  "
   },
   {
      "_id": "13013225",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-18 15:29:59",
      "description": "The {{SetPropertyTest}} fails on Oak Segment Tar:\n\n{noformat}\njavax.jcr.InvalidItemStateException: This item [/testfb3e8f1a/ca1ef350-f650-4466-b9e3-7f77d83e6303] does not exist anymore\n\tat org.apache.jackrabbit.oak.jcr.delegate.ItemDelegate.checkAlive(ItemDelegate.java:86)\n\tat org.apache.jackrabbit.oak.jcr.session.ItemImpl$ItemWriteOperation.checkPreconditions(ItemImpl.java:96)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl$35.checkPreconditions(NodeImpl.java:1366)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.prePerform(SessionDelegate.java:615)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:205)\n\tat org.apache.jackrabbit.oak.jcr.session.ItemImpl.perform(ItemImpl.java:112)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.internalSetProperty(NodeImpl.java:1363)\n\tat org.apache.jackrabbit.oak.jcr.session.NodeImpl.setProperty(NodeImpl.java:506)\n\tat org.apache.jackrabbit.oak.benchmark.SetPropertyTest.runTest(SetPropertyTest.java:65)\n\tat org.apache.jackrabbit.oak.benchmark.AbstractTest.execute(AbstractTest.java:372)\n\tat org.apache.jackrabbit.oak.benchmark.AbstractTest.runTest(AbstractTest.java:221)\n\tat org.apache.jackrabbit.oak.benchmark.AbstractTest.run(AbstractTest.java:197)\n\tat org.apache.jackrabbit.oak.benchmark.BenchmarkRunner.main(BenchmarkRunner.java:456)\n\tat org.apache.jackrabbit.oak.run.BenchmarkCommand.execute(BenchmarkCommand.java:26)\n\tat org.apache.jackrabbit.oak.run.Mode.execute(Mode.java:63)\n\tat org.apache.jackrabbit.oak.run.Main.main(Main.java:49)\n{noformat}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SetPropertyTest benchmark fails on Segment Tar"
   },
   {
      "_id": "13013213",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-18 14:37:26",
      "description": "{{MutableRecordNumbers}} is based on a map. This turns to be expensive as the items in the map are accessed very frequently. I would like to look into way of optimising this using a linear storage model instead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimise MutableRecordNumbers"
   },
   {
      "_id": "13013126",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-18 10:27:28",
      "description": "The {{SegmentWriter}} currently buffers the list of child nodes changed on a nodestate update [0] (new node or updated node). This can be problematic in a scenario where there are a large number of children added to a node (ie. unique index size seen to spike above {{10MM}} in one case).\n\nTo have a reference for the impact of this, at the {{SegmentWriter}} level, for a list of map entries of almost {{3MM}} items, I saw it take up around {{245MB}} heap.\n\nThis issue serves to track a possible improvement here in how we handle this update scenario.\n\n\n\n\n[0] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentWriter.java#L516",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentWriter buffers child node list changes"
   },
   {
      "_id": "13012799",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-17 09:29:18",
      "description": "This is the {{oak-segment-tar}} side of OAK-4919",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide status for gc process "
   },
   {
      "_id": "13012756",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-10-17 04:31:46",
      "description": "Currently if any one of the async index gets corrupted it brings down the whole async indexer and no other index gets updated untill system administrator reindexes the problamatic async index. \n\nInstead of fail all we should isolate such corrupted index and mark them as corrupted. And still let async indexer progress for other working indexes. \n\nThis would ensure that one corrupted index does not affect the whole system and allow the application to work partially. \n\nFeature branch - https://github.com/chetanmeh/jackrabbit-oak/compare/trunk...chetanmeh:OAK-4939?expand=1",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Isolate corrupted index and make async indexer more resilient"
   },
   {
      "_id": "13012046",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-13 16:18:45",
      "description": "Running the {{ConcurrentWriteTest}} benchmark and monitoring the hits and misses of the segment cache (LIRS), I noticed that some segments are loaded over and over again (up to 3000 times). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Too many segment cache misses"
   },
   {
      "_id": "13011274",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2016-10-11 07:22:28",
      "description": "The tests are currently failing with \n\n{noformat}\nava.lang.RuntimeException: Unable to invoke method 'activate' for class org.apache.jackrabbit.oak.segment.SegmentNodeStoreService\n\n\tat org.apache.sling.testing.mock.osgi.OsgiServiceUtil.invokeMethod(OsgiServiceUtil.java:262)\n\tat org.apache.sling.testing.mock.osgi.OsgiServiceUtil.activateDeactivate(OsgiServiceUtil.java:86)\n\tat org.apache.sling.testing.mock.osgi.MockOsgi.activate(MockOsgi.java:162)\n\tat org.apache.sling.testing.mock.osgi.MockOsgi.activate(MockOsgi.java:173)\n\tat org.apache.sling.testing.mock.osgi.context.OsgiContextImpl.registerInjectActivateService(OsgiContextImpl.java:142)\n\tat org.apache.jackrabbit.oak.segment.SegmentS3DataStoreStatsTest.registerSegmentNodeStoreService(SegmentS3DataStoreStatsTest.java:113)\n\tat org.apache.jackrabbit.oak.segment.SegmentS3DataStoreStatsTest.testUseS3BlobStore(SegmentS3DataStoreStatsTest.java:74)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n\tat org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:239)\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:117)\n\tat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:43)\n\tat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:239)\n\tat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)\nCaused by: java.lang.NoSuchMethodError: org.apache.jackrabbit.oak.spi.state.RevisionGC.<init>(Ljava/lang/Runnable;Ljava/util/concurrent/Executor;)V\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStoreService.registerSegmentStore(SegmentNodeStoreService.java:471)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStoreService.registerNodeStore(SegmentNodeStoreService.java:339)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStoreService.activate(SegmentNodeStoreService.java:304)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.sling.testing.mock.osgi.OsgiServiceUtil.invokeMethod(OsgiServiceUtil.java:253)\n\t... 38 more\n{noformat}\n\nMost likely our changes in OAK-4835 caused this regression. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "regression",
         "test-failure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentS3DataStoreStatsTest failing"
   },
   {
      "_id": "13011087",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-10-10 15:59:23",
      "description": "The methods to invoke and cancel revision gc return void. This is by design as those calls are asynchronous. The idea is that {{RevisionGC.getRevisionGCStatus()}} would return the current status of an ongoing gc operation. However, currently that method only returns the status of the asynchronous task that was fired off. It should instead be able to convey back the real status of the underlying operation. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Better feedback from method invocations on RevisionGCMBean"
   },
   {
      "_id": "13011031",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-10 13:20:11",
      "description": "Sub task of OAK-4835 for the {{document}} specific changes",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "management"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Interrupt online revision cleanup on documentmk"
   },
   {
      "_id": "13011027",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-10 13:13:38",
      "description": "Sub task of OAK-4835 for the {{segment-tar}} specific changes",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "management"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Interrupt online revision cleanup on segment-tar"
   },
   {
      "_id": "13010103",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-10-06 08:48:58",
      "description": "The diff persistent cache is important for efficient processing of external changes and should be enabled by default.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable persistent caches by default"
   },
   {
      "_id": "13010089",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-10-06 07:57:14",
      "description": "With OAK-4765 Oak Segment Tar acquired the capability for stopping a running revision gc task. This is currently exposed via {{SegmentRevisionGCMBean.stopCompaction}}. I think it would make to expose this functionality through {{RevisionGCMBean}} and {{RepositoryManagementMBean}} also/instead. \n\n[~mreutegg], [~alex.parvulescu] WDYT? Could the document node store also implement this or would we just not support it there? ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "management",
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Include option to stop GC in RevisionGCMBean and RepositoryManagementMBean"
   },
   {
      "_id": "13009902",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-05 15:42:41",
      "description": "{{FileStore.cleanup()}} currently returns a list of {{File}} instances relying on the caller to remove those files. This breaks encapsulation as the file store is the sole owner of these files and only the file store should be removing them.\n\nI suggest to replace the current cleanup method with one that returns {{void}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "FileStore cleanup should not leak out file handles"
   },
   {
      "_id": "13009826",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2016-10-05 09:56:31",
      "description": "We should add documentation how Oak deals with conflicts. This was once documented in the Javadocs of {{MicroKernel.rebase()}} but got lost along with that class. Note that OAK-1553 refines conflict handling but this refinement has not been implemented in all backends yet. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document conflict handling"
   },
   {
      "_id": "13009491",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-10-04 10:24:00",
      "description": "The {{BlobGarbageCollection}} MBean is no longer available on a standby instance, this affects non-shared datastore setups (on a shared datastore you'd only need to run blob gc on the primary).\nThis change was introduced by OAK-4089 (and backported to 1.4 branch with OAK-4093).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Missing BlobGarbageCollection MBean on standby instance"
   },
   {
      "_id": "13009466",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-10-04 08:02:33",
      "description": "Currently the merge semaphore in SegmentNodeStore is by default non fair. OAK-3588 provided a config option to make it fair.\n\nWe should change the default to fair so as to ensure writer threads never get starved. \n\nEventually this change would need to be backported to branches. Further going forward OAK-4122 would replace the lock",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make merge semaphore in SegmentNodeStore fair by default"
   },
   {
      "_id": "13009230",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-03 13:24:28",
      "description": "With OAK-2404 we started logging all segment ids that a cleanup cycle removes. While this is useful for post mortems in the case of a {{SNFE}}, it also increases log files by many megabytes. \n\nSince OAK-2405 added some additional gc information, which is logged along with the missing segment in the case of a {{SNFE}}, I think the logging of the cleaned segment ids is not superfluous and we should remove it. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "logging",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove logging of cleaned segment id on cleanup"
   },
   {
      "_id": "13009176",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-10-03 07:26:29",
      "description": "As {{RevisionGCMBean.startRevisionGC()}} can be used to manually invoke a gc cycle, there is the danger of running into a {{SNFE}} when gc is run multiple times in quick succession (due to the retention time being based on number of generations). We should come up with a mechanism to prevent this scenario. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Avoid running GC too frequently"
   },
   {
      "_id": "13008676",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-29 19:06:27",
      "description": "Revision GC in a first phase finds all documents for deleted nodes and their previous documents. Reading the previous documents can be avoided in some cases. The ids of first level previous documents can be derived directly from the previous map in the main document.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Avoid queries for first level previous documents during GC"
   },
   {
      "_id": "13008560",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-29 14:57:21",
      "description": "Said test sometimes fails with the following stack trace:\n\n{noformat}\n09:46:40.900 ERROR [main] SegmentId.java:127                Segment not found: 8399230c-9338-47e3-acf5-b92d326cf171. SegmentId age=7473ms,gc-count=32,gc-status=success,store-generation=29,reclaim-predicate=(generation<=27),segment-generation27\norg.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment 8399230c-9338-47e3-acf5-b92d326cf171 not found\nat org.apache.jackrabbit.oak.segment.file.FileStore$14.call(FileStore.java:1345) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.file.FileStore$14.call(FileStore.java:1285) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.load(CacheLIRS.java:1013) ~[oak-core-1.5.8.jar:1.5.8]\nat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.get(CacheLIRS.java:974) ~[oak-core-1.5.8.jar:1.5.8]\nat org.apache.jackrabbit.oak.cache.CacheLIRS.get(CacheLIRS.java:285) ~[oak-core-1.5.8.jar:1.5.8]\nat org.apache.jackrabbit.oak.segment.SegmentCache.getSegment(SegmentCache.java:92) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:1285) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:123) ~[oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.Record.getSegment(Record.java:70) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeState.getStableIdBytes(SegmentNodeState.java:139) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeState.getStableId(SegmentNodeState.java:122) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeState.fastEquals(SegmentNodeState.java:633) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.execute(SegmentNodeStore.java:604) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.SegmentNodeStore.merge(SegmentNodeStore.java:265) [oak-segment-tar-0.0.13-SNAPSHOT.jar:na]\nat org.apache.jackrabbit.oak.segment.HeavyWriteIT.heavyWrite(HeavyWriteIT.java:85) [test-classes/:na]\n{noformat}\n\nThis is a problem with the test, not a regression:\n\n{noformat}\nSegment not found: 8399230c-9338-47e3-acf5-b92d326cf171. SegmentId age=7473ms,gc-count=32,gc-status=success,store-generation=29,reclaim-predicate=(generation<=27),segment-generation27\n{noformat}\n\nThis means the missing segment was successfully gc'ed at GC #32. Its generation was 27 while the store just got bumped to generation 29. This causes a cleanup of all generations <= 27. \n\nThe test itself calls {{FileStore.gc()}} in quick succession while at the same time writing to the store. This is likely to at some point cause a write to be based on an already collected segment. I suggest to fix this by increasing the number of retained generations to a sufficiently high value (for this test). \n\nOn a side node, this issue (and being able to to a root cause analysis) validates the additional logging that we added with OAK-2405! \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Test failure: HeavyWriteIT"
   },
   {
      "_id": "13008550",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-09-29 14:30:59",
      "description": "MongoVersionGCSupport uses the default batchSize when it queries for possibly deleted documents. The default will initially read 100 documents and then as many as fit into a 4MB response. Depending on the document size a couple of thousand will fit in there and take time to process. It may happen that the MongoDB cursor then times out and the VersionGC fails.\n\nAn easy and safe solution is to reduce the batch size to a given number of documents.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Reduce query batch size for deleted documents"
   },
   {
      "_id": "13006824",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-22 11:51:36",
      "description": "OAK-4631 introduced a simplified serialisation for record ids. This causes their footprint on disk to increase from 3 bytes to 18 bytes. OAK-4631 has some initial analysis on the effect this is having on repositories as a whole. \n\nI'm opening this issue as a dedicated task to further look into mitigation strategies (if necessary). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Analyse effects of simplified record ids"
   },
   {
      "_id": "13006821",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-22 11:44:29",
      "description": "Oak segment tar does not export {{org.apache.jackrabbit.oak.backup}}, which makes backup restore functionality unavailable from OSGi containers. \n\nInstead of just exporting this package I think we should:\n* Separate API from implementation\n* Add semantic versioning to the exported API\n\n/cc [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "API",
         "OSGi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Missing export for org.apache.jackrabbit.oak.backup package"
   },
   {
      "_id": "13006493",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-09-21 13:18:24",
      "description": "JMX binding for stopping a running compaction process",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "management",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide generic option to interrupt online revision cleanup"
   },
   {
      "_id": "13006454",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-21 10:26:36",
      "description": "This issue serves as collection of all changes to the storage format introduced with  Oak Segment Tar and their impact. Once sufficiently stabilised this information should serve as basis for the documentation in {{oak-doc}}. \n\n|| Change || Rational || Impact || Migration || Since || Issues ||\n|Generation in segment header |Required to unequivocally determine the generation of a segment during cleanup. Segment retention time is given in number of generations (2 by default). |No performance, space impact expected |offline |0.0.2 |OAK-3348 | \n|Stable id for node states |Required to efficiently determine equality of node states. This can be seen as an intermediate step to decoupling the address of records from their identity. The next step is to introduce logical record ids (OAK-4659). |Node states increase by the size of one record id (3 bytes / 20 bytes after OAK-4631). On top of that there is an additional block record \u00e0 18 bytes per node state. |offline |0.0.2 |OAK-3348\n|Binary index in tar files |Avoid traversing the repository to collect the gc roots for DSGC. Fetch them from an index instead. |Additional index entry per tar file. Adds a couple of bytes per external binary to each tar file. Exact size to be determined. [~frm] could you help with this? OAK-4740 is a regression wrt. to resiliency caused by this change (and the fact that the blob store might return blob ids longer than 2k chars).  |offline |0.0.4 |OAK-4101\n|Simplified record ids |Preparation and precondition for logical record ids (OAK-4659). At the same time the simplest possible fix for OAK-2896. The latter leads to degeneration of segment sizes, which in turn has adverse effects on overall performance, resource utilisation and memory requirements. Without this fix OAK-2498 would need to be fixed in a different way that would require other changes in the storage format. I started to regard this issue as removing a premature optimisation (which caused OAK-2498). OTOH with OAK-4844 we should also start looking into mitigations and what those would mean to size vs. simplicity vs. performance.  |Record ids grow from 3 bytes to 18 bytes when serialised into records. Impact on repositories to be assessed but can be anywhere between almost none to x6. OAK-4812 is a performance regression caused by this chance. Its overall impact is yet to be assessed. |offline |0.0.10 |OAK-4631, OAK-4844\n|Storage format versioning |In order to be able to further evolve the storage format with minimal impact on existing deployments we need to carefully versions the various storage entities (segments, tar files, etc.) |No performance, space impact expected |offline |0.0.2/ 0.0.10 |OAK-4232, OAK-4683, OAK-4295\n|Logical record ids |We need to separate addresses of records from their identity to be able to further scale the TarMK. OAK-3348 (the online compaction misery) can be seen as a symptom of failing to understand this earlier. The stable ids introduced with OAK-3348 are a first step into this direction. However this is not sufficient to implement features like e.g. background compaction (OAK-4756), partial compaction (OAK-3349) or incremental compaction (OAK-3350).  |A small size overhead per segment for the logical id table. Further impact to be evaluated ([~frm], please add your assessment here). |offline |0.0.14 (planned) |OAK-4659\n|External index for segments |Avoid recreating tar files if indexes are corrupt/missing. Just recreate the indexes. |Faster startup after a crash. Overall less disk space usage as no unnecessary backup files are created. |online |not yet planned |OAK-4649\n|In-place journal |Reduce complexity by in-lining the journal log. Less files, less chances to break something. Also the granularity of the log would increase as flushing of the persisted head would not be required any more. Resilience would improve as the roll-back functionality could operate at a finer granularity. |No more journal.log. Better resiliency. Significant risk for regression of OAK-4291 if not implemented properly. Most likely a significant refactoring of some parts of the code is required before we can proceed with this issue.  |online |not yet planned |OAK-4103\n|Root record types |With the information currently available from the segment headers we cannot collect statistics about segment usage on repositories of non trivial sizes. This fix would allow us to build more scalable tools to that respect.  |None expected wrt. to performance and size under normal operation. |offline |0.0.14 (planned) (waiting for OAK-4659 as implementation depends on how we progress there) |OAK-2498\n\nMisc ideas currently on the back burner:\n* SegmentMK: Arch segments (OAK-1905)\n* Extension headers for segments (no issue yet)\n* More memory efficient serialisation of values (e.g. boolean) (no issue yet)\n* Protocol Buffer for serialising records (no issue yet)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document storage format changes"
   },
   {
      "_id": "13006181",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-20 13:18:23",
      "description": "OAK-4775 upgraded Netty to 4.0.41.Final. This version seem to bring a couple of optional dependencies that we should also specify as optional in the Import-Package clause. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "OSGi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use optional resolution for optional dependencies"
   },
   {
      "_id": "13005873",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-19 10:57:25",
      "description": "Revision GC may currently fail when a document with a malformed id is read from the DocumentStore. E.g. a document stored accidentally in the nodes collection or malformed for some other reason.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve revision GC resilience"
   },
   {
      "_id": "13005064",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-09-15 04:19:03",
      "description": "{{LuceneIndexEditor}} currently creates 2 tree instances for determining IndexRule. [~ianeboston] highlighted this on list [1] and this is something which we should avoid and remove usage of Tree api\n\nThis was earlier done so as to simplify future support for conditional rules (OAK-2281) which might need access to ancestor which is not possible with NodeState api.  As that is not going to be done so we can get rid of Tree construction in the editor.\n\n[1] https://lists.apache.org/thread.html/7d51b45296f5801c3b510a30a4847ce297707fb4e0d4c2cefe19be62@%3Coak-dev.jackrabbit.apache.org%3E\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove usage of Tree in LuceneIndexEditor"
   },
   {
      "_id": "13004849",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-14 11:47:13",
      "description": "OAK-4774 and OAK-4793 aim to check if the cache behaviour of a DocumentStore implementation when the underlying backend throws an exception even though the operation succeeded. E.g. the response cannot be sent back because of a network issue.\n\nThis issue will provide the DocumentStore independent part of those tests.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Basic cache consistency test on exception"
   },
   {
      "_id": "13004315",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-12 14:51:00",
      "description": "Currently {{SegmentNodeState#getStableId()}} returns a string with all its associated overhead:\n* high memory requirements (42 characters plus the overhead of a {{String}} instance. The raw requirements are a mere 20 bytes (long msb, long lsb, int offset). The memory overhead is problematic as the stable id is used as key in the node deduplication cache (See OAK-4635).\n* high serialisation cost. I have seen {{getStableId()}} occurring in stack traces. This is to be expected as that method is called quite often when comparing node states. \n\nThis issue is to explore options for reducing both CPU and memory overhead of stable ids. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "memory",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimise stable ids "
   },
   {
      "_id": "13004306",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-12 14:00:13",
      "description": "The statistics about writing nodes collected by the {{SegmentWriter}} instances is a bit off. This was caused by the changes introduced with OAK-4570. Starting with these changes also base node states of a node being written are de-duplicated. Collecting the node writer stats does not differentiate however e.g. the cache hits/misses between deduplication for the base state or the actual state being written. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Node writer statistics is skewed"
   },
   {
      "_id": "13003584",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-08 13:51:31",
      "description": "ClusterNodeInfo.renewLease() does not detect when it is being recovered by another cluster node.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ClusterNodeInfo may renew lease while recovery is running"
   },
   {
      "_id": "13003477",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-09-08 07:30:14",
      "description": "With OAK-4771 the usage of DocumentStoreException was clarified in the DocumentStore interface. The purpose of this task is to check usage of the DocumentStoreException in MongoDocumentStore and make sure MongoDB Java driver specific exceptions are handled consistently and wrapped in a DocumentStoreException. At the same time, cache consistency needs to be checked as well in case of a driver exception. E.g. invalidate if necessary.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Check usage of DocumentStoreException in MongoDocumentStore"
   },
   {
      "_id": "13003229",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-07 13:12:10",
      "description": "The current DocumentStore contract is rather vague about exceptions. The class JavaDoc mentions implementation specific runtime exceptions, but does not talk about the DocumentStoreException used by all the DocumentStore implementations. We should make this explicit in all relevant methods.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Clarify exceptions in DocumentStore"
   },
   {
      "_id": "13003226",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-07 13:04:05",
      "description": "ClusterNodeInfo.renewLease() does not handle a potential DocumentStoreException on {{findAndModify()}}. This may leave {{previousLeaseEndTime}} in an inconsistent state and a subsequent {{renewLease()}} call then considers the lease timed out. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Missing exception handling in ClusterNodeInfo.renewLease()"
   },
   {
      "_id": "13002851",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2016-09-06 08:09:13",
      "description": "Some default values timeouts of the MongoDB Java driver do not work well with the lease time we use in Oak.\n\nPer default there is no socket timeout set and the driver waits for a new connection up to 120 seconds, which is too log for lease update operations. \n\nSee also OAK-4739.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Adjust default timeout values for MongoDocumentStore"
   },
   {
      "_id": "13002746",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-05 15:08:09",
      "description": "Assuming that:\n\n# Logic record IDs are implemented.\n# TAR files are ordered in reverse chronological order.\n# When reading segments, TAR files are consulted in order.\n# Segments in recent TAR files shadow segments in older TAR files with the same segment ID.\n\nA new algorithm for garbage collection can be implemented:\n\n# Define the input for the garbage collection process. The input consists of the current set of TAR files and a set of record IDs representing the GC roots.\n# Traverse the GC roots and mark the records that are still in use. The mark phase traverses the record graph and produces a list of record IDs. These record IDs are referenced directly or indirectly by the given set of GC roots and need to be kept. The list of record IDs is ordered by segment ID first and record number next. This way, it is possible to process this list in one pass and figure out which segment and which record should be saved at the end of the garbage collection.\n# Remove unused records from segments and rewrite them in a new set of TAR files. The list is produced in the previous step is traversed. For each segment encountered, a new segment is created containing only the records that were marked in the previous phase. This segment is then saved in a new set of TAR files. The set of new TAR files is the result of the garbage collection process. \n# Add the new TAR files to the system. The system will append the new TAR files to the segment store. The segments in these TAR files will shadow the ones in older TAR files.\n# Remove TAR files from the old generation. It is safe to do so because the new set of TAR files are currently shadowing the initial set of TAR files.\n\nWhile the garbage collection process is running, the system can work as usual by starting a fresh TAR file. The result of the garbage collection is made visible atomically only at the end, when the new TAR files are integrated into the running system.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "gc",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "A parallel approach to garbage collection"
   },
   {
      "_id": "13002722",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-09-05 12:30:56",
      "description": "ConsolidatedListenerMBean contains various stats about JCR event listeners. However, it is rather difficult to get an overview of how expensive listeners are.\n\nThe MBean should expose a simple leaderboard that orders the listener according to the processing time (producer & consumer time).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Leaderboard in ConsolidatedListenerMBean"
   },
   {
      "_id": "13002681",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-09-05 07:58:40",
      "description": "The jackrabbit-jcr-commons {{ListenerTracker}} collects timing for JCR event listeners. It tracks producer (oak internal) and consumer (JCR EventListener) time. The initial producer cost is currently not reflected in these stats, because {{ChangeProcessor}} in oak-jcr does an initial {{hasNext()}} on the {{EventIterator}} outside of the {{ListenerTracker}}. For some listeners this initial producer time may even account for the entire cost when the event filter rejects all changes.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Include initial cost in stats for observation processing"
   },
   {
      "_id": "13002069",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-09-01 14:27:20",
      "description": "We should add further data to that MBean (if feasible):\n\n* Number of commits\n* Number of commits queuing (blocked on the commit semaphore)\n* Percentiles of commit times (exclude queueing time)\n* Percentiles of commit queueing times \n* Last gc run / size before gc and after gc / time gc took broken down into the various phases\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve FileStoreStatsMBean"
   },
   {
      "_id": "13001917",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-09-01 07:06:43",
      "description": "There is another case where the local cache is incorrectly updated, which leads to unnecessary reads from the DocumentStore. See also OAK-4715.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Reduce DocumentStore reads for local changes (2)"
   },
   {
      "_id": "13001743",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-31 16:23:34",
      "description": "When fetching the current root from the {{SegmentNodeStore}} an older revision will be returned when a commit is being processed concurrently. I think it would make sense to wait for a short time in this case increasing the chance of returning an up to date state. The idea is that this would lower the rebasing work that need to be done later on should the returned root be used for further modifications. \n\nAn interesting value for the wait time is to use  the median (or more general a percentile) of the commit time of the last say 1000 commits. This would mean that (for the median) we have a 50% chance of getting up to date date. For a 90% percentile we would have longer wait times but then a 90% chance of getting up to date date. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "Performance",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "(Slightly) prioritise reads over writes "
   },
   {
      "_id": "13001737",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-31 16:16:04",
      "description": "Forced compaction currently acquires an exclusive write lock on the repository blocking all concurrent commits during the complete time it needs to finish compaction. I think we should refine this:\n\n* Add a time out so we could limit the time during which the repository does not accept writes while still giving compaction another chance to finish.\n\n* Boost the compaction threads priority. This could actually already be done during the regular compaction cycles to increase the changes to finish in time. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refine forced compaction"
   },
   {
      "_id": "13001638",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-31 12:39:27",
      "description": "Checking the node store fixture {{commons.FixturesHelper#getFixtures()}} is a left over from when the segment node store was part of {{oak-core}} and we wanted to avoid running the tests multiple times. As we are now in a separate module this check is not necessary any more. It is currently even harmful as certain tests are skipped. The default value for the fixtures is still {{SEGMENT_MK}} because {{oak-segment-tar}} cannot yet depend on Oak 1.5.9 (not released yet) where the default was switched to {{SEGMENT_TAR}} (see OAK-4706).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tests"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak Segment Tar tests should not check node store fixture"
   },
   {
      "_id": "13001354",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-30 15:12:41",
      "description": "In a cluster with listeners that are registered to receive external changes, pulling in external changes can become a bottleneck. While processing those external changes, further local changes are put into the observation queue leading to a system where the queue eventually fills up.\n\nInstead of processing external changes one after another, the implementation could prefetch them as they come in and if needed pull them in parallel.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Prefetch external changes"
   },
   {
      "_id": "13001317",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-30 13:59:18",
      "description": "PathRev instances are used as keys for various cache entries and asString() / fromString() methods are called frequently when the persistent cache is enabled.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimize PathRev as/from String"
   },
   {
      "_id": "13000913",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-29 10:06:52",
      "description": "The observation test added for OAK-4528 shows significant time spent in reading documents from the store when local changes are processed. Since those changes were done on the local cluster node, they should be served from cache and not reach out to the underlying store.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": " Reduce DocumentStore reads for local changes"
   },
   {
      "_id": "13000012",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-25 13:29:13",
      "description": "Oak's integration tests still run against the {{SEGMENT_MK}} fixture. I suggest we switch to the {{SEGMENT_TAR}} fixture. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "testing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Run tests against SEGMENT_TAR fixture"
   },
   {
      "_id": "12999637",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-08-24 11:43:48",
      "description": "Reading a node state with an old revision from a document can be expensive when many changes happened on a property in the meantime.\n\nA typical stack trace looks like this:\n\n{noformat}\n\tat org.apache.jackrabbit.oak.plugins.document.NodeDocument.getPreviousDocument(NodeDocument.java:1337)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$1.apply(PropertyHistory.java:70)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$1.apply(PropertyHistory.java:63)\n\tat com.google.common.collect.Iterators$8.transform(Iterators.java:794)\n\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:48)\n\tat com.google.common.collect.Iterators$7.computeNext(Iterators.java:646)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n\tat com.google.common.collect.Iterators$PeekingImpl.hasNext(Iterators.java:1139)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$2.refillQueue(PropertyHistory.java:121)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$2.computeNext(PropertyHistory.java:96)\n\tat org.apache.jackrabbit.oak.plugins.document.PropertyHistory$2.computeNext(PropertyHistory.java:88)\n\tat com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)\n\tat com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)\n\tat org.apache.jackrabbit.oak.plugins.document.ValueMap$1$3.nextIterator(ValueMap.java:105)\n\tat org.apache.jackrabbit.oak.plugins.document.util.MergeSortedIterators.fetchNextIterator(MergeSortedIterators.java:98)\n\tat org.apache.jackrabbit.oak.plugins.document.util.MergeSortedIterators.next(MergeSortedIterators.java:85)\n\tat com.google.common.collect.Iterators$PeekingImpl.peek(Iterators.java:1162)\n\tat org.apache.jackrabbit.oak.plugins.document.util.MergeSortedIterators.adjustFirst(MergeSortedIterators.java:117)\n\tat org.apache.jackrabbit.oak.plugins.document.util.MergeSortedIterators.next(MergeSortedIterators.java:78)\n\tat org.apache.jackrabbit.oak.plugins.document.NodeDocument.getLatestValue(NodeDocument.java:1972)\n\tat org.apache.jackrabbit.oak.plugins.document.NodeDocument.getNodeAtRevision(NodeDocument.java:990)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readNode(DocumentNodeStore.java:1079)\n{noformat}\n\nThe read operation goes through the property history until it finds the most recent change. The old the read revision, the more changes are scanned.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize read of old node state"
   },
   {
      "_id": "12998462",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-08-19 11:21:10",
      "description": "At the moment it is possible to have concurrent calls to {{FileStore.cleanup}} and to {{FileStore.compact()}}. The former is called from the latter and also from {{FileStore.flush()}} (this is tracked in OAK-4138). We should change this status quo and also make the calls to {{compact()}} and {{cleanup()}} mutually exclusive.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid concurrent calls to FileStore.cleanup() and FileStore.compact()"
   },
   {
      "_id": "12997573",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-08-16 12:55:29",
      "description": "{{SegmentNotFoundException}} is thrown from time to time in the following scenario: plenty of concurrent writes (each creating a {{625 bytes}} blob) interrupted by a cleanup. \n\nStack trace (including some debugging statements added by me):\n{code:java}\nPre cleanup readers: []\nBefore cleanup readers: [/Users/dulceanu/work/test-repo/data00000a.tar]\nInitial size: 357.4 kB\nAfter cleanup readers: [/Users/dulceanu/work/test-repo/data00000a.tar]\nAfter cleanup size: 357.4 kB\nFinal size: 361.0 kB\nException in thread \"pool-5-thread-74\" org.apache.jackrabbit.oak.segment.SegmentNotFoundException: Cannot copy record from a generation that has been gc'ed already\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.isOldGeneration(SegmentWriter.java:1207)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNodeUncached(SegmentWriter.java:1096)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNode(SegmentWriter.java:1013)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNodeUncached(SegmentWriter.java:1074)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNode(SegmentWriter.java:1013)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNode(SegmentWriter.java:987)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.access$700(SegmentWriter.java:379)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$8.execute(SegmentWriter.java:337)\n\tat org.apache.jackrabbit.oak.segment.SegmentBufferWriterPool.execute(SegmentBufferWriterPool.java:105)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter.writeNode(SegmentWriter.java:334)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:111)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.prepare(SegmentNodeStore.java:550)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.optimisticMerge(SegmentNodeStore.java:571)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.execute(SegmentNodeStore.java:627)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore.merge(SegmentNodeStore.java:287)\n\tat org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT$1.run(CompactionAndCleanupIT.java:961)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment 4fb637cc-5013-4925-ab13-0629c4406481 not found\n\tat org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:1341)\n\tat org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:123)\n\tat org.apache.jackrabbit.oak.segment.RecordId.getSegment(RecordId.java:94)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.isOldGeneration(SegmentWriter.java:1199)\n\t... 18 more\nCaused by: java.util.concurrent.ExecutionException: java.lang.IllegalStateException: Invalid segment format. Dumping segment 4fb637cc-5013-4925-ab13-0629c4406481\n00000000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000030 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000040 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000060 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000070 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000080 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000090 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000B0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000C0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000D0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000E0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000F0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000100 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000110 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000120 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000130 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000140 39 37 39 31 31 36 30 38 2D 63 31 63 65 2D 34 62 97911608-c1ce-4b\n00000150 35 63 2D 61 36 33 37 2D 39 36 61 65 39 34 38 38 5c-a637-96ae9488\n00000160 61 37 65 38 2E 30 61 62 34 30 36 38 36 00 00 00 a7e8.0ab40686...\n00000170 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000180 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000190 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000001A0 00 00 00 00 30 30 30 30 34 30 30 00 30 30 30 30 ....0000400.0000\n000001B0 30 30 30 00 30 30 30 30 30 30 30 00 30 30 30 30 000.0000000.0000\n000001C0 30 30 30 31 33 30 30 00 31 32 37 35 34 36 30 33 0001300.12754603\n000001D0 37 32 32 00 30 31 32 33 30 37 00 20 30 00 00 00 722.012307. 0...\n000001E0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000001F0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000200 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000210 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000220 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000230 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000240 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000250 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000260 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000270 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000280 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000290 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000002A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000002B0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.load(CacheLIRS.java:1015)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.get(CacheLIRS.java:972)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS.get(CacheLIRS.java:283)\n\tat org.apache.jackrabbit.oak.segment.SegmentCache.getSegment(SegmentCache.java:92)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:1275)\n\t... 21 more\nCaused by: java.lang.IllegalStateException: Invalid segment format. Dumping segment 4fb637cc-5013-4925-ab13-0629c4406481\n00000000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000030 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000040 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000060 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000070 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000080 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000090 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000B0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000C0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000D0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000E0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000000F0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000100 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000110 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000120 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000130 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000140 39 37 39 31 31 36 30 38 2D 63 31 63 65 2D 34 62 97911608-c1ce-4b\n00000150 35 63 2D 61 36 33 37 2D 39 36 61 65 39 34 38 38 5c-a637-96ae9488\n00000160 61 37 65 38 2E 30 61 62 34 30 36 38 36 00 00 00 a7e8.0ab40686...\n00000170 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000180 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000190 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000001A0 00 00 00 00 30 30 30 30 34 30 30 00 30 30 30 30 ....0000400.0000\n000001B0 30 30 30 00 30 30 30 30 30 30 30 00 30 30 30 30 000.0000000.0000\n000001C0 30 30 30 31 33 30 30 00 31 32 37 35 34 36 30 33 0001300.12754603\n000001D0 37 32 32 00 30 31 32 33 30 37 00 20 30 00 00 00 722.012307. 0...\n000001E0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000001F0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000200 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000210 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000220 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000230 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000240 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000250 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000260 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000270 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000280 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n00000290 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000002A0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n000002B0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................\n\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:150)\n\tat org.apache.jackrabbit.oak.segment.Segment.<init>(Segment.java:185)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore$15.call(FileStore.java:1292)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore$15.call(FileStore.java:1)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.load(CacheLIRS.java:1011)\n\t... 25 more\n0\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SNFE thrown while testing FileStore.cleanup() running concurrently with writes"
   },
   {
      "_id": "12996938",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-12 13:05:48",
      "description": "On some deployments I have seen tar files with a quite hight generation post-fix (e.g. 'v'). From the log files I could deduce that this particular tar file was rewritten multiple times without actually any segment being removed.\nI assume this is caused by the 25% gain threshold not taking the sizes contributed by the index and the graph entries into account.\n\nThe attached test case can be used to verify the above hypothesis.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cleanup creates new generation of tar file without removing any segments "
   },
   {
      "_id": "12994907",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-04 13:58:46",
      "description": "Improve the page at [1] to include a picture of the contents of a TAR file, as done for segments in [2], to cover missing parts (e.g. binary references files) and to better align it with latest oak-segment-tar improvements.\n\n[1] http://jackrabbit.apache.org/oak/docs/nodestore/segment/tar.html\n[2] http://jackrabbit.apache.org/oak/docs/nodestore/segment/records.html",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve documentation about structure of TAR files"
   },
   {
      "_id": "12994527",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-08-03 09:10:58",
      "description": "{{NodeCache}} uses one stripe per depth (of the nodes in the tree). Once its overall capacity (default 1000000 nodes) is exceeded, it clears all nodes from the stripe with the greatest depth. This can be problematic when the stripe with the greatest depth contains most of the nodes as clearing it would result in an almost empty cache. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve cache eviction policy of the node deduplication cache"
   },
   {
      "_id": "12993523",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-29 12:08:41",
      "description": "The background operations (flush, compact, cleanup, etc.) are historically part of the implementation of the {{FileStore}}. They should better be scheduled and invoked by an external agent. The code deploying the {{FileStore}} might have better insights on when and how these background operations should be invoked. See also OAK-3468.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "External invocation of background operations"
   },
   {
      "_id": "12993518",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-29 11:58:50",
      "description": "There is {{org.apache.jackrabbit.oak.cache.CacheStats}} in {{oak-core}} and {{org.apache.jackrabbit.oak.segment.RecordCacheStats}} in {{oak-segment-tar}}. Both exposing quite similar functionality. We should try to unify them as much as possible. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Unify RecordCacheStats and CacheStats"
   },
   {
      "_id": "12993517",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-29 11:55:50",
      "description": "The {{GCMonitorMBean}} MBean still dates back to the old {{oak-segment}}. We need to review its endpoints and only keep those that make sense for {{oak-segment-tar}}, adapt the others as necessary any add further functionality as required. \n\nSpecifically I think we should get rid of the time series for {{getRepositorySize()}} and {{getReclaimedSize()}}.\n\nAlso the name {{getRepositorySize()}} is confusing and we should change it. It leads callers to think it would return current size of the repository opposed to the size it had after the last cleanup. (There is {{FileStoreStatsMBean.getRepositorySize()}} for the latter.)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Align GCMonitorMBean MBean with new generation based GC"
   },
   {
      "_id": "12993514",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-29 11:51:45",
      "description": "The {{SegmentRevisionGC}} MBean still dates back to the old {{oak-segment}}. We need to review its endpoints and only keep those that make sense for {{oak-segment-tar}}, adapt the others as necessary any add further functionality as required. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Align SegmentRevisionGC MBean with new generation based GC"
   },
   {
      "_id": "12992910",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-07-27 12:28:35",
      "description": "This is related to JCR-4000 and the remaining work in Oak that hooks into the ListenerTracker and exposes the info also in the consolidated listener MBean.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Report age of oldest queue entry in EventListenerMBean and ConsolidatedListenerMBean"
   },
   {
      "_id": "12992628",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-26 16:00:27",
      "description": "The DocumentNodeStore currently uses a single persistent cache for all types (node, nodeChildren, diff, etc.). With this setup it is not possible to assign a specific amount of disk space for some cache type(s). If there are many inserts for one cache type, entries of another type may become unavailable. In practice this can be a problem for the local_diff cache entries that are important for efficient node state comparison.\n\nSeparating the diff and local_diff cache entries would also allow for different configuration options like compression and different behaviour when the async write back queue is full.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Separate persistent cache for diff and local_diff"
   },
   {
      "_id": "12992483",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-26 05:08:58",
      "description": "When large number of external blobs are added to the DataStore (50000) and a cycle of compaction executed then the reference collection logic only returns lesser number of blob references. It reports correct number of blob references when number of blobs added are less indicatingsome sort of overflow.\nAnother related issue observed when testing with lesser number of blobs is that the references returned are double the amount expected, so maybe there should be some sort of de-duplication which should be added.\n\nWithout compaction the blob references are returned correctly atleast till 100000 (ExternalBlobId#testNullBlobId)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "datastore",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Collection of references retrieves less when large number of blobs added"
   },
   {
      "_id": "12991809",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-22 13:09:18",
      "description": "There is a few peculiarities with that method:\n\n* The Javadoc \"A bulk segment is reclaimable if it is in bulkRefs\" is wrong. It should be \"A bulk segment is reclaimable if it is *not* in bulkRefs\".\n* (Why) is it necessary to iterate in reverse over the entries in tar file?\n* Why the extra check for bulk references in the else branch?\n* The condition {{!reclaim.remove(id)}} is always true as {{id}} can only be in {{reclaim}} it it had been added in the same iteration (as ids are unique). But this would have been in the if branch, contradicting us being in the else branch. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clarify implementation and documentation of TarReader#mark"
   },
   {
      "_id": "12991357",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-21 07:11:08",
      "description": "There are some DocumentMK specific methods in DocumentNodeStore, which should be moved to the DocumentMK.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move DocumentMK specific methods from DocumentNodeStore"
   },
   {
      "_id": "12991135",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-20 14:24:43",
      "description": "A new approach for calculating {{FileStore::size}} is needed because this method is prone to lock contention and should not be called too often.\n\nThe steps to implement the approach are:\n# reduce the lock surface of the size() method. This should be simple enough by creating a copy of the readers / writer inside the lock and do the actual size calculation on that snapshot but outside of the lock.\n# lower size() visibility to package to avoid misuse (from monitoring tools)\n# remove {{approximateSize}} and associated logic and replace it with {{size()}}.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve FileStore.size calculation"
   },
   {
      "_id": "12990383",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-18 13:07:35",
      "description": "The overflow to disk threshold for {{StringSort}} used by JournalEntry is too high. JournalEntry assumes the threshold is in bytes, whereas the threshold is actually the number of Strings.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Overflow to disk threshold too high"
   },
   {
      "_id": "12990286",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-18 07:56:39",
      "description": "While applying the changes from {{StringSort}} to the diff cache, the method recreates the entire change tree in memory. Depending on the revision range, the number of changes can be very high and cause an OOME.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JournalEntry.applyTo() creates complete change tree in memory"
   },
   {
      "_id": "12990274",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-07-18 07:04:38",
      "description": "In most cases where code uses JcrUtils.putFile [1] it leads to\ncreation of below content structure\n\n{noformat}\n+ foo.jpg (nt:file)\n   + jcr:content (nt:resource)\n       - jcr:data\n{noformat}\n\nDue to usage of nt:resource each nt:file node creates a entry in uuid\nindex as nt:resource is referenceable. So if a system has 1M\nnt:file nodes then we would have 1M entries in /oak:index/uuid as in\nmost cases the files are created via [1] and hence all such files are\nreferenceable\n\nThe nodetype defn for nt:file does not mandate that the\nrequirement for jcr:content being nt:resource. To support such non referenceable files we would define a new nodeType similar to nt:resource but which is non referenceable.\n\nSee [2] for related discussion\n\n[1] https://github.com/apache/jackrabbit/blob/trunk/jackrabbit-jcr-commons/src/main/java/org/apache/jackrabbit/commons/JcrUtils.java#L1062\n[2] http://jackrabbit-oak.markmail.org/thread/qicpzm5ltnzfsd42",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Define oak:Resource nodetype as non referenceable alternative to nt:resource"
   },
   {
      "_id": "12989714",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-07-15 08:36:47",
      "description": "While running Oak in Sling we rely on Sling Scheduler to ensure that async indexing task are run on leader (OAK-1246) with specified frequency. \n\nBe default Sling Scheduler uses a default pool for managing all tasks. It can happen that number of task can be quite hight which can then lead to default thread pool getting exhausted and that causes async indexing to get delayed.\n\nTo ensure that async indexing is not affected by such scenarios we should make use of a dedicated thread pool. This is now supported by SLING-5831",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Specify thread pool name which should be used by Async Indexing task"
   },
   {
      "_id": "12989393",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-07-14 09:08:48",
      "description": "The implementation of {{SegmentNodeState.fastEquals()}} compares the stable IDs of two instances of {{SegmentNodeState}}. In some cases, reading the stable ID would trigger a read of an additional record, the block record containing the serialized version of the segment ID.\n\nThis issue is about evaluating the performance implications of this strategy and, in particular, if it would be better to store the serialized stable ID in the node record itself.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeState.fastEquals() can trigger two I/O operations"
   },
   {
      "_id": "12987139",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2016-07-06 13:16:54",
      "description": "I'm not sure if it's possible in the current scheme of things (implementation), but it'd useful to be able to easily differentiate between slow diff calculation or slow observer as a reason to see why observation queue might fill up.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "monitoring",
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add info about event generation and consumption by observer"
   },
   {
      "_id": "12987119",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-06 11:01:10",
      "description": "When caches are updated after a commit (within CommitQueue.Callback.headOfQueue()), other threads are blocked when they try to acquire new revisions from the queue.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cache update blocks new commits"
   },
   {
      "_id": "12986196",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-07-01 14:12:30",
      "description": "Currently, diff information is filled into caches actively (local commits pushed in local_diff, externally read changes pushed into memory_diff). At the time of event processing though, the entries could have already been evicted.\nIn that case, we fall back to computing diff by comparing 2 node-states which becomes more and more expensive (and eventually fairly non-recoverable leading to OAK-2683).\n\nTo improve the situation somewhat, we can probably try to consult journal entries to read a smaller-superset of changed paths before falling down to comparison.\n\n/cc [~mreutegg], [~chetanm], [~egli]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "diff calculation in DocumentNodeStore should try to re-use journal info on diff cache miss"
   },
   {
      "_id": "12979401",
      "assignee": "chetanm",
      "components": [],
      "created": "2016-06-15 15:53:49",
      "description": "These failures are caused by adding the SEGMENT_TAR fixture to the matrix. That one doesn't exit in the branches thus the {{IllegalArgumentException}} \"No enum constant\".\n\nSee discussion http://markmail.org/message/oaptnvco5y2a4rjk",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "build",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CI failing on branches due to unknown fixture SEGMENT_TAR"
   },
   {
      "_id": "12979389",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-15 15:07:22",
      "description": "{{SegmentCache}} needs documentation, management instrumentation and monitoring tests and logging. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cache",
         "monitoring",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Finalise SegmentCache"
   },
   {
      "_id": "12979326",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-15 10:31:10",
      "description": "The {{SegmentReader.readHeadState()}} introduces a de-facto dependency to {{Revisions}} as access to the latter is required for obtaining the record id of the head. \n\nTo decouple SegmentReader from Revisions I propose to replace {{SegmentReader.readHeadState()}} with {{SegmentReader.readHeadState(Revisions revisions)}}. As this results in a lot of boilerplate for callers (i.e. {{fileStore.getReader().getHeadState(fileStore.getRevisions())}}), we should also introduce a convenience method {{FileStore.getHead()}} clients could use to that matter.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Decouple SegmentReader from Revisions"
   },
   {
      "_id": "12979249",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-06-15 05:23:12",
      "description": "Aim of this task is to evaluate storage cost of current approach for various Documents in DocumentNodeStore. And then evaluate possible alternative to see if we can get a significant reduction in storage size.\n\nPossible areas of improvement\n# NodeDocument\n## Use binary encoding for property values - Currently property values are stored in JSON encoding i.e. arrays and single values are encoded in json along with there type\n## Use binary encoding for Revision values - In a given document Revision instances are a major part of storage size. A binary encoding might provide more compact storage\n# Journal - The journal entries can be stored in compressed form\n\nAny new approach should support working with existing setups i.e. provide gradual change in storage format. \n\n*Possible Benefits*\nMore compact storage would help in following ways\n# Low memory footprint of Document in Mongo and RDB\n# Low memory footprint for in memory NodeDocument instances - For e.g. property values when stored in binary format would consume less memory\n# Reduction in IO over wire - That should reduce the latency in say distributed deployments where Oak has to talk to remote primary\n\nNote that before doing any such change we must analyze the gains. Any change in encoding would make interpreting stored data harder and also represents significant change in stored data where we need to be careful to not introduce any bug!",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "More compact storage format for Documents"
   },
   {
      "_id": "12978771",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12324386",
            "id": "12324386",
            "name": "auth-external",
            "description": "Oak External Authentication"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328326",
            "id": "12328326",
            "name": "examples"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12327590",
            "id": "12327590",
            "name": "webapp"
         }
      ],
      "created": "2016-06-14 12:34:33",
      "description": "For OAK-2605 we copied the source of {{ReversedLinesFileReader}} to Oak to get the fix for IO-471 in. As this is now fixed in {{commons-io}} 2.5, I suggest we upgrade our dependency and remove that duplicated class.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Upgrade commons-io to 2.5 and remove ReversedLinesFileReader"
   },
   {
      "_id": "12977615",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-10 13:56:07",
      "description": "I like to remove {{SegmentNodeStore.getSuperRoot}} That method leaks implementations details (e.g. checkpoints). Access to the super root is still possible through lower level APIs (e.g. {{SegmentReader#readHeadState}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove SegmentNodeStore.getSuperRoot()"
   },
   {
      "_id": "12977548",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-10 09:39:20",
      "description": "When compaction needs to go into cycles because of concurrent commits the number of total cycles should be logged alongside with the number of attempted cycles. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve logging during compaction cycles"
   },
   {
      "_id": "12977379",
      "assignee": "mduerig",
      "components": [],
      "created": "2016-06-09 20:50:55",
      "description": "As [discussed | http://markmail.org/message/2dk6i3yxjfkknrzp] we should also have CI coverage on Windows.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "CI",
         "build",
         "infrastructure",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Setup Windows builds "
   },
   {
      "_id": "12976918",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 16:13:59",
      "description": "We should make an effort to consistently use the term \"segment-tar\" instead of \"SegmentMK\", \"TarMK\", etc. in logging, exceptions, labels, descriptions, documentation etc.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Consistently use the term segment-tar"
   },
   {
      "_id": "12976915",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 16:08:39",
      "description": "The template cache is currently just a map per segment. This is problematic in various ways: \n* A segment needs to be in memory and probably loaded first only to read something from the cache. \n* No monitoring, instrumentation of the cache\n* No control over memory consumption \n\nWe should there for come up with a proper template cache implementation in the same way we have done for strings ({{StringCache}}) in OAK-3007. Analogously that cache should be owned by the {{CachingSegmentReader}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cache",
         "monitoring",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement a proper template cache"
   },
   {
      "_id": "12976909",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 15:51:47",
      "description": "{{SegmentNodeStoreBuilder}} and {{FileStoreBuilder}} should log the arguments used to build new instances of the respective classes when one of its {{build()}} methods is called. This facilitates post mortem analysis of log files.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "logging",
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeStore and SegmentStore builders should log their parameters on build()"
   },
   {
      "_id": "12976870",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 13:38:34",
      "description": "Tweak our setup in order to be able to cut an initial release of {{oak-segment-tar}} and perform the release. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "release"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release oak-segment-tar"
   },
   {
      "_id": "12976859",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-08 13:12:24",
      "description": "We should come up with a good set of write statistics to collect like number of records/nodes/properties/bytes. Additionally those statistics should be collected for normal operation vs. compaction related operation. This would allow us to more precisely analyse the effect of compaction on the overall system. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Collect write statistics "
   },
   {
      "_id": "12976857",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2016-06-08 13:06:54",
      "description": "The result of the static {{MergingNodeStateDiff.merge}} method is only used in the base case of a recursive diff. In all other cases while traversing the child diffs that result is simply discarded. As calculating the result involves an extra call to {{NodeBuilder.getNodeState}} it inflicts a performance penalty in the case of segment-tar: in that case this call causes the changes in the builder to be written ahead into the store. I figure it is simple enough to specialise the merge method in a way so that call is only done when its result is actually used. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce number of calls to NodeBuilder.getNodeState from MergingNodeStateDiff"
   },
   {
      "_id": "12976475",
      "assignee": "frm",
      "components": [],
      "created": "2016-06-07 14:44:49",
      "description": "Some Javadoc is not strict enough according to the Javadoc tool shipped in JDK8.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix the errors reported by the Javadoc tool in JDK8"
   },
   {
      "_id": "12976451",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-07 13:58:44",
      "description": "Cleaning of segment created by an unsuccessful compaction run currently only works if forced compaction is enabled. Otherwise those segments will only get cleaned in a much later cleanup cycle. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Segments created by an unsuccessful compaction run should get cleaned"
   },
   {
      "_id": "12976346",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-07 08:19:55",
      "description": "I've seen {{HeavyWriteIT}} fail sporadically on my local checkout.\n\n{noformat}\n3d13e2927fc0d75454a692ef5c8703880dc2ea0d\norg.apache.jackrabbit.oak.segment.SegmentNotFoundException: Segment 31b75992-aaf7-4f2b-a5de-b5a268c1fdb3 not found\n\n\tat org.apache.jackrabbit.oak.segment.file.FileStore$14.call(FileStore.java:1377)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore$14.call(FileStore.java:1317)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.load(CacheLIRS.java:1011)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS$Segment.get(CacheLIRS.java:972)\n\tat org.apache.jackrabbit.oak.cache.CacheLIRS.get(CacheLIRS.java:283)\n\tat org.apache.jackrabbit.oak.segment.SegmentCache.geSegment(SegmentCache.java:80)\n\tat org.apache.jackrabbit.oak.segment.file.FileStore.readSegment(FileStore.java:1317)\n\tat org.apache.jackrabbit.oak.segment.SegmentId.getSegment(SegmentId.java:111)\n\tat org.apache.jackrabbit.oak.segment.RecordId.getSegment(RecordId.java:94)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.isOldGeneration(SegmentWriter.java:1010)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNodeUncached(SegmentWriter.java:906)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.writeNode(SegmentWriter.java:885)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$SegmentWriteOperation.access$700(SegmentWriter.java:319)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter$8.execute(SegmentWriter.java:277)\n\tat org.apache.jackrabbit.oak.segment.SegmentBufferWriterPool.execute(SegmentBufferWriterPool.java:110)\n\tat org.apache.jackrabbit.oak.segment.SegmentWriter.writeNode(SegmentWriter.java:274)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:111)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore$Commit.<init>(SegmentNodeStore.java:516)\n\tat org.apache.jackrabbit.oak.segment.SegmentNodeStore.merge(SegmentNodeStore.java:284)\n\tat org.apache.jackrabbit.oak.segment.HeavyWriteIT.heavyWrite(HeavyWriteIT.java:91)\n{noformat}\n\nI suspect this is a problem with {{isOldGeneration}} itself not being prepared for the old segment actually being gone. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "HeavyWriteIT sporadically fails"
   },
   {
      "_id": "12976344",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-07 08:12:27",
      "description": "{{CompactionAndCleanupIT.checkpointDeduplication}} irregularly [fails|https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/938/jdk=latest1.7,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=integrationTesting/console] on Jenkins. \n\nThis might point to an issue with the de-duplication caches, which are crucial in getting the checkpoints de-duplicated. \n\n{code}\ncheckpointDeduplicationTest(org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT)  Time elapsed: 0.15 sec  <<< FAILURE!\norg.junit.ComparisonFailure: expected:<[7211975a-04ce-45ff-aff5-16795ec2cc72]:261932> but was:<[11083c4b-9b2e-4d17-a8c0-8f6b1f2a3173]:261932>\n\tat org.junit.Assert.assertEquals(Assert.java:115)\n\tat org.junit.Assert.assertEquals(Assert.java:144)\n\tat org.apache.jackrabbit.oak.segment.CompactionAndCleanupIT.checkpointDeduplicationTest(CompactionAndCleanupIT.java:899)\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "checkpointDeduplicationTest sometimes fails on Jenkins"
   },
   {
      "_id": "12976334",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-06-07 07:40:43",
      "description": "The {{SegmentWriter}} and its related classes accept a {{SegmentVersion}} argument. This is confusing since that version is only stored in the segment's segment version field. The writer cannot and does not actually write segments at older version than the latest (12). \n\nI suggest we remove the explicit segment version from all classes where it can be specified and hard code the segment version to 12 for now. This is the only segment version {{segment-tar}} currently supports anyway. Should  the need to support other segment version arise in the future, we need to decide at that point how to parametrise {{segment-tar}} on the segment version. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "refactoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove segment version argument from segment writer and and related classes"
   },
   {
      "_id": "12975788",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-06-05 06:30:35",
      "description": "{{RevisionVector}} is used in very critical paths and we should look into optimzing some of its critical method\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimize RevisionVector methods"
   },
   {
      "_id": "12975375",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         }
      ],
      "created": "2016-06-03 04:25:04",
      "description": "{{PathUtils.concat}} does not specify the default size of StringBuilder. Default string constructor uses a string.length() + 16 as the buffer size. Given size of appended path is known we can properly size the string builder buffer to avoid any expansion during actual append",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimize PathUtils.concat by using a properly sized StringBuilder"
   },
   {
      "_id": "12975125",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-06-02 11:04:58",
      "description": "Current implementation of Revision {{fromString}} and {{toString}} make use of std JDK API to perform string manipulation. While running some performance test it was seen that these 2 methods are called quite frequently and that adds up to some decent times. Further they also generate quite a bit of short lived objects.\n\n!hot-methods.png!\n\nIt would be worthwhile to perform a micro benchmark of these method and optimize them further such that they perform better and also generate less garbage. The micro optimized code would be bit more complex but if performance numbers are better we can look into changing the current implementation",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize Revison fromString and toString implementation"
   },
   {
      "_id": "12974757",
      "assignee": "frm",
      "components": [],
      "created": "2016-06-01 10:21:52",
      "description": "(Some of?) the changes done in the other subtasks cause the temporary files to be created in the systems temporary folder instead of the target folder as before. This causes issues on system where the temporary folder resides on a small partition. \n\nSee my [comment |https://issues.apache.org/jira/browse/OAK-4208?focusedCommentId=15296019&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15296019] on OAK-4208 where we have been seeing this on the Apache Jenkins instance. See also  INFRA-11837.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move temp files to target directory"
   },
   {
      "_id": "12972439",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-05-24 16:36:42",
      "description": "Currently, if the definition of an index is changed without reindexing, it will get in an \"inconsistent\" state. \n\nOf course, the reindexing is usually necessary, but it would be useful to know with which definition the index was built. This could increase the visibility of the indexing state and help debugging issues related to it.\n\nSome questions this improvement should respond to:\n# What is the definition of the index when the (re)indexing was triggered?\n# Are there any changes in the definition since the trigger? Which?\n\nI can imagine a solution built by \"versioning\" the definition nodes (oak:QueryIndexDefinition). When the reindex is triggered, a new version of the node is created and the indexer stores a reference to it.\nThis would also allow the indexer to keep using the same definition until a new reindex, even if changes are made meanwhile (i.e. use a fixed version instead of the latest definition).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Correlate index with the index definition used to build it"
   },
   {
      "_id": "12972025",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-05-23 10:30:23",
      "description": "Running of the memory store would improve test speed without impacting test coverage.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Run SegmentParserTest off memory store instead of file store"
   },
   {
      "_id": "12972022",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-05-23 10:21:29",
      "description": "OAK-3007 replaced the now deprecated strings cache with a proper cache. We should now remove the former. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove deprecated string cache"
   },
   {
      "_id": "12972018",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-05-23 10:09:02",
      "description": "That test is currently unnecessarily strongly tied to the file store, which makes it prone to failing if implementation details in the store change. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Decouple FileStoreStatsTest"
   },
   {
      "_id": "12970406",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-05-17 15:36:45",
      "description": "The {{SegmentTracker}} class has become the dumping ground for everything that wouldn't fit else where. In a personal discussion with [~frm], we figured that this class might be a good starting point refactoring {{segment-tar}} towards better encapsulation. \nThe aim would be to return {{SegmentTracker}} to its initial purpose (i.e. tracking segments) and move all unrelated concerns elsewhere.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor SegmentTracker"
   },
   {
      "_id": "12970308",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-05-17 09:23:47",
      "description": "{{FileStore.compact}} logs a warning {{TarMK GC #{}: compaction found {} checkpoints, you might need to run checkpoint cleanup}} if there is more than a single checkpoints. \n\nAFIK this is now the norm as async indexing has uses 2 checkpoints ([~chetanm], [~edivad] please clarify). \n\nIn any case should we improve this and not hard code any number of expected checkpoints. Maybe make the threshold configurable?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "logging"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Overly zealous warning about checkpoints on compaction "
   },
   {
      "_id": "12962944",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-27 09:34:09",
      "description": "{{BlobReferenceRetriever#collectReferences}} currently does not allow implementations to throw an exception. In case anything goes wrong during reference collection, implementations should be able to indicate this through an exception so the DSGC can safely abort. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "datastore",
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "BlobReferenceRetriever#collectReferences should allow exceptions"
   },
   {
      "_id": "12962623",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-26 15:08:29",
      "description": "{{SegmentDataStoreBlobGCIT#gcWithInlined}}, {{gc}}, {{gcLongRunningBlobCollection}} and {{consistencyCheckWithGc}} fail since the removal of the old cleanup strategy in OAK-4276. \n\nThe test setup needs to be adapted to the brutal strategy: i.e. {{setup()}} needs to simulate so many compaction cycles until a subsequent cleanup actually remove the segments in question. \n\nThis is not sufficient though as then {{SegmentTracker#collectBlobReferences}} causes a SNFE for those segment ids actually removed but still in the segment id tables. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fix test failures in SegmentDataStoreBlobGCIT"
   },
   {
      "_id": "12962573",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-26 12:06:47",
      "description": "We need to align / improve the labels and descriptions in {{SegmentNodeStoreService}} to match their actual purpose. At the same time I would opt for changing \"compaction\" to \"revision gc\" in all places where it is used synonymously for the latter. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "production"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Align property labels and descriptions in SegmentNodeStoreService"
   },
   {
      "_id": "12962140",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-04-25 04:19:11",
      "description": "Currently default cost per entry for Lucene index of type\n# v1 - which uses query time aggregation\n# v2 - which uses index time aggregation\n\nAre same. However given that query time aggregation would require more effort it should result in a higher cost per entry.\n\nThis fact impacts the result in cases like OAK-2081 (see last few comments) where with usage of limits both index are currently considered equals",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cost per entry for Lucene index of type v1 should be higher than that of v2"
   },
   {
      "_id": "12961897",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 20:05:14",
      "description": "OAK-3348 introduced changes to the segment format (which has been bumped to 12 with OAK-4232). However it also changes the format of the tar files (the gc generation of the segments is written to the index file) which would also require proper versioning.\n\nIn a offline discussion [~frm] brought up the idea of adding a manifest file to the store that would specify the format versions of the individual components. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "resilience",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Proper versioning of storage format"
   },
   {
      "_id": "12961896",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 20:01:12",
      "description": "That filed is not volatile although access by different threads. We should consider changing it to volatile.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Consider making FileStore.writer volatile"
   },
   {
      "_id": "12961891",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:43:02",
      "description": "Document Oak Segment Tar. Specifically:\n* New and changed configuration and monitoring options\n* Changes in gc (OAK-3348 et. all)\n* Changes in segment / tar format (OAK-3348)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document oak-segment-tar"
   },
   {
      "_id": "12961884",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:36:57",
      "description": "There is a small window in {{FileStore.flush}} that could lead to data corruption: if we crash right after setting the persisted head but before any delay-flushed {{SegmentBufferWriter}} instance flushes (see {{SegmentBufferWriterPool.returnWriter()}}) then that data is lost although it might already be referenced from the persisted head.\n\nWe need to come up with a test case for this. \n\nA possible fix would be to return a future from {{SegmentWriter.flush}} and rely on a completion callback. Such a change would most likely also be useful for OAK-3690. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "FileStore.flush prone to races leading to corruption"
   },
   {
      "_id": "12961872",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:23:42",
      "description": "{{SegmentParser}} does not correctly handle the record id added to the segment node states: for those segment node state containing an actual record id the segment parser should process it and call the respective call backs. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update segment parser to work with the new segment format"
   },
   {
      "_id": "12961864",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:14:59",
      "description": "The segment meta info (OAK-3550) still contains the segment's gc generation. As with OAK-3348 the gc generation gets written to the segment header directly we should remove it from the segment meta info and update {{oak-run graph}} accordingly. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove the gc generation from the segment meta data"
   },
   {
      "_id": "12961852",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:09:49",
      "description": "{{TarReader.calculateForwardReferences}} is not used for production but only for tooling so it would be good if we could remove that method from the production code an put it into a tooling specific module. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "TarReader.calculateForwardReferences only used by oak-run graph tool"
   },
   {
      "_id": "12961845",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 19:03:44",
      "description": "{{SegmentBufferWriter#checkGCGen}} is an after the fact check for back references (see OAK-3348), logging a warning if detects any. As this check loads the segment it checks the reference for, it is somewhat expensive. We should either come up with a cheaper way for this check or remove it (at least disable it by default). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "assertion",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Disable / remove SegmentBufferWriter#checkGCGen"
   },
   {
      "_id": "12961706",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:58:09",
      "description": "The fix for OAK-3348 caused some of the tests in {{CompactionAndCleanupIT}} to fail and I put the to ignored for the time being. We need to check whether the test expectations still hold and rework them as required. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc",
         "tests"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Rework failing tests in CompactionAndCleanupIT"
   },
   {
      "_id": "12961701",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:48:55",
      "description": "As a result of the new cleanup approach introduced with OAK-3348 (brutal) a compaction cycle that is not successful (either because of cancellation of because of giving up waiting for the lock) leaves garbage behind, which is only cleaned up 2 generations later. \n\nWe should look into ways to remove such garbage more pro-actively. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Garbage left behind when compaction does not succeed"
   },
   {
      "_id": "12961684",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:34:56",
      "description": "The number of retained gc generations (\"brutal\" cleanup strategy) is currently hard coded to 2. I think we need to make this configurable. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make the number of retained gc generation configurable"
   },
   {
      "_id": "12961679",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:29:31",
      "description": "As a result of OAK-3348 we need to partially rework the memory estimation step done for deciding whether compaction can run or not. In {{oak-segment}} there was a {{delta}} value derived from the compaction map. As the latter is gone in {{oak-segment-next}} we need to decide whether there is another way to derive this delta or whether we want to drop it entirely. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Rework memory estimation for compaction"
   },
   {
      "_id": "12961673",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 15:20:26",
      "description": "As a result of the de-duplication cache based online compaction approach from OAK-3348 compaction cannot be cancelled any more (in the sense of OAK-3290). \n\nAs I assume we still need this feature we should look into ways to re-implement it on top of the current approach. \n\nAlso I figure implementing a [partial compaction | https://issues.apache.org/jira/browse/OAK-4122?focusedCommentId=15223924&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15223924]\u00a0approach on top of a commit scheduler (OAK-4122) would need a feature of this sort. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction cannot be cancelled "
   },
   {
      "_id": "12961656",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 14:29:25",
      "description": "OAK-3348 \"promoted\" the record cache to a de-duplication cache, which is heavily relied upon during compaction. Now also node states go through this cache, which can seen as one concern of the former compaction map (the other being equality). \nThe current implementation of these caches is quite simple and served its purpose for a POC for getting rid of the \"back references\" (OAK-3348). Before we are ready for a release we need to finalise a couple of things though:\n\n* Implement cache monitoring and management\n* Make cache parameters now hard coded configurable\n* Implement proper UTs \n* Add proper Javadoc\n* Fine tune eviction logic and move it into the caches themselves (instead of relying on the client to evict items pro-actively)\n* Fine tune caching strategies: For the node state cache the cost of the item is determined just by its position in the tree. We might want to take further things into account (e.g. number of child nodes). Also we might want to implement pinning so e.g. checkpoints would never be evicted. \n* Finally we need to decide who should own this cache. It currently lives with the {{SegmentWriter}}. However this is IMO not the correct location as during compaction there is dedicated segment writer whose cache need to be shared with the primary's segment writer upon successful completion. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "caching",
         "compaction",
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Finalise de-duplication caches"
   },
   {
      "_id": "12961650",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-22 14:05:01",
      "description": "After the changes from OAK-3348 many if not all of the options in {{CompactionStrategy}} do not apply any more. Specifically the new \"brutal\" strategy is hard coded to always be in effect. We need to:\n\n* Decide which cleanup methods we want to keep supporting,\n* decide which options to expose through CompactionStrategy. E.g. {{cloneBinaries}} was so far always set to {{false}} and I would opt to remove the option as implementing might be tricky with the de-duplication cache based compaction we now have,\n* optimally refactor {{CompactionStrategy}} into a proper abstract data type. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor / rework compaction strategies "
   },
   {
      "_id": "12960635",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2016-04-21 07:39:17",
      "description": "In some cases where a user is tweaking the indexing config it can happen that he saves the config mid way which triggers a long indexing run. Currently there is no easy way to abort such a run and only way to avoid wasting time in the long indexing cycle is to shut down the system.\n\nFor such cases it would be good to provide an \"abort\" operation as part of {{IndexStatsMBean}} which user can invoke to abort any run safely and cleanly",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide a way to abort an async indexing run"
   },
   {
      "_id": "12960367",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 14:35:39",
      "description": "We need fixtures to run UTs / ITs against either or both segment implementations {{oak-segment}} and {{oak-segment-next}}. \n\nIdeally we can enable them individually through e.g. environment variables. A standard build would run against {{oak-segment}} so not to affect others. {{oak-segment-next}} could be enabled on request locally or for the CI. \nOnce we deprecate {{oak-segment}} we would switch the default fixture to {{oak-segment-next}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "testing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Implement fixtures for running again oak-segment and/or oak-segment-next"
   },
   {
      "_id": "12960329",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-04-20 12:47:20",
      "description": "I suspect that certain write operations during compaction can cause references from compacted segments to pre-compacted ones. This would effectively prevent the pre-compacted segments from getting evicted in subsequent cleanup phases. \n\nThe scenario is as follows:\n* A session is opened and a lot of content is written to it such that the update limit is exceeded. This causes the changes to be written to disk. \n* Revision gc runs causing a new, compacted root node state to be written to disk.\n* The session saves its changes. This causes rebasing of its changes onto the current root (the compacted one). At this point any node that has been added will be added again in the sub-tree rooted at the current root. Such nodes however might have been written to disk *before* revision gc ran and might thus be contained in pre-compacted segments. As I suspect the node-add operation in the rebasing process *not* to create a deep copy of such nodes but to rather create a *reference* to them, a reference to a pre-compacted segment is introduced here. \n\nGoing forward we need to validate above hypothesis, assess its impact if necessary come up with a solution.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "CLONE - Cross gc sessions might introduce references to pre-compacted segments"
   },
   {
      "_id": "12960318",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 12:29:20",
      "description": "{{FileStore.containsSegment()}} looks [funky|https://github.com/mduerig/jackrabbit-oak/blob/36cb3bf6e5078e3afa75581fb789eeca7b5df2e2/oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/file/FileStore.java#L1197-L1197]. This \"optimisation\" causes it to always return {{true}}. \n\n{{containsSegment}} is used for deduplication and revision gc. The current implementation causes {{SNFE}} exceptions once gc is effective (as I experienced while working on OAK-3348). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "stability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "CLONE - FileStore.containsSegment returns alway true (almost)"
   },
   {
      "_id": "12960315",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 12:24:48",
      "description": "If the run method of a {{BackgroundThread}} instance hits an {{Error}} it dies silently. Instead it should log an re-throw the error. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CLONE - BackgroundThread should log and re-throw instances of Error"
   },
   {
      "_id": "12960313",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 12:19:56",
      "description": "{{org.apache.jackrabbit.oak.plugins.segment.file.TarReader#loadGraph}} sometimes detects a segment graph as corrupt although it isn't. This results in cleanup rewriting the tar file (all over again). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CLONE - TarReader#loadGraph wrongly detects segment graph as corrupt "
   },
   {
      "_id": "12960275",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-04-20 09:20:15",
      "description": "Before the next major release we need to deprecate {{oak-segment}} and make {{oak-segment-tar}} the new default implementation:\n\n* Deprecate all classes in {{oak-segment}}\n* Update documentation to reflect this change\n* Update tooling to target {{oak-segment-tar}} (See OAK-4246). \n* Update dependencies of upstream modules / projects from {{oak-segment}} to {{oak-segment-tar}}. \n* Ensure {{oak-segment-tar}} gets properly released (See OAK-4258). \n* Tests run against the {{SEGMENT_TAR}} fixture.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Deprecate oak-segment"
   },
   {
      "_id": "12960273",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-20 09:16:20",
      "description": "We need to add command line options segment specific tooling so users could chose between {{oak-segment}} and {{oak-segment-next}}. {{oak-segment}} should be the default until deprecated, where {{oak-segment-next}} should be made the default. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Update segment tooling to choose target store"
   },
   {
      "_id": "12959937",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-19 08:47:03",
      "description": "We need to bump {{SegmentVersion}} to 12 to properly reflect the change in persistence format. At the same time we need to remove our dependencies to older segment versions as this is a non backward compatible change. \n\nAll segment stores written by code prior to this change will not work any more with code once this change has been applied and vice versa. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "compatibility",
         "version"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bump segment version to 12"
   },
   {
      "_id": "12958434",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-04-13 10:27:52",
      "description": "Switch API clients to {{SegmentNodeStoreBuilder}} instead. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove deprecated constructors from SegmentNodeStore"
   },
   {
      "_id": "12958002",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-04-12 07:08:01",
      "description": "DocumentNodeStore makes use of persistent cache to speed up its processing and save on making remote calls for data already present in cache\n\nIn addition to that we can look into make use of Segment NodeStore as kind of \"local copy\" for certain paths in repository and route calls to it if possible. As part of this task I would like to prototype such an approach. At high level it would work as below\n\n# At start bootstrap the setup and shutdown it down\n# Use a modified \"sidegrade\" and copy over the NodeStats from Document store to Segment store. In such a copy we also store some Document specific properties like {{readRevision}} and {{lastRevision}} as hidden property in Segment NodeStates\n# In DocumentNodeStore we refactor the current code to extract a \n## {{AbstractDocumentNodeState}} - Abase class which has some logic move out from {{DocumentNodeState}}\n## {{SegmentDocumentNodeState}} extends above and delegate calls to a wrapped {{SegmentNodeState}}\n## {{DocumentNodeState}} would also extend {{AbstractDocumentNodeState}} and hence delegate to some calls to parent. In this when a call comes for {{getChildNode}} it can check if that can be served by a local copy of {{SegmentNodeStore}} for given {{rootRevision}} then it delegates to that\n# For update plan is to make use of {{Observer}} which listens to changes and updates the local copy for certain configured paths. \n## Key aspect to address here is handle the restart case where in a cluster a specific node restarts after some time then how it refreshes itself there\n\n*Usage*\nFollowing 2 OSGi configs would need to be seed\n\n* org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.config\n{noformat}\nsecondary=B\"true\"\n{noformat}\n* org.apache.jackrabbit.oak.plugins.document.secondary.SecondaryStoreCacheService.config\n{noformat}\nincludedPaths=[ \\\n  \"/\",\n  ]\n{noformat}\n\nWith these settings if DocumentNodeStoreService gets started it would pickup the cache and use it. Change {{includedPaths}} depending on paths in repository which you want to include in secondary store.\n\n*Feature Docs*\nhttp://jackrabbit.apache.org/oak/docs/nodestore/document/secondary-store.html",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "secondary-nodestore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use another NodeStore as a local cache for a remote Document store"
   },
   {
      "_id": "12955262",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-04-01 10:34:58",
      "description": "{{FileStore.cleanup}} logs the segment id of any forward reference found when including those in the reference graph. The logged information can amount to several MBs impacting normal operation. Furthermore the actually reclaimed segments are logged, which also makes the log files explode. Finally the processing of the references and individual tar files might be too wordy. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc",
         "logging"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Too verbose logging during revision gc"
   },
   {
      "_id": "12952080",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-21 16:15:40",
      "description": "I suggest we decouple revision cleanup from the flush thread. With large repositories where cleanup can take several minutes to complete it blocks the flush thread from updating the journal and the persisted head thus resulting in larger then necessary data loss in case of a crash. \n\n/cc [~alex.parvulescu]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Decouple revision cleanup from the flush thread"
   },
   {
      "_id": "12951446",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2016-03-18 06:14:36",
      "description": "Following failure is seen on some CI\n\n{noformat}\nRunning org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.98 sec <<< FAILURE!\ndefaultConfigSpiAuth(org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest)  Time elapsed: 0.97 sec  <<< ERROR!\njava.lang.reflect.UndeclaredThrowableException\n\tat com.sun.proxy.$Proxy16.login(Unknown Source)\n\tat javax.jcr.Repository$login.call(Unknown Source)\n\tat org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:45)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:108)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:116)\n\tat org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest.defaultConfigSpiAuth(JaasConfigSpiTest.groovy:78)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.jackrabbit.oak.run.osgi.OakOSGiRepositoryFactory$RepositoryProxy.invoke(OakOSGiRepositoryFactory.java:485)\n\t... 39 more\nCaused by: javax.jcr.LoginException: No LoginModules configured for jackrabbit.oak\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:288)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:244)\n\t... 44 more\nCaused by: javax.security.auth.login.LoginException: No LoginModules configured for jackrabbit.oak\n\tat javax.security.auth.login.LoginContext.init(LoginContext.java:272)\n\tat javax.security.auth.login.LoginContext.<init>(LoginContext.java:520)\n\tat org.apache.jackrabbit.oak.spi.security.authentication.JaasLoginContext.<init>(JaasLoginContext.java:49)\n\tat org.apache.jackrabbit.oak.security.authentication.LoginContextProviderImpl.getLoginContext(LoginContextProviderImpl.java:85)\n\tat org.apache.jackrabbit.oak.core.ContentRepositoryImpl.login(ContentRepositoryImpl.java:164)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:280)\n\t... 45 more\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "JaasConfigSpiTest fails intermittently with missing LoginModule exception"
   },
   {
      "_id": "12949107",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-11 14:45:34",
      "description": "{{SegmentNodeStore}} currently uses a semaphore to coordinate concurrent commits thus relying on the scheduling algorithm of that implementation and ultimately of the JVM for in what order commits are processed. \n\nI think it would be beneficial to replace that semaphore with an explicit queue of pending commit. This would allow us to implement a proper scheduler optimising for e.g. minimal system load, maximal throughput or minimal latency etc. A scheduler could e.g. give precedence to big commits and order commits along the order of its base revisions, which would decrease the amount of work to be done in rebasing. \n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "operations",
         "performance",
         "scalability",
         "throughput"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Replace the commit semaphore in the segment node store with a scheduler"
   },
   {
      "_id": "12949098",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-03-11 14:21:13",
      "description": "{{CompactionMap#get(RecordId before)}} searches through the compaction maps until it finds one containing {{before}} returning its value. However that one might already have been compacted again an be present as key in a later compaction map generation. \n\nA correct implementation of {{CompactionMap#get(RecordId before)}} should consider the transitive closure over all maps starting at {{before}}. Note however that in this case we would also need to stop removing keys from the compaction map after cleanup as this would break transitivity again. (See http://svn.apache.org/viewvc?view=revision&revision=1673791)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CompactionMap#get not transitive across compaction map generations"
   },
   {
      "_id": "12948663",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-03-10 05:31:47",
      "description": "Currently Oak Lucene support would copy index files to local file system as part of CopyOnRead feature. In one of the setup it has been observed that index logic was failing with following error\n\n{noformat}\n04.02.2016 17:47:52.391 *WARN* [oak-lucene-3] org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier [/oak:index/lucene] Found local copy for _2ala.cfs in MMapDirectory@/mnt/crx/author/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 lockFactory=NativeFSLockFactory@/mnt/crx/author/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 but size of local 9320 differs from remote 3714150. Content would be read from remote file only\n04.02.2016 17:47:52.399 *WARN* [oak-lucene-3] org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier [/oak:index/lucene] Found local copy for segments_28je in MMapDirectory@/mnt/crx/author/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 lockFactory=NativeFSLockFactory@/mnt/crx/author/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 but size of local 1214 differs from remote 1175. Content would be read from remote file only\n04.02.2016 17:47:52.491 *ERROR* [oak-lucene-3] org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker Failed to open Lucene index at /oak:index/lucene\norg.apache.lucene.index.CorruptIndexException: codec header mismatch: actual header=1953790076 vs expected header=1071082519 (resource: SlicedIndexInput(SlicedIndexInput(_2ala.fnm in _2ala.cfs) in _2ala.cfs slice=8810:9320))\n\tat org.apache.lucene.codecs.CodecUtil.checkHeader(CodecUtil.java:128)\n\tat org.apache.lucene.codecs.lucene46.Lucene46FieldInfosReader.read(Lucene46FieldInfosReader.java:56)\n\tat org.apache.lucene.index.SegmentReader.readFieldInfos(SegmentReader.java:215)\n{noformat}\n\nHere size of __2ala.cfs_ differed from remote copy and possible other index file may have same size but different content. Comparing the modified time of the files with those in Oak it can be seen that one of file system was older than one in Oak\n\n{noformat}\n\n_2alr.cfs={name=_2alr.cfs, size=1152402, sizeStr=1.2 MB, modified=Thu Feb 04 17:52:31 GMT 2016, osModified=Feb 4 17:52, osSize=1152402, mismatch=false}\n_2ala.cfe={name=_2ala.cfe, size=224, sizeStr=224 B, modified=Thu Feb 04 17:47:28 GMT 2016, osModified=Feb 4 17:17, osSize=224, mismatch=false}\n_2ala.si={name=_2ala.si, size=252, sizeStr=252 B, modified=Thu Feb 04 17:47:28 GMT 2016, osModified=Feb 4 17:17, osSize=252, mismatch=false}\n_2ala.cfs={name=_2ala.cfs, size=3714150, sizeStr=3.7 MB, modified=Thu Feb 04 17:47:28 GMT 2016, osModified=Feb 4 17:17, osSize=9320, mismatch=true}\n_14u3_29.del={name=_14u3_29.del, size=1244036, sizeStr=1.2 MB, modified=Thu Feb 04 16:37:35 GMT 2016, osModified=Feb 4 16:37, osSize=1244036, mismatch=false}\n_2akw.si={name=_2akw.si, size=252, sizeStr=252 B, modified=Thu Feb 04 16:37:07 GMT 2016, osModified=Feb 4 16:37, osSize=252, mismatch=false}\n_2akw.cfe={name=_2akw.cfe, size=224, sizeStr=224 B, modified=Thu Feb 04 16:37:07 GMT 2016, osModified=Feb 4 16:37, osSize=224, mismatch=false}\n_2akw.cfs={name=_2akw.cfs, size=4952761, sizeStr=5.0 MB, modified=Thu Feb 04 16:37:07 GMT 2016, osModified=Feb 4 16:37, osSize=4952761, mismatch=false}\n{noformat}\n\nAnd on same setup the system did saw a rollback in segment node store \n{noformat}\n\n-rw-rw-r--. 1 crx crx  25961984 Feb  4 16:47 data01357a.tar\n-rw-rw-r--. 1 crx crx  24385536 Feb  4 16:41 data01357a.tar.bak\n-rw-rw-r--. 1 crx crx    359936 Feb  4 17:18 data01358a.tar\n-rw-rw-r--. 1 crx crx    345088 Feb  4 17:17 data01358a.tar.bak\n-rw-rw-r--. 1 crx crx  70582272 Feb  4 18:35 data01359a.tar\n-rw-rw-r--. 1 crx crx  66359296 Feb  4 18:33 data01359a.tar.bak\n-rw-rw-r--. 1 crx crx    282112 Feb  4 18:46 data01360a.tar\n-rw-rw-r--. 1 crx crx    236544 Feb  4 18:45 data01360a.tar.bak\n-rw-rw-r--. 1 crx crx    138240 Feb  4 18:56 data01361a.tar\n{noformat}\n\nSo one possible cause is that \n# At some time earlier to 17:17 lucene index got updated and __2ala.cfs_ got created. \n# Post update the head revision in Segment store was updated but the revision yet to made it to journal log\n# Lucene CopyOnRead logic got event for the change and copied the file\n# System crashed and hence journal did not got updated\n# System restarted and per last entry in journal system suffered with some \"data loss\" and hence index checkpoint also moved back\n# As checkpoint got reverted index started at earlier state and hence created a file with same name __2ala.cfs_ \n# CopyOnRead detected file length change and logged a warning routing call to remote\n# However other files like _2ala.si, _2ala.cfe which were created in same commit had same size but likely different content which later cause lucene query to start failing\n\nIn such a case a restart after cleaning the existing index content would have brought back the system to normal state.\n\nSo as a fix we would need to come up with some sanity check at time of system startup",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Cached lucene index gets corrupted in case of unclean shutdown and journal rollback in SegmentNodeStore"
   },
   {
      "_id": "12948139",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-08 19:49:35",
      "description": "The current implementation simply reports the difference between the repository size before cleanup to the size after cleanup. As cleanup runs concurrently to other commits, the size increase contributed by those is not accounted for. In the extreme case where cleanup cannot reclaim anything this can even result in negative values being reported. \n\nWe should either change the wording of the respective log message and speak of before and after sizes or adjust our calculation of reclaimed size (preferred). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Reclaimed size reported by FileStore.cleanup is off"
   },
   {
      "_id": "12948135",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-08 19:43:06",
      "description": "{{FileStore.size()}} is prone to lock contention and should not be called too often. As OAK-2879 already introduced an approach for tracking the current size of the file store without having to lock, we might as well promote his to be \"the official\" implementation. \n\n[~frm] WDYT?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Implement FileStore.size through FileStore.approximateSize"
   },
   {
      "_id": "12948120",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-08 19:14:51",
      "description": "Instead of writing the current head revision to the {{journal.log}} file we could make it an integral part of the node states: as OAK-3804 demonstrates we already have very good heuristics to reconstruct a lost journal. If we add the right annotations to the root node states this could replace the current approach. The latter is problematic as it relies on the flush thread properly and timely updating {{journal.log}}. See e.g. OAK-3303. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Replace journal.log with an in place journal"
   },
   {
      "_id": "12948112",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-03-08 19:03:23",
      "description": "{{SegmentTracker}} and {{FileStore}} are mutually dependent on each other. This is problematic and makes initialising instances of these classes difficult: the {{FileStore}} constructor e.g. passes a not fully initialised instance to the {{SegmentTracker}}, which in turn writes an initial node state to the store. Notably using the not fully initialised {{FileStore}} instance!",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Break cyclic dependency of FileStore and SegmentTracker"
   },
   {
      "_id": "12947985",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-03-08 12:09:13",
      "description": "While running on SegmentNodStore and online compaction enabled it can happen that access to Lucene index start failing with SegmentNotFoundException\n\n{noformat}\nCaused by: org.apache.jackrabbit.oak.plugins.segment.SegmentNotFoundException: Segment a949519a-8903-44f9-a17e-b6d83fb32186 not found\n       at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:870)\n       at org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.getSegment(SegmentTracker.java:136)\n       at org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:108)\n       at org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n       at org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.getNewStream(SegmentBlob.java:64)\n       at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexFile.loadBlob(OakDirectory.java:259)\n       at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexFile.readBytes(OakDirectory.java:307)\n       at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.readBytes(OakDirectory.java:404)\n       at org.apache.jackrabbit.oak.plugins.index.lucene.OakDirectory$OakIndexInput.readByte(OakDirectory.java:411)\n       at org.apache.lucene.store.DataInput.readVInt(DataInput.java:108)\n       at org.apache.lucene.codecs.BlockTreeTermsReader$FieldReader$SegmentTermsEnum$Frame.loadBlock(BlockTreeTermsReader.java:2397)\n       at org.apache.lucene.codecs.BlockTreeTermsReader$FieldReader$SegmentTermsEnum.seekCeil(BlockTreeTermsReader.java:1973)\n       at org.apache.lucene.index.FilteredTermsEnum.next(FilteredTermsEnum.java:225)\n       at org.apache.lucene.search.TermCollectingRewrite.collectTerms(TermCollectingRewrite.java:78)\n       at org.apache.lucene.search.ConstantScoreAutoRewrite.rewrite(ConstantScoreAutoRewrite.java:95)\n       at org.apache.lucene.search.MultiTermQuery$ConstantScoreAutoRewrite.rewrite(MultiTermQuery.java:220)\n       at org.apache.lucene.search.MultiTermQuery.rewrite(MultiTermQuery.java:288)\n       at org.apache.lucene.search.BooleanQuery.rewrite(BooleanQuery.java:418)\n       at org.apache.lucene.search.IndexSearcher.rewrite(IndexSearcher.java:636)\n       at org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:683)\n       at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:378)\n{noformat}\n\nThe above segmentId was mentioned in the compaction log\n\n{noformat}\n06.03.2016 02:03:30.706 *INFO* [TarMK flush thread [/app/repository/segmentstore], active since Sun Mar 06 02:03:29 GMT 2016, previous max duration 8218ms] org.apache.jackrabbit.oak.plugins.segment.file.TarReader-GC Cleaned segments from data00233a.tar:\n       37ec786e-a9f7-46eb-a3b5-ce5d4777ea01, f36051fe-d8c4-46d1-ac1d-081946389eb6, fae91ff2-8ca6-4ac1-a8d8-d4bd09b7f6a6, 16d87f09-721b-4155-a9c8-b8ecf471bfc3,\n       e641f1a3-b323-44e6-aad0-7b894a1efb69, edc9d141-6c05-42c9-a2a2-d7130fd9c826, b602372c-b17a-448a-a8e9-8bdccc64fb82, acc2f032-07ba-46ed-a9c7-d3a05ab53d7a,\n       a7323ed2-b2de-4006-ae51-e4f84165a0e4, cb320c70-5ca9-4ed1-a972-e87a6bba9f9b, f45afd7e-5417-42dd-a2f7-4624f74b6c6e, c66f66ef-cdd0-4327-abc6-bf910cb5768d,\n       7f925a07-ff56-4613-ac8f-272a0e481926, 4ad044ec-3b2d-4c3e-aeb0-d5f5a04bc23e, 82f1c3aa-2e0c-421c-a033-e4ffcb6002c7, 1387655b-f633-4011-a55c-d9580e40929b,\n       c50c94fc-2e8b-4904-a37f-0a33cc001312, 7915e9ce-bb9d-4628-ad6f-e7f2844b2399, e7cd013b-a147-426a-af29-fa025058a08a, f16d43b0-2113-4808-aea6-5910102e5c7d,\n...\n*31edad2e-e14b-463d-a6af-540bac6009f1*,\n...,\n*a949519a-8903-44f9-a17e-b6d83fb32186*,\n...\n{noformat}\n\n*Note that system recovered after a restart so the corruption was transient*\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Lucene index appear to be corrupted with compaction enabled"
   },
   {
      "_id": "12947896",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-03-08 03:45:39",
      "description": "Currently the journal log has entries like below. At times while debugging crash or some issue we need to determine the probable root state at some point in the past. \n\n{noformat}\n3dea11bb-bd43-4319-a37d-59df778a7271:260988 root\na7a509ac-a9d4-4e2c-a0d8-df71ebe123a0:259736 root\n1d889da9-b41c-4889-a0cd-a9aa9dcc1737:259992 root\nb78e4aa6-ec68-4e70-a364-f04ccbf4c3b3:259964 root\n{noformat}\n\nCurrently there is no way to determine from above log what is the root state wrt time. So we need to workaround that by reading each root state and look for some path which has some time related property. To simplify such case it would be helpful to also include timestamp while adding a journal entry\n\n{noformat}\n1d889da9-b41c-4889-a0cd-a9aa9dcc1737:259992 root 1457408708772\nb78e4aa6-ec68-4e70-a364-f04ccbf4c3b3:259964 root 1457408708899\n{noformat}\n\n*Key points*\n# Timestamp comes at end\n# Such a feature can be enabled without affecting backward compatibility - Just that new entries would have timestamp included\n# {{JournalReader}} - Just reads the first column so would work as is",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Include timestamp in journal log entries"
   },
   {
      "_id": "12944433",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-02-25 09:26:21",
      "description": "Pre Extraction support was implemented with an assumption that such big indexing would happen as part of reindex so it was used in reindex phase only. Reason to avoid using it in incremental indexing (non reindex case) were\n# Incremental index would does not have text for newly added files. So checking with pre extracted cache would not be useful\n# PreExtraction logic keeps in memory state (blobs_empty.txt,blobs_error.txt) which would then unnecessary hog memory.\n\nHowever in some cases people make use of new incremental migration feature in upgrade. Which would lead to one big incremental indexing step once next migration is done and that would then not able to make use of pre extraction support.\n\nSo as a fix we should provide a policy option to ignore the reindex clause per admin setting",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Allow use of pre extrcated text cache for incremental indexing"
   },
   {
      "_id": "12943081",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-02-24 20:52:14",
      "description": "{{FileStore.containsSegment()}} looks [funky|https://github.com/mduerig/jackrabbit-oak/blob/36cb3bf6e5078e3afa75581fb789eeca7b5df2e2/oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/file/FileStore.java#L1197-L1197]. This \"optimisation\" causes it to always return {{true}}. \n\n{{containsSegment}} is used for deduplication and revision gc. The current implementation causes {{SNFE}} exceptions once gc is effective (as I experienced while working on OAK-3348). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc",
         "stability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "FileStore.containsSegment returns alway true (almost)"
   },
   {
      "_id": "12941554",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-23 21:53:59",
      "description": "{code}\nException in thread \"main\" java.lang.NumberFormatException: null\n\tat java.lang.Long.parseLong(Long.java:404)\n\tat java.lang.Long.valueOf(Long.java:540)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentGraph.asLong(SegmentGraph.java:494)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentGraph.writeNode(SegmentGraph.java:464)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentGraph.writeSegmentGraph(SegmentGraph.java:173)\n\tat org.apache.jackrabbit.oak.run.GraphCommand.execute(GraphCommand.java:92)\n\tat org.apache.jackrabbit.oak.run.Mode.execute(Mode.java:63)\n{code}\n\nThe cause for this is not properly checking the info map before deciding whether to print a bulk or a data node. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NPE in oak-run graph when repository contains bulk segments"
   },
   {
      "_id": "12941553",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-23 21:48:57",
      "description": "Running oak-run from within the IDE causes a {{NPE}}:\n\n{code}\nException in thread \"main\" java.lang.NullPointerException\n\tat java.util.Properties$LineReader.readLine(Properties.java:434)\n\tat java.util.Properties.load0(Properties.java:353)\n\tat java.util.Properties.load(Properties.java:341)\n\tat org.apache.jackrabbit.oak.run.Main.getProductVersion(Main.java:76)\n\tat org.apache.jackrabbit.oak.run.Main.getProductVersion(Main.java:66)\n\tat org.apache.jackrabbit.oak.run.Main.getProductInfo(Main.java:53)\n\tat org.apache.jackrabbit.oak.run.Main.printProductInfo(Main.java:86)\n{code}\n\nThis is caused by not checking the return value of {{getResourceAsStream}} for {{null}} when trying to load {{/META-INF/maven/org.apache.jackrabbit/oak-run/pom.properties}}. That file is not on the class path when running from within the IDE. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NPE when running oak-run from within the IDE"
   },
   {
      "_id": "12941339",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-02-23 09:31:16",
      "description": "Classes {{org.apache.jackrabbit.oak.plugins.segment.compaction.CompactionStrategy}} and {{org.apache.jackrabbit.oak.plugins.segment.compaction.CompactionStrategyMBean}} should be exported. The former is used in the public API of multiple classes from {{org.apache.jackrabbit.oak.plugins.segment.file}} and {{org.apache.jackrabbit.oak.plugins.segment}}, while the latter is used as interface type for a service registered in the whiteboard.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Some classes from o.a.j.o.plugins.segment.compaction should be exported"
   },
   {
      "_id": "12940564",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-02-19 17:13:43",
      "description": "The DocumentNodeStore currently requires that the local time and the persistence time differ at most 2 seconds.\n\nI recently tried to run a cluster with two Windows machines, and despite them being configured to use the same NTP service, they were still 4..5 s off.\n\nhttps://blogs.technet.microsoft.com/askds/2007/10/23/high-accuracy-w32time-requirements/ seems to confirm that by default, Windows can't provide the required accuracy.\n\nOne workaround seems to be to install custom ntp clients; but do we really want to require this?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/20",
         "id": "20",
         "description": "Documentation or Website",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/documentation.png",
         "name": "Documentation",
         "subtask": false
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore: required server time accuracy"
   },
   {
      "_id": "12938830",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-02-12 15:42:17",
      "description": "Concurrent commits during compaction cause those to be re-compacted. Currently it seems that the compaction thread can end up waiting for some time to acquire the commit lock [1], which in turn causes more commits to pile up to be re-compacted. I think this could be improved by tweaking the lock such that the compactor could jump ahead of the queue. I.e. use a lock which can be acquired in expedited mode. \n\n[1] SegmentNodeStore#commitSemaphore",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "perfomance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expedite commits from the compactor"
   },
   {
      "_id": "12938753",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-02-12 09:28:21",
      "description": "As online compaction is still not at the point where we would like it to have we will need to disable it by default for the upcoming major release. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Set online compaction default to paused"
   },
   {
      "_id": "12936960",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-05 06:36:28",
      "description": "Text pre extraction feature introduced in OAK-2892 only supports FileDataStore. For files present in S3 we should add support for S3DataStore",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add S3 datastore support for Text Pre Extraction"
   },
   {
      "_id": "12936387",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-03 16:45:09",
      "description": "The segment graph produced by {{oak-run graph}} should also contain the sizes of the segments. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add segment size to segment graph"
   },
   {
      "_id": "12936278",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-02-03 08:28:56",
      "description": "The graph produced by {{oak-run graph}} does not include forward edges (i.e. references from older segments to newer segments). Such references where introduced with  OAK-1828. See also OAK-3864, where this has been fixed for the file store cleanup.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc",
         "technical_debt",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Forward edges missing in SegmentGraph "
   },
   {
      "_id": "12934509",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-27 16:28:26",
      "description": "When {{CompactionStrategy.CleanupType#CLEAN_OLD}} releases a segment for gc because of its age it should log a message. This helps to determine the root cause of a {{SNFE}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Log ids of segments being released for gc because of their age. "
   },
   {
      "_id": "12934109",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-26 13:36:03",
      "description": "The primary and standby run modes should exit with an error if run on a store with non matching segment version.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "oak-run primary/standby should check segment version"
   },
   {
      "_id": "12934107",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-26 13:33:00",
      "description": "The checkpoint runmode should exit with an error if run on a store with non matching segment version.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run checkpoint should check segment version"
   },
   {
      "_id": "12934106",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-26 13:30:58",
      "description": "Backup/restore should exit with an error if run on a store with non matching segment version. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-run backup/recover should check segment version"
   },
   {
      "_id": "12933019",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-01-21 08:54:42",
      "description": "In some rare cases it may happen that the DocumentNodeStore considers a commit as failed even though the changes were applied entirely to the DocumentStore. The issue happens when the update of the commit root is applied to the storage of a DocumentStore but then shortly after the communication between Oak the the storage system fails. On the Oak side the call will be considered as failed, but the change was actually applied.\n\nThe issue can be reproduced with the test attached to OAK-1641 and a replica-set with 3 nodes. Killing the primary node and restarting it a after a while in a loop will eventually lead to a commit that conflicts itself.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Commit fails even though change made it to the DocumentStore"
   },
   {
      "_id": "12932451",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-19 15:35:37",
      "description": "I like to add a filter capability to {{oak-run graph}} to specify the inclusion criteria of segments via a regular expression.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add filter capabilities to the segment graph run mode"
   },
   {
      "_id": "12932118",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-18 10:45:13",
      "description": "{{FileStoreIT.testRecovery}} currently hard codes expected segment offsets. I would like to refactor this to make it more robust against changes in how exactly records are stored / de-duplicated. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Robuster test expectations for FileStoreIT"
   },
   {
      "_id": "12930181",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-01-14 16:16:46",
      "description": "Following up [discussion|http://markmail.org/message/m5jk5nbby77nlqs5] \\[0] to avoid bad commits due to misbehaving clocks. Points from the discussion:\n* We can start self-destruct mode while updating lease\n* Revision creation should check that newly created revision isn't beyond leaseEnd time\n* Implementation done for OAK-2682 might be useful\n\n[0]: http://markmail.org/message/m5jk5nbby77nlqs5",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid commit from too far in the future (due to clock skews) to go through"
   },
   {
      "_id": "12930165",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2016-01-14 15:14:50",
      "description": "In some rare cases it may happen that a collision marks the wrong commit. OAK-3344 introduced a conditional update of the commit root with a collision marker. However, this may fail when the commit revision of the condition is moved to a split document at the same time.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Collision may mark the wrong commit"
   },
   {
      "_id": "12930078",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2016-01-14 08:43:32",
      "description": "When using a Lucene fulltext index with compatVersion 2, then the following query does not return any results. When using compatVersion 1, the correct result is returned.\n\n{noformat}\nSELECT * FROM [nt:unstructured] AS c \nWHERE CONTAINS(c.[jcr:description], 'abc!') \nAND ISDESCENDANTNODE(c, '/content')\n{noformat}\n\nWith compatVersion 1 and 2, searching for just 'abc' works. Also, searching with '=' instead of 'contains' works.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "docs-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Lucene index / compatVersion 2: search for 'abc!' does not work"
   },
   {
      "_id": "12929747",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-13 09:07:53",
      "description": "That argument is unused and I'll remove it thus. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Don't pass the compaction map to FileStore.cleanup"
   },
   {
      "_id": "12929505",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2016-01-12 14:54:19",
      "description": "I think it would be cleaner if {{RecordId.write}} would always return a {{RecordId}} instead of depending on its type parametrisation and would like to refactor it to that respect.. \n\nThis is also a pre-requisite for my work on OAK-3348 and might also be for OAK-3864. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor RecordWriter.write to always return a RecordId"
   },
   {
      "_id": "12929502",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-12 14:41:06",
      "description": "I think it makes sense to move said method. This simplifies the code in various places as it somewhat decouples the concern \"writing segments\" from an implementation ({{FileStore}}). \n\nAlso this is somewhat a prerequisite for my current work on OAK-3348.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move createSegmentWriter() from FileStore to SegmentTracker"
   },
   {
      "_id": "12929459",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-12 11:05:42",
      "description": "In some situations {{FileStore.cleanup()}} may remove segments that are still referenced, subsequently causing a {{SNFE}}. \n\nThis is a regression introduced with OAK-1828. \n\n{{FileStore.cleanup()}} relies on the ordering of the segments in the tar files: later segments only reference earlier segments. As we have seen in other places this assumption does not hold any more (e.g. OAK-3794, OAK-3793) since OAK-1828.\n {{cleanup}} traverses the segments backwards maintaining a list of referenced ids. When a segment is not in that list, it is removed. However, this approach does not work with forward references as those are only seen later when the segment has been removed already. \n\ncc [~alex.parvulescu], [~frm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "regression"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Filestore cleanup removes referenced segments"
   },
   {
      "_id": "12929232",
      "assignee": "frm",
      "components": [],
      "created": "2016-01-11 17:08:56",
      "description": "While moving the Segment Store and related packages into its own bundle, I figured out that integration tests contained in {{oak-core}} contribute to a cyclic dependency between the (new) {{oak-segment}} bundle and {{oak-core}}.\n\nThe dependency is due to the usage of {{NodeStoreFixture}} to instantiate different implementations of {{NodeStore}} in a semi-transparent way.\n\nTests depending on {{NodeStoreFixture}} are most likely integration tests. A clean solution to this problem would be to move those integration tests into a new Maven module, referencing the API and implementation modules as needed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move integration tests in a different Maven module"
   },
   {
      "_id": "12929149",
      "assignee": "mreutegg",
      "components": [],
      "created": "2016-01-11 10:50:47",
      "description": "Some of the tests executed during a normal {{mvn clean test}} execution seem to be very slow if compared with the rest of the suite. On my machine, some problematic tests are:\n\n{noformat}\nRunning org.apache.jackrabbit.oak.spi.blob.FileBlobStoreTest\nTests run: 18, Failures: 0, Errors: 0, Skipped: 2, Time elapsed: 10.982 sec\nRunning org.apache.jackrabbit.oak.plugins.document.BasicDocumentStoreTest\nTests run: 50, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.961 sec\nRunning org.apache.jackrabbit.oak.plugins.document.BulkCreateOrUpdateTest\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.076 sec\nRunning org.apache.jackrabbit.oak.plugins.document.ConcurrentDocumentStoreTest\nTests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.054 sec\nRunning org.apache.jackrabbit.oak.plugins.document.DocumentDiscoveryLiteServiceTest\nTests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 982.526 sec\nRunning org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreTest\nTests run: 53, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.132 sec\nRunning org.apache.jackrabbit.oak.plugins.document.LastRevRecoveryAgentTest\nTests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.068 sec\nRunning org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStorePerformanceTest\nTests run: 10, Failures: 0, Errors: 0, Skipped: 10, Time elapsed: 10.006 sec\nRunning org.apache.jackrabbit.oak.plugins.document.rdb.RDBDocumentStoreTest\nTests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.017 sec\nRunning org.apache.jackrabbit.oak.plugins.document.VersionGCWithSplitTest\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.128 sec\nRunning org.apache.jackrabbit.oak.security.authentication.ldap.LdapLoginStandaloneTest\nTests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.96 sec\n{noformat}\n\nThese tests should be analyzed for potential errors or moved to the integration test phase.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Review slow running tests"
   },
   {
      "_id": "12928734",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-08 21:02:51",
      "description": "{{SegmentGraphTest}} has a somewhat complicated setup phase to build a segment store of a certain structure. This is will probably prove unreliable when underlying implementation details of how segments are written change (e.g. with OAK-3348). I would like to refactor the test such that it becomes independent of such implementation details. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Simplify SegmentGraphTest"
   },
   {
      "_id": "12928689",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-08 17:06:48",
      "description": "Off line compaction should exit with a warning if run on a store with non matching segment version. It should provide a {{--force}} option to override this behaviour such that it can still be used for explicit upgrading. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "gc",
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "oak-run compact should check segment version"
   },
   {
      "_id": "12928688",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-08 17:02:40",
      "description": "Running tools that write into a segment store might result in unwanted upgrading if the version of the tool uses a more recent segment version than the store. E.g. off line compaction currently upgrades segment format 10 to 11. \n\nTo protected against inadvertent upgrades, a tool should check whether the segment version of the store matches its expectation (currently 11). If not, the tool should exit with a respective warning / error. For some tools it can make sense to provide a flag (e.g. {{--force}}) to override this. With this e.g. offline compaction can still be used for upgrading a segment store if explicitly told to do so. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "TarMK tools should check whether they run against a matching version of the repository"
   },
   {
      "_id": "12928653",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2016-01-08 14:38:28",
      "description": "Currently {{SegmentGraph}} just bails out upon hitting a {{SNFE}}. I would like to improve this and include the error in the generated graph. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve SegmentGraph resilience "
   },
   {
      "_id": "12928039",
      "assignee": "mduerig",
      "components": [],
      "created": "2016-01-06 15:31:32",
      "description": "We need to adjust the package export declarations such that they become manageable with our branch / release model. \n\nSee http://markmail.org/thread/5g3viq5pwtdryapr for discussion.\n\nI propose to remove package export declarations from all packages that we don't consider public API / SPI beyond Oak itself. This would allow us to evolve Oak internal stuff (e.g. things used across Oak modules) freely without having to worry about merges to branches messing up semantic versioning. OTOH it would force us to keep externally facing public API / SPI reasonably stable also across the branches. Furthermore such an approach would send the right signal to Oak API / SPI consumers regarding the stability assumptions they can make. \n\nAn external API / SPI having a (transitive) dependency on internals might be troublesome. In doubt I would remove the export version here until we can make reasonable guarantees (either through decoupling the code or stabilising the dependencies). \n\nI would start digging through the export version and prepare an initial proposal for further discussion. \n\n/cc [~frm], [~chetanm], [~mmarth]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "api",
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Adjust package export declarations "
   },
   {
      "_id": "12927995",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2016-01-06 11:08:47",
      "description": "The {{FileStore}} constructor consists of more than 150 LoC and is a mess as it depends on the order of initialisation, calls overrideable methods handles different concerns (read only vs. read / write) etc. \n\nWe should up with a cleaner way of instantiating a file store.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clean up the FileStore constructor"
   },
   {
      "_id": "12923060",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-18 16:28:37",
      "description": "I think we should disable compaction estimation when compaction is paused. Estimation interferes with the caches, wastes CPU and IO cycles and is not essential for Oak's operation when compaction is disabled. The only reason it was unconditionally enabled initially is to gather the respective information in production. I think this has turned out to be not too useful so it is safe to disable. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Disable compaction gain estimation if compaction is paused"
   },
   {
      "_id": "12923058",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-18 16:23:57",
      "description": "The {{check}} run mode currently has no option to be run with an external data store. We should probably add such an option. Or/and ensure the check works probably for a segment store with external binaries even if no data store is present.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide option to pass external data store to oak-run check"
   },
   {
      "_id": "12922638",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-12-17 09:12:51",
      "description": "oak-core and oak-jcr modules uses the fixture mechanism to provide NodeStore implementations to the unit/integration tests. There is a few problems with the fixture implementation:\n\n* the {{NodeStoreFixture}} class is duplicated between two modules and supports different set of options (eg. the oak-core version doesn't support the RDB node store at all, while the oak-jcr doesn't support MemoryNodeStore)\n* it isn't possible to set the MongoDB URL manually from the Maven command line (it can be done for the RDB, though), which makes running the tests on a Mongo replica hard,\n* the Mongo fixture doesn't remove the test database after the test is done.\n\nThere should be just one NodeStoreFixture implementation (the oak-jcr can reuse the oak-core version), supporting all values of the {{Fixture}} enum. The Mongo fixture should be more customisable and also should clean-up the database.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "tech-debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clean up the fixtures code in core and jcr modules"
   },
   {
      "_id": "12922590",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-12-17 04:29:15",
      "description": "Due to changes done in OAK-3477 SessionMBean is not getting registered as it contains ',' in the ObjectName. Unfortunately the exception thrown gets lost and this did not got detected so far\n\n{noformat}\njavax.management.MalformedObjectNameException: Invalid character in value: `,'\n\tat javax.management.ObjectName.checkValue(ObjectName.java:1009)\n\tat javax.management.ObjectName.construct(ObjectName.java:725)\n\tat javax.management.ObjectName.<init>(ObjectName.java:1425)\n\tat org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils.registerMBean(WhiteboardUtils.java:79)\n\tat org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils.registerMBean(WhiteboardUtils.java:68)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl$RegistrationTask.run(RepositoryImpl.java:523)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n{noformat}\n\nThe name passed for ObjectName is \n{code}\n{name=admin@session-11@Dec 17, 2015 9:57:11 AM, type=SessionStatistics}\n{code}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "regresion"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SessionMBean not getting registered due to MalformedObjectNameException"
   },
   {
      "_id": "12922345",
      "assignee": "mduerig",
      "components": [],
      "created": "2015-12-16 11:19:24",
      "description": "The Oak checkout contains a module {{oak-js}}, which is mostly empty apart from a TODO statement. As we didn't work on this and AFAIK do not intend to work on this in the near future, I propose to drop the module for now. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Drop module oak-js"
   },
   {
      "_id": "12921095",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-11 16:29:57",
      "description": "While OAK-3560 allows us to detect reference to pre compacted segments through manual inspection, we also need tooling to help detect such cases on site, during longevity tests and for UT/IT.  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "compaction",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Tool for detecting references to pre compacted segments"
   },
   {
      "_id": "12920482",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-09 16:42:02",
      "description": "Once a compaction cycle is through the compaction progress logger prints a message like:\n\n{noforma}\nFinished compaction: 26 nodes, 7 properties, 0 binaries.\n{noformat}\n\nHowever the number for nodes and properties includes those items deduplicated through the compaction map, effectively counting some items multiple times even though those where compacted only once and reused later. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction progress logger: reported number of nodes and binaries is too high"
   },
   {
      "_id": "12920359",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-09 08:34:48",
      "description": "{{org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT}} failed on Jenkins:\n\n{noformat}\nheavyWrite[usePersistedMap: false](org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT)  Time elapsed: 106.519 sec  <<< ERROR!\njava.lang.IllegalStateException\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:134)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.<init>(Segment.java:214)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.<init>(Segment.java:198)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:1177)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.readSegment(SegmentTracker.java:224)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:149)\n\tat org.apache.jackrabbit.oak.plugins.segment.RecordId.getSegment(RecordId.java:88)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:506)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:79)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getChildNode(SegmentNodeState.java:381)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder$UnconnectedHead.update(MemoryNodeBuilder.java:651)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder$ConnectedHead.update(MemoryNodeBuilder.java:729)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.head(MemoryNodeBuilder.java:171)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.access$300(MemoryNodeBuilder.java:88)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder$UnconnectedHead.update(MemoryNodeBuilder.java:650)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder$ConnectedHead.update(MemoryNodeBuilder.java:729)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.head(MemoryNodeBuilder.java:171)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.exists(MemoryNodeBuilder.java:273)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setProperty(MemoryNodeBuilder.java:506)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setProperty(MemoryNodeBuilder.java:515)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createProperties(HeavyWriteIT.java:156)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createNodes(HeavyWriteIT.java:148)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createNodes(HeavyWriteIT.java:149)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.heavyWrite(HeavyWriteIT.java:129)\n{noformat}\n\nSeen at build 597",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Test failure: HeavyWriteIT"
   },
   {
      "_id": "12920357",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2015-12-09 08:29:48",
      "description": "{{org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT}} fails on Jenkins: \n\n{noformat}\ntestSync(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT)  Time elapsed: 54.498 sec  <<< FAILURE!\njava.lang.AssertionError: expected:<{ root = { ... } }> but was:<{ root : { } }>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotEquals(Assert.java:834)\n\tat org.junit.Assert.assertEquals(Assert.java:118)\n\tat org.junit.Assert.assertEquals(Assert.java:144)\n\tat org.apache.jackrabbit.oak.plugins.segment.standby.DataStoreTestBase.testSync(DataStoreTestBase.java:104)\n{noformat}\n\nSeen at builds 163, 164, 598, 601\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "ci",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: ExternalSharedStoreIT"
   },
   {
      "_id": "12920094",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-08 14:33:39",
      "description": "To diagnose certain issues with gc / checkpoints / indexing we need a tool to trace the evolution of a given node through the revision history. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement tooling for tracing a node through the revision history"
   },
   {
      "_id": "12919998",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-08 08:23:33",
      "description": "This epic tracks the work done to move the Segment Store into an independent bundle, detached from oak-core.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move the Segment Store into its own bundle"
   },
   {
      "_id": "12919659",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-07 11:30:25",
      "description": "For post mortem analysis it would be helpful to have the revisions that where involved in a compaction run. I.e. the revision that was compacted, the revisions of the cycles (if any) and the revision that is ultimately applied?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Compactor should log revisions acting upon"
   },
   {
      "_id": "12919023",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-04 17:00:15",
      "description": "This is a regression introduced with OAK-3329 where cleaning up unreferenced tar files was taken out of {{FileStore#cleanup}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Offline compaction doesn't clean up unreferenced tar files"
   },
   {
      "_id": "12917203",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-01 09:58:17",
      "description": "Having {{compaction.forceAfterFail}} set to {{true}} will block repository writes for an extended period of time (minutes, probably hours) if all previous compaction cycles couldn't catch up with the latest changes. I think this is not acceptable and we should change the default to {{false}}: if compaction is not able to catch up the recommendation should be to move it to a quieter time. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Change default of compaction.forceAfterFail to false"
   },
   {
      "_id": "12917183",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-01 08:41:23",
      "description": "{{SegmentStore.writeSegment}} doesn't specify its behaviour in the face of IO errors. Moreover {{FileStore.writeSegment}} just catches any {{IOException}} and throws a {{RuntimeException}} with the former as its cause. \n\nI think we need to clarify this as an immediate cause of the current state is that some of the {{SegmentWriter}} write methods *do* throw an {{IOException}} and some *don't*. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve handling of IOException"
   },
   {
      "_id": "12917177",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-12-01 08:28:50",
      "description": "Currently {{BackgroundThread}} dies silently when hit by an uncaught exception. We should log a warning. \n\nAlso calling {{Thread#start}} from within the constructor is an anti-pattern as it exposes {{this}} before fully initialised. This is potentially causing OAK-3303. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "More resilient BackgroundThread implementation"
   },
   {
      "_id": "12916934",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-11-30 10:59:05",
      "description": "Epic for collection SegmentMK resilience improvements",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve SegmentMK resilience"
   },
   {
      "_id": "12916638",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-11-27 13:34:17",
      "description": "Currently {{SegmentBufferWriter.flush()}} directly calls {{SegmentStore.writeSegment()}} once the current segment does not have enough space for the next record. We should try to cut this dependency as {{SegmentBufferWriter}} should only be concerned with providing buffers for segments. Actually writing these to the store should be handled by a higher level component. \n\nA number of deadlock (e.g. (OAK-2560, OAK-3179, OAK-3264) we have seen is one manifestation of this troublesome dependency. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Decouple SegmentBufferWriter from SegmentStore"
   },
   {
      "_id": "12916181",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-11-25 15:32:13",
      "description": "ATM indexes break (by whatever circumstances) users need to perform a full re-index. Depending on the size off the repository this can take a long time.\nIf the user knows that the indexes were in a good state at a certain revision in the past then it would be very useful, if the user could trigger a \"partial\" re-index where only the content added after a certain revision was updated in the index.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Partial re-index from last known good state"
   },
   {
      "_id": "12915355",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-11-23 14:59:44",
      "description": "{{CompactionAndCleanupIT#testMixedSegments}} might fail under some circumstances. It can be certainly be made to fail by increasing concurrency. I suspect this to be caused by OAK-3348. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Potential test failure: CompactionAndCleanupIT#testMixedSegments"
   },
   {
      "_id": "12914080",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-11-18 11:03:37",
      "description": "As discussed in OAK-2187 and due to changes done in OAK-3002 HierrachialCacheInvalidator is now redundant and should be removed. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove HierarchicalCacheInvalidator"
   },
   {
      "_id": "12913682",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-11-17 12:35:04",
      "description": "This is similar to OAK-3388, but about hierarchy information like which child nodes exist at a given revision of the parent node. This issue only occurs in a cluster.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Inconsistent read of hierarchy "
   },
   {
      "_id": "12911832",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-11-10 11:12:36",
      "description": "Some of the issues related to TarMK revision gc should be back ported to the branches. This issue is for keeping track of which issues and which svn revisions we consider for back porting. The task consists of the following steps:\n\n# Identify issue to back port\n# Merge the respective commits into a private forks of the 1.0 and 1.2 branches\n# Run tests on builds from the private forks\n# On success merge the private forks to the 1.0 and 1.2 branches and update the fix versions of the respective issues. \n    * Update the svn merge info with the respective merged svn revisions. \n    * Update the fix versions of the affected issues.\n\n[~dhasler]: FYI\n[~alex.parvulescu], [~frm]: please refrain from merging potential conflicting changes into the branches in the meanwhile. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Backport TarMK revision gc related issues"
   },
   {
      "_id": "12908277",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-10-27 16:36:57",
      "description": "[Gephi|https://gephi.org/] turned out to be very valuable for examining segment graphs. I would like to add some tooling so we could dump the segment graph of a {{FileStore}} to a file. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Tooling for writing segment graphs to a file"
   },
   {
      "_id": "12908135",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-10-27 06:41:11",
      "description": "Currently while connecting to Mongo MongoDocumentStore relies on default write concern provided as part of mongouri. \n\nRecently some issues were seen where Mongo based Oak was connecting to 3 member replica set and there were frequent replica state changes due to use of VM for Mongo. This caused data loss and corruption of data in Oak.\n\nTo avoid such situation Oak should default to write concern of majority by default. If some write concern is specified as part of mongouri then that should take precedence. This would allow system admin to take the call of tweaking write concern if required and at same time allows Oak to use the safe write concern.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use write concern of w:majority when connected to a replica set"
   },
   {
      "_id": "12907331",
      "assignee": "frm",
      "components": [],
      "created": "2015-10-23 08:52:41",
      "description": "The o.a.j.o.api has multiple dependencies on classes exported by the Google Guava bundle. The the o.a.j.o.api package should be made independent from Google Guava.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "o.a.j.o.api should not depend on Guava"
   },
   {
      "_id": "12905902",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-10-19 10:33:05",
      "description": "Most if not all calls to {{SessionDelegate#performVoid}} pass a raw type to that method instead of parametrizing it with the {{Void}} type, which leads to an \"unchecked assignment\" warning. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Unchecked assignements in calls to performVoid()"
   },
   {
      "_id": "12904464",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-13 07:26:55",
      "description": "Said test fails sporadically:\n\n{noformat}\nat org.junit.Assert.assertNull(Assert.java:562)\nat org.apache.jackrabbit.oak.plugins.segment.CompactionMapTest.removeSome(CompactionMapTest.java:156)\n{noformat}\n\nThis is a regression introduced with OAK-3501: the {{recent}} map gets not cleared when {{segmentIdMap}} is empty. This can happen when a recent key is removed again while there are no other changes. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: CompactionMapTest.removeSome"
   },
   {
      "_id": "12904208",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-10-12 15:11:48",
      "description": "The logs generated during different phases of tar garbage collection (compaction) are currently quite heterogenous and difficult to grep/parse.\n\nI propose with the attached patch to uniformize these logs, changing the following:\n# all logs start with the prefix {{TarMK GargabeCollection \\{\\}#:}}\n# different phases of garbage collection are easier to identify by the first word after prefix, e.g. estimation, compaction, cleanup\n# all values are also printed in a standard unit, with the following format: {{<human_readable_value> (<standard_unit_value>)}}. This makes extraction of information much easier.\n# messages corresponding to the same cycle (run) can be grouped by including the runId in the prefix.\n\nNote1: I don't have enough visibility, but the changes might impact any system relying on the old format. Yet, I've seen they have changed before so this might not be a real concern.\n\nNote2: the runId is implemented as a static variable, which is reset every time the class is reloaded (e.g. at restart), so it is unique only during one run.\n\nBelow you can find an excerpt of old logs and new logs to compare:\n\nNEW:\n{code}\n12.10.2015 16:11:56.705 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: started\n12.10.2015 16:11:56.707 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: estimation started\n12.10.2015 16:11:59.275 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: estimation completed in 2.569 s (2567 ms). Gain is 16% or 1.1 GB/1.3 GB (1062364160/1269737472 bytes), so running compaction\n12.10.2015 16:11:59.275 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: compaction started, strategy=CompactionStrategy{paused=false, cloneBinaries=false, cleanupType=CLEAN_OLD, olderThan=36000000, memoryThreshold=5, persistedCompactionMap=true, retryCount=5, forceAfterFail=true, compactionStart=1444659116706, offlineCompaction=false}\n12.10.2015 16:12:05.839 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.Compactor Finished compaction: 420022 nodes, 772259 properties, 20544 binaries.\n12.10.2015 16:12:07.459 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:11:56 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: compaction completed in 8.184 s (8183 ms), after 0 cycles\n12.10.2015 16:12:11.912 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:12:11 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: cleanup started. Current repository size is 1.4 GB (1368899584 bytes)\n12.10.2015 16:12:12.368 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:12:11 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: cleanup marking file for deletion: data00008a.tar\n12.10.2015 16:12:12.434 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 16:12:11 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK GarbageCollection #1: cleanup completed in 522.8 ms (522 ms). Post cleanup size is 1.2 GB (1217132544 bytes)and space reclaimed 151.8 MB (151767040 bytes). Compaction map weight/depth is 0 B/1 (0 bytes/1).\n{code} \n\nOLD:\n{code}\n12.10.2015 15:54:55.115 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK compaction started\n12.10.2015 15:54:56.082 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore Estimated compaction in 967.6 ms, gain is 7% (1083809280/1170960384) or (1.1 GB/1.2 GB), so running compaction\n12.10.2015 15:54:56.083 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK compaction running, strategy=CompactionStrategy{paused=false, cloneBinaries=false, cleanupType=CLEAN_OLD, olderThan=36000000, memoryThreshold=5, persistedCompactionMap=true, retryCount=5, forceAfterFail=true, compactionStart=1444658095115, offlineCompaction=false}\n12.10.2015 15:55:01.986 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.Compactor Finished compaction: 419878 nodes, 771824 properties, 20542 binaries.\n12.10.2015 15:55:03.273 *INFO* [TarMK compaction thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:54:55 CEST 2015, previous max duration 0ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK compaction completed after 0 cycles in 7190ms\n12.10.2015 15:55:08.032 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:55:08 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK revision cleanup started. Current repository size 1.3 GB\n12.10.2015 15:55:08.719 *INFO* [TarMK flush thread [/Users/volteanu/workspace/test/qp/quickstart-author-4502/crx-quickstart/repository/segmentstore], active since Mon Oct 12 15:55:08 CEST 2015, previous max duration 10ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK revision cleanup completed in 688.0 ms. Post cleanup size is 1.3 GB and space reclaimed 0. Compaction map weight/depth is 0 B/1.\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Uniformization of compaction log messages"
   },
   {
      "_id": "12903762",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-09 15:01:22",
      "description": "We should have better logging during cleanup. E.g. why a file has been skipped / cleaned etc. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve logging during cleanup"
   },
   {
      "_id": "12903311",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-10-08 09:32:54",
      "description": "The method is only used by the DocumentMK class, which is now considered a test helper (OAK-2907) and part of the API anymore.\n\nThe method should be removed from the DocumentNodeStore and functionality moved to the DocumentMK.find() method.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove DocumentNodeStore.diff()"
   },
   {
      "_id": "12902999",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-10-07 13:55:53",
      "description": "Each entry in {{MemoryDiffCache}} is keyed with {{(path, fromRev, toRev)}} for the list of modified children at {{path}}. A diff calcualted by {{DocumentNodeStore.diffImpl}} at '/' (passively via loader) or {{JournalEntry.applyTo}} (actively) fill each path for which there are modified children (including the hierarchy)\n\nBut, if an observer calls {{compareWithBaseState}} on a unmodified sub-tree, the observer will still go down to {{diffImpl}} although cached parent entry can be used to answer the query.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MemoryDiffCache should also check parent paths before falling to Loader (or returning null)"
   },
   {
      "_id": "12902989",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-07 13:27:14",
      "description": "A deadlock was detected while stopping the {{SegmentCompactionIT}} using the exposed MBean.\n\n{noformat}\n\"main@1\" prio=5 tid=0x1 nid=NA waiting for monitor entry\n waiting for pool-1-thread-10@2111 to release lock on <0xae8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.dropCache(SegmentWriter.java:871)\n  at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.close(FileStore.java:1031)\n  - locked <0xae7> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT.tearDown(SegmentCompactionIT.java:282)\n\n\"pool-1-thread-10@2111\" prio=5 tid=0x1d nid=NA waiting for monitor entry\n  java.lang.Thread.State: BLOCKED\n blocks main@1\n waiting for main@1 to release lock on <0xae7> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n  at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.writeSegment(FileStore.java:1155)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.flush(SegmentWriter.java:253)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.prepare(SegmentWriter.java:350)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeListBucket(SegmentWriter.java:468)\n  - locked <0xae8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeList(SegmentWriter.java:719)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1211)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1156)\n  at org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1147)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1175)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.prepare(SegmentNodeStore.java:451)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.optimisticMerge(SegmentNodeStore.java:474)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.execute(SegmentNodeStore.java:530)\n  at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:208)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Deadlock when closing a concurrently used FileStore 2.0"
   },
   {
      "_id": "12902929",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-10-07 08:58:41",
      "description": "Currently, when a cluster node starts and discovers that it wasn't properly shutdown, it first runs the complete LastRevRecovery and only continues startup when done.\n\nHowever, when it fails to acquire the recovery lock, which implies that a different cluster node is already running the recovery on its behalf, it simply skips recovery and continues startup?\n\nSo what is it? Is running the recovery before proceeding critical or not? If it is, this code in {{LastRevRecoveryAgent}} needs to change:\n\n{code}\n        //TODO What if recovery is being performed for current clusterNode by some other node\n        //should we halt the startup\n        if(!lockAcquired){\n            log.info(\"Last revision recovery already being performed by some other node. \" +\n                    \"Would not attempt recovery\");\n            return 0;\n        }\n{code}\n\nIf it's not critical, we may want to run the recovery always asynchronously. \ncc [~mreutegg]  and [~chetanm]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "LastRevRecovery for self async?"
   },
   {
      "_id": "12902653",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-10-06 10:04:52",
      "description": "Each test in the class retains about 16MB of heap and subsequent tests may fail with an OOME. E.g. see recent build failure on travis: https://travis-ci.org/apache/jackrabbit-oak/builds/83848567",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "CompactionMapTest does not close file store"
   },
   {
      "_id": "12902425",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-10-05 14:16:10",
      "description": "Running \n\n{{oak-run debug  /path/to/segmentStore}}\n\ncan result in {{SNFE}} s being logged if the file store has been compacted before. This can happen even though the repository is actually consistent according to {{oak-run check}}. \n\nThe reason is {{debug}} traversing all node states of all record ids in all tar files. When a previous cleanup of a tar file did not reach 25% gain it will not clean up that file leaving behind segments possibly containing node states pointing to limbo. Those nodes would result in said {{SNFE}} of {{oak-run}} debug. But as those node states are not reachable from the head node state the repository is still consistent itself. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Confusing SNFE whith oak-run debug"
   },
   {
      "_id": "12902419",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-10-05 13:12:45",
      "description": "{{NodeDocument.getNodeAtRevision}} tried to look at latest revisions entries for each property in current document. But it just looks at the *last* entry for a given property. In case this last entry isn't committed, the code would go into previous documents to look for a committed value.\n\n(cc [~mreutegg])",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NodeDocument.getNodeAtRevision can go into property history traversal when latest rev on current doc isn't committed"
   },
   {
      "_id": "12902115",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-10-02 13:07:22",
      "description": "I think we should replace the background thread with some kind of a scheduler. The goal would be to decouple threading from scheduling. IMO threads should not be managed by the application but by the container. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Replace BackgroundThread with Scheduler"
   },
   {
      "_id": "12900998",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-09-28 10:52:10",
      "description": "The offline compaction instantiates {{FileStore}} using a deprecated constructor. This constructor forces a no-op {{GCMonitor}} that swallows log messages and caught exception.\n\nIt would be more appropriate to create the {{FileStore}} using the corresponding {{Builder}}. This has the side effect of configuring a {{LoggingGCMonitor}}, which provides way more information than the current default.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve the logging capabilities of offline compaction"
   },
   {
      "_id": "12895116",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-21 13:12:19",
      "description": "The conflict check does not consider changes that are made visible between the rebase and the background read.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Background update may create journal entry with incorrect id"
   },
   {
      "_id": "12864161",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-15 07:27:07",
      "description": "Similar to OAK-3390, the instanceof check in LastRevRecoveryAgent does not work when the MongoDocumentStore is wrapped.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Avoid instanceof check in LastRevRecoveryAgent"
   },
   {
      "_id": "12863902",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-14 15:17:51",
      "description": "Supporting multiplexing repository would have impact on various places in Oak design. There are various sub components in Oak which maintain there own storage built on top of NodeStore. For e.g. indexes are stored within NodeStore, permissions are also stored within NodeStore. Adding multiplexing support would impact such stores in following ways\n\nThe most basic application of multiplexing support is to support private and shared storage. Under this an Oak application would have a private store and a shared store. Content under certain paths would be stored under private repo while all other content is stored under shared repo\n\n# *Writing* - Any content written via JCR API passes through some {{CommitHooks}}. These hooks are responsible for updating the indexes, permission store etc. Now if any path say /foo/bar gets modified the commits hooks would need to determine under which path in NodeStore should the derived data (index entries, permission etc) should be stored. For simple case of private and shared store where we have 2 sets of paths private and shared these hooks would need to be aware of that and use different path in NodeStore to store the derived content. Key point to note here that any such storage has to differentiate wether the path from which the content is being derived is a private path or shared path\n\n# *Reading* - Reading requirement compliments the writing problem. While performing any JCR operation Oak might need to invoke QueryIndex, PermissionStore etc. These stores in turn would need to perform a read from there storage area within NodeStore. For multiplexing support these components would then need to be aware that there storage can exist in both shared and private stores\n\nh4. Terms Used\n\n# _private repo_ (PR) - Set of paths which are considered private to the application. Tentative example /lib,/apps\n# _shared repo_ (SR) - Set of paths which are considered shared and different versions of the application can perform read and write operations on them. Tentative example /content, /etc/workflow/instances\n# {{PathToStoreMapper}} - Responsible for mapping a path to store type. For now it can just answer either PR or SR. But the concept can be generalized \n\nAim of this story is to prototype changes in Oak layer in a fork to asses the impact on current implementation",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "multiplexing"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Multiplexing NodeStore support in Oak layer"
   },
   {
      "_id": "12863035",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-10 12:39:42",
      "description": "This issue is similar to OAK-2929 but related to how the DocumentNodeStore reads a node state when there is a clock difference between multiple cluster nodes. The node state read from a NodeDocument may not be correct when there is a clock difference.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Inconsistent read in cluster with clock differences"
   },
   {
      "_id": "12862389",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-08 11:49:32",
      "description": "BackgroundObserver currently merges external events if the last one in queue is also an external event. This leads to diff being done for a revision pair which is different from the ones pushed actively into cache during backgroud read (using JournalEntry) i.e. diff queries for {{diff(\"/a/b\", rA, rC)}} while background read had pushed results of {{diff(\"/a/b\", rA, rB)}} and {{diff(\"/a/b\", rB, rC)}}.\n\n(cc [~mreutegg], [~egli], [~chetanm], [~mduerig])",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Collapsing external events in BackgroundObserver even before queue is full leads to JournalEntry not getting used"
   },
   {
      "_id": "12862325",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-09-08 06:27:07",
      "description": "When the boost support was added the intention was to support a usecase like \n\n{quote}\nFor the fulltext search on a node where the fulltext content is derived from multiple field it should be possible to boost specific text contributed by individual field. Meaning that if a title field is boosted more than description, the title (part) in the fulltext field will mean more than the description (part) in the fulltext field.\n{quote}\n\nThis would enable a user to perform a search like _/jcr:root/content/geometrixx-outdoors/en//element(*, cq:Page)\\[jcr:contains(., 'Keyword')\\]_ and get a result where pages having 'Keyword' in title come above in search result compared to those where Keyword is found in description.\n\nCurrent implementation just sets the boost while add the field value to fulltext field with the intention that Lucene would use the boost as explained above. However it does not work like that and boost value gets multiplies with other field and hence boosting does not work as expected",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Boosting fields not working as expected"
   },
   {
      "_id": "12862191",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-09-07 10:06:36",
      "description": "If a node is cached, 1/4 of the time which is used to call DocumentNodeStore.getNode is spent in PerfLogger.start and PerfLogger.end just for checking whether or not debug logging is enabled (this is likely much less if no TurboFilters are used).\n\nTo reduce the overhead of the PerfLogger, it should not check if debug is enabled in end() if start is below 0 anyway. Moreover, it would help to check only every second if debug is really enabled.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Reduce PerfLogger isDebugEnabled overhead"
   },
   {
      "_id": "12861787",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-09-04 09:00:14",
      "description": "This is OAK-3349 taken to the extreme: given a segment that is almost not referenced any more we could just rewrite the still referenced content. That is, say a segment contains two properties reachable from the current root node state and all its remaining content is not reachable from the root node state. In that case we could rewrite these two properties and create a new root node state referencing the rewritten properties. This would effectively make the segment eligible for being gc-ed. \nSuch an approach would start from segments that are sparse and compact these instead of compacting everything as we currently do, which might cause a lot of copying around stuff that already is compact. The challenging part here is probably finding the segments that are sparse as this involves inverting the reference graph. \n\nTodo: Asses feasibility and impact, implement prototype.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Incremental compaction"
   },
   {
      "_id": "12861783",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-09-04 08:45:58",
      "description": "On big repositories compaction can take quite a while to run as it needs to create a full deep copy of the current root node state. For such cases it could be beneficial if we could partially compact the repository thus splitting full compaction over multiple cycles. \nPartial compaction would run compaction on a sub-tree just like we now run it on the full tree. Afterwards it would create a new root node state by referencing the previous root node state replacing said sub-tree with the compacted one. \n\nTodo: Asses feasibility and impact, implement prototype.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Partial compaction"
   },
   {
      "_id": "12861779",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-09-04 08:32:39",
      "description": "I suspect that certain write operations during compaction can cause references from compacted segments to pre-compacted ones. This would effectively prevent the pre-compacted segments from getting evicted in subsequent cleanup phases. \n\nThe scenario is as follows:\n* A session is opened and a lot of content is written to it such that the update limit is exceeded. This causes the changes to be written to disk. \n* Revision gc runs causing a new, compacted root node state to be written to disk.\n* The session saves its changes. This causes rebasing of its changes onto the current root (the compacted one). At this point any node that has been added will be added again in the sub-tree rooted at the current root. Such nodes however might have been written to disk *before* revision gc ran and might thus be contained in pre-compacted segments. As I suspect the node-add operation in the rebasing process *not* to create a deep copy of such nodes but to rather create a *reference* to them, a reference to a pre-compacted segment is introduced here. \n\nGoing forward we need to validate above hypothesis, assess its impact if necessary come up with a solution.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Cross gc sessions might introduce references to pre-compacted segments"
   },
   {
      "_id": "12861773",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-04 08:17:52",
      "description": "The cleanup phase after a compaction run is currently not able to remove the pre compacted segments as the previous (pre-compacted) root is still being referenced. Those references are coming from:\n\n* The {{before}} [local variable|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/file/FileStore.java#L653] in {{FileStore.flush}}.\n* The [current head|https://github.com/apache/jackrabbit-oak/blob/trunk/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeStore.java#L85-L85] of the {{SegmentNodeStore}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compac",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Ineffective cleanup after compaction due to references to root"
   },
   {
      "_id": "12861552",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-03 12:20:39",
      "description": "It may happen that a commit adds a collision marker for a revision which is already committed. {{Collision.markCommitRoot()}} does not perform a conditional update when it adds the collision marker. Though, it checks the document after the update if the marked revision is committed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Commit may add collision marker for committed revision"
   },
   {
      "_id": "12861256",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-09-02 08:55:22",
      "description": "OAK-2528 introduced purging of _commitRoot entries without associated local changes on the document. Those _commitRoot entries are created when a child nodes is added and the _children flag is touched on the parent.\n\nThe purge operation is too eager and removes all such entries, which may result in an undetected hierarchy conflict.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SplitOperations purges _commitRoot entries too eagerly"
   },
   {
      "_id": "12861236",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-02 07:26:38",
      "description": "Concurrently writing to the file store can lead to a sever lock contention in {{FileStore#readSegment}}. That method searches the current {{TarWriter}} instance for the segment once it could not be found in any of the {{TarReader}} instances. This is the point where synchronizes on the {{FileStore}} instance, which leads to  the contention. \nThe effect is only observable once the segment cache becomes full and reads actually need to go to the file store. Thus a possible improvement could be to pin segments from the current tar writer to the cache. Alternatively we could try to ease locking by employing read/write locks where possible. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "FileStore lock contention with concurrent writers"
   },
   {
      "_id": "12861233",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-09-02 07:06:17",
      "description": "TarMK cleanup exclusively locks the {{FileStore}}, which causes concurrent writers to block until cleanup finished. Initially cleanup was expected to be reasonably fast, however I have seen it taking dozens of minutes under certain circumstances (most likely many tar files with many small segments, aka OAK-2896).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TarMK cleanup blocks writers"
   },
   {
      "_id": "12860662",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-31 12:15:08",
      "description": "{noformat}\nRunning org.apache.jackrabbit.oak.plugins.segment.SegmentOverflowExceptionIT\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 2,426.873 sec <<< FAILURE!\nrun(org.apache.jackrabbit.oak.plugins.segment.SegmentOverflowExceptionIT)  Time elapsed: 2,426.373 sec  <<< ERROR!\njava.util.ConcurrentModificationException\n\tat java.util.ArrayList$Itr.checkForComodification(ArrayList.java:859)\n\tat java.util.ArrayList$Itr.next(ArrayList.java:831)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.wasCompactedTo(CompactionMap.java:60)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.wasCompactedTo(Record.java:64)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.equals(SegmentBlob.java:213)\n\tat com.google.common.base.Objects.equal(Objects.java:55)\n\tat org.apache.jackrabbit.oak.plugins.memory.AbstractPropertyState.equal(AbstractPropertyState.java:53)\n\tat org.apache.jackrabbit.oak.plugins.memory.AbstractPropertyState.equals(AbstractPropertyState.java:90)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1176)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.<init>(SegmentNodeStore.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentOverflowExceptionIT.run(SegmentOverflowExceptionIT.java:130)\n{noformat}\n\nThis is caused by concurrently accessing the underlying list of maps in {{CompactionMap#remove}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ConcurrentModificationException when running SegmentOverflowExceptionIT"
   },
   {
      "_id": "12859572",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-08-27 11:08:40",
      "description": "When a DocumentNodeStore instance is killed and restarted, the _lastRev recovery mechanism is triggered on startup. It may happen that the restarted instance does not see all changes that were recovered.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Self recovering instance may not see all changes"
   },
   {
      "_id": "12858956",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-26 11:45:50",
      "description": "{{org.apache.jackrabbit.oak.plugins.segment.SegmentOverflowExceptionIT}} can fail with an {{SNFE}}. This is somewhat expected due to the low segment retention time used for this test. That time is apparently needed for this test to reproduce the original issue. So I'd rather not touch it. \n\nI propose to ignore that exception and retry a couple of times until failing the test. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SNFE in SegmentOverflowExceptionIT "
   },
   {
      "_id": "12858640",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-25 14:36:20",
      "description": "Currently {{SegmentOverflowExceptionIT}} runs forever or until it fails. We should add a time out after which the test is considered passed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentOverflowExceptionIT runs forever unless it fails"
   },
   {
      "_id": "12858615",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-25 13:14:25",
      "description": "Shutting down the repository while revision gc is running might block for a long time until either compaction estimation/compaction or clean up has finished. We should provide a way to interrupt those operations for a timely shut down. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Revision gc blocks repository shutdown"
   },
   {
      "_id": "12858277",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-08-24 11:57:55",
      "description": "Collection of DocMK resilience improvements",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Improve DocumentMK resilience"
   },
   {
      "_id": "12858273",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-08-24 11:52:32",
      "description": "As discussed bilaterally grouping the improvements for indexer resilience in this issue for easier tracking",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Improve indexing resilience"
   },
   {
      "_id": "12857823",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-21 11:30:38",
      "description": "Just seen this deadlock while running {{SegmentCompactionIT}}:\n\n{noformat}\n\"pool-1-thread-47\":\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:910)\n\t- waiting to lock <0x0000000700110bd0> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.readSegment(SegmentTracker.java:211)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:149)\n\t- locked <0x0000000700328b88> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:154)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:121)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:103)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.get(CompactionMap.java:93)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.uncompact(SegmentWriter.java:1074)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1098)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:85)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.updated(MemoryNodeBuilder.java:214)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:81)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.remove(MemoryNodeBuilder.java:355)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.modify(SegmentCompactionIT.java:448)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:430)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:406)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\"TarMK flush thread [target/SegmentCompactionIT9065337410200765612dir], active since Fri Aug 21 06:53:18 GMT+00:00 2015, previous max duration 40846ms\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:145)\n\t- waiting to lock <0x0000000700328b88> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:154)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.compress(PersistedCompactionMap.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.remove(PersistedCompactionMap.java:155)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.remove(CompactionMap.java:108)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.cleanup(FileStore.java:699)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.flush(FileStore.java:628)\n\t- locked <0x0000000700110bd0> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\t- locked <0x000000070017f1c0> (a java.util.concurrent.atomic.AtomicReference)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore$1.run(FileStore.java:413)\n\tat java.lang.Thread.run(Thread.java:745)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.BackgroundThread.run(BackgroundThread.java:70)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Deadlock between persisted compaction map and cleanup 2"
   },
   {
      "_id": "12857550",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-08-20 14:45:01",
      "description": "Most of the time NodeDocument.getNewestRevision() is able to quickly identify the newest revision, but sometimes the code falls to a more expensive calculation, which attempts to read through available {{_revisions}} and {{_commitRoot}} entries. If either of those maps are empty, the method will go through the entire revision history.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize NodeDocument.getNewestRevision()"
   },
   {
      "_id": "12856839",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-08-18 07:32:20",
      "description": "{{DocumentNodeSTore#retrieve(checkpoint)}} may throw an {{IllegalArgumentException}} via {{Revision.fromString(checkpoint)}}.\n\nThe javadocs say that it returns a {{NodeState}} or {{null}}. The exception prevents recovery of {{AsyncIndexUpdate}} from a bad recorded checkpoint.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore.retrieve() should not throw IllegalArgumentException"
   },
   {
      "_id": "12856168",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-14 14:06:12",
      "description": "A deadlock was detected while stopping the {{SegmentCompactionIT}} using the exposed MBean.\n\n{noformat}\nFound one Java-level deadlock:\n=============================\n\"pool-1-thread-23\":\n  waiting to lock monitor 0x00007fa8cf1f0488 (object 0x00000007a0081e48, a org.apache.jackrabbit.oak.plugins.segment.file.FileStore),\n  which is held by \"main\"\n\"main\":\n  waiting to lock monitor 0x00007fa8cc015ff8 (object 0x00000007a011f750, a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter),\n  which is held by \"pool-1-thread-23\"\n\nJava stack information for the threads listed above:\n===================================================\n\"pool-1-thread-23\":\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.writeSegment(FileStore.java:948)\n\t- waiting to lock <0x00000007a0081e48> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.flush(SegmentWriter.java:228)\n\t- locked <0x00000007a011f750> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.prepare(SegmentWriter.java:329)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeListBucket(SegmentWriter.java:447)\n\t- locked <0x00000007a011f750> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeList(SegmentWriter.java:698)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1190)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1154)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:85)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.updated(MemoryNodeBuilder.java:214)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:81)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setChildNode(MemoryNodeBuilder.java:346)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeAdded(AbstractRebaseDiff.java:211)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:527)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:531)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord$2.childNodeChanged(MapRecord.java:404)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:488)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:394)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.spi.state.AbstractRebaseDiff.childNodeChanged(AbstractRebaseDiff.java:219)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:488)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compareBranch(MapRecord.java:565)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.compare(MapRecord.java:470)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.compareAgainstBaseState(SegmentNodeState.java:583)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.prepare(SegmentNodeStore.java:446)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.optimisticMerge(SegmentNodeStore.java:471)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.execute(SegmentNodeStore.java:527)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:205)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:426)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:399)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\"main\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.dropCache(SegmentWriter.java:850)\n\t- waiting to lock <0x00000007a011f750> (a org.apache.jackrabbit.oak.plugins.segment.SegmentWriter)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.close(FileStore.java:830)\n\t- locked <0x00000007a0081e48> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT.tearDown(SegmentCompactionIT.java:266)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\n\nFound 1 deadlock.\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Deadlock when closing a concurrently used FileStore"
   },
   {
      "_id": "12851653",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-05 10:39:15",
      "description": "Just seen this deadlock while running {{SegmentCompactionIT}}:\n\n{noformat}\n\"TarMK flush thread [target/SegmentCompactionIT3250704011919039778dir], active since Wed Aug 05 09:25:57 GMT+00:00 2015, previous max duration 2325ms\" daemon prio=10 tid=0x00007f5674872800 nid=0x5dc8 waiting for monitor entry [0x00007f5666a00000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:145)\n\t- waiting to lock <0x0000000707fc7fe8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:154)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.compress(PersistedCompactionMap.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.remove(PersistedCompactionMap.java:155)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.remove(CompactionMap.java:108)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.cleanup(FileStore.java:694)\n\t- locked <0x000000070017b330> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.flush(FileStore.java:628)\n\t- locked <0x000000070017b330> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\t- locked <0x00000007000aed60> (a java.util.concurrent.atomic.AtomicReference)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore$1.run(FileStore.java:413)\n\tat java.lang.Thread.run(Thread.java:745)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.BackgroundThread.run(BackgroundThread.java:70)\n\n\"pool-1-thread-34\" prio=10 tid=0x00007f55ec002800 nid=0x5dea waiting for monitor entry [0x00007f56648de000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:904)\n\t- waiting to lock <0x000000070017b330> (a org.apache.jackrabbit.oak.plugins.segment.file.FileStore)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.readSegment(SegmentTracker.java:210)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:149)\n\t- locked <0x0000000707fc7fe8> (a org.apache.jackrabbit.oak.plugins.segment.SegmentId)\n\tat org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:400)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:215)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n\tat org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:121)\n\tat org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:103)\n\tat org.apache.jackrabbit.oak.plugins.segment.CompactionMap.get(CompactionMap.java:93)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.uncompact(SegmentWriter.java:1074)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1098)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1154)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1154)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1154)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1135)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:399)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1126)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.<init>(SegmentNodeStore.java:418)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:204)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:433)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomWriter.call(SegmentCompactionIT.java:406)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cleanup",
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Deadlock between persisted compaction map and cleanup"
   },
   {
      "_id": "12851413",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-08-04 14:58:15",
      "description": "OAK-2734 introduced retry cycles and the option to force compaction when all cycles fail. However OAK-2192 introduced a performance regression: each compaction cycle takes in the order of the size of the repository to complete instead of in the order of the number of remaining changes to compact. This is caused by comparing compacted with pre-compacted node states, which is necessary to avoid mixed segments (aka OAK-2192). To fix the performance regression I propose to pass the compactor an additional node state (the 'onto' state). The diff would then be calculated across the pre compacted states, which performs in the order of number of changes. The changes would then be applied to the 'onto' state, which is a compacted state to avoid mixed segments. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction slow on repository with continuous writes"
   },
   {
      "_id": "12849923",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-07-29 12:38:43",
      "description": "OAK-2619 introduced the possibility to run the same upgrade repeatedly and achieve incremental upgrades. This reduces the time taken for {{CommitHook}} processing, because the diff is reduced.\n\nHowever, for incremental upgrades to be really useful, the content-copy phase needs to be fast. Currently an optimization that was proposed in OAK-2626 was lost due to the implementation of a better solution to some part of the problem. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve binary comparison during repeated upgrades"
   },
   {
      "_id": "12849891",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-07-29 10:10:48",
      "description": "Currently the documentation at http://jackrabbit.apache.org/oak/docs/osgi_config.html#SegmentNodeStore only documents the properties\n# repository.home and\n# tarmk.size\nAll the other properties like customBlobStore, tarmk.mode, .... are not documented. Please extend that. Also it would be good, if the table could be extended with what type is supported for the individual properties.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/17",
         "id": "17",
         "description": "A technical task.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/task_agile.png",
         "name": "Technical task",
         "subtask": true
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Extend documentation for SegmentNodeStoreService in http://jackrabbit.apache.org/oak/docs/osgi_config.html#SegmentNodeStore"
   },
   {
      "_id": "12849611",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-07-28 13:20:30",
      "description": "Currently in oak-lucene where ever call is made to Lucene it passes Version.LUCENE_47 as hardcoded version. To enable easier upgrade of Lucene and hence change of defaults for fresh setup this version should be instead based on {{IndexFormatVersion}}.\n\nSay\n* For IndexFormatVersion set to V2 (current default) - Lucene version used is LUCENE_47\n* For IndexFormatVersion set to V3 (proposed) - Lucene version used would be per Lucene library version\n\nIf the index is reindexed then it would automatically be updated to the latest revision",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Lucene Version should be based on IndexFormatVersion"
   },
   {
      "_id": "12848545",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-07-23 12:50:01",
      "description": "When using {{CLEAN_OLD}} it might happen that segments of the persisted compaction map get collected. --The reason for this is that only the segment containing the root of the map is pinned ({{SegmentId#pin}}), leaving other segments of the compaction map eligible for collection once old enough.--\n\n{noformat}\norg.apache.jackrabbit.oak.plugins.segment.SegmentNotFoundException: Segment 95cbb3e2-3a8c-4976-ae5b-6322ff102731 not found\n        at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:919)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.getSegment(SegmentTracker.java:134)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:108)\n        at org.apache.jackrabbit.oak.plugins.segment.Record.getSegment(Record.java:82)\n        at org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:154)\n        at org.apache.jackrabbit.oak.plugins.segment.MapRecord.getEntry(MapRecord.java:186)\n        at org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:118)\n        at org.apache.jackrabbit.oak.plugins.segment.PersistedCompactionMap.get(PersistedCompactionMap.java:100)\n        at org.apache.jackrabbit.oak.plugins.segment.CompactionMap.get(CompactionMap.java:93)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.uncompact(SegmentWriter.java:1023)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1033)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:100)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore$Commit.<init>(SegmentNodeStore.java:418)\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStore.merge(SegmentNodeStore.java:204)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "SNFE in persisted comapation map when using CLEAN_OLD"
   },
   {
      "_id": "12845515",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-07-16 08:30:51",
      "description": "UnsavedModifications performance degrades when used in combination with the MapDB backed MapFactory. Calls become more and more expensive the longer the instance is in use. The is caused by a limitation of MapDB, which does not remove empty BTree nodes.\n\nA test performed with random paths added to the map and later removed again in a loop shows a increase to roughly 1 second to read keys present in the map when the underlying data file is about 50MB in size.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Performance degradation of UnsavedModifications on MapDB"
   },
   {
      "_id": "12845482",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-07-16 04:38:56",
      "description": "At times the CopyOnWrite reports following exception\n\n{noformat}\n15.07.2015 14:20:35.930 *WARN* [pool-58-thread-1] org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate The async index update failed\norg.apache.jackrabbit.oak.api.CommitFailedException: OakLucene0004: Failed to close the Lucene index\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:204)\n\tat org.apache.jackrabbit.oak.plugins.index.IndexUpdate.leave(IndexUpdate.java:219)\n\tat org.apache.jackrabbit.oak.spi.commit.VisibleEditor.leave(VisibleEditor.java:63)\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:56)\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.updateIndex(AsyncIndexUpdate.java:366)\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:311)\n\tat org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105)\n\tat org.quartz.core.JobRunShell.run(JobRunShell.java:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.FileNotFoundException: _2s7.fdt\n\tat org.apache.lucene.store.FSDirectory.fileLength(FSDirectory.java:261)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier$CopyOnWriteDirectory$COWLocalFileReference.fileLength(IndexCopier.java:837)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier$CopyOnWriteDirectory.fileLength(IndexCopier.java:607)\n\tat org.apache.lucene.index.SegmentCommitInfo.sizeInBytes(SegmentCommitInfo.java:141)\n\tat org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529)\n\tat org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:502)\n\tat org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:508)\n\tat org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:618)\n\tat org.apache.lucene.index.IndexWriter.doFlush(IndexWriter.java:3147)\n\tat org.apache.lucene.index.IndexWriter.flush(IndexWriter.java:3123)\n\tat org.apache.lucene.index.IndexWriter.closeInternal(IndexWriter.java:988)\n\tat org.apache.lucene.index.IndexWriter.close(IndexWriter.java:932)\n\tat org.apache.lucene.index.IndexWriter.close(IndexWriter.java:894)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorContext.closeWriter(LuceneIndexEditorContext.java:192)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditor.leave(LuceneIndexEditor.java:202)\n\t... 10 common frames omitted\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "AsyncIndexer fails due to FileNotFoundException thrown by CopyOnWrite logic"
   },
   {
      "_id": "12844356",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-07-11 07:54:53",
      "description": "It can happen that text can be extracted from same binary multiple times in a given indexing cycle. This can happen due to 2 reasons\n\n# Multiple Lucene indexes indexing same node - A system might have multiple Lucene indexes e.g. a global Lucene index and an index for specific nodeType. In a given indexing cycle same file would be picked up by both index definition and both would extract same text\n# Aggregation - With Index time aggregation same file get picked up multiple times due to aggregation rules\n\nTo avoid the wasted effort for duplicate text extraction from same file in a given indexing cycle it would be better to have an expiring cache which can hold on to extracted text content for some time. The cache should have following features\n# Limit on total size\n# Way to expire the content using [Timed Evicition|https://code.google.com/p/guava-libraries/wiki/CachesExplained#Timed_Eviction] - As chances of same file getting picked up are high only for a given indexing cycle it would be better to expire the cache entries after some time to avoid hogging memory unnecessarily \n\nSuch a cache would provide following benefit\n# Avoid duplicate text extraction - Text extraction is costly and has to be minimized on critical path of {{indexEditor}}\n# Avoid expensive IO specially if binary content are to be fetched from a remote {{BlobStore}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cache recently extracted text to avoid duplicate extraction"
   },
   {
      "_id": "12843210",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-07-07 15:01:49",
      "description": "As mentioned in [OAK-2131|https://issues.apache.org/jira/browse/OAK-2131?focusedCommentId=14616391&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14616391] there can be a situation wherein the LastRevRecoveryAgent updates some nodes in the tree but not the root. This seems to happen due to OAK-2131's change in the Commit.applyToCache (where paths to update are collected via tracker.track): in that code, paths which are non-root and for which no content has changed (and mind you, a content change includes adding _deleted, which happens by default for nodes with children) are not 'tracked', ie for those the _lastRev is not update by subsequent backgroundUpdate operations - leaving them 'old/out-of-date'. This seems correct as per description/intention of OAK-2131 where the last revision can be determined via the commitRoot of the parent. But it has the effect that the LastRevRecoveryAgent then finds those intermittent nodes to be updated while as the root has already been updated (which is at first glance non-intuitive).\n\nI'll attach a test case to reproduce this.\n\nPerhaps this is a bug, perhaps it's ok. [~mreutegg] wdyt?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "LastRevRecoveryAgent can update _lastRev of children but not the root"
   },
   {
      "_id": "12842853",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-07-06 10:34:13",
      "description": "I suggest to remove the throws clause and fix the affected clients. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "FileStore.size doesn't throw IOException but declares it as thrown"
   },
   {
      "_id": "12842397",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-07-02 18:08:38",
      "description": "As explained in OAK-1966 diff logic makes a call like\n\nbq. db.nodes.find({ _id: { $gt: \"3:/content/foo/01/\", $lt: \"3:/content/foo010\" }, _modified: { $gte: 1405085300 } }).sort({_id:1})\n\nFor better and deterministic query performance we would need to create a compound index like \\{_modified:1, _id:1\\}. This index would ensure that Mongo does not have to perform object scan while evaluating such a query.\n\nCare must be taken that index is only created by default for fresh setup. For existing setup we should expose a JMX operation which can be invoked by system admin to create the required index as per maintenance window",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Add a compound index for _modified + _id"
   },
   {
      "_id": "12842389",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-07-02 17:58:34",
      "description": "As part of OAK-3062 [~mreutegg] suggested\n\n{quote}\nAs a further optimization we could also limit the lower bound of the _modified\nrange. The revision GC does not need to check documents with a _deletedOnce\nagain if they were not modified after the last successful GC run. If they\ndidn't change and were considered existing during the last run, then they\nmust still exist in the current GC run. To make this work, we'd need to\ntrack the last successful revision GC run. \n{quote}\n\nLowest last validated _modified can be possibly saved in settings collection and reused for next run",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use a lower bound in VersionGC query to avoid checking unmodified once deleted docs"
   },
   {
      "_id": "12842186",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2015-07-02 04:29:16",
      "description": "Some of RemoteServerIT failing with Address already in use. Possibly the test setup needs to be changed to use random available port \n\n{noformat}\njava.net.BindException: Address already in use\n\tat sun.nio.ch.Net.bind0(Native Method)\n\tat sun.nio.ch.Net.bind(Net.java:444)\n\tat sun.nio.ch.Net.bind(Net.java:436)\n\tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:214)\n\tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\tat org.eclipse.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)\n\tat org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)\n\tat org.eclipse.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)\n\tat org.eclipse.jetty.server.Server.doStart(Server.java:291)\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)\n\tat org.apache.jackrabbit.oak.remote.http.handler.RemoteServer.start(RemoteServer.java:54)\n\tat org.apache.jackrabbit.oak.remote.http.handler.RemoteServerIT.setUp(RemoteServerIT.java:134)\n{noformat}\n\n[1] https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/236/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "RemoteServerIT failing due to address already in use"
   },
   {
      "_id": "12841717",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-30 15:16:32",
      "description": "The hand crafted segment cache in {{SegmentTracker}} is prone to lock contentions in concurrent access scenarios. As {{SegmentNodeStore#merge}} might also end up acquiring this lock while holding the commit semaphore the situation can easily lead to many threads being blocked on the commit semaphore. The {{SegmentTracker}} cache doesn't differentiate between read and write access, which means that reader threads can block writer threads. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting",
         "resilience",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve segment cache in SegmentTracker"
   },
   {
      "_id": "12841626",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-30 09:17:12",
      "description": "Currently compaction is skipped if the compaction gain estimator determines that less than 10% of space could be reclaimed. Instead of relying on a hard coded value of 10% we should make this configurable. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Make compaction gain estimate threshold configurable"
   },
   {
      "_id": "12841623",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-30 09:13:31",
      "description": "When compaction is started on a new and sufficiently small repository such that there is yet no tar reader the compaction gain estimator logs the somewhat confusing message {{gain is 0% (0/0) or (0 B/0 B)}}. \n\nWe should improve the logging for this case.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Improve compaction gain estimation logging for the case where there are no tar readers"
   },
   {
      "_id": "12841614",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-06-30 08:53:06",
      "description": "The {{oak-it}} module only contains the single {{oak-it-osgi}} module, which in turn consists of a single test class. \n\nI suggest to at least move {{oak-it-osgi}} to the top level reactor to be consistent with the flat module hierarchy we adopted. IMO an even better solution would be to move the single test class to {{oak-run}}. Not sure whether this is viable though due to the custom assembly necessary. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Move oak-it-osgi to top level "
   },
   {
      "_id": "12841567",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2015-06-30 05:03:47",
      "description": "Most of the test in {{RemoteServerIT}} at times fail on the CI server [1] with following exception\n\n{noformat}\nError Message\n\n/home/jenkins/jenkins-slave/workspace/Apache%20Jackrabbit%20Oak%20matrix/jdk/latest1.7/label/Ubuntu/nsfixtures/SEGMENT_MK/profile/unittesting/oak-remote/target/test-classes/org/apache/jackrabbit/oak/remote/http/handler/addNodeMultiPathProperty.json (No such file or directory)\nStacktrace\n\njava.io.FileNotFoundException: /home/jenkins/jenkins-slave/workspace/Apache%20Jackrabbit%20Oak%20matrix/jdk/latest1.7/label/Ubuntu/nsfixtures/SEGMENT_MK/profile/unittesting/oak-remote/target/test-classes/org/apache/jackrabbit/oak/remote/http/handler/addNodeMultiPathProperty.json (No such file or directory)\n\tat java.io.FileInputStream.open(Native Method)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:146)\n\tat com.google.common.io.Files$FileByteSource.openStream(Files.java:127)\n\tat com.google.common.io.Files$FileByteSource.openStream(Files.java:117)\n\tat com.google.common.io.ByteSource$AsCharSource.openStream(ByteSource.java:404)\n\tat com.google.common.io.CharSource.read(CharSource.java:155)\n\tat com.google.common.io.Files.toString(Files.java:391)\n\tat org.apache.jackrabbit.oak.remote.http.handler.RemoteServerIT.load(RemoteServerIT.java:119)\n\tat org.apache.jackrabbit.oak.remote.http.handler.RemoteServerIT.testPatchLastRevisionAddMultiPathProperty(RemoteServerIT.java:1199)\n{noformat}\n\n[1] https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/232/testReport/",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "RemoteServerIT test are failing on the CI server"
   },
   {
      "_id": "12841279",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-06-29 09:18:49",
      "description": "A DocumentNodeStore cluster currently shows a conflict behavior, which\nis not intuitive. A modification may fail with a conflict even though\nbefore and after the conflict, the external change is not visible to\nthe current session. There are two aspects to this issue.\n\n1) a modification may conflict with a change done on another cluster\nnode, which is committed but not yet visible on the current cluster node.\n\n2) even after the InvalidItemStateException caused by the conflict, a\nrefreshed session may still not see the external change.\n\nThe first aspect is a fundamental design decision and cannot be changed\neasily.\n\nThe second part can be addressed by suspending the commit until the external\nconflict becomes visible on the current cluster node. This would at least\navoid the awkward situation where the external change is not visible after\nthe InvalidItemStateException.\n\nThe system would also become more deterministic. A commit currently goes\ninto a number of retries with exponential back off, but there's no guarantee\nthe external modification becomes visible within those retries. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Suspend commit on conflict"
   },
   {
      "_id": "12840750",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-06-26 06:43:59",
      "description": "update.limit decides whether a commit is persisted using a branch or not. The default is 10000 (and can be overridden using the system property).\n\nA typical call pattern in JCR is to persist batches of ~1024 nodes. These translate to more than 10000 changes (see PackageImportIT), due to JCR properties, and also indexing commit hooks.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "candidate_oak_1_4",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "DocumentRootBuilder: revisit update.limit default"
   },
   {
      "_id": "12839799",
      "assignee": "mreutegg",
      "components": [],
      "created": "2015-06-23 09:38:48",
      "description": "Most queries on MongoDB are usually rather fast and the TreeLock acquired in MongoDocumentStore (to ensure cache consistency) is released rather quickly. However there may be cases when a query is more expensive and a TreeLock is held for a long time. This may block other threads from querying MongoDB and limit concurrency.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Long running MongoDB query may block other threads"
   },
   {
      "_id": "12839549",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-06-22 13:23:29",
      "description": "(From an earlier [post on the list|http://markmail.org/thread/mkrvhkfabit4osli]) The DocumentNodeStore.backgroundWrite goes through the heavy work of updating the lastRev for all pending changes and does so in a hierarchical-depth-first manner. Unfortunately, if the pending changes all come from separate commits (as does not sound so unlikely), the updates are sent in individual update calls to mongo (whenever the lastRev differs). Which, if there are many changes, results in many calls to mongo.\n\nOAK-2066 is about extending the DocumentStore API with a batch-update method. That one, once available, should thus be used in the {{backgroundWrite}} as well.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use batch-update in backgroundWrite"
   },
   {
      "_id": "12838792",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-18 13:40:24",
      "description": "The SegmentStore cache size calculation ignores the size of the field Segment.string (a concurrent hash map). It looks like a regular segment in a memory mapped file has the size 1024, no matter how many strings are loaded in memory. This can lead to out of memory. There seems to be no way to limit (configure) the amount of memory used by strings. In one example, 100'000 segments are loaded in memory, and 5 GB are used for Strings in that map.\n\nWe need a way to configure the amount of memory used for that. This seems to be basically a cache. OAK-2688 does this, but it would be better to have one cache with a configurable size limit.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "doc-impacting",
         "resilience",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentStore cache does not take \"string\" map into account"
   },
   {
      "_id": "12838394",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-06-17 07:00:23",
      "description": "This subtask is about spawning out a [comment|https://issues.apache.org/jira/browse/OAK-2829?focusedCommentId=14588114&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14588114] on OAK-2829 re optimizing docCache invalidation using the newly introduced external diff journal:\n\n{quote}\nAttached OAK-2829-improved-doc-cache-invaliation.patch which is a suggestion on how to avoid invalidating the entire document cache when doing a {{backgroundRead}} but instead making use of the new journal: ie only invalidate from the document cache what has actually changed.\n\nI'd like to get an opinion ([~mreutegg], [~chetanm]?) on this first, I have a load test pending locally which found invalidation of the document cache to be the slowest part thus wanted to optimize this first.\n\nOpen still/next:\n * also invalidate only necessary parts from the docChildrenCache\n * junits for all of these\n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize docCache and docChildrenCache invalidation by filtering using journal"
   },
   {
      "_id": "12836776",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2015-06-10 09:18:44",
      "description": "http://jackrabbit.apache.org/oak/docs/command_line.html points to http://jackrabbit.apache.org/oak/docs/oak-mongo-js/oak.html, which doesn't exit. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Broken link on documentation site"
   },
   {
      "_id": "12834989",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-06-03 10:06:37",
      "description": "Long running sessions limit the efficient of revision gc as they keep reference to old node states. \n\nWe should consider to add an MBean through which all sessions can be enforced to refresh. This would provide clients with means to fine tune revision gc by first calling that MBean and then triggering a gc cycle. IMO this is preferable to directly enforcing a refresh from the garbage collector. The latter is too invasive and also not required when there are no long running sessions. Offering this functionality to clients as an additional knob to turn is safer. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "doc-impacting",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add MBean to enforce session refresh on all open sessions"
   },
   {
      "_id": "12834514",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-02 08:07:48",
      "description": "The sampling rate feature introduced with OAK-2595 is not efficient. It only prevents uuids from being stored in the bloom filter while the visited set is not affected and thus keeps growing. \n\nI will remove the feature again for now. We should look for a better solution once this becomes a problem. Will follow up on OAK-2939 re. this. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Sampling rate feature CompactionGainEstimate is not efficient"
   },
   {
      "_id": "12834513",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-02 08:06:25",
      "description": "The sampling rate feature introduced with OAK-2595 is not efficient. It only prevents uuids from being stored in the bloom filter while the visited set is not affected and thus keeps growing. \n\nI will remove the feature again for now. We should look for a better solution once this becomes a problem. Will follow up on OAK-2939 re. this. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Sampling rate feature CompactionGainEstimate is not efficient"
   },
   {
      "_id": "12834195",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-06-01 09:27:08",
      "description": "Currently compaction will be skipped if some rough estimation determines that there is not  enough memory to run. That estimation however assumes that each compaction cycle requires as much space as the compaction map already takes up. This is too conservative. Instead the amount of memory taken up by the last compaction cycle should be a better estimate. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Estimation of required memory for compaction is off"
   },
   {
      "_id": "12834183",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-06-01 08:37:19",
      "description": "DocumentNodeStore has some code related to off heap which makes use of Apache Directmemory (OAK-891). This feature was not much used and PersistentCache made this feature obsolete.\n\nRecently it was mentioned on Directmemory that there is not much activity going on [1] in that project and it might be referred to attic. In light of that we should remove this feature from Oak\n\n[1] http://markmail.org/thread/atia2ecaa2mugmjx",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove code related to directmemory for off heap caching"
   },
   {
      "_id": "12833739",
      "assignee": "frm",
      "components": [],
      "created": "2015-05-29 10:20:53",
      "description": "Oak currently exports *a lot* of packages even though those are only used by Oak itself. We should probably leverage OSGi subsystems here and only export the bare minimum to the outside world. This will simplify evolution of Oak internal APIs as with the current approach changes to such APIs always leak to the outside world. \n\nThat is, we should have an Oak OSGi sub-system as an deployment option. Clients would then only need to deploy that into their OSGi container and would only see APIs actually meant to be exported for everyone (like e.g. the JCR API). At the same time Oak could go on leveraging OSGi inside this subsystem.\n\ncc [~bosschaert] as you introduced us to this idea. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "modularization",
         "osgi",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Limit the scope of exported packages"
   },
   {
      "_id": "12833670",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-29 04:59:11",
      "description": "With OAK-2673, it's now possible to have hidden intermediate nodes created concurrently.\nSo, a scenario like:\n{noformat}\nstart -> /:hidden\nN1 creates /:hiddent/parent/node1\nN2 creates /:hidden/parent/node2\n{noformat}\nis allowed.\n\nBut, if N2's creation of {{parent}} got persisted later than that on N1, then N2 is currently able to delete {{parent}} even though there's {{node1}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Parent of unseen children must not be removable"
   },
   {
      "_id": "12833421",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-05-28 13:35:03",
      "description": "In a large migration its seen that {{ReferenceEditor}} {{newIds}} can consume lots of memory as it records all the uuid property. This system has 33 million uuid index and the set was consuming ~1.5G of memory\n\nWe should look into ways such that it does not have to maintain such a big in memory state",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ReferenceEditor newIds consuming lots of memory during migration"
   },
   {
      "_id": "12833338",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-05-28 07:40:06",
      "description": "Seen in a log file:\n\n{noformat}\n27.05.2015 11:34:48.130 *WARN* [DocumentNodeStore background update thread] org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore Background operation failed: org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: com.ibm.db2.jcc.am.SqlTransactionRollbackException: DB2 SQL Error: SQLCODE=-911, SQLSTATE=40001, SQLERRMC=68, DRIVER=3.65.77\norg.apache.jackrabbit.oak.plugins.document.DocumentStoreException: com.ibm.db2.jcc.am.SqlTransactionRollbackException: DB2 SQL Error: SQLCODE=-911, SQLSTATE=40001, SQLERRMC=68, DRIVER=3.65.77\n{noformat}\n\nWe need to decide whether these are harmless in that the operation will be repeated anyway. If the answer is yes, we may want to tune the log message. If the answer is no, we need to dig deeper.\n\n[~mreutegg] wdyt?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore background update thread handling of persistence exceptions"
   },
   {
      "_id": "12832953",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-05-27 04:44:07",
      "description": "Currently oak-jcr bundle needs to be embedded within some other bundle if the Oak needs to be properly configured in OSGi env. Need to revisit this aspect and see what needs to be done to enable Oak to be properly configured without requiring the oak-jcr bundle to be embedded in the repo",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization",
         "osgi",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "oak-jcr bundle should be usable as a standalone bundle"
   },
   {
      "_id": "12832746",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-05-26 15:26:53",
      "description": "There is the {{Oak}} and {{Jcr}} builder classes for setting up Oak and Jcr repositories. Both builders don't have clear semantics regarding the life cycle of the individual components they register. On top of that the requirements regarding those life cycles differ depending on whether the individual components run within an OSGi container or not. In the former case the container would already manage the life cycle so the builder should not. \n\nIMO we should specify the builders to only be used for non OSGi deployments and have the manage the life cycles of the components they instantiate. OTOH for OSGi deployments we should leverage OSGi subsystems to properly set things up.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "modularization",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Review and improve Oak and Jcr repository setup"
   },
   {
      "_id": "12832736",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-05-26 15:00:08",
      "description": "The DocumentMK class is not directly used (when using the JCR API), but it is only really used by tests. So it should be moved to tests.\n\nThe DocumentMK.Builder class needs to be moved first (to a top level class for example).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Move DocumentMK to test"
   },
   {
      "_id": "12831690",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317808",
            "id": "12317808",
            "name": "parent",
            "description": "Parent POM"
         }
      ],
      "created": "2015-05-21 10:35:42",
      "description": "OAK-2748 introduced a snapshot dependency to Jackrabbit 2.10.1-SNAPSHOT. Now that 2.10.1 is released, the snapshot dependency can be removed again.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Update to Jackrabbit 2.10.1"
   },
   {
      "_id": "12831661",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2015-05-21 09:02:53",
      "description": "DataStoreBlobStore directly exposes the InputStream from the wrapped DataStore. In most cases underlying DataStore exposes a LazyFileInputStream [0] which is not buffered.\n\nFor performance reason the stream finally exposed at the BlobStore layer should be buffered one. See [1] for the discussion\n\n[1] http://markmail.org/thread/xi4isnzw57vphcsq\n[0]\nhttps://github.com/apache/jackrabbit/blob/trunk/jackrabbit-data/src/main/java/org/apache/jackrabbit/core/data/LazyFileInputStream.java#L102 \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DataStoreBlobStore should expose a buffer input stream for getInputStream call"
   },
   {
      "_id": "12831424",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-05-20 16:32:35",
      "description": "There is an issue with how the HAMT implementation ({{SegmentWriter.writeMap()}} interacts with the 256 segment references limit when putting many entries into the map: This limit gets regularly reached once the maps contains about 200k entries. At that points segments get prematurely flushed resulting in more segments, thus more references and thus even smaller segments. It is common for segments to be as small as 7k with a tar file containing up to 35k segments. This is problematic as at this point handling of the segment graph becomes expensive, both memory and CPU wise. I have seen persisted segment graphs as big as 35M where the usual size is a couple of ks. \n\nAs the HAMT map is used for storing children of a node this might have an advert effect on nodes with many child nodes. \n\nThe following code can be used to reproduce the issue: \n\n{code}\nSegmentWriter writer = new SegmentWriter(segmentStore, getTracker(), V_11);\nMapRecord baseMap = null;\n\nfor (;;) {\n    Map<String, RecordId> map = newHashMap();\n    for (int k = 0; k < 1000; k++) {\n        RecordId stringId = writer.writeString(String.valueOf(rnd.nextLong()));\n        map.put(String.valueOf(rnd.nextLong()), stringId);\n    }\n\n    Stopwatch w = Stopwatch.createStarted();\n    baseMap = writer.writeMap(baseMap, map);\n    System.out.println(baseMap.size() + \" \" + w.elapsed());\n}\n{code}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Putting many elements into a map results in many small segments. "
   },
   {
      "_id": "12831411",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-05-20 15:44:16",
      "description": "Currently the recommended way to exclude certain types of files from getting indexed is to add them to {{EmptyParser}} in Tika Config. However looking at how Tika works even if mimetype is provided as part metadata. \n\nTika Detector try to determine the mimetype by actually reading some bytes from InputStream [1] before looking up from passed MetaData. This would cause unnecessary IO in case large number of binaries are excluded.\n\nWe would need to look for way where any access to binary content which is not being indexed can be avoided. One option can to expose a multi value config property which takes a list of mimetypes to be excluded from indexing. If the mimeType provided as part of JCR data is part of that excluded list then call to Tika should be avoided\n\n[1] https://github.com/apache/tika/blob/trunk/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java#L446",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Avoid accessing binary content if the mimeType is excluded from indexing"
   },
   {
      "_id": "12831410",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-05-20 15:39:49",
      "description": "{{RepositoryImpl}} uses an instance of {{ContentRepository}} that is passed as an external dependency in its constructor.\n\n{{RepositoryImpl}} is not responsible for the creation of the {{ContentRepository}} instance and, as such, should not manage its lifecycle. In particular, the {{ContentRepository#close}} method should not be called when the {{RepositoryImpl#shutdown}} method is executed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "modularization",
         "resilience",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RepositoryImpl should not manage the lifecycle of ContentRepository"
   },
   {
      "_id": "12831360",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-05-20 12:43:05",
      "description": "While migrating large repositories say having 3 M docs (250k PDF) Lucene indexing takes long time to complete (at time 4 days!). Currently the text extraction logic is coupled with Lucene indexing and hence is performed in a single threaded mode which slows down the indexing process. Further if the reindexing has to be triggered it has to be done all over again.\n\nTo speed up the Lucene indexing we can decouple the text extraction\nfrom actual indexing. It is partly based on discussion on OAK-2787\n\n# Introduce a new ExtractedTextProvider which can provide extracted text for a given Blob instance\n# In oak-run introduce a new indexer mode - This would take a path in repository and would then traverse the repository and look for existing binaries and extract text from that\n\nSo before or after migration is done one can run this oak-run tool to create this store which has the text already extracted. Then post startup we need to wire up the ExtractedTextProvider instance (which is backed by the BlobStore populated before) and indexing logic can just get content from that. This would avoid performing expensive text extraction in the indexing thread.\n\nSee discussion thread http://markmail.org/thread/ndlfpkwfgpey6o66",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Speed up lucene indexing post migration by pre extracting the text content from binaries"
   },
   {
      "_id": "12830964",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-19 09:45:28",
      "description": "{{SegmentBlob}} currently returns recordId for {{contentIdentity}} even when an external DataStore is configured. Given that recordId is not stable it would be better to return the blobId as part of  {{contentIdentity}} if external DataStore is configured",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "SegmentBlob does not return blobId for contentIdentity"
   },
   {
      "_id": "12830954",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-19 09:14:14",
      "description": "In rare cases a commit may fail to update the pending changes on {{_lastRev}}    of documents. The stack trace is:\n\n{noformat}\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 0\n        at org.mapdb.BTreeMap.replace(BTreeMap.java:1174)\n        at org.apache.jackrabbit.oak.plugins.document.UnsavedModifications.put(UnsavedModifications.java:90)\n        at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore$10.track(DocumentNodeStore.java:1990)\n        at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.applyChanges(DocumentNodeStore.java:1056)\n        at org.apache.jackrabbit.oak.plugins.document.Commit.applyToCache(Commit.java:598)\n        at org.apache.jackrabbit.oak.plugins.document.CommitQueue.afterTrunkCommit(CommitQueue.java:127)\n        at org.apache.jackrabbit.oak.plugins.document.CommitQueue.done(CommitQueue.java:83)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "ArrayIndexOutOfBoundsException in UnsavedModifications.put()"
   },
   {
      "_id": "12830925",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-05-19 06:40:46",
      "description": "At time to analyse a issue with {{DocumentNodeStore}} running on Mongo we need a dump of various documents so as to recreate the scenario locally. In most case if issue is being observed for a specific path like /a/b then its sufficient to get Mongo documents for /, /a, /a/b and all the split documents for those paths.\n\nIt would be useful to have a function in oak-mongo which generates the required export command. For e.g. for path like /a/b following export command would dump all required info\n\n{noformat}\nmongoexport -h <mongo server> --port 27017 --db <db name> --collection nodes --out all-required-nodes.json --query '{$or:[{_id : /^4:p\\/a\\/b\\//},{_id : /^3:p\\/a\\//},{_id : /^2:p\\//},{_id:{$in:[\"2:/a/b\",\"1:/a\",\"0:/\"]}}]}'\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add support for generating mongo export command to oak-mongo"
   },
   {
      "_id": "12830668",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-18 12:43:30",
      "description": "{{SegmentNodeStoreService}} currently has no test coverage whatsoever. We should change that.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Tests for SegmentNodeStoreService"
   },
   {
      "_id": "12830649",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-05-18 10:46:35",
      "description": "Migration currently involves access to DataStore as its configured as part of repository.xml. However in complete migration actual binary content in DataStore is not accessed and migration logic only makes use of\n\n* Dataidentifier = id of the files\n* Length = As it gets encoded as part of blobId (OAK-1667)\n\nIt would be faster and beneficial to allow migration without actual access to the DataStore. It would serve two benefits\n\n# Allows one to test out migration on local setup by just copying the TarPM files. For e.g. one can only zip following files to get going with repository startup if we can somehow avoid having direct access to DataStore\n{noformat}\n>crx-quickstart# tar -zcvf repo-2.tar.gz repository --exclude=repository/repository/datastore --exclude=repository/repository/index --exclude=repository/workspaces/crx.default/index --exclude=repository/tarJournal\n{noformat}\n# Provides faster (repeatable) migration as access to DataStore can be avoided which in cases like S3 might be slow.  Given we solve how to get length\n\n*Proposal*\nHave a DataStore implementation which can be provided a mapping file having entries for blobId and length. This file would be used to answer queries regarding length and existing of blob and thus would avoid actual access to DataStore.\n\nGoing further this DataStore can be configured with a delegate which can be used as a fallback in case the required details is not present in pre computed data set (may be due to change in content after that data was computed)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "docs-impacting",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support migration without access to DataStore"
   },
   {
      "_id": "12830643",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-05-18 10:01:39",
      "description": "When running the consistency checker against a repository with a corrupt journal, it fails with an {{ISA}} instead of trying to skip over invalid revision identifiers:\n\n{noformat}\nException in thread \"main\" java.lang.IllegalArgumentException: Bad record identifier: foobar\nat org.apache.jackrabbit.oak.plugins.segment.RecordId.fromString(RecordId.java:57)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:227)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:178)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:156)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore.<init>(FileStore.java:166)\nat org.apache.jackrabbit.oak.plugins.segment.file.FileStore$ReadOnlyStore.<init>(FileStore.java:805)\nat org.apache.jackrabbit.oak.plugins.segment.file.tooling.ConsistencyChecker.<init>(ConsistencyChecker.java:108)\nat org.apache.jackrabbit.oak.plugins.segment.file.tooling.ConsistencyChecker.checkConsistency(ConsistencyChecker.java:70)\nat org.apache.jackrabbit.oak.run.Main.check(Main.java:701)\nat org.apache.jackrabbit.oak.run.Main.main(Main.java:158)\n{noformat}\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ConsistencyChecker#checkConsistency can't cope with inconsistent journal"
   },
   {
      "_id": "12830634",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-18 09:51:34",
      "description": "Under some rare conditions which are not entirely clear yet {{SegmentWriter.writeMap}} results in a {{NPE}}:\n\n{noformat}\njava.lang.NullPointerException\n\tat com.google.common.base.Preconditions.checkNotNull(Preconditions.java:192)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeRecordId(SegmentWriter.java:366)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapLeaf(SegmentWriter.java:417)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:475)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:511)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMap(SegmentWriter.java:711)\n{noformat}\n\nThis happens when the {{base}} passed to {{writeMap(MapRecord base, Map<String, RecordId> changes)}} is not null but doesn't contain some of the keys *removed* through the updates provided in the passed {{changes}}. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NPE in SegmentWriter.writeMap"
   },
   {
      "_id": "12830623",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-18 09:19:48",
      "description": "In the worst case compaction doubles the repository size while running. As this is somewhat unexpected we should check whether there is enough free disk space before running compaction and log a warning otherwise. This is to avoid a common source of running out of disk space and ending up with a corrupted repository. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "doc-impacting",
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction should check for required disk space before running"
   },
   {
      "_id": "12829503",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-13 09:55:35",
      "description": "Currently all commits go through the CommitQueue. This applies to commits that fit into memory, branch commits, merge commits and even reset commits.\n\nThe guarantee provided by the CommitQueue is only necessary for commits that affect the head revision of the store: commits that fit into memory and merge commits.\n\nBranch and reset commits should bypass the CommitQueue to avoid unnecessary delays of commits. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bypass CommitQueue for branch commits"
   },
   {
      "_id": "12829452",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-05-13 04:49:38",
      "description": "For issues like OAK-2787 it would helpful if we collect some stats around how much time is spent in extracting text from binaries.\n\nFor that purpose I would like add some logging around text extraction",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Log stats around time spent in extracting text from binaries"
   },
   {
      "_id": "12828838",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-05-11 14:59:47",
      "description": "I've seen {{CompactionMap#compress()}} take up most of the time spent in compaction. With 40M record ids in the compaction map compressing runs for hours. \n\nI will back this with numbers as soon as I have a better grip on the issue.  ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "doc-impacting",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CompactionMap#compress() inefficient for large compaction maps"
   },
   {
      "_id": "12828761",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-11 09:53:12",
      "description": "OAK-2624 decoupled the background read from the background write but the methods implementing the operations are synchronized. This means they cannot run at the same time and e.g. an expensive background write may unnecessarily block a background read.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Run background read and write operation concurrently"
   },
   {
      "_id": "12828314",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-05-08 10:30:33",
      "description": "{{CopyOnReadDirectory}} currently deletes local files which are not found in remote upon close. The list of remote file is fixed for a given revision however list of local files may vary. \n\n{{IndexTracker}} opens a new {{IndexNode}} upon update before closing the older one. When CopyOnRead is enabled it can happen that same local directory might be in use by two wrapper directories at the same time. \n\nThis introduces a race condition in {{removeDeletedFiles}} method as by the time it is invoked a newer wrapped directory might have started adding new files so those files would get included in the listing done for local directory and hence cause them to be deleted as they would not be found in remote directory which is pinned to older revision. Leading to following exception\n\n{noformat}\nCaused by: java.io.FileNotFoundException: /path/to/crx-quickstart/repository/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/4/_1r.cfe (No such file or directory)\n\tat java.io.RandomAccessFile.open(Native Method)\n\tat java.io.RandomAccessFile.<init>(RandomAccessFile.java:241)\n\tat org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:193)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier$CopyOnReadDirectory$FileReference.openLocalInput(IndexCopier.java:393)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier$CopyOnReadDirectory.openInput(IndexCopier.java:221)\n\tat org.apache.lucene.store.Directory.copy(Directory.java:185)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexMBeanImpl.dumpIndexContent(LuceneIndexMBeanImpl.java:104)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n{noformat}\n\nAs a fix the list of local file should be maintained as progress is made once the CopyOnRead instance gets created to ensure it does not pick up files which are added once the directory is closed",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CopyOnReadDirectory mode might delete a valid local file upon close"
   },
   {
      "_id": "12827982",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-05-07 10:40:07",
      "description": "This is a container issue for the ongoing effort to improve revision gc of the SegmentMK. \n\nI'm exploring \n* ways to make the reference graph as exact as possible and necessary: it should not contain segments that are not referenceable any more and but must contain all segments that are referenceable. \n* ways to segregate the reference graph reducing dependencies between certain set of segments as much as possible. \n* Reducing the number of in memory references and their impact on gc as much as possible.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve revision gc on SegmentMK"
   },
   {
      "_id": "12827624",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-05-06 11:26:46",
      "description": "At times in migration following exception is seen\n\n{noformat}\nCaused by: java.lang.NullPointerException\nat org.apache.jackrabbit.oak.upgrade.JackrabbitNodeState.createProperties(JackrabbitNodeState.java:311)\nat org.apache.jackrabbit.oak.upgrade.JackrabbitNodeState.<init>(JackrabbitNodeState.java:149)\nat org.apache.jackrabbit.oak.upgrade.JackrabbitNodeState.getChildNodeEntries(JackrabbitNodeState.java:255)\nat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1014)\nat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1015)\nat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1015)\n{noformat}\n\nThis would happen if the NodePropBundle is null for a given id. It would be good to add a NPE check in loader itself",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Log NodePropBundle id for which no bundle is found"
   },
   {
      "_id": "12827602",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-05-06 09:42:44",
      "description": "The OSGiIT tests are failing silently, so not failing the build when the tests don't pass.\n\n{code}\nRunning org.apache.jackrabbit.oak.osgi.OSGiIT\n[main] INFO org.ops4j.pax.exam.spi.DefaultExamSystem - Pax Exam System (Version: 3.4.0) created.\n[main] INFO org.ops4j.pax.exam.junit.impl.ProbeRunner - creating PaxExam runner for class org.apache.jackrabbit.oak.osgi.OSGiIT\n[main] INFO org.ops4j.pax.exam.junit.impl.ProbeRunner - running test class org.apache.jackrabbit.oak.osgi.OSGiIT\nERROR: org.apache.jackrabbit.oak-lucene (23): [org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProviderService(1)] The activate method has thrown an exception\njava.lang.NullPointerException: Index directory cannot be determined as neither index directory path [localIndexDir] nor repository home [repository.home] defined\n\tat com.google.common.base.Preconditions.checkNotNull(Preconditions.java:236)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProviderService.createTracker(LuceneIndexProviderService.java:197)\n\tat org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProviderService.activate(LuceneIndexProviderService.java:125)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Test failure: OSGiIT"
   },
   {
      "_id": "12827338",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-05-05 15:59:52",
      "description": "Container issue for refactoring the TarMK to make it more testable, maintainable, extensible and less entangled. \n\nFor example the segment format should be readable, writeable through standalone means so tests, tools and production code can share this code. Currently there is a lot of code duplication involved here. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Refactor TarMK"
   },
   {
      "_id": "12827300",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         }
      ],
      "created": "2015-05-05 14:49:27",
      "description": "{{org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest.org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest}} fails on Jenkins.\n\nSee e.g. https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/123/jdk=latest1.7,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=unittesting/console\n\nSeen on {{DOCUMENT_RDB}} and {{SEGMENT_MK}} with Java 1.7. and 1.8. \n\n{noformat}\nTests run: 13, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 23.572 sec <<< FAILURE!\norg.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest  Time elapsed: 23.255 sec  <<< ERROR!\ncom.carrotsearch.randomizedtesting.ThreadLeakError: 21 threads leaked from SUITE scope at org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultAnalyzersConfigurationTest: \n   1) Thread[id=32, name=oak-scheduled-executor-13, state=TIMED_WAITING, group=main]\n        at sun.misc.Unsafe.park(Native Method)\n        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:1125)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:807)\n        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n   2) Thread[id=25, name=oak-scheduled-executor-6, state=TIMED_WAITING, group=main]\n        at sun.misc.Unsafe.park(Native Method)\n        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:1125)\n        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:807)\n        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n...\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failure: DefaultAnalyzersConfigurationTest"
   },
   {
      "_id": "12827231",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-05-05 09:33:07",
      "description": "Comparing node states for local changes has been improved already with OAK-2669. But in a clustered setup generating events for external changes cannot make use of the introduced cache and is therefore slower. This can result in a growing observation queue, eventually reaching the configured limit. See also OAK-2683.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "docs-impacting",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "Comparing node states for external changes is too slow"
   },
   {
      "_id": "12825863",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-29 08:56:22",
      "description": "The default multipler is currently 3, which translates into a lock try timeout of 6 seconds. This is rather low and may result in merge failures even when a commit acquired the merge lock exclusively. I would like to increase it to 30.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Change default for oak.maxLockTryTimeMultiplier"
   },
   {
      "_id": "12825846",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-29 07:54:45",
      "description": "The DocumentNodeStoreBranch retries merges in two phases. First it retries merges while holding the merge lock non-exclusive and performing sleeps between attempts. If those retries fail the next phase will acquire the merge lock exclusively and perform retries. In the first phase the merge lock is released when the commit goes to sleep, while in the second it is not and may block other commits while sleeping.\n\nDocumentNodeStoreBranch should be changed to release the exclusive lock when the commit goes to sleep.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release merge lock in retry loop"
   },
   {
      "_id": "12824211",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-27 09:46:38",
      "description": "{{ObservationManagerImpl}} has a optimize method which process the list of includes and excludes and removes redundant clauses. That logic is now also being used in index filtering (OAK-2599) and is getting duplicated.\n\nGoing forward we need to refactor this logic so that both places can use it without copying. Possibly making it part of PathUtils\n\n[~mduerig] Also suggested to further optimize\nbq. Also PathFilter#optimise could be further optimised by removing entries that subsume each other (e.g. including /a/b, /a is the same as including (/a. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Refactor the optimize logic regarding path include and exclude to avoid duplication"
   },
   {
      "_id": "12823779",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-24 15:30:59",
      "description": "OakDirectory has to at times perform directory listing specially at the time of opening of index. With DocumentNodeStore such listing of child nodes \"might\" be slow if there are lots more deleted nodes and GC has not cleared them so far (due to OAK-1557). \n\nAs seen in OAK-2808 Lucene might be creating and deleting lot more files. To speed up such lookup one OakDirectory can save the listing of child nodes as an array property once the writer is closed. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Save Lucene directory listing as array property"
   },
   {
      "_id": "12823366",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2015-04-23 10:09:41",
      "description": "When starting up oak with oak-run the JMX beans are not registered, but it would be convenient for the registration to happen.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "oak-run: register JMX beans "
   },
   {
      "_id": "12823041",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-22 14:25:41",
      "description": "The DocumentStore API allows for conditional inserts (only add document if not present yet) and updates (using findAndModify() with a condition), but it doesn't allow you to remove a document given some conditions are met.\n\nThis feature is required to make sure the VersionGarbageCollector does not remove document that are modified concurrently. See OAK-2778.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Conditional remove on DocumentStore"
   },
   {
      "_id": "12822994",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-22 11:24:40",
      "description": "{{FileStore#cleanup}} would be more efficient when getting rid of as much references as possibly beforehand. Excess references are contributed by the current {{TarWriter}} instance and segment cache in {{SegmentTracker}}. \n\nThose excess references turn out to be especially harmful with many concurrent writers continuously writing to the repository. Starting with a certain write load clean up will become completely blocked. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Clear excess references before cleanup"
   },
   {
      "_id": "12822976",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-22 10:26:56",
      "description": "{{TarWriter#cleanup}} currently adds all its references to the initial elements of the reference graph. It would be sufficient though to just add the references in the tar writer's own graph. \n\nAt the same time I'd like to rename that method from {{cleanup}} to {{collectReferences}}, which better reflects its semantics. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make contributions to reference graph from TarWriter less conservative "
   },
   {
      "_id": "12822650",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-21 11:42:18",
      "description": "This issue is related to OAK-2646. Every now and then I see reports of background reads with a cache invalidation that takes a rather long time. Sometimes minutes. It would be good to give the HierarchicalInvalidator an upper limit for the time it may take to perform the invalidation. When the time is up, the implementation should simply invalidate the remaining documents.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Time limit for HierarchicalInvalidator"
   },
   {
      "_id": "12822289",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332439",
            "id": "12332439",
            "name": "indexing",
            "description": "Asynchronous and Sync Indexing"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-04-20 11:35:22",
      "description": "I have had issues in cases when the async Lucene index had gotten corrupted. With this index unusable the only option was to re-index.  The problem however was that there were ongoing queries relying on this index even during re-indexing. Because the original index was corrupted these queries led to further load on the system (traversals afair).\n\nI wonder if we could improve the system resilience in such situations.\nOne thing I could think of: could we maybe fallback to the last known non-corrupted index state while the re-index is running? This would at least take off the load due to new incoming queries.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve system resilience in case of index corruption"
   },
   {
      "_id": "12821795",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-17 07:50:32",
      "description": "{code}\n@Override\n            public int getLocalEventCount() {\n                return size(filter(queue, new Predicate<ContentChange>() {\n                    @Override\n                    public boolean apply(@Nullable ContentChange input) {\n                        return input.info != null;\n                    }\n                }));\n            }\n\n            @Override\n            public int getExternalEventCount() {\n                return size(filter(queue, new Predicate<ContentChange>() {\n                    @Override\n                    public boolean apply(@Nullable ContentChange input) {\n                        return input.info == null;\n                    }\n                }));\n            }\n{code}\n\nboth methods should probably check for {{input}} being null before accessing {{input.info}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Remove Nullable annotation in Predicates of BackgroundObserver"
   },
   {
      "_id": "12821153",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-15 13:26:25",
      "description": "The {{Oak#createContentRepository()}} method changes the state of the builder at every invocation. In particular, it always adds a new {{CommitHook}}.\n\nThe observable behavior is that all the {{IndexEditor}} instances are executed twice when the {{Oak}} and {{Jcr}} builders are used together - i.e. when both an instance of {{Repository}} and {{ContentRepository}} are needed.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak builder changes its state during repository creation"
   },
   {
      "_id": "12820818",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-14 13:42:39",
      "description": "The backgroundOperationLock in DocumentNodeStore uses the default non-fair acquisition order. According to JavaDoc of ReentrantReadWriteLock it is possible that a background operation task gets delayed for a long time when the system is under load. We should probably consider using the fair mode for the backgroundOperationLock to make sure background operation tasks do not get delayed excessively.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Fair mode for backgroundOperationLock"
   },
   {
      "_id": "12820786",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-14 11:04:36",
      "description": "OAK-2127 introduced a maxLockTryTimeMS to allow a writer to proceed with a merge even if the merge lock is currently acquired by another thread. The value is currently hardcoded.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Configurable maxLockTryTimeMS"
   },
   {
      "_id": "12820540",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-13 14:02:11",
      "description": "Under some rare circumstances there is a warning in the logs:\n\n{noformat}\n11:57:47.375 WARN  [pool-1-thread-24] FileStore.java:865    Failed to read from tar file target/SegmentCompactionIT1331315031754226278dir/data01460a.tar\njava.io.IOException: Stream Closed\n        at java.io.RandomAccessFile.seek(Native Method) ~[na:1.7.0_75]\n        at org.apache.jackrabbit.oak.plugins.segment.file.FileAccess$Random.read(FileAccess.java:105) ~[classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.file.TarReader.readEntry(TarReader.java:502) ~[classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.file.FileStore.readSegment(FileStore.java:860) ~[classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentTracker.getSegment(SegmentTracker.java:128) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentId.getSegment(SegmentId.java:108) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.readString(Segment.java:348) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.readPropsV11(Segment.java:476) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.loadTemplate(Segment.java:449) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:402) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.Segment.readTemplate(Segment.java:396) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getTemplate(SegmentNodeState.java:79) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState.getChildNodeCount(SegmentNodeState.java:357) [classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomReader.readRandomTree(SegmentCompactionIT.java:410) [test-classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomPropertyReader.call(SegmentCompactionIT.java:446) [test-classes/:na]\n        at org.apache.jackrabbit.oak.plugins.segment.SegmentCompactionIT$RandomPropertyReader.call(SegmentCompactionIT.java:439) [test-classes/:na]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_75]\n{noformat}\n\nThis happens due to a race between {{FileStore#readSegment}} reading from tar files and already removed by {{FileStore#flush}}. This isn't a problem as the tar file in question is still present at a newer generation and the {{FileStore}} will eventually read from that one. However the warning looks rather scaring and somewhat implies a defect. \n\nWe should either lower the log level or remove the race. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Failed to read from tar file "
   },
   {
      "_id": "12820397",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-12 14:45:45",
      "description": "Oak Observation support exposes a {{EventListenerMBean}} [1] which provide quite a bit of details around registered observation listeners. However in a typical application there would be multiple listeners registered. To simplify monitoring it would be helpful to have a _consolidated_ view of all listeners related statistics.\n\nFurther the stats can also include some more details which are Oak specific\n* Subtree paths to which the listener listens to - By default JCR Api allows single path however Oak allows a listener to register to multiple paths\n* If listener is enabled to listen to cluster local and cluster external changes\n* Size of queue in BackgroundObserver\n* Distribution of change types present in the queue - Local, External etc\n\n[1] https://github.com/apache/jackrabbit/blob/trunk/jackrabbit-api/src/main/java/org/apache/jackrabbit/api/jmx/EventListenerMBean.java",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring",
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Consolidated JMX view of all EventListener related statistics"
   },
   {
      "_id": "12820275",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-11 06:33:43",
      "description": "{{LucenePropertyIndex}} currently uses unique PathCursor [1] due to which the cursor would maintain an in memory set of visited path. This might grow big if result size is big and cursor is traversed completely.\n\nAs with current impl the path would not be duplicated we can avoid using unique cursor\n\n[1] https://github.com/apache/jackrabbit-oak/blob/trunk/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java#L1153-1154",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Use non unique PathCursor in LucenePropertyIndex"
   },
   {
      "_id": "12819969",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326717",
            "id": "12326717",
            "name": "cache"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-04-10 07:43:21",
      "description": "Currently the Cache invalidation logic used in MongoDocumentStore check for cache consistency for all the entries present in the cache. With use of persistent cache its possible that pressure on backend cache would be reduced and some of the cache entries are not being accessed for long time.\n\nCache invalidation logic should take into account such access statistics and not perform consistency check for cached instance which are not accessed for some long time (10 mins?). Such cache entries should be directly discarded.\n\nPS: Looking at [1] it appears that Guava cache does not enforces a global LRU eviction policy. The policy is maintained per segment table\n\n[1] http://stackoverflow.com/questions/10236057/guava-cache-eviction-policy",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Ignore lesser used old cache entries while invalidating cache entries in background read"
   },
   {
      "_id": "12819945",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2015-04-10 05:17:25",
      "description": "By default the cache memory in DocumentNodeStore is distributed in following ratio\n\n* nodeCache - 25%\n* childrenCache - 10%\n* docChildrenCache - 3%\n* diffCache - 5%\n* documentCache - Is given the rest i.e. 57%\n\nHowever off late we have found that with persistent cache enabled we can lower the cache allocated to Document cache. That would reduce the time spent in invalidating cache entries in periodic reads. So far we are using following ration in few setup and that is turning out well\n\n* nodeCachePercentage=35\n* childrenCachePercentage=20\n* diffCachePercentage=30\n* docChildrenCachePercentage=10\n* documentCache - Is given the rest i.e. 5%\n\nWe should use the above distribution by default if the persistent cache is found to be enabled\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Change default cache distribution ratio if persistent cache is enabled"
   },
   {
      "_id": "12819638",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-09 11:23:41",
      "description": "Oak.createContentRepository does not closes the executors it creates upon close. It should close the executor if that is created by itself and not passed by outside\n\nAlso see recent [thread|http://markmail.org/thread/rryydj7vpua5qbub].",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Oak instance does not close the executors created upon ContentRepository creation"
   },
   {
      "_id": "12819623",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-09 10:06:23",
      "description": "The diff created by the test uses a lot of memory. Either test test should be changed or the implementation should ignore further changes once a threshold is reached.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MongoDiffCacheTest.sizeLimit() uses too much memory"
   },
   {
      "_id": "12819614",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-04-09 09:21:38",
      "description": "A repository with continuous writes can keep the compactor from completing causing the repository size to grow indefinitely. \n\nThis effect is caused by the compactor trying to catch up with changes that occurred while compacting. I.e. compacting them on top of the already compacted head. When there is a steady stream of incoming changes it can happen that the compactor never actually catches up. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "doc-impacting",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Compaction does not finish on repository with continuous writes "
   },
   {
      "_id": "12819364",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-04-08 15:56:16",
      "description": "On a very busy site, we're observing an NPE in the code that should gather information about a JCR event for our custom event handler. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "NPE when calling Event.getInfo()"
   },
   {
      "_id": "12818886",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-07 10:32:11",
      "description": "{{IndexCopier}} tries to remove the older index directory incase of reindex. This might fails on platform like Windows if the files are still memory mapped or are locked.\n\nFor deleting directories we would need to take similar approach like being done with deleting old index files i.e. do retries later.\n\nDue to this following test fails on Windows (Per [~julian.reschke@gmx.de] )\n\n{noformat}\nTests run: 9, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.07 sec <<< FAILURE!\ndeleteOldPostReindex(org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopierTest)  Time elapsed: 0.02 sec  <<< FAILURE!\njava.lang.AssertionError: Old index directory should have been removed\n        at org.junit.Assert.fail(Assert.java:93)\n        at org.junit.Assert.assertTrue(Assert.java:43)\n        at org.junit.Assert.assertFalse(Assert.java:68)\n        at org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopierTest.deleteOldPostReindex(IndexCopierTest.java:160)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "IndexCopier fails to delete older index directory upon reindex"
   },
   {
      "_id": "12818550",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-04-06 07:05:18",
      "description": "At times following warning is seen in logs\n\n{noformat}\n31.03.2015 14:04:57.610 *WARN* [pool-6-thread-7] org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier Found local copy for _0.cfs in NIOFSDirectory@/path/to/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 lockFactory=NativeFSLockFactory@/path/to/index/e5a943cdec3000bd8ce54924fd2070ab5d1d35b9ecf530963a3583d43bf28293/1 but size of local 1040384 differs from remote 1958385. Content would be read from remote file only\n{noformat}\n\nThe file length check provides a weak check around index file consistency. In some cases this warning is misleading. For e.g. \n\n# Index version Rev1 - Task submitted to copy index file F1 \n# Index updated to Rev2 - Directory bound to Rev1 is closed\n# Read is performed with Rev2 for F1 - Here as the file would be locally created the size would be different as the copying is in progress\n\nIn such a case the logic should ensure that once copy is done the local file gets used",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Misleading warn message about local copy size different than remote copy in oak-lucene with copyOnRead enabled"
   },
   {
      "_id": "12787285",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-04-01 07:40:32",
      "description": "This issue is for tracking test failures seen at our Jenkins instance that might yet be transient. Once a failure happens too often we should remove it here and create a dedicated issue for it. \n\nh2. Current issues\n\n|| Test                                                                                       || Builds || Fixture      || JVM || Branch ||\n| org.apache.jackrabbit.oak.jcr.ConcurrentAddIT.addNodesSameParent | 427, 428, 758 | DOCUMENT_NS, SEGMENT_MK, DOCUMENT_RDB | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.jcr.ConcurrentAddIT.addNodes\\[DocumentNodeStore\\[RDB\\] on jdbc:h2:file:./target/oaktest\\] | 829, 846 | | | 1.4 |\n| org.apache.jackrabbit.oak.jcr.ConcurrentAddIT| 720, 818 | DOCUMENT_RDB | 1.7 | 1.5 |\n| org.apache.jackrabbit.oak.jcr.ConcurrentAddReferenceTest.addReferences[DocumentNodeStore\\[RDB] on jdbc:h2:file:./target/oaktest] |  778, 850 | RDB, NS | 1.7, 1.8 | 1.4 |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTest.testReorder\\[RDBDocumentStore on jdbc:h2:file:./target/oaktest] |  851 | | | 1.2 |\n| org.apache.jackrabbit.oak.osgi.OSGiIT.listServices | 851 | | | 1.2 |\n| org.apache.jackrabbit.oak.plugins.document.BulkCreateOrUpdateClusterTest.testConcurrentWithConflict\\[RDBFixture:RDB-Derby(embedded)] | 797, 823, 841, 842, 843, 847, 848, 850, 853 | | | 1.4, 1.5 |\n| org.apache.jackrabbit.oak.plugins.document.BulkCreateOrUpdateTest | 731, 732, 767 | DOCUMENT_RDB, DOCUMENT_NS | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.plugins.document.DocumentDiscoveryLiteServiceIT.testLargeStartStopFiesta | 803, 823, 849, 853 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.document.DocumentDiscoveryLiteServiceTest | 361, 608 | DOCUMENT_NS, SEGMENT_MK | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreTest.recoverBranchCommit | 805 | | | 1.0 |\n| org.apache.jackrabbit.oak.plugins.document.blob.RDBBlobStoreTest | 673, 674, 786, 787 | SEGMENT_MK, DOCUMENT_NS, DOCUMENT_RDB | 1.7, 1.8 |  |\n| org.apache.jackrabbit.oak.plugins.document.blob.RDBBlobStoreTest.testUpdateAndDelete[MyFixture: RDB-Derby(embedded)] | 780, 785, 786, 787 | RDB, NS, | 1.7, 1.8 | 1.5, 1.4 |\n| org.apache.jackrabbit.oak.plugins.document.persistentCache.BroadcastTest | 648, 679 | SEGMENT_MK, DOCUMENT_NS | 1.8 |  |\n| org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopierTest.reuseLocalDir                 | 81      | DOCUMENT_RDB | 1.7   | |\n| org.apache.jackrabbit.oak.plugins.index.lucene.IndexDefinitionTest | 770 | DOCUMENT_RDB, DOCUMENT_NS, SEGMENT_MK | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexEditorTest | 490, 623, 624, 656, 679 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexHookIT.testPropertyAddition | 775, 782, 783, 789, 821, 832 | Segment, rdb | 1.7, 1.8 | 1.5, 1.2, 1.0 |\n| org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTestIT.testNativeMLTQuery | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.plugins.index.solr.query.SolrIndexQueryTestIT.testNativeMLTQueryWithStream | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.plugins.index.solr.query.SolrQueryIndexTest | 148, 151, 490, 656, 679 | SEGMENT_MK, DOCUMENT_NS, DOCUMENT_RDB | 1.5, 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.server.EmbeddedSolrServerProviderTest.testEmbeddedSolrServerInitialization | 490, 656, 679 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.util.NodeTypeIndexingUtilsTest | 663 | SEGMENT_MK | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.index.solr.util.NodeTypeIndexingUtilsTest.testSynonymsFileCreation | 627 | DOCUMENT_RDB |1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.ExternalBlobIT.testDataStoreBlob | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.ExternalBlobIT.testNullBlobId | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.ExternalBlobIT.testSize | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.heavyWrite\\[usePersistedMap: false] | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.heavyWrite\\[usePersistedMap: true] | 841 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest | 731, 766, 767, 773, 777, 815 | SEGMENT_MK | 1.7, 1.8 | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest.testProxyFlippedEndByte | 804 | | | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest.testProxyFlippedIntermediateByteSSL | 777 | Segment | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest.testProxyFlippedStartByteSSL | 773, 843 | Segment | 1.8 | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.BrokenNetworkTest.testProxySSLSkippedBytes | 788,806 | Segment | 1.7, 1.8 | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT | 722, 731, 733, 755, 759, 776, 812, 815, 816, 817 | SEGMENT_MK | 1.7, 1.8 | 1.4, 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxyFlippedIntermediateByte | 837, 848 | | | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxyFlippedIntermediateByte2 | 837 | | | | \n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxyFlippedIntermediateByteChange2 | 797, 837 | | | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxyFlippedStartByte | 794, 837, 848 | | | 1.5 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxySkippedBytes | 788, 837, 848 | Segment | 1.7, 1.8 | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testProxySkippedBytesIntermediateChange | 779, 776, 773 | Segment | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalPrivateStoreIT.testSync | 837 | | | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT.testProxySkippedBytes | 788 | Segment | 1.7, 1.8 | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.FailoverSslTestIT | 759 | SEGMENT_MK | 1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.FailoverSslTestIT.testFailoverSecure | 794, 846 | | | 1.4 |\n| org.apache.jackrabbit.oak.plugins.segment.standby.StandbyTest.testSync | 839 | | | |\n| org.apache.jackrabbit.oak.remote.http.handler.RemoteServerIT | 643 | DOCUMNET_NS | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.run.osgi.DocumentNodeStoreConfigTest.testRDBDocumentStoreRestart | 621 | DOCUMENT_NS | 1.8 | |\n| org.apache.jackrabbit.oak.run.osgi.DocumentNodeStoreConfigTest.testRDBDocumentStore_CustomBlobStore | 52, 181, 399 |  SEGMENT_MK, DOCUMENT_NS | 1.7 | |\n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapDefaultLoginModuleTest | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest | 689 | SEGMENT_MK | 1.8 | |\n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testAuthenticate | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testAuthenticateCaseInsensitive | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testAuthenticateFail | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testAuthenticateValidateTrueTrue | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetGroups | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetMembers | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetUserByForeignRef | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetUserByRef | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testGetUserByUserId | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testListUsersWithMissingUid | 833 | | | | \n| org.apache.jackrabbit.oak.security.authentication.ldap.LdapProviderTest.testSplitDNIntermediatePath | 833 | | | | \n| org.apache.jackrabbit.oak.spi.security.authorization.cug.impl.* | 648 | SEGMENT_MK, DOCUMENT_NS | 1.8 |  |\n| org.apache.jackrabbit.oak.standalone.RepositoryBootIT | 755 | DOCUMENT_NS | 1.7 | |\n| org.apache.jackrabbit.oak.standalone.RepositoryBootIT.repositoryLogin | 778, 781, 793 | RDB, NS | 1.7, 1.8 | 1.5, 1.4 |\n\nh2. fixed or not happening for a while\n\n|| Test                                                                                       || Builds || Fixture      || JVM || Branch ||\n| Build crashes: malloc(): memory corruption | 477 | DOCUMENT_NS | 1.5 | |\n| org.apache.jackrabbit.j2ee.TomcatIT | 589 | SEGMENT_MK | 1.8 | |\n| org.apache.jackrabbit.j2ee.TomcatIT.testTomcat | 489, 493, 597, 648, 801 | DOCUMENT_NS, SEGMENT_MK | 1.7 |  |\n| org.apache.jackrabbit.oak.jcr.ConcurrentFileOperationsTest.concurrent | 110, 382 | DOCUMENT_RDB | 1.5 | |\n| org.apache.jackrabbit.oak.jcr.MoveRemoveTest.removeExistingNode | 115 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.jcr.OrderedIndexIT.oak2035                                         | 76, 128 | SEGMENT_MK , DOCUMENT_RDB  | 1.5   | |\n| org.apache.jackrabbit.oak.jcr.RepositoryTest.addEmptyMultiValue | 115 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.jcr.cluster.NonLocalObservationIT | 731 | DOCUMENT_RDB | 1.8 | |\n| org.apache.jackrabbit.oak.jcr.nodetype.NodeTypeTest.updateNodeType | 243, 400 | DOCUMENT_RDB | 1.5, 1.8 | |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTest.disjunctPaths | 121, 157, 396 | DOCUMENT_RDB | 1.5, 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTest.removeSubtreeFilter | 94 | DOCUMENT_RDB | 1.5 | |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTest.testReorder | 155 | DOCUMENT_RDB | 1.8 | |\n| org.apache.jackrabbit.oak.jcr.observation.ObservationTesttestMove | 308 | DOCUMENT_RDB | 1.5 | |\n| org.apache.jackrabbit.oak.jcr.query.QueryPlanTest.nodeType | 272 | DOCUMENT_RDB | 1.8 | |\n| org.apache.jackrabbit.oak.jcr.query.QueryPlanTest.propertyIndexVersusNodeTypeIndex | 90 | DOCUMENT_RDB | 1.5 | |\n| org.apache.jackrabbit.oak.jcr.query.SuggestTest | 171 | SEGMENT_MK | 1.8 | |\n| org.apache.jackrabbit.oak.jcr.query.SuggestTest.testNoSuggestions | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.jcr.query.SuggestTest.testSuggestSql | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.jcr.query.SuggestTest.testSuggestXPath | 783 | Segment, rdb | 1.7, 1.8 | 1.0 |\n| org.apache.jackrabbit.oak.jcr.version.VersionablePathNodeStoreTest.testVersionablePaths | 361 | DOCUMENT_RDB | 1.7 | |\n| org.apache.jackrabbit.oak.osgi.OSGiIT | 767, 770 | SEGMENT_MK, DOCUMENT_RDB, DOCUMENT_NS | 1.7, 1.8 | |\n| org.apache.jackrabbit.oak.osgi.OSGiIT.bundleStates | 163, 656 | SEGMENT_MK, DOCUMENT_RDB, DOCUMENT_NS | 1.5, 1.7 | |\n| org.apache.jackrabbit.oak.plugins.segment.standby.StandbyTestIT.testSyncLoop                 | 64      | ?            | ?     | |\n| org.apache.jackrabbit.oak.run.osgi.JsonConfigRepFactoryTest.testRepositoryTar                | 41      | ?            | ?     | |\n| org.apache.jackrabbit.oak.run.osgi.PropertyIndexReindexingTest.propertyIndexState | 492 | DOCUMENT_NS | 1.5 | |\n| org.apache.jackrabbit.oak.stats.ClockTest.testClockDriftFast | 115, 142 | SEGMENT_MK, DOCUMENT_NS | 1.6, 1.8 | |\n| org.apache.jackrabbit.oak.upgrade.cli.SegmentToJdbcTest.validateMigration | 486 | DOCUMENT_NS | 1.7|  |\n| org.apache.jackrabbit.test.api.observation.PropertyAddedTest.testMultiPropertyAdded          | 29      | ?            | ?     | |\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/15",
         "id": "15",
         "description": "Created by Jira Software - do not edit or delete. Issue type for a big user story that needs to be broken down.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21137&avatarType=issuetype",
         "name": "Epic",
         "subtask": false,
         "avatarId": 21137
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failures on Jenkins"
   },
   {
      "_id": "12787040",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-31 14:26:33",
      "description": "In environments with a lot of volatile content the {{CompactionMap}} can end up eating a lot of memory. From {{CompactionStrategyMBean#getCompactionMapStats}}:\n\n{noformat}\n[Estimated Weight: 317,5 MB, Records: 39500094, Segments: 36698], \n[Estimated Weight: 316,4 MB, Records: 39374593, Segments: 36660], \n[Estimated Weight: 315,4 MB, Records: 39253205, Segments: 36620], \n[Estimated Weight: 315,1 MB, Records: 39221882, Segments: 36614], \n[Estimated Weight: 314,9 MB, Records: 39195490, Segments: 36604], \n[Estimated Weight: 315,0 MB, Records: 39182753, Segments: 36602], \n[Estimated Weight: 360 B, Records: 0, Segments: 0],\n{noformat}\n\n\nThis causes compaction to be skipped:\n\n{noformat}\n2015-03-30:30.03.2015 02:00:00.038 *INFO* [] [TarMK compaction thread [/foo/bar/crx-quickstart/repository/segmentstore], active since Mon Mar 30 02:00:00 CEST 2015, previous max duration 3854982ms] org.apache.jackrabbit.oak.plugins.segment.file.FileStore Not enough available memory 5,5 GB, needed 6,3 GB, last merge delta 1,3 GB, so skipping compaction for now\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "High memory usage of CompactionMap"
   },
   {
      "_id": "12787023",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-31 13:29:15",
      "description": "the default {{toString}} for all tree implementations calculates a string containing the path, the toString of all properties as well as the names of all child tree... this is prone to cause troubles in case for trees that have plenty of properties and children.\n\ni would strongly recommend to review this and make the toString of trees both meaningful and cheap.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Troublesome AbstractTree.toString"
   },
   {
      "_id": "12785837",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-26 10:28:08",
      "description": "Currently the DocumentNodeState has two revisions:\n\n- {{getRevision()}} returns the read revision of this node state. This revision was used to read the node state from the underlying {{NodeDocument}}.\n- {{getLastRevision()}} returns the revision when this node state was last modified. This revision also reflects changes done further below the tree when the node state was not directly affected by a change.\n\nThe lastRevision of a state is then used as the read revision of the child node states. This avoids reading the entire tree again with a different revision after the head revision changed because of a commit.\n\nThis approach has at least two problems related to comparing node states:\n\n- It does not work well with the current DiffCache implementation and affects the hit rate of this cache. The DiffCache is pro-actively populated after a commit. The key for a diff is a combination of previous and current commit revision and the path. The value then tells what child nodes were added/removed/changed. As the comparison of node states proceeds and traverses the tree, the revision of a state may go back in time because the lastRevision is used as the read revision of the child nodes. This will cause misses in the diff cache, because the revisions do not match the previous and current commit revisions as used to create the cache entries. OAK-2562 tried to address this by keeping the read revision for child nodes at the read revision of the parent in calls of compareAgainstBaseState() when there is a diff cache hit. However, it turns out node state comparison does not always start at the root state. The {{EventQueue}} implementation in oak-jcr will start at the paths as indicated by the filter of the listener. This means, OAK-2562 is not effective in this case and the diff needs to be calculated again based on a set of revisions, which is different from the original commit.\n\n- When a diff is calculated for a parent with many child nodes, the {{DocumentNodeStore}} will perform a query on the underlying {{DocumentStore}} to get child nodes modified after a given timestamp. This timestamp is derived from the lower revision of the two lastRevisions of the parent node states to compare. The query gets problematic for the {{DocumentStore}} if the timestamp is too far in the past. This will happen when the parent node (and sub-tree) was not modified for some time. E.g. the {{MongoDocumentStore}} has an index on the _id and the _modified field. But if there are many child nodes the _id index will not be that helpful and if the timestamp is too far in the past, the _modified index is not selective either. This problem was already reported in OAK-1970 and linked issues.\n\nBoth of the above problems could be addressed by keeping track of the read revision of the root node state in each of the node states as the tree is traversed. The revision of the root state would then be used e.g. to derive the timestamp for the _modified constraint in the query. Because the revision of the root state is rather recent, the _modified constraint is very selective and the index on it would be the preferred choice.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Track root state revision when reading the tree"
   },
   {
      "_id": "12785538",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-25 14:50:54",
      "description": "A lease update of the DocumentNodeStore on MongoDB will acquire a lock in MongoDocumentStore to perform the changes. The locking is only necessary for changes in the 'nodes' collection, because only those documents are cached and the locking makes sure the cache is consistent. The MongoDocumentStore must be changed to only acquire a lock when changes are done in the 'nodes' collection.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Update lease without holding lock"
   },
   {
      "_id": "12783856",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-21 12:03:42",
      "description": "{noformat}\nheavyWrite(org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT)  Time elapsed: 96.384 sec  <<< ERROR!\norg.apache.jackrabbit.oak.plugins.segment.SegmentOverflowException: Segment cannot have more than 255 references 47a9dc3c-c6f9-4b5f-a61a-6711da8b68c2\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.getSegmentRef(SegmentWriter.java:353)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeRecordId(SegmentWriter.java:382)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapLeaf(SegmentWriter.java:426)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:484)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMapBucket(SegmentWriter.java:511)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeMap(SegmentWriter.java:720)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1108)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter$2.childNodeChanged(SegmentWriter.java:1091)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.compareAgainstBaseState(ModifiedNodeState.java:396)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1082)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentWriter.writeNode(SegmentWriter.java:1110)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.getNodeState(SegmentNodeBuilder.java:97)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:83)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.updated(MemoryNodeBuilder.java:214)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeBuilder.updated(SegmentNodeBuilder.java:79)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setProperty(MemoryNodeBuilder.java:501)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.setProperty(MemoryNodeBuilder.java:507)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createProperties(HeavyWriteIT.java:137)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createNodes(HeavyWriteIT.java:129)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.createNodes(HeavyWriteIT.java:130)\n\tat org.apache.jackrabbit.oak.plugins.segment.HeavyWriteIT.heavyWrite(HeavyWriteIT.java:110)\n{noformat}\n\nSee https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/35/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=integrationTesting/\n\ncc [~alex.parvulescu]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "SegmentOverflowException in HeavyWriteIT on Jenkins"
   },
   {
      "_id": "12783618",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2015-03-20 14:20:42",
      "description": "I see many similar test failures for {{FailoverMultipleClientsTestIT}} and {{RecoverTestIT}} on Jenkins. For example:\n\n{noformat}\ntestSyncLoop(org.apache.jackrabbit.oak.plugins.segment.standby.StandbyTestIT): expected:<{ checkpoints = { ... }, root = { ... } }> but was:<{ root : { } }>\n  testLocalChanges(org.apache.jackrabbit.oak.plugins.segment.standby.RecoverTestIT): expected: org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState<{ root = { ... } }> but was: org.apache.jackrabbit.oak.plugins.segment.SegmentNodeState<{ root = { ... } }>\n{noformat}\n\nSee\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=jdk1.8.0_11,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=integrationTesting/console\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=latest1.7,label=Ubuntu,nsfixtures=SEGMENT_MK,profile=integrationTesting/console\nhttps://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=latest1.7,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=integrationTesting/console",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "Jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Failed expectations in TarMK standby tests"
   },
   {
      "_id": "12783612",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325109",
            "id": "12325109",
            "name": "tarmk-standby",
            "description": "Oak TarMK Standby"
         }
      ],
      "created": "2015-03-20 14:07:16",
      "description": "The following tests fail probably all for the same reason:\n\n{noformat}\ntestProxySkippedBytes(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxySkippedBytesIntermediateChange(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedStartByte(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedIntermediateByte(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedIntermediateByte2(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedIntermediateByteChange(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\ntestProxyFlippedIntermediateByteChange2(org.apache.jackrabbit.oak.plugins.segment.standby.ExternalSharedStoreIT): proxy not started\n{noformat}\n\nStacktraces always look something like:\n{noformat}\njava.lang.Exception: proxy not started\n\tat org.apache.jackrabbit.oak.plugins.segment.NetworkErrorProxy.reset(NetworkErrorProxy.java:87)\n\tat org.apache.jackrabbit.oak.plugins.segment.standby.DataStoreTestBase.useProxy(DataStoreTestBase.java:176)\n\tat org.apache.jackrabbit.oak.plugins.segment.standby.DataStoreTestBase.testProxySkippedBytes(DataStoreTestBase.java:118)\n{noformat}\n\nSee https://builds.apache.org/job/Apache%20Jackrabbit%20Oak%20matrix/31/jdk=latest1.7,label=Ubuntu,nsfixtures=DOCUMENT_NS,profile=integrationTesting/console",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "jenkins"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Test failures in TarMK standby: Address already in use"
   },
   {
      "_id": "12783611",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2015-03-20 14:07:07",
      "description": "I noticed that during the upgrade we can distinguish 2 phases: first copying the data from the source, then applying all the Editors (indexes and co.).\nAfter phase 1 is done the repository upgrader could shut down the old repo to allow clearing some memory resources which might be used for the second phase.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Repository Upgrade could shut down the source repository early"
   },
   {
      "_id": "12782216",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-16 14:53:21",
      "description": "The current implementation of TimeSeriesMax - which is what is backing eg the very important 'ObservationQueueMaxLength' statistics - has a very infamous behavior: it does very frequent, intermittent 'jumps back to 0'. This even though the queue-lengths are still at the previous highs, as can often be seen with subsequent measurements (which eg are still showing there are 1000 events in the observation queue).\n\nThe reason seems to be that\n* the value is increased via {{TimeSeriesMax.recordValue()}} during a 1 second interval\n* reset to 0 via {{TimeSeriesMax<init>.run()}} every second\n\nSo basically, every second the counter is reset, then during 1 second if any call to {{recordValue()}} happens, it is increased.\n\nThis in my view is rather unfortunate - as it can result in mentioned 'jumpy-0' behavior, but it can also jump to values in between if the largest queue does not reports its length during 1 second.\n\nIt sounds a bit like this was done this way intentionally? (perhaps to make it as inexpensive as possible) or could this be fixed?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "TimeSeriesMax's frequent 'drops to 0'"
   },
   {
      "_id": "12782058",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2015-03-15 09:45:56",
      "description": "Lucene provides a buffered variants for {{IndexInput}} and {{IndexOutput}}. Currently Oak extends these classes directly. For better performance itshould extend the buffered variants.\n\nAs discussed [here|https://issues.apache.org/jira/browse/OAK-2222?focusedCommentId=14178265#comment-14178265]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use buffered variants for IndexInput and IndexOutput"
   },
   {
      "_id": "12781804",
      "assignee": "mduerig",
      "components": [],
      "created": "2015-03-13 13:28:04",
      "description": "Since we're moving towards Jenkins, let's remove the buildbot jobs for Oak.\nThe buildbot configuration is here: https://svn.apache.org/repos/infra/infrastructure/buildbot/aegis/buildmaster/master1/projects",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cleanup Oak jobs on buildbot"
   },
   {
      "_id": "12781803",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2015-03-13 13:27:19",
      "description": "Since we're moving toward Jenkins, let's remove the Travis jobs for Oak. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Cleanup Oak Travis jobs"
   },
   {
      "_id": "12781604",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-12 20:17:42",
      "description": "The DocumentNodeStore issues a lot of reads when sibling nodes are deleted, which are also index with a property index.\n\nThe following calls will become a hotspot:\n\n{noformat}\n\tat org.apache.jackrabbit.oak.plugins.document.mongo.MongoDocumentStore.query(MongoDocumentStore.java:406)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readChildDocs(DocumentNodeStore.java:846)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.readChildren(DocumentNodeStore.java:788)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.getChildren(DocumentNodeStore.java:753)\n\tat org.apache.jackrabbit.oak.plugins.document.DocumentNodeState.getChildNodeCount(DocumentNodeState.java:194)\n\tat org.apache.jackrabbit.oak.plugins.memory.ModifiedNodeState.getChildNodeCount(ModifiedNodeState.java:198)\n\tat org.apache.jackrabbit.oak.plugins.memory.MutableNodeState.getChildNodeCount(MutableNodeState.java:265)\n\tat org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder.getChildNodeCount(MemoryNodeBuilder.java:293)\n\tat org.apache.jackrabbit.oak.plugins.index.property.strategy.ContentMirrorStoreStrategy.prune(ContentMirrorStoreStrategy.java:456)\n{noformat}\n\nI think the code triggering this issue is in {{ModifiedNodeState.getChildNodeCount()}}. It keeps track of already deleted children and requests {{max += deleted}}. The actual {{max}} is always 1 as requested from {{ContentMirrorStoreStrategy.prune()}}, but as more nodes get deleted, the higher {{max}} gets passed to {{DocumentNodeState.getChildNodeCount()}}. The DocumentNodeStore then checks if it has the children in the cache, only to find out the cache entry has too few entries and it needs to fetch one more.\n\nIt would be best to have a minimum number of child nodes to fetch from MongoDB in this case. E.g. when NodeState.getChildNodeEntries() is called, the DocumentNodeState fetches 100 children.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Too many reads for child nodes"
   },
   {
      "_id": "12781593",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-12 19:40:10",
      "description": "MongoMK still holds the merge lock when it resets a persisted branch. Concurrency can be improved if the merge lock is released before the branch is reset.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release merge lock before branch is reset"
   },
   {
      "_id": "12781432",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-12 08:17:33",
      "description": "Reading through a ValueMap can be very inefficient if the changes of a given\nproperty are distributed sparsely across the previous documents. The current\nimplementation has to scan through the entire set of previous documents to\ncollect the changes.\n\nIntermediate documents should have additional information about what properties\nare present on referenced previous documents. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Annotate intermediate docs with property names"
   },
   {
      "_id": "12781228",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2015-03-11 15:59:29",
      "description": "We have a sporadic problem with Sling's JCR installer 3.3.8 and Oak (tar mk). It seems to timing related: the JCR installer does a Thread#interrupt at one point and sometimes this brings the hole instance to stop. Nothing else is going on any more. \nWhile of course, a workaround is to remove the Thread.interrupt call in the JCR installer (which we did, see SLING-4477), I have the fear that this can happen with any code that is using the repository and gets interrupted.\nThis error is hard to reproduce, however with three people testing we could see this several times happening",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc-impacting",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Thread.interrupt seems to stop repository"
   },
   {
      "_id": "12780726",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2015-03-10 06:17:29",
      "description": "Currently an {{IndexEditor}} gets to index all nodes under the tree where it is defined (post OAK-1980).  Due to this IndexEditor would traverse the whole repo (or subtree if configured in non root path) to perform reindex. Depending on the repo size this process can take quite a bit of time. It would be faster if an IndexEditor can exclude certain paths from traversal\n\nConsider an application like Adobe AEM and an index which only index dam:Asset or the default full text index. For a fulltext index it might make sense to avoid indexing the versionStore. So if the index editor skips such path then lots of redundant traversal can be avoided. \n\nAlso see http://markmail.org/thread/4cuuicakagi6av4v",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Allow excluding certain paths from getting indexed for particular index"
   },
   {
      "_id": "12780520",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-09 15:51:07",
      "description": "While debugging issues with the observation queue it would be handy to have more detailed information available. At the moment you can only see one value wrt length of the queue: that is the maximum of all queues. It is unclear if the queue is that long for only one or many listeners. And it is unclear from that if the listener is slow or the engine that produces the events for the listener.\n\nSo I'd suggest to add the following details - possible exposed via JMX? :\n# add queue length details to each of the observation listeners\n# have a history of the last, eg 1000 events per listener showing a) how long the event took to be created/generated and b) how long the listener took to process. Sometimes averages are not detailed enough so such a in-depth information might become useful. (Not sure about the feasibility of '1000' here - maybe that could be configurable though - just putting the idea out here).\n# have some information about whether a listener is currently 'reading events from the cache' or whether it has to go to eg mongo \n# maybe have a 'top 10' listeners that have the largest queue at the moment to easily allow navigation instead of having to go through all (eg 200) listeners manually each time.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring",
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "more (jmx) instrumentation for observation queue"
   },
   {
      "_id": "12780517",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-09 15:43:30",
      "description": "{{CompactionGainEstimate}} keeps a set for the visited record ids. Each entry in that set is represented by an instance of {{ThinRecordId}}. For big repositories the instance overhead lead to {{OOME}} while running the compaction estimator. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "High memory consumption of CompactionGainEstimate"
   },
   {
      "_id": "12780441",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-03-09 09:38:12",
      "description": "The MongoDocumentStore uses {{findAndModify()}} to commit a transaction. This operation does not allow an application specified write concern and always uses the MongoDB default write concern {{Acknowledged}}. This means a commit may not make it to a majority of a replica set when the primary fails. From a MongoDocumentStore perspective it may appear as if a write was successful and later reverted. See also the test in OAK-1641.\n\nTo fix this, we'd probably have to change the MongoDocumentStore to avoid {{findAndModify()}} and use {{update()}} instead.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Commit does not ensure w:majority"
   },
   {
      "_id": "12780152",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-06 19:34:26",
      "description": "The current implementation of oak's observation event processing is too eager and thus unfair under load scenarios. \n\nConsider having many (eg 200) Eventlisteners but only a relatively small threadpool (eg 5 as is the default in sling) backing them. When processing changes for a particular BackgroundObserver, that one (in BackgroundObserver.completionHandler.call) currently processes *all changes irrespective of how many there are* - ie it is *eager*. Only once that BackgroundObserver processed all changes will it let go and 'pass the thread' to the next BackgroundObserver. Now if for some reason changes (ie commits) are coming in while a BackgroundObserver is busy processing an earlier change, this will lengthen that while loop. As a result the remaining (eg 195) *EventListeners will have to wait for a potentially long time* until it's their turn - thus *unfair*.\n\nNow combine the above pattern with a scenario where mongo is used as the underlying store. In that case in order to remain highly performant it is important that the diffs (for compareAgainstBaseState) are served from the MongoDiffCache for as many cases as possible to avoid doing a round-trip to mongoD. The unfairness in the BackgroundObservers can now result in a large delay between the 'first' observers getting the event and the 'last' one (of those 200). When this delay increases due to a burst in the load, there is a risk of the diffs to no longer be in the cache - those last observers are basically kicked out of the (diff) cache. Once this happens, *the situation gets even worse*, since now you have yet new commits coming in and old changes still having to be processed - all of which are being processed through in 'stripes of 5 listeners' before the next one gets a chance. This at some point results in a totally inefficient cache behavior, or in other words, at some point all diffs have to be read from mongoD.\n\nTo avoid this there are probably a number of options - a few one that come to mind:\n* increase thread-pool to match or be closer to the number of listeners (but this has other disadvantages, eg cost of thread-switching)\n* make BackgroundObservers fairer by limiting the number of changes they process before they give others a chance to be served by the pool.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "observation processing too eager/unfair under load"
   },
   {
      "_id": "12780035",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-03-06 10:33:30",
      "description": "As we start seeing good results with the current approach to compaction I'd like to have it running per default. This allows us to gather more information while we are running up towards the 1.2 release. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Set pauseCompaction default to false"
   },
   {
      "_id": "12779689",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2015-03-05 05:08:53",
      "description": "{{org.apache.jackrabbit.oak.jcr.osgi.RepositoryManager}} currently registers the {{WhiteboardExecutor}} with Oak which internally again register with OSGi ServiceRegistry. This causes recursion as leading to stackoverflow.\n\nAs Oak creates an {{Executor}} in absence on explicitly provided one RepositoryManager should not set the {{Executor}}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "RepositoryManager must not register WhiteboardExecutor with Oak"
   },
   {
      "_id": "12779007",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-03-03 10:25:15",
      "description": "The session auto refresh feature is implemented by marking sessions pending for refresh. The refresh operation itself however only happens on the next access to the session. \n\nIt would be helpful if {{SessionMBean}} could expose the information whether a session has a pending refresh. Additionally we could expose the current {{RefreshStrategy}} to make the auto refresh behaviour more transparent. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SessionMBean should provide information about pending refresh"
   },
   {
      "_id": "12777494",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-02-25 11:23:29",
      "description": "Provide monitoring for the garbage collection process:\n* time series of repository size\n* time series of space reclaimed\n* time stamp of last clean up\n* time stamp of last compaction\n* last error\n* time stamp when next gc run is scheduled\n* ...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "compaction",
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement MBean monitoring garbage collection"
   },
   {
      "_id": "12774577",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-02-12 14:20:06",
      "description": "After off line compaction the repository contains a single revision. However the journal.log file will still contain the trail of all revisions that have been removed during the compaction process. I suggest we truncate the journal.log to only contain the latest revision created during compaction.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Truncate journal.log after off line compaction"
   },
   {
      "_id": "12774256",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2015-02-11 16:34:37",
      "description": "To provide something that can be played with, and to verify the feasibility of the specification draft, an initial implementation of the HTTP API should be provided.\n\nThe API should follow the general behavior described [here|https://wiki.apache.org/jackrabbit/frm/RemoteOperations] and the HTTP semantics defined [here|https://wiki.apache.org/jackrabbit/frm/HttpOperations]. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "api",
         "remoting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Provide initial implementation of the Remote Operations specification"
   },
   {
      "_id": "12773875",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-02-10 15:50:46",
      "description": "According to the [documentation | http://jackrabbit.apache.org/oak/docs/nodestore/segmentmk.html] the root record references in a segment header provide enough context for parsing all records within this segment without any external information. \n\nTurns out this is not true: if a root record reference turns e.g. to a list record. The items in that list are record ids of unknown type. So even though those records might live in the same segment, we can't parse them as we don't know their type. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Root record references provide too little context for parsing a segment"
   },
   {
      "_id": "12773538",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2015-02-09 18:58:38",
      "description": "Current DocumentMK logic while performing a diff for child nodes works as below\n\n# Get children for _before_ revision upto MANY_CHILDREN_THRESHOLD (which defaults to 50). Further note that current logic of fetching children nodes also add children {{NodeDocument}} to {{Document}} cache and also reads the complete Document for those children\n# Get children for _after_ revision with limits as above\n# If the child list is complete then it does a direct diff on the fetched children\n# if the list is not complete i.e. number of children are more than the threshold then it for a query based diff (also see OAK-1970)\n\nSo in those cases where number of children are large then all work done in #1 above is wasted and should be avoided. To do that we can mark those parent nodes which have many children via special flag like {{_manyChildren}}. One such nodes are marked the diff logic can check for the flag and skip the work done in #1\n\nThis is kind of similar to way we mark nodes which have at least one child (OAK-1117)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Flag Document having many children"
   },
   {
      "_id": "12772397",
      "assignee": "mduerig",
      "components": [],
      "created": "2015-02-04 15:35:23",
      "description": "We should strive for stabilization of our CI setup, as of now we had Buildbot and Travis.\nIt seems ASF Jenkins can perform jobs on different environments (*nix, Windows and others) so we can evaluate that and check if it better address our needs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI",
         "build",
         "infrastructure"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Move our CI to Jenkins"
   },
   {
      "_id": "12770899",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2015-01-29 03:30:18",
      "description": "Currently PersistentCache uses the directory path directly. Various other parts in Oak which need access to the filesystem currently make use of {{repository.home}} framework property in OSGi env [1]\n\nSame should also be used in PersistentCache\n\n[1] http://jackrabbit.apache.org/oak/docs/osgi_config.html#SegmentNodeStore ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Resolve the base directory path of persistent cache against repository home"
   },
   {
      "_id": "12768421",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-01-19 11:23:51",
      "description": "Implement support for continuable sessions to keeps state across multiple client/server interactions. Continuable sessions do not require any additional state on the server (i.e. Oak) apart form the apparent repository state. \n\nTo continue a session a client would obtain a continuation token from the current session. This token can be used on the next call to {{Repository.login}} to obtain a new {{Session}} instance that is based on the same repository revision that the session the token was obtained from. Additionally the token could contain information re. authentication so subsequent request can go through a simplified authentication procedure. ([~asanso]'s work on OAuth might be of help here.)\n\nTransient changes are not supported in continuable sessions. Obtaining a continuation token from a session with transient changes results in an error. \n\nContinuable sessions are typically short lived (i.e. the time of a single HTTP request). Specifically continuable session do not retain the underlying repository revision from being garbage collected. Clients need to be able to cope with respective exceptions. \n\n\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "api"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Support continuable sessions "
   },
   {
      "_id": "12768418",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322318",
            "id": "12322318",
            "name": "remoting",
            "description": "Oak Remoting"
         }
      ],
      "created": "2015-01-19 11:10:06",
      "description": "Container issues for collecting tasks related to remoting the Oak API. Such a remoting should be:\n\n* stateless on the Oak side apart from the apparent persisted state in the content repository, \n\n* independent from {{oak-jcr}}, but reusing JCR related plugins from {{oak-core}} as required (e.g. for name space and node type handling),\n\n* agnostic of any protocol bindings,\n\n* ...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "api",
         "remoting"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Oak API remoting"
   },
   {
      "_id": "12767764",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-01-15 15:58:05",
      "description": "Current approaches to revision garbage collection tend to be too conservative (too little space reclaimed, e.g. OAK-2045) or too aggressive (removing segments still being used, e.g. OAK-2384). \n\nThis issue is to explore ways to make revision gc on TarMk more precise. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Investigate ways to make revision gc more precise "
   },
   {
      "_id": "12767762",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-01-15 15:51:07",
      "description": "The approach to revision garbage collection taken in OAK-2192 assumes that long running background sessions call refresh once they become active again. Incidentally this is true as such background sessions usually are admin sessions and those are always auto-refreshed on access (see OAK-88, OAK-803, and OAK-960). However as soon as we move away from admin sessions this might not be true any more and we might start seeing {{SegmentNotFoundException}} s unless the user explicitly refreshes the session. \n\nTo prevent this we should make all sessions auto refresh once revision gc runs. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Auto-refresh sessions on revision gc"
   },
   {
      "_id": "12767745",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-01-15 15:08:42",
      "description": "We should add some monitoring that allows us to track \"old\" node states, which potentially block revision gc. \n\nPossible approaches:\n\n* Add monitoring too old revisions (root node states) along with the stack traces from where they have been acquired.\n\n* Include RecordId of root node state in the {{SessionMBean}}.\n\n* Add additional tooling on top of the {{SessionMBean}} to make it easier to make sense of the wealth of information provided. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "gc",
         "monitoring",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Monitoring to track old NodeStates"
   },
   {
      "_id": "12767742",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-01-15 15:05:49",
      "description": "There is currently no way to distinguish between a {{SegmentNotFoundException}} occurring because of a removed segment by gc or because of another corruption. Optimally we would tell in the exception why the segment is gone, how old it was when gc removed it and who/what was still referring to it at that time. In order to do that, we probably need some kind of log for the following data: When a segment was removed (because a new generation of the .tar file was made, or because the .tar file was removed), we should log the segment, the file name, and the date+time of the removal. If the segment was then not found because it was too old, then another type of exception should be thrown instead, for example \"ReadTimeoutException\", with a message that contains as much data as possible: the data+time of the segment, date+time of the removal of the segment, about when compaction was run, date+time of the session login and last refresh, the stack trace of where the session was acquired.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "gc",
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Provide more information in SegmentNotFoundException"
   },
   {
      "_id": "12767740",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2015-01-15 14:59:39",
      "description": "Container devoted to improving monitoring of the TarMk revision garbage collection process. The overall goal is to make it more transparent what revision gc does, how it performs, why it failed etc. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "gc",
         "monitoring",
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve monitoring capabilities for TarMk revision gc"
   },
   {
      "_id": "12767690",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2015-01-15 09:29:50",
      "description": "The SegmentNodeStoreService is prone to deadlocks because of the way in which is synchronizes access to the _SegmentNodeStore_ delegate.\n\nThe issue can now be seen on #deactivate, when the deregistration is being synchronously broadcast and if a referring service calls #getNodeStore the deadlock happens.\n\n{code}\nFound one Java-level deadlock:\n=============================\n\"qtp844483043-936\":\n  waiting to lock monitor 0x000001d1aacc7208 (object 0x000001d231f52698, a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService),\n  which is held by \"CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\"\n\"CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\":\n  waiting to lock monitor 0x000001d4d0907c88 (object 0x000001d2334be930, a java.lang.Object),\n  which is held by \"pool-5-thread-4\"\n\"pool-5-thread-4\":\n  waiting to lock monitor 0x000001d1aacc7208 (object 0x000001d231f52698, a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService),\n  which is held by \"CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\"\n\nJava stack information for the threads listed above:\n===================================================\n\"qtp844483043-936\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.getNodeStore(SegmentNodeStoreService.java:144)\n\t- waiting to lock <0x000001d231f52698> (a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.getNodeStore(SegmentNodeStoreService.java:73)\n\tat org.apache.jackrabbit.oak.spi.state.ProxyNodeStore.getRoot(ProxyNodeStore.java:35)\n\tat org.apache.jackrabbit.oak.core.MutableRoot.<init>(MutableRoot.java:160)\n\tat org.apache.jackrabbit.oak.core.ContentSessionImpl.getLatestRoot(ContentSessionImpl.java:110)\n\tat org.apache.jackrabbit.oak.spi.security.authentication.AbstractLoginModule.getRoot(AbstractLoginModule.java:403)\n\tat org.apache.jackrabbit.oak.security.authentication.token.TokenLoginModule.getTokenProvider(TokenLoginModule.java:215)\n\tat org.apache.jackrabbit.oak.security.authentication.token.TokenLoginModule.login(TokenLoginModule.java:128)\n\tat org.apache.felix.jaas.boot.ProxyLoginModule.login(ProxyLoginModule.java:52)\n\tat sun.reflect.GeneratedMethodAccessor65.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat javax.security.auth.login.LoginContext.invoke(LoginContext.java:762)\n\tat javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)\n\tat javax.security.auth.login.LoginContext$4.run(LoginContext.java:690)\n\tat javax.security.auth.login.LoginContext$4.run(LoginContext.java:688)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:687)\n\tat javax.security.auth.login.LoginContext.login(LoginContext.java:595)\n\tat org.apache.jackrabbit.oak.core.ContentRepositoryImpl.login(ContentRepositoryImpl.java:161)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:256)\n\tat com.adobe.granite.repository.impl.CRX3RepositoryImpl.login(CRX3RepositoryImpl.java:92)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:197)\n\tat org.apache.sling.jcr.base.AbstractSlingRepository2.login(AbstractSlingRepository2.java:297)\n\tat org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProviderFactory.getResourceProviderInternal(JcrResourceProviderFactory.java:289)\n\tat org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProviderFactory.getResourceProvider(JcrResourceProviderFactory.java:201)\n\tat org.apache.sling.resourceresolver.impl.tree.ResourceProviderFactoryHandler.login(ResourceProviderFactoryHandler.java:164)\n\tat org.apache.sling.resourceresolver.impl.tree.RootResourceProviderEntry.loginToRequiredFactories(RootResourceProviderEntry.java:95)\n\tat org.apache.sling.resourceresolver.impl.CommonResourceResolverFactoryImpl.getResourceResolverInternal(CommonResourceResolverFactoryImpl.java:109)\n\tat org.apache.sling.resourceresolver.impl.CommonResourceResolverFactoryImpl.getResourceResolver(CommonResourceResolverFactoryImpl.java:90)\n\tat org.apache.sling.resourceresolver.impl.ResourceResolverFactoryImpl.getResourceResolver(ResourceResolverFactoryImpl.java:93)\n\tat org.apache.sling.auth.core.impl.SlingAuthenticator.getAnonymousResolver(SlingAuthenticator.java:839)\n\tat org.apache.sling.auth.core.impl.SlingAuthenticator.doHandleSecurity(SlingAuthenticator.java:478)\n\tat org.apache.sling.auth.core.impl.SlingAuthenticator.handleSecurity(SlingAuthenticator.java:438)\n\tat org.apache.sling.engine.impl.SlingHttpContext.handleSecurity(SlingHttpContext.java:121)\n\tat org.apache.felix.http.base.internal.context.ServletContextImpl.handleSecurity(ServletContextImpl.java:335)\n\tat org.apache.felix.http.base.internal.handler.ServletHandler.doHandle(ServletHandler.java:337)\n\tat org.apache.felix.http.base.internal.handler.ServletHandler.handle(ServletHandler.java:300)\n\tat org.apache.felix.http.base.internal.dispatch.ServletPipeline.handle(ServletPipeline.java:93)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:50)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.sling.i18n.impl.I18NFilter.doFilter(I18NFilter.java:128)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.felix.http.sslfilter.internal.SslFilter.doFilter(SslFilter.java:55)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.felix.http.sslfilter.internal.SslFilter.doFilter(SslFilter.java:89)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat com.adobe.granite.license.impl.LicenseCheckFilter.doFilter(LicenseCheckFilter.java:298)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.sling.security.impl.ReferrerFilter.doFilter(ReferrerFilter.java:290)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.sling.featureflags.impl.FeatureManager.doFilter(FeatureManager.java:115)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.sling.engine.impl.log.RequestLoggerFilter.doFilter(RequestLoggerFilter.java:75)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.doHandle(FilterHandler.java:108)\n\tat org.apache.felix.http.base.internal.handler.FilterHandler.handle(FilterHandler.java:80)\n\tat org.apache.felix.http.base.internal.dispatch.InvocationFilterChain.doFilter(InvocationFilterChain.java:46)\n\tat org.apache.felix.http.base.internal.dispatch.HttpFilterChain.doFilter(HttpFilterChain.java:31)\n\tat org.apache.felix.http.base.internal.dispatch.FilterPipeline.dispatch(FilterPipeline.java:76)\n\tat org.apache.felix.http.base.internal.dispatch.Dispatcher.dispatch(Dispatcher.java:49)\n\tat org.apache.felix.http.base.internal.DispatcherServlet.service(DispatcherServlet.java:67)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:722)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:501)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:229)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:255)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:370)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)\n\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)\n\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)\n\"CM Event Dispatcher (Fire ConfigurationEvent: pid=org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\":\n\tat org.apache.sling.discovery.impl.DiscoveryServiceImpl.unbindTopologyEventListener(DiscoveryServiceImpl.java:242)\n\t- waiting to lock <0x000001d2334be930> (a java.lang.Object)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invokeMethod(BaseMethod.java:231)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.access$500(BaseMethod.java:39)\n\tat org.apache.felix.scr.impl.helper.BaseMethod$Resolved.invoke(BaseMethod.java:624)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invoke(BaseMethod.java:508)\n\tat org.apache.felix.scr.impl.helper.BindMethod.invoke(BindMethod.java:37)\n\tat org.apache.felix.scr.impl.manager.DependencyManager.invokeUnbindMethod(DependencyManager.java:1717)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.invokeUnbindMethod(SingleComponentManager.java:404)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$MultipleDynamicCustomizer.removedService(DependencyManager.java:376)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$MultipleDynamicCustomizer.removedService(DependencyManager.java:304)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1506)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1401)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$AbstractTracked.untrack(ServiceTracker.java:1261)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.serviceChanged(ServiceTracker.java:1440)\n\tat org.apache.felix.framework.util.EventDispatcher.invokeServiceListenerCallback(EventDispatcher.java:940)\n\tat org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:794)\n\tat org.apache.felix.framework.util.EventDispatcher.fireServiceEvent(EventDispatcher.java:544)\n\tat org.apache.felix.framework.Felix.fireServiceEvent(Felix.java:4425)\n\tat org.apache.felix.framework.Felix.access$000(Felix.java:75)\n\tat org.apache.felix.framework.Felix$1.serviceChanged(Felix.java:402)\n\tat org.apache.felix.framework.ServiceRegistry.unregisterService(ServiceRegistry.java:153)\n\tat org.apache.felix.framework.ServiceRegistrationImpl.unregister(ServiceRegistrationImpl.java:128)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager$3.unregister(AbstractComponentManager.java:1011)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager$3.unregister(AbstractComponentManager.java:992)\n\tat org.apache.felix.scr.impl.manager.RegistrationManager.changeRegistration(RegistrationManager.java:141)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.unregisterService(AbstractComponentManager.java:1054)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.doDeactivate(AbstractComponentManager.java:900)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.deactivateInternal(AbstractComponentManager.java:883)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$SingleStaticCustomizer.removedService(DependencyManager.java:974)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$SingleStaticCustomizer.removedService(DependencyManager.java:895)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1506)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1401)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$AbstractTracked.untrack(ServiceTracker.java:1261)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.serviceChanged(ServiceTracker.java:1440)\n\tat org.apache.felix.framework.util.EventDispatcher.invokeServiceListenerCallback(EventDispatcher.java:940)\n\tat org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:794)\n\tat org.apache.felix.framework.util.EventDispatcher.fireServiceEvent(EventDispatcher.java:544)\n\tat org.apache.felix.framework.Felix.fireServiceEvent(Felix.java:4425)\n\tat org.apache.felix.framework.Felix.access$000(Felix.java:75)\n\tat org.apache.felix.framework.Felix$1.serviceChanged(Felix.java:402)\n\tat org.apache.felix.framework.ServiceRegistry.unregisterService(ServiceRegistry.java:153)\n\tat org.apache.felix.framework.ServiceRegistrationImpl.unregister(ServiceRegistrationImpl.java:128)\n\tat org.apache.sling.jcr.base.AbstractSlingRepositoryManager.unregisterService(AbstractSlingRepositoryManager.java:258)\n\tat org.apache.sling.jcr.base.AbstractSlingRepositoryManager.stop(AbstractSlingRepositoryManager.java:345)\n\tat com.adobe.granite.repository.impl.SlingRepositoryManager.deactivate(SlingRepositoryManager.java:194)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invokeMethod(BaseMethod.java:231)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.access$500(BaseMethod.java:39)\n\tat org.apache.felix.scr.impl.helper.BaseMethod$Resolved.invoke(BaseMethod.java:624)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invoke(BaseMethod.java:508)\n\tat org.apache.felix.scr.impl.helper.ActivateMethod.invoke(ActivateMethod.java:149)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.disposeImplementationObject(SingleComponentManager.java:355)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.deleteComponent(SingleComponentManager.java:170)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.doDeactivate(AbstractComponentManager.java:908)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.deactivateInternal(AbstractComponentManager.java:883)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$SingleStaticCustomizer.removedService(DependencyManager.java:974)\n\tat org.apache.felix.scr.impl.manager.DependencyManager$SingleStaticCustomizer.removedService(DependencyManager.java:895)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1506)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.customizerRemoved(ServiceTracker.java:1401)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$AbstractTracked.untrack(ServiceTracker.java:1261)\n\tat org.apache.felix.scr.impl.manager.ServiceTracker$Tracked.serviceChanged(ServiceTracker.java:1440)\n\tat org.apache.felix.framework.util.EventDispatcher.invokeServiceListenerCallback(EventDispatcher.java:940)\n\tat org.apache.felix.framework.util.EventDispatcher.fireEventImmediately(EventDispatcher.java:794)\n\tat org.apache.felix.framework.util.EventDispatcher.fireServiceEvent(EventDispatcher.java:544)\n\tat org.apache.felix.framework.Felix.fireServiceEvent(Felix.java:4425)\n\tat org.apache.felix.framework.Felix.access$000(Felix.java:75)\n\tat org.apache.felix.framework.Felix$1.serviceChanged(Felix.java:402)\n\tat org.apache.felix.framework.ServiceRegistry.unregisterService(ServiceRegistry.java:153)\n\tat org.apache.felix.framework.ServiceRegistrationImpl.unregister(ServiceRegistrationImpl.java:128)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.unregisterNodeStore(SegmentNodeStoreService.java:320)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.deactivate(SegmentNodeStoreService.java:295)\n\t- locked <0x000001d231f52698> (a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invokeMethod(BaseMethod.java:231)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.access$500(BaseMethod.java:39)\n\tat org.apache.felix.scr.impl.helper.BaseMethod$Resolved.invoke(BaseMethod.java:624)\n\tat org.apache.felix.scr.impl.helper.BaseMethod.invoke(BaseMethod.java:508)\n\tat org.apache.felix.scr.impl.helper.ActivateMethod.invoke(ActivateMethod.java:149)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.disposeImplementationObject(SingleComponentManager.java:355)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.deleteComponent(SingleComponentManager.java:170)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.doDeactivate(AbstractComponentManager.java:908)\n\tat org.apache.felix.scr.impl.manager.AbstractComponentManager.deactivateInternal(AbstractComponentManager.java:883)\n\tat org.apache.felix.scr.impl.manager.SingleComponentManager.reconfigure(SingleComponentManager.java:638)\n\tat org.apache.felix.scr.impl.config.ConfigurableComponentHolder.configurationUpdated(ConfigurableComponentHolder.java:328)\n\tat org.apache.felix.scr.impl.config.ConfigurationSupport.configurationEvent(ConfigurationSupport.java:290)\n\tat org.apache.felix.cm.impl.ConfigurationManager$FireConfigurationEvent.sendEvent(ConfigurationManager.java:2032)\n\tat org.apache.felix.cm.impl.ConfigurationManager$FireConfigurationEvent.run(ConfigurationManager.java:2002)\n\tat org.apache.felix.cm.impl.UpdateThread.run(UpdateThread.java:103)\n\tat java.lang.Thread.run(Thread.java:745)\n\"pool-5-thread-4\":\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.getNodeStore(SegmentNodeStoreService.java:144)\n\t- waiting to lock <0x000001d231f52698> (a org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService)\n\tat org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService.getNodeStore(SegmentNodeStoreService.java:73)\n\tat org.apache.jackrabbit.oak.spi.state.ProxyNodeStore.getRoot(ProxyNodeStore.java:35)\n\tat org.apache.jackrabbit.oak.core.MutableRoot.<init>(MutableRoot.java:160)\n\tat org.apache.jackrabbit.oak.core.ContentSessionImpl.getLatestRoot(ContentSessionImpl.java:110)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.<init>(SessionDelegate.java:160)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl$1.<init>(RepositoryImpl.java:273)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.createSessionDelegate(RepositoryImpl.java:271)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:257)\n\tat com.adobe.granite.repository.impl.CRX3RepositoryImpl.login(CRX3RepositoryImpl.java:92)\n\tat com.adobe.granite.repository.impl.SlingRepositoryImpl$2.run(SlingRepositoryImpl.java:108)\n\tat com.adobe.granite.repository.impl.SlingRepositoryImpl$2.run(SlingRepositoryImpl.java:100)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAsPrivileged(Subject.java:536)\n\tat com.adobe.granite.repository.impl.SlingRepositoryImpl.createAdministrativeSession(SlingRepositoryImpl.java:100)\n\tat org.apache.sling.jcr.base.AbstractSlingRepository2.loginAdministrative(AbstractSlingRepository2.java:362)\n\tat org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProviderFactory.getResourceProviderInternal(JcrResourceProviderFactory.java:246)\n\tat org.apache.sling.jcr.resource.internal.helper.jcr.JcrResourceProviderFactory.getAdministrativeResourceProvider(JcrResourceProviderFactory.java:209)\n\tat org.apache.sling.resourceresolver.impl.tree.ResourceProviderFactoryHandler.login(ResourceProviderFactoryHandler.java:162)\n\tat org.apache.sling.resourceresolver.impl.tree.RootResourceProviderEntry.loginToRequiredFactories(RootResourceProviderEntry.java:95)\n\tat org.apache.sling.resourceresolver.impl.CommonResourceResolverFactoryImpl.getResourceResolverInternal(CommonResourceResolverFactoryImpl.java:109)\n\tat org.apache.sling.resourceresolver.impl.CommonResourceResolverFactoryImpl.getAdministrativeResourceResolver(CommonResourceResolverFactoryImpl.java:76)\n\tat org.apache.sling.resourceresolver.impl.ResourceResolverFactoryImpl.getAdministrativeResourceResolver(ResourceResolverFactoryImpl.java:98)\n\tat org.apache.sling.discovery.impl.cluster.ClusterViewServiceImpl.getClusterView(ClusterViewServiceImpl.java:132)\n\tat org.apache.sling.discovery.impl.DiscoveryServiceImpl.getTopology(DiscoveryServiceImpl.java:418)\n\tat org.apache.sling.discovery.impl.DiscoveryServiceImpl.handlePotentialTopologyChange(DiscoveryServiceImpl.java:466)\n\tat org.apache.sling.discovery.impl.DiscoveryServiceImpl.handleTopologyChanged(DiscoveryServiceImpl.java:650)\n\t- locked <0x000001d2334be930> (a java.lang.Object)\n\tat org.apache.sling.discovery.impl.topology.TopologyChangeHandler.handleTopologyChanged(TopologyChangeHandler.java:134)\n\tat org.apache.sling.discovery.impl.topology.TopologyChangeHandler.handleEvent(TopologyChangeHandler.java:124)\n\tat org.apache.felix.eventadmin.impl.handler.EventHandlerProxy.sendEvent(EventHandlerProxy.java:412)\n\tat org.apache.felix.eventadmin.impl.tasks.SyncDeliverTasks.execute(SyncDeliverTasks.java:118)\n\tat org.apache.felix.eventadmin.impl.handler.EventAdminImpl.sendEvent(EventAdminImpl.java:114)\n\tat org.apache.felix.eventadmin.impl.security.EventAdminSecurityDecorator.sendEvent(EventAdminSecurityDecorator.java:96)\n\tat org.apache.sling.jcr.resource.internal.OakResourceListener.sendOsgiEvent(OakResourceListener.java:243)\n\tat org.apache.sling.jcr.resource.internal.OakResourceListener.changed(OakResourceListener.java:133)\n\tat org.apache.jackrabbit.oak.plugins.observation.NodeObserver$NodeEventHandler.leave(NodeObserver.java:208)\n\tat org.apache.jackrabbit.oak.plugins.observation.FilteredHandler.leave(FilteredHandler.java:51)\n\tat org.apache.jackrabbit.oak.plugins.observation.EventGenerator$Continuation.run(EventGenerator.java:175)\n\tat org.apache.jackrabbit.oak.plugins.observation.EventGenerator.generate(EventGenerator.java:118)\n\tat org.apache.jackrabbit.oak.plugins.observation.NodeObserver.contentChanged(NodeObserver.java:156)\n\tat org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1$1.call(BackgroundObserver.java:117)\n\tat org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1$1.call(BackgroundObserver.java:111)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nFound 1 deadlock.\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "SegmentNodeStoreService prone to deadlocks"
   },
   {
      "_id": "12765997",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2015-01-09 11:21:56",
      "description": "With OAK-2192 revision gc started to remove segments older than a certain threshold. The underlying assumption was that old sessions would call refresh (i.e. auto refresh) anyway once they become active again. However, it turns out that refreshing a sessions does not affect JCR values as those are directly tied to the underlying record. Accessing those values after its segment has been gc'ed results in a {{SegmentNotFoundException}}. \n\nKeeping reference to JCR values is an important use case for Sling's {{JcrPropertyMap}}, which is widely used.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "SegmentNotFoundException when keeping JCR Value references"
   },
   {
      "_id": "12762836",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         }
      ],
      "created": "2014-12-19 12:37:16",
      "description": "See http://markmail.org/message/idx2y2dwpkaxchsp for previous mention.\n\nI suggest to use the mechanism from OAK-2371 to exclude the tests on that CI environment for now. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "buildbot",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Sporadic test failure of OSGiIT.listBundles on Buildbot"
   },
   {
      "_id": "12760809",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-12-10 17:31:47",
      "description": "{{BackgroundThread}} catches {{InterruptedException}} but doesn't set the thread's interrupted status. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Wrong handling of InterruptedException in BackgroundThread"
   },
   {
      "_id": "12760088",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-12-08 08:54:05",
      "description": "We need a tool to check a SegmentMK repository for consistency. Such a tool should start at the most recent version in the journal and traverse back until it finds the latest good revision. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "offline",
         "production",
         "resilience",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "SegmentMK consistency check"
   },
   {
      "_id": "12757647",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2014-11-25 08:55:34",
      "description": "OAK-2276 added support for {{IndexFormatVersion}} where {{V1}} is compatible with existing {{LuceneIndex}} while {{V2}} is compatible with newer index implemention being worked on OAK-2278.\n\nOnce implementation in OAK-2278 is stable enough we should switch the default version to be used for fresh index (unless overrided with {{compatMode}} ) from V1 to V2",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Switch default IndexFormatVersion to V2 "
   },
   {
      "_id": "12754445",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-11-11 11:27:33",
      "description": "When getting _PROPERTY_CHANGED_ events on non-multivalued properties only one value can have actually changed so that handlers of such events do not need any further information to process it and eventually work on the changed value; on the other hand _PROPERTY_CHANGED_ events on multivalued properties (e.g. String[]) may relate to any of the values and that brings a source of uncertainty on event handlers processing such changes because there's no mean to understand which property value had been changed and therefore to them to react accordingly.\nA workaround for that is to create Oak specific _Observers_ which can deal with the diff between before and after state and create a specific event containing the \"diff\", however this would add a non trivial load to the repository because of the _Observer_ itself and because of the additional events being generated while it'd be great if the 'default' events would have metadata e.g. of the changed value index or similar information that can help understanding which value has been changed (added, deleted, updated). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add metadata about the changed value to a PROPERTY_CHANGED event on a multivalued property"
   },
   {
      "_id": "12753132",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-11-05 19:04:16",
      "description": "This is related to OAK-2000. I think the accessibility check needs to respect the session refresh settings when acquiring the root object.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation events accessibility check should respect session refresh settings"
   },
   {
      "_id": "12751610",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12326663",
            "id": "12326663",
            "name": "lucene",
            "description": "Lucene"
         }
      ],
      "created": "2014-10-30 05:05:49",
      "description": "Currently a Lucene index when is written directly to OakDirectory. For reindex case it might happen that Lucene merge policy read the written index files again and then perform a sgement merge. This might have lower performance when OakDirectroy is writing to remote storage.\n\nInstead of that we can implement a CopyOnWriteDirectory on similar lines to  OAK-1724 where CopyOnReadDirectory support copies the  index locally for faster access. \n\nAt high level flow would be\n\n# While writing index the index file is first written to local directory\n# Any write is done locally and once a file is written its written asynchronously to OakDirectory\n# When IndexWriter is closed it would wait untill all the write is completed\n\nThis needs to be benchmarked with existing reindex timings to see it its actually beneficial",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "docs-impacting",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "CopyOnWriteDirectory implementation for Lucene for use in indexing"
   },
   {
      "_id": "12748070",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-10-14 16:18:35",
      "description": "I think it would be useful if the segment explorer could print the graph of a tar file along with its references. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Print tar file graph in segment explorer"
   },
   {
      "_id": "12748057",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-10-14 15:26:19",
      "description": "Tar garbage collection generates new generation of tar files once it determines a given file contains garbage. New generations will have the next lower case letter from the alphabet appended to its file name. When the letter 'z' is reached, no further garbage collection is done. \n\nI think we need to fix this as otherwise garbage collection just stops working arbitrarily. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "No garbage collection after reaching generation z"
   },
   {
      "_id": "12748055",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-10-14 15:10:26",
      "description": "Changes that are committed during a segment store compaction run will be compacted on top of the already compacted changes. However the compactor uses the wrong before state in this case. Instead of compacting against the compacted before state it uses the un-compacted before state. The resulting state will thus contain references to un-compacted state, making those not eligible for later clean up. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "compaction",
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Concurrent commit during compaction results in mixed segments"
   },
   {
      "_id": "12747934",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12325112",
            "id": "12325112",
            "name": "pojosr"
         }
      ],
      "created": "2014-10-14 06:08:06",
      "description": "Intermittent failures on windows are observed in JaasConfigSpiTest with following exception\n\n{noformat}\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 3.841 sec <<< FAILURE!\ndefaultConfigSpiAuth(org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest)  Time elapsed: 3.835 sec  <<< ERROR!\njava.lang.reflect.UndeclaredThrowableException\n\tat $Proxy7.login(Unknown Source)\n\tat javax.jcr.Repository$login.call(Unknown Source)\n\tat org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:45)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:108)\n\tat org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:116)\n\tat org.apache.jackrabbit.oak.run.osgi.JaasConfigSpiTest.defaultConfigSpiAuth(JaasConfigSpiTest.groovy:75)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.jackrabbit.oak.run.osgi.OakOSGiRepositoryFactory$RepositoryProxy.invoke(OakOSGiRepositoryFactory.java:325)\n\t... 37 more\nCaused by: javax.jcr.LoginException: No LoginModules configured for jackrabbit.oak\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:264)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:222)\n\t... 42 more\nCaused by: javax.security.auth.login.LoginException: No LoginModules configured for jackrabbit.oak\n\tat javax.security.auth.login.LoginContext.init(LoginContext.java:256)\n\tat javax.security.auth.login.LoginContext.<init>(LoginContext.java:499)\n\tat org.apache.jackrabbit.oak.spi.security.authentication.JaasLoginContext.<init>(JaasLoginContext.java:49)\n\tat org.apache.jackrabbit.oak.security.authentication.LoginContextProviderImpl.getLoginContext(LoginContextProviderImpl.java:85)\n\tat org.apache.jackrabbit.oak.core.ContentRepositoryImpl.login(ContentRepositoryImpl.java:161)\n\tat org.apache.jackrabbit.oak.jcr.repository.RepositoryImpl.login(RepositoryImpl.java:256)\n\t... 43 more\n\nRunning org.apache.jackrabbit.oak.run.osgi.JsonConfigRepFactoryTest\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI",
         "buildbot",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Fix intermittent failure in JaasConfigSpiTest"
   },
   {
      "_id": "12746165",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-10-06 15:17:11",
      "description": "{{JackrabbitNodeTest#testRenameEventHandling}} fails sporadically on the Apache buildbot with missing events (e.g. http://ci.apache.org/builders/oak-trunk-win7/builds/642). \n\nSame holds for other tests in the {{ObservationIT}} suite. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "CI",
         "buildbot",
         "observation",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation tests sporadically failing"
   },
   {
      "_id": "12744000",
      "assignee": "mreutegg",
      "components": [],
      "created": "2014-09-25 11:26:20",
      "description": "Issues for 1.0.7: https://issues.apache.org/jira/issues/?jql=project%20%3D%20OAK%20AND%20fixVersion%20%3D%201.0.7",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "Release"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Release Oak 1.0.7"
   },
   {
      "_id": "12742399",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-09-18 09:27:09",
      "description": "When killing a node that is running the sync index update, then this async index update will not run for up to 15 minutes, because the lease time is set to 15 minutes.\n\nI think the lease time should be much smaller, for example 1 minute, or maybe even 10 seconds.\n\nAlso, we might need to better document this issue (in addition to the warning in the log file). For non cluster case we can do away with lease time out and this for such cases indexing would not get paused upon restart post abrupt shutdown",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Killing a node may stop async index update to to 30 minutes (Tar storage)"
   },
   {
      "_id": "12738281",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322500",
            "id": "12322500",
            "name": "rdbmk",
            "description": "RDB Store"
         }
      ],
      "created": "2014-09-01 15:04:34",
      "description": "The DocumentStore API currently has a call for creating many nodes at once.\n\nHowever, this will sometimes fail for large save operations in JCR, because in the DS persistence, JCR-deleted nodes are still present (with a deleted flag). This causes two subsequent sequences of\n\n1) create test container\n2) create many child nodes\n3) remove test container\n\nto behave very differently, depending on whether the test container is created for the first time or not.\n\n(see CreateManyChildNodesTest)\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/1",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/blocker.svg",
         "name": "Blocker",
         "id": "1"
      },
      "projectname": "OAK",
      "summary": "DocumentStore API: batch create, but no batch update"
   },
   {
      "_id": "12738253",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2014-09-01 12:05:40",
      "description": "Currently DocumentStore performs various background operations like\n\n# Cache consistency check\n# Pushing the lastRev updates\n# Synchrnizing the root node version\n\nWe should capture some stats like time taken in various task and expose them over JMX to determine if those background operations are performing well or not. For example its important that all tasks performed in background task should be completed under 1 sec (default polling interval). If the time taken increases then it would be cause of concern\n\nSee http://markmail.org/thread/57fax4nyabbubbef",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "tooling"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JMX stats for operations being performed in DocumentNodeStore"
   },
   {
      "_id": "12737509",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-08-28 17:32:24",
      "description": "Currently DocumentNodeStore has 5 different types of caches and each register there own MBean. To get a better understanding of the overall cache usage it would be good to have a {{ConsolidatedCacheStatsMBean}} which depicts all the stats in tabular form",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MBean to provide consolidated cache stats "
   },
   {
      "_id": "12735772",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-08-21 12:32:27",
      "description": "Cleanup operation in SegmentNodeStore detects the un referenced garbage and clean it up. To determine the reference validity it starts with an initial set of SegmentId which have a live java reference. \n\nThis works fine for simple setup but when Oak repository is used in an application (like Sling) where application code can create long running session (for observation) then such session are bound to old NodeState at time of startup. Such references prevent the cleanup logic to remove older revisions while system is running. Such revisions can only be removed via an offline compaction-> cleanup.\n\nNeed to find out a way where we can _migrate_ such old NodeState references to newer revisions",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "gc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Long running JCR session prevent live cleanup in Segment FileStore"
   },
   {
      "_id": "12730767",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-07-30 11:56:22",
      "description": "Currently the maven baseline plugin only logs the package version mismatches, it doesn't fail the build. It would be beneficial to start looking at the output and possibly fix some of the warnings (increase the OSGi package versions).",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "build",
         "modularization",
         "osgi",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Verify the maven baseline output and fix the warnings"
   },
   {
      "_id": "12730473",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-29 12:56:48",
      "description": "Before delivering an observation event it is checked whether the respective item is actually accessible through the associated session. However the check is currently done against the state of the session from the time the event listener was registered instead of from the time the event is being sent. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation events accessibility not checked correctly"
   },
   {
      "_id": "12729663",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-07-25 06:13:55",
      "description": "Oak Console 'ls' command currently lists down all the child node which cause issue for node have large no of children. As a fix ls command should dump max say 50 child node and allow user to change the limit as part of arguments",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "console"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Limit no of children listed with ls command in Oak Console"
   },
   {
      "_id": "12729658",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-07-25 05:13:09",
      "description": "Add a command in Oak Run Console to dump lucene index and also provide stats related to Lucene index\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "console"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Add command to dump Lucene index in Oak Console"
   },
   {
      "_id": "12729095",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-07-23 06:54:24",
      "description": "So far we have implemented garbage collection in some form with OAK-1341. Those approaches help us remove quite a bit of garbage (mostly due to deleted nodes) but till some part is left\n\nHowever full GC is still not performed due to which some of the old revision related data cannot be GCed like\n* Revision info present in revision maps of various commit roots\n* Revision related to unmerged branches (OAK-1926)\n* Revision data created to property being modified by different cluster nodes\n\nSo having a tool which can perform above GC would be helpful. For start we can have an implementation which takes a brute force approach and scans whole repo (would take quite a bit of time) and later we can evolve it. Or allow system admins to determine to what level GC has to be done",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "resilience",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement full scale Revision GC for DocumentNodeStore"
   },
   {
      "_id": "12728484",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-21 07:20:33",
      "description": "Implement the new Jackrabbit API introduced with JCR-3797",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add path exclusion to JackrabbitEventFilter"
   },
   {
      "_id": "12727885",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-17 09:27:23",
      "description": "The value reported for the {{RepositoryStatistics.Type#OBSERVATION_EVENT_DURATION}} statistic is wrong. Instead of the total time spent *processing* observation events it reports the total time *producing* observation events. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "monitoring",
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Wrong values reported for OBSERVATION_EVENT_DURATION"
   },
   {
      "_id": "12727863",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-07-17 07:09:16",
      "description": "The current MongoMK implementation performs retries when it runs into merge\nconflicts caused by collisions. It may be possible to resolve a conflict by resetting\nthe branch back to the state as it was before the merge and re-run the commit hooks again.\nThis helps if the conflict was introduced by a commit hook. At the moment the retries\nalso happen when the conflict was introduced before the merge. In this case, a retry\nis useless and the commit should fail fast.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Fail fast on branch conflict"
   },
   {
      "_id": "12727333",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-07-15 13:13:52",
      "description": "DocumentNodeStore currently makes use of query to determine child nodes which have changed after certain time. Query used is something like\n\n{noformat}\ndb.nodes.find({ _id: { $gt: \"3:/content/foo/01/\", $lt: \"3:/content/foo010\" }, _modified: { $gte: <start time> } }).sort({_id:1})\n{noformat}\n\nOAK-1966 tries to optimize the majority case where start times is recent and in that case it makes use of _modified index. However if the start time is quite old and a node has large number of children say 100k then it would involve scan of all those 100k nodes as _modified index would not be of much help. \n\nInstead of querying like this we can have a special handling for cases where large number of children are involved. It would involve following steps\n\nAfter analyzing the runtime queries in most case it is seen that even with old modified time the number of change nodes is < 50\n\n# Mark parent nodes which have large number of children say > 50\n# On such nodes we would keep an array of \\{modifiedtime, childName\\} ## Array would be bounded say keep last 50 updates. This can be done via splice and push operators [1]\n## Each entry in array would record modifiedtime and name of child node which was modified. \n## Array would be sorted on modifiedtime\n# Each updated to any child belonging to such parent would also involve update to above array\n# When we query for modified we check if the parent has such an array (if parent is in cache) and if that array has time entries from the required start time we directly make use of that and avoid the query\n\nThis should reduce needs for such queries in majority of cases\n\n[1] http://docs.mongodb.org/manual/reference/operator/update-array/\n ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimize the diff logic for large number of children case "
   },
   {
      "_id": "12726576",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-10 12:46:38",
      "description": "In OAK-1703, we have added a new class WarningLock that internally uses an Exception to remember the stack trace. This seems to be used for every SessionDelegate object. With Java 6 and older, this is very problematic because it will cause \"java.lang.Throwable.fillInStackTrace(Native Method)\" to be called for almost every call to any of the Oak JCR methods, and \"fillInStackTrace(Native Method)\" is known to be be very slow. Java 7, I believe, will at some point give up and not fill in the stack trace any more. But with Java 6 and older, this is a big problem.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Performance degradation due to SessionDelegate.WarningLock"
   },
   {
      "_id": "12726532",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-07-10 09:23:04",
      "description": "In certain scenarios for performance reasons its desirable to have direct access to the Blob source. \n\nFor e.g. if using a FileDataStore having a direct access to the native file system path of the blob (if not stored in chunks) is more useful than repository path e.g. native tools don't understand repository path, instead file system path can be passed directly to native tools for processing binary.\n\nAnother usecase being ability exposed signed S3 url which would allow access to binary content directly",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "datastore"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose URL for Blob source "
   },
   {
      "_id": "12726185",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-07-08 20:50:32",
      "description": "Problem:\nSession.logout was observed to take 14% of time in a performance test of a reasonably real-world load.\n\nMethod:\nUse the attached sling junit test case to run 8 concurrent instances of the test. profile with YourKit or  similar and see >50% time taken by logout.\n\nExpected:\nLogout should be practically free.\n\nSolution:\nThe attached patch avoids a bug in guava-15 (still present in guava-17 the latest) where the former use of addCallback triggered many CancellationExceptions when sessions were quickly created and logged out.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Session.logout performance poor"
   },
   {
      "_id": "12725972",
      "assignee": "mduerig",
      "components": [],
      "created": "2014-07-08 08:52:12",
      "description": "This issue serves as a reminder to set the correct OSGi package export versions before we release 1.2.\n\nOAK-1536 added support for the BND baseline feature: the baseline.xml files in the target directories should help us figuring out the correct versions. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "modularization",
         "osgi",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/2",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/critical.svg",
         "name": "Critical",
         "id": "2"
      },
      "projectname": "OAK",
      "summary": "Set correct OSGi package export version"
   },
   {
      "_id": "12724756",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-07-01 15:50:06",
      "description": "Since OAK-1422 the  {{Continuation}} created in {{fullQueue()}} is put to the front of the List. This causes it to be taken right off the list again on the next call to {{generate()}} instead of first continuing with the rest of the list allowing it to shrink. As a result the list may grow up to 2 x {{MAX_QUEUED_CONTINUATIONS}} instead of 1 + {{MAX_QUEUED_CONTINUATIONS}} as anticipated. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "Observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MAX_QUEUED_CONTINUATIONS feature not working in EventGenerator class"
   },
   {
      "_id": "12717071",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-05-28 16:01:06",
      "description": "The generic interface for operation management tasks added with OAK-1160 does so far not provide a way for specific tasks to return a value apart from a genetic status. With the consistency checking we are starting to add (OAK-1448) such a needs start to arise. \n\nTo address this I propose to change type of the tasks that can be passed to the constructor of {{ManagementOperation}}. The result type of the task (i.e. {{Callable}}) should change from {{Long}} to some generic container, which would carry the result of the task. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Generic operation tasks should be able to return specific results"
   },
   {
      "_id": "12715768",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317805",
            "id": "12317805",
            "name": "it",
            "description": "Integration Tests"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320390",
            "id": "12320390",
            "name": "solr",
            "description": "Oak Solr index"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12321728",
            "id": "12321728",
            "name": "upgrade",
            "description": "Oak Upgrade"
         }
      ],
      "created": "2014-05-21 14:43:48",
      "description": "There are still a few places left where {{MicroKernelImpl}} is used for running tests. As {{SegementMK}} is the default for going forward I suggest we change those tests accordingly. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Use SegmentMK for testing where possible"
   },
   {
      "_id": "12715514",
      "assignee": "frm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12322602",
            "id": "12322602",
            "name": "blob",
            "description": "Oak Blob Store"
         }
      ],
      "created": "2014-05-20 15:43:31",
      "description": "The stacktrace of the call shows something like\n{code}\n20.05.2014 11:13:07.428 *ERROR* [OsgiInstallerImpl] com.adobe.granite.installer.factory.packages.impl.PackageTransformer Error while processing install task.\njava.lang.IllegalStateException: Unexpected value record type: f2\nat org.apache.jackrabbit.oak.plugins.segment.SegmentBlob.length(SegmentBlob.java:101)\nat org.apache.jackrabbit.oak.plugins.value.BinaryImpl.getSize(BinaryImpl.java:74)\nat org.apache.jackrabbit.oak.jcr.session.PropertyImpl.getLength(PropertyImpl.java:435)\nat org.apache.jackrabbit.oak.jcr.session.PropertyImpl.getLength(PropertyImpl.java:376)\nat org.apache.jackrabbit.vault.packaging.impl.JcrPackageImpl.getPackage(JcrPackageImpl.java:324)\n{code}\n\nThe blob store was configured correctly and according to the log also correctly initialized\n{code}\n20.05.2014 11:11:07.029 *INFO* [FelixStartLevel] org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService Initializing SegmentNodeStore with BlobStore [org.apache.jackrabbit.oak.spi.blob.FileBlobStore@7e3dec43]\n20.05.2014 11:11:07.029 *INFO* [FelixStartLevel] org.apache.jackrabbit.oak.plugins.segment.SegmentNodeStoreService Component still not activated. Ignoring the initialization call\n20.05.2014 11:11:07.077 *INFO* [FelixStartLevel] org.apache.jackrabbit.oak.plugins.segment.file.FileStore TarMK opened: crx-quickstart/repository/segmentstore (mmap=true)\n{code}\n\nUnder which circumstances can the length within the SegmentBlob be invalid?\nThis only happens if a File Blob Store is configured (http://jackrabbit.apache.org/oak/docs/osgi_config.html). If a file datastore is used, there is no such exception.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ISE: \"Unexpected value record type: f2\" is thrown when FileBlobStore is used"
   },
   {
      "_id": "12715494",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2014-05-20 14:34:08",
      "description": "the 'clustering' page in our oak documentation is currently an empty placeholder and it would be great if there would be some initial pointers.\n\n[~chetanm], [~mreutegg], what do you think?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Document Oak Clustering"
   },
   {
      "_id": "12713027",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-05-08 07:07:54",
      "description": "While running ConcurrentCreateNodesTest with 5 instances writing to same Mongo instance following exception is seen\n\n{noformat}\nException in thread \"Background job org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest$Writer@3f56e5ed\" java.lang.RuntimeException: javax.jcr.nodetype.ConstraintViolationException: OakConstraint0001: /: The primary type rep:root does not exist\n    at org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest$Writer.run(ConcurrentCreateNodesTest.java:111)\n    at org.apache.jackrabbit.oak.benchmark.AbstractTest$1.run(AbstractTest.java:481)\nCaused by: javax.jcr.nodetype.ConstraintViolationException: OakConstraint0001: /: The primary type rep:root does not exist\n    at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:225)\n    at org.apache.jackrabbit.oak.api.CommitFailedException.asRepositoryException(CommitFailedException.java:212)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.newRepositoryException(SessionDelegate.java:679)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:553)\n    at org.apache.jackrabbit.oak.jcr.session.SessionImpl$8.perform(SessionImpl.java:417)\n    at org.apache.jackrabbit.oak.jcr.session.SessionImpl$8.perform(SessionImpl.java:414)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:308)\n    at org.apache.jackrabbit.oak.jcr.session.SessionImpl.perform(SessionImpl.java:127)\n    at org.apache.jackrabbit.oak.jcr.session.SessionImpl.save(SessionImpl.java:414)\n    at org.apache.jackrabbit.oak.benchmark.ConcurrentCreateNodesTest$Writer.run(ConcurrentCreateNodesTest.java:100)\n    ... 1 more\nCaused by: org.apache.jackrabbit.oak.api.CommitFailedException: OakConstraint0001: /: The primary type rep:root does not exist\n    at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.constraintViolation(TypeEditor.java:150)\n    at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.getEffectiveType(TypeEditor.java:286)\n    at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditor.<init>(TypeEditor.java:101)\n    at org.apache.jackrabbit.oak.plugins.nodetype.TypeEditorProvider.getRootEditor(TypeEditorProvider.java:85)\n    at org.apache.jackrabbit.oak.spi.commit.CompositeEditorProvider.getRootEditor(CompositeEditorProvider.java:80)\n    at org.apache.jackrabbit.oak.spi.commit.EditorHook.processCommit(EditorHook.java:53)\n    at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:60)\n    at org.apache.jackrabbit.oak.spi.commit.CompositeHook.processCommit(CompositeHook.java:60)\n    at org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch$InMemory.merge(AbstractNodeStoreBranch.java:498)\n    at org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch.merge(AbstractNodeStoreBranch.java:300)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStoreBranch.merge(DocumentNodeStoreBranch.java:129)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentRootBuilder.merge(DocumentRootBuilder.java:159)\n    at org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.merge(DocumentNodeStore.java:1275)\n    at org.apache.jackrabbit.oak.core.MutableRoot.commit(MutableRoot.java:247)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.commit(SessionDelegate.java:405)\n    at org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.save(SessionDelegate.java:551)\n    ... 7 more\n{noformat}\n\nThis has been reported by [~rogoz]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ConstraintViolationException seen with multiple Oak/Mongo with ConcurrentCreateNodesTest"
   },
   {
      "_id": "12712931",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-05-07 20:21:02",
      "description": "It would be nice to for {{oak-run}} to come with a debugging console like the {{cli}} mode in {{jackrabbit-standalone}}.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "production",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Debugging console"
   },
   {
      "_id": "12712602",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         }
      ],
      "created": "2014-05-06 15:31:41",
      "description": "oak-doc is missing documentation about the usage of the OrderedIndex.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "doc"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Missing documentation around Ordered Index"
   },
   {
      "_id": "12711671",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-05-01 07:28:50",
      "description": "Occurs every now and then on buildbot. E.g.:\nhttp://ci.apache.org/builders/oak-trunk-win7/builds/16",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "ConcurrentConflictTest fails occasionally"
   },
   {
      "_id": "12710305",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2014-04-24 12:59:37",
      "description": "Every now and then we see commit failures in a cluster when many sessions try to update the same property or perform some other conflicting update.\n\nThe current implementation will retry the merge after a delay, but chances are some session on another cluster node again changed the property in the meantime. This will lead to yet another retry until the limit is reached and the commit fails. The conflict logic is quite unfair, because it favors the winning session.\n\nThe implementation should be improved to show a more fair behavior across cluster nodes when there are conflicts caused by competing session.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency",
         "scalability"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Better cooperation for conflicting updates across cluster nodes"
   },
   {
      "_id": "12710287",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-04-24 10:51:34",
      "description": "This is a follow up from OAK-1757.\n\nThe accuracy of the values reported by {{RepositoryStatsMBean}} for {{SESSION_WRITE_DURATION}} and {{SESSION_READ_DURATION}} depend on the value of {{Clock#FAST_CLOCK_INTERVAL}}. \n\nThe 1s reset interval of the duration counters might be to small for the inaccuracies of the clock resolution to average out. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Inaccurate values reported by RepositoryStatsMBean"
   },
   {
      "_id": "12709986",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-04-23 09:30:36",
      "description": "Seeing the below IlegalStateException about tracker being null several times on a 4-node oak-mongo cluster. There were no log.warn 'Timed out waiting for change processor to stop' near those errors (but there was once hour(s) before in one case).\n\n{code}16.04.2014 05:34:50.908 *ERROR* [oak-executor-1619] org.apache.sling.extensions.threaddump.internal.Activator Uncaught exception in Thread Thread[oak-executor-1619,1,Configuration\n Admin Service]\njava.lang.IllegalStateException: null\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:134)\n        at org.apache.jackrabbit.oak.spi.whiteboard.AbstractServiceTracker.getServices(AbstractServiceTracker.java:60)\n        at org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardExecutor.execute(WhiteboardExecutor.java:40)\n        at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$1.run(BackgroundObserver.java:130)\n        at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$ListenableFutureTask.run(BackgroundObserver.java:283)\n        at org.apache.jackrabbit.oak.spi.commit.BackgroundObserver$ListenableFutureTask.done(BackgroundObserver.java:278)\n        at java.util.concurrent.FutureTask$Sync.innerSet(FutureTask.java:281)\n        at java.util.concurrent.FutureTask.set(FutureTask.java:141)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:339)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Sporadic IllegalStateException in AbstractServiceTracker.getServices"
   },
   {
      "_id": "12709744",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-04-22 11:21:11",
      "description": "we should document how to use MongoMK when MongoDB requires credentials to connect to. According to [~chetanm] this would work as\n{quote}\nin OSGi config we can specify uri [1] to mongodb://admin:admin@localhost:27017\n\n[1] http://api.mongodb.org/java/current/com/mongodb/MongoURI.html \n{quote}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "add docu how to connect to Mongo w/ credentials"
   },
   {
      "_id": "12709720",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320003",
            "id": "12320003",
            "name": "query",
            "description": "Query"
         }
      ],
      "created": "2014-04-22 09:15:40",
      "description": "The node name queries don't use any index currently, making them really slow and triggering a lot of traversal warnings.\n\nSimply adding node names to a property index would be too much content indexed, but as Lucene already indexes the node names, using this index would be one viable option.\n\n{code}\n/jcr:root//*[fn:name() = 'jcr:content']\n/jcr:root//*[jcr:like(fn:name(), 'jcr:con%')] \n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Node name queries should use an index"
   },
   {
      "_id": "12709036",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-04-17 12:26:45",
      "description": "The documentation of\n\n  Document.MOD_COUNT\n\n\"The modification count on the document. This is an long value incremented on every modification.\"\n\ngives the impression that this is a mechanism that is part of the DocumentStore API contract (which IMHO it is not)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Cleanup documentation of _modCount"
   },
   {
      "_id": "12707639",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12332458",
            "id": "12332458",
            "name": "benchmarks",
            "description": "Oak Benchmarks"
         }
      ],
      "created": "2014-04-10 05:21:44",
      "description": "Benchmark runner has support for specifying concurrency levels to execute the test with varying level of concurrency. In most cases the test case would be operating on a JCR session. With multi threaded runs we need a way to have jcr session bound to that thread of execution.\n\nTo support that {{AbstractTest}} should provide a way for client to provide a executionContext object which sub classes can provide. That context would be managed per thread and passed to the runTest method if not null",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable passing of a execution context to runTest in multi threaded runs"
   },
   {
      "_id": "12707374",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-04-09 07:26:44",
      "description": "OAK-1601 introduced warnings that are logged when a session is accessed concurrently from different threads. The modalities however differ from those of Jackrabbit 2. The message \n\n{code}\nAttempt to perform \"sessionOperation\" while another thread is concurrently writing to \"session\". Blocking until the other thread is finished using this session. Please review your code to avoid concurrent use of a session.\n{code}\n\nis logged for the current thread\n\n* if the current threads attempts a write operation while another thread already executes a write operation in Jackrabbit 2,\n* if the current thread attempts a write operation while another thread already executes any operation. \n\nWe should make these warnings identical to those of Jackrabbit 2.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve warning logged on concurrent Session access"
   },
   {
      "_id": "12707136",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-04-08 08:48:51",
      "description": "As [noted | https://issues.apache.org/jira/browse/OAK-1414?focusedCommentId=13942016&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13942016] on OAK-1414 {{LargeOperationIT}} is somewhat inaccurate for the document node store fixture where the collected data tends to be noisy. We should look into ways to make  the tests results more accurate for this case.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Improve LargeOperationIT accuracy for document nodes store fixture"
   },
   {
      "_id": "12706946",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-04-07 13:21:51",
      "description": "Please document (I'll assume it's similar to \"remove\", in that it is \"best effort\")?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "document atomicity of DS.update(collection, keys, update)"
   },
   {
      "_id": "12706594",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-04-04 09:14:11",
      "description": "[~mreutegg]\nI believe it's best effort (looking at the MongoDB impl), but it would be good to clarify.\n\nIn particular, should the operation abort then one removal failed, or keep going? What's the expectation when a document doesn't exist?",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "document atomicity of DS.remove(collection, keys)"
   },
   {
      "_id": "12706187",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-04-02 15:03:21",
      "description": "OAK-1661 added node type information for {{NODE_ADDED}} and {{NODE_REMOVED}} events. We should consider adding this for all event types however.  Even property events would contain node type of the node the property is associated with (parent).\n\nAn implication of this is however that we also need to adapt the TCK as this will cause {{org.apache.jackrabbit.test.api.observation.GetInfoTest}} to fail, which expects the info map to be generally empty. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "JCR Event Info should contain NodeType for all Events "
   },
   {
      "_id": "12706142",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-04-02 11:17:55",
      "description": "JR2 FileDataStore#inUseMap [1] is currently a synchronized map and that at times causes contention concurrent env. This map is used for supporting the Blob GC logic for JR2. \n\nWith Oak this map content is not used. As a fix we can either\n\n# Set inUseMap to a Guava Cache Map which has weak keys and value\n# Set inUseMap to a no op map where all put calls are ignored\n# Modify FDS to disable use of inUseMap or make {{usesIdentifier}} protected\n\n#3 would be a proper fix and #2 can be used as temp workaround untill FDS gets fixed\n\n[1] https://github.com/apache/jackrabbit/blob/trunk/jackrabbit-data/src/main/java/org/apache/jackrabbit/core/data/FileDataStore.java#L118",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "FileDataStore inUse map causes contention in concurrent env"
   },
   {
      "_id": "12705591",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-31 07:13:16",
      "description": "Currently when a checkpoint is created in DocumentNodeStore then it is saved in form of currentHeadRev=>expiryTime. Now if multiple checkpoints are created where head revision has not changed then only the last one would be saved and previous entries would be overridden as revision is used as key\n\nOne fix would be to change the expiry time only if the new expiry time is greater than previous entry. However doing that safely in a cluster (check then save) is currently not possible with DocumentStore API as the modCount check if only supported for Nodes.\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Creating multiple checkpoint on same head revision overwrites previous entries"
   },
   {
      "_id": "12703715",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-26 13:15:19",
      "description": "Implement the {{noInternal}} flag that will be added with JCR-3759. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Implement noInternal from JackrabbitEventFilter"
   },
   {
      "_id": "12703438",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-25 12:08:32",
      "description": "Currently we log a warning when calling {{Event.getUserID()}}, {{Event.getUserData()}} or {{Event.getDate()}} without first checking whether the event is not external. However we should inhibit such warnings for the case where the filter already excludes external events. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Omit warnings about accessing commit related info when external events are excluded"
   },
   {
      "_id": "12702892",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-21 16:03:50",
      "description": "Fails frequently on my W7 desktop:\n\ntestCacheInvalidationHierarchicalNotExist(org.apache.jackrabbit.oak.plugins.document.mongo.CacheInvalidationIT)  Time elapsed: 0.04 sec  <<< FAILURE!\njava.lang.AssertionError\n        at org.junit.Assert.fail(Assert.java:92)\n        at org.junit.Assert.assertTrue(Assert.java:43)\n        at org.junit.Assert.assertTrue(Assert.java:54)\n        at org.apache.jackrabbit.oak.plugins.document.mongo.CacheInvalidationIT.testCacheInvalidationHierarchicalNotExist(CacheInvalidationIT.java:171)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "CI"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "org.apache.jackrabbit.oak.plugins.document.mongo.CacheInvalidationIT fails"
   },
   {
      "_id": "12702434",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-19 17:42:06",
      "description": "Implement refined conflict resolution for addExistingNode conflicts as defined in the parent issue for the document NS.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DocumentNS: Implement refined conflict resolution for addExistingNode conflicts"
   },
   {
      "_id": "12702110",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320387",
            "id": "12320387",
            "name": "segmentmk",
            "description": "Segment Store"
         }
      ],
      "created": "2014-03-18 10:19:10",
      "description": "{{NodeStore}} implementations should expose the {{RevisionGCMBean}} in order to be interoperable with {{RepositoryManagementMBean}}. See OAK-1160.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose RevisionGCMBean for supported NodeStores "
   },
   {
      "_id": "12702108",
      "assignee": "dulceanu",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12329487",
            "id": "12329487",
            "name": "segment-tar",
            "description": "Segment Store Tar"
         }
      ],
      "created": "2014-03-18 10:16:05",
      "description": "{{NodeStore}} implementations should expose the {{FileStoreBackupRestoreMBean}} in order to be interoperable with {{RepositoryManagementMBean}}. See OAK-1160.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose FileStoreBackupRestoreMBean for supported NodeStores"
   },
   {
      "_id": "12701867",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-03-17 10:53:23",
      "description": "{{MicroKernel.rebase}} says: \"addExistingNode: node has been added that is different from a node of them same name that has been added to the trunk.\"\n\nHowever, the {{NodeStore}} implementation\n# throws a {{CommitFailedException}} itself instead of annotating the conflict,\n# also treats the equal childs with the same name as a conflict. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency",
         "observation",
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Incorrect handling of addExistingNode conflict in NodeStore"
   },
   {
      "_id": "12700973",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-12 13:53:09",
      "description": "I'm seeing this test fail consistently on our internal CI builds.\n\n_org.apache.jackrabbit.core.observation.ShareableNodesTest.testAddShareableMixin_:\nbq. Change processor already stopped\n\nStacktrace\n{code}\njava.lang.IllegalStateException: Change processor already stopped\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:150)\n\tat org.apache.jackrabbit.oak.jcr.observation.ChangeProcessor$RunningGuard.stop(ChangeProcessor.java:259)\n\tat org.apache.jackrabbit.oak.jcr.observation.ChangeProcessor.stop(ChangeProcessor.java:192)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationManagerImpl.stop(ObservationManagerImpl.java:267)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationManagerImpl.dispose(ObservationManagerImpl.java:117)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionContext.dispose(SessionContext.java:387)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl$10.perform(SessionImpl.java:465)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl$10.perform(SessionImpl.java:462)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.perform(SessionDelegate.java:263)\n\tat org.apache.jackrabbit.oak.jcr.delegate.SessionDelegate.safePerform(SessionDelegate.java:306)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl.safePerform(SessionImpl.java:129)\n\tat org.apache.jackrabbit.oak.jcr.session.SessionImpl.logout(SessionImpl.java:462)\n\tat org.apache.jackrabbit.test.AbstractJCRTest.cleanUp(AbstractJCRTest.java:439)\n\tat org.apache.jackrabbit.test.AbstractJCRTest.tearDown(AbstractJCRTest.java:448)\n\tat org.apache.jackrabbit.test.api.observation.AbstractObservationTest.tearDown(AbstractObservationTest.java:67)\n\tat junit.framework.TestCase.runBare(TestCase.java:140)\n\tat junit.framework.TestResult$1.protect(TestResult.java:110)\n\tat junit.framework.TestResult.runProtected(TestResult.java:128)\n\tat junit.framework.TestResult.run(TestResult.java:113)\n\tat junit.framework.TestCase.run(TestCase.java:124)\n\tat org.apache.jackrabbit.test.AbstractJCRTest.run(AbstractJCRTest.java:464)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:243)\n\tat junit.framework.TestSuite.run(TestSuite.java:238)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:243)\n\tat org.apache.jackrabbit.test.ConcurrentTestSuite.access$001(ConcurrentTestSuite.java:29)\n\tat org.apache.jackrabbit.test.ConcurrentTestSuite$2.run(ConcurrentTestSuite.java:67)\n\tat EDU.oswego.cs.dl.util.concurrent.PooledExecutor$Worker.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ShareableNodesTest.testAddShareableMixin failures"
   },
   {
      "_id": "12699169",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-06 15:03:55",
      "description": "We should implement these monitoring for those MKs where it makes sense. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Implement low disk space and low memory monitoring"
   },
   {
      "_id": "12699101",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317807",
            "id": "12317807",
            "name": "run",
            "description": "Runnable Jar"
         }
      ],
      "created": "2014-03-06 09:29:55",
      "description": "The benchmark test fails when run concurrently in a cluster. Setting up the test content fails with a conflict. I assume this happens because nodes in the permission store are populated concurrently and may conflict.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Concurrent FlatTreeWithAceForSamePrincipalTest fails on Oak-Mongo"
   },
   {
      "_id": "12698610",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-03-04 11:13:04",
      "description": "{{ObservationTest}} fails often on some Windows machines:\n\n{noformat}\npathFilter[3](org.apache.jackrabbit.oak.jcr.observation.ObservationTest)  Time elapsed: 0.864 sec  <<< FAILURE!\njava.lang.AssertionError: Missing events: [path = /events/only/here/below/this, type = 1]\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationTest.pathFilter(ObservationTest.java:315)\n{noformat}\n\nand\n\n{noformat}\nfilterPropertyOfParent[2](org.apache.jackrabbit.oak.jcr.observation.ObservationTest)  Time elapsed: 0.88 sec  <<< FAILURE!\njava.lang.AssertionError: Missing events: [path = /test_node/a/jcr:primaryType, type = 4, path = /test_node/a/foo, type = 4, path = /test_node/a/b, type = 1]\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationTest.filterPropertyOfParent(ObservationTest.java:614)\n{noformat}\n\nI have the suspicion this is an issue with the test similar to OAK-1486",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ObservationTest failure on Windows"
   },
   {
      "_id": "12698426",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2014-03-03 13:57:15",
      "description": "{{BackgroundObserverTest.concurrentObservers}} occasionally fails for the Windows 7 CI build:\n\n{noformat}\nconcurrentObservers(org.apache.jackrabbit.oak.spi.commit.BackgroundObs)  Time elapsed: 5.058 sec  <<< FAILURE!\njava.lang.AssertionError\n\tat org.junit.Assert.fail(Assert.java:92)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.junit.Assert.assertTrue(Assert.java:54)\n\tat org.apache.jackrabbit.oak.spi.commit.BackgroundObserverTest.concurrentObservers(BackgroundObserverTest.java:62)\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "BackgroundObserverTest occasionally failing"
   },
   {
      "_id": "12697726",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-02-27 15:25:45",
      "description": "While running Oak in a two node clutser following exception is seen. It basically comes because the AsynchUpdate tries to update async-status concurrently\n\n{noformat}\n27.11.2013 17:56:35.507 *ERROR* [pool-5-thread-1] org.apache.sling.commons.scheduler.impl.QuartzScheduler Exception during job execution of org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate@fcf98c2 : com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\ncom.google.common.util.concurrent.UncheckedExecutionException: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199) ~[na:na]\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:3932) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diff(MongoMK.java:165) ~[na:na]\n\tat org.apache.jackrabbit.oak.kernel.KernelNodeState.compareAgainstBaseState(KernelNodeState.java:481) ~[na:na]\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:52) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:103) ~[na:na]\n\tat org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105) ~[org.apache.sling.commons.scheduler:2.4.2]\n\tat org.quartz.core.JobRunShell.run(JobRunShell.java:207) [org.apache.sling.commons.scheduler:2.4.2]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_40]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_40]\n\tat java.lang.Thread.run(Thread.java:724) [na:1.7.0_40]\nCaused by: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199) ~[na:na]\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:3932) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.getNode(MongoNodeStore.java:507) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diffFewChildren(MongoMK.java:313) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diffImpl(MongoMK.java:229) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK$1.call(MongoMK.java:168) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK$1.call(MongoMK.java:165) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) ~[na:na]\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) ~[na:na]\n\t... 11 common frames omitted\nCaused by: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat org.apache.jackrabbit.oak.plugins.mongomk.util.MergeSortedIterators.fetchNextIterator(MergeSortedIterators.java:103) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.util.MergeSortedIterators.next(MergeSortedIterators.java:85) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.NodeDocument.getLatestValue(NodeDocument.java:1041) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.NodeDocument.getNodeAtRevision(NodeDocument.java:456) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.readNode(MongoNodeStore.java:653) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.access$000(MongoNodeStore.java:80) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore$2.call(MongoNodeStore.java:510) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore$2.call(MongoNodeStore.java:507) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) ~[na:na]\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) ~[na:na]\n\t... 23 common frames omitted\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cluster"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Failing test for MergeSortedIterators"
   },
   {
      "_id": "12696542",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-02-21 14:10:42",
      "description": "When moving a node many extra events are dispatched in OAK in compared to other implementations\n\nOn Oak a node added and node remove events are dispatched for each node in the hierarchy being moved.  As well there is a property add and property remove event dispatched for each property in the node hierarchy.  \n\nThis compares to previous implementations where only a Node Moved, node added and node removed event is dispatched for the parentnode being moved.\n\nSee [0] for an example.\n\nFor me this is problematic for a couple of reasons:\n\n1) We are dispatching more events than we did previously.  In cases where nodes are frequently moved this will add extra load on the system. \n2) It is becoming increasingly difficult to ignore events related to a move without spending extra cycles to make that determination. \n3) Many pre-existing event listeners will be executing on events that they previously would not have.\n\nI know the JCR spec indicates that an implementation may choose to dispatch these events or not, but I suggest we change OAK to not throw these extra events.  If we do not many observation listeners will act on events they previously did not will likely cause problems.\n\nAlso, if we could add a simple marker in any event\u2019s info map which is related to a node move (ie: the node removed, node added etc) it would be very helpful when trying to ignore events caused by a move.  (which I believe to be the case in many situations).\n\n[0] \nMove \u201cc\u201d in the hierarchy below from /a/b to /a/z:\n\n/a/b/c/d/e\nto:\n/a/z/c/d/e\n\nResults in:\n\nCRX2:\n/a/b, type: {node removed}\n/a/z/b, type: {node added}\n/a/z/b, type: {node moved}\n\nOAK:\n/a/b/c, type: {node removed}\n/a/z/c, type: {node moved}\n/a/z/c, type: {node added}\n/a/b/c/jcr:primaryType, type: {property removed}\n/a/b/c/jcr:createdBy, type: {property removed}\n/a/b/c/jcr:created, type: {property removed}\n/a/b/c/d, type: {node removed}\n/a/z/c/jcr:primaryType, type: {property added}\n/a/z/c/jcr:createdBy, type: {property added}\n/a/z/c/jcr:created, type: {property added}\n/a/z/c/d, type: {node added}\n/a/b/c/d/jcr:primaryType, type: {property removed}\n/a/b/c/d/jcr:createdBy, type: {property removed}\n/a/b/c/d/jcr:created, type: {property removed}\n/a/b/c/d/e, type: {node removed}\n/a/z/c/d/jcr:primaryType, type: {property added}\n/a/z/c/d/jcr:createdBy, type: {property added}\n/a/z/c/d/jcr:created, type: {property added}\n/a/z/c/d/e, type: {node added}\n/a/b/c/d/e/jcr:primaryType, type: {property removed}\n/a/b/c/d/e/jcr:createdBy, type: {property removed}\n/a/b/c/d/e/jcr:created, type: {property removed}\n/a/z/c/d/e/jcr:primaryType, type: {property added}\n/a/z/c/d/e/jcr:createdBy, type: {property added}\n/a/z/c/d/e/jcr:created, type: {property added}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Many extra events are dispatched from a move event"
   },
   {
      "_id": "12696536",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-02-21 13:53:37",
      "description": "Expose capability to purge JCR versions so that higher level apps can start a clean up.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JCR version purge"
   },
   {
      "_id": "12696532",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12320827",
            "id": "12320827",
            "name": "doc",
            "description": "Oak Documentation "
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-02-21 13:42:25",
      "description": "For long child node lists it is much better (in terms of performance) to use a non-ordered node type. Unfortunately, nt:unstructured is ordered.\nWe should have a \"performance hint\" on this in the docs.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "documentation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "document oak:unstructured performance advantages"
   },
   {
      "_id": "12696529",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-02-21 13:40:13",
      "description": "It is an explicit design non-goal of Oak to support huge amounts of values in multi-valued properties. If a user still tries to create these we should at least throw a WARN in the logs to indicate that usage of MVPs is wrong.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/5",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/trivial.svg",
         "name": "Trivial",
         "id": "5"
      },
      "projectname": "OAK",
      "summary": "Warn on huge multi-valued properties"
   },
   {
      "_id": "12696503",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-02-21 12:03:16",
      "description": "For cases where the document semantics in Mongo that are created by Oak get corrupted to a point that Oak does not come up anymore (but MongoDB is still available), we should have a mechanism to fix those inconsistencies.\n\nOf course, one could use Mongo tools like cmdline or MongoHub to manually go in, but an automated approach would be preferable in the medium term.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "production",
         "resilience",
         "tools"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Offline tool to repair MongoMK documents"
   },
   {
      "_id": "12693122",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-02-04 15:24:49",
      "description": "Most recent test failure on buildbot http://ci.apache.org/builders/oak-trunk/builds/4290/steps/compile/logs/stdio says:\n\n{noformat}\nconcurrent[2](org.apache.jackrabbit.oak.jcr.ConcurrentFileOperationsTest)  Time elapsed: 1.69 sec  <<< ERROR!\njavax.jcr.InvalidItemStateException: OakState0001: Unresolved conflicts in /test-node/session-6\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "concurrency"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Occasional ConcurrentFileOperationsTest failure"
   },
   {
      "_id": "12692131",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-01-29 20:32:24",
      "description": "As mentioned in OAK-1332, a case where a single session registers multiple observation listeners can be troublesome if events are delivered concurrently to all of those listeners, since in such a case the {{NamePathMapper}} and other session internals will likely suffer from lock contention.\n\nA good way to avoid this would be to have all the listeners registered within a single session be tied to a single {{Observer}} and thus processed sequentially.\n\nDoing so would also improve performance as the listeners could leverage the same content diff. As the listeners come from a single session and thus presumably from a single client, there's no need to worry about one client blocking the work of another.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Only one Observer per session"
   },
   {
      "_id": "12691621",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-01-28 11:51:42",
      "description": "{{DocumentNodeState#compareAgainstBaseState}} usually falls back to the default implementation in {{AbstractNodeState#compareAgainstBaseState(NodeState, NodeStateDiff)}}, which is slow. See also the TODO in the code. This negatively affects performance when generation observation events. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeState#compareAgainstBaseState too slow"
   },
   {
      "_id": "12691096",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-01-24 19:08:34",
      "description": "The problem is that the different stores have different transient space characteristics. for example the MongoMK is very slow when handling large saves.\n\nsuggest to expose a repository descriptor that can be used to estimate the preferred transient space, for example when importing content.\n\nso either a boolean like: \n  {{option.infinite.transientspace}}\n\nor a number like:\n  {{option.transientspace.preferred.size}}\n\nthe later would denote the average number of modified node states that should be put in the transient space before the persistence starts to degrade.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "api"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose the preferred transient space size as repository descriptor "
   },
   {
      "_id": "12689805",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2014-01-20 12:35:07",
      "description": "Implement repository statistics (TimeSeries) for those values it makes sense on Oak.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement RepositoryStatistics from Jackrabbit API"
   },
   {
      "_id": "12688733",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2014-01-14 13:21:44",
      "description": "As discussed with Chetan offline we'd like to reduce the number of calls to MongoDB when content is added to the repository with a filevault package import.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Reduce calls to MongoDB"
   },
   {
      "_id": "12688013",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2014-01-09 07:55:27",
      "description": "For very fine grained content with many nodes and only few properties per node it would be more efficient to bundle multiple nodes into a single MongoDB document. Mostly reading would benefit because there are less roundtrips to the backend. At the same time storage footprint would be lower because metadata overhead is per document.\n\nFeature branch - https://github.com/chetanmeh/jackrabbit-oak/compare/trunk...chetanmeh:OAK-1312\n\n*Feature Docs* - http://jackrabbit.apache.org/oak/docs/nodestore/document/node-bundling.html",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Bundle nodes into a document"
   },
   {
      "_id": "12684964",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-12-16 14:30:35",
      "description": "This happened while running the maven build with {{-PintegrationTesting}}:\n\n{code}\nRunning org.apache.jackrabbit.oak.jcr.random.RandomizedReadTest\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.418 sec\norg.apache.maven.surefire.util.SurefireReflectionException: java.lang.reflect.InvocationTargetException; nested exception is java.lang.reflect.InvocationTargetException: null\njava.lang.reflect.InvocationTargetException\nException in thread \"main\" java.lang.OutOfMemoryError: PermGen space\n\nResults :\n\nTests run: 722, Failures: 0, Errors: 0, Skipped: 48\n{code}\n\nThe crucial point being Surefire silently ignoring the following tests such that the build happily succeeds making following failures. Note, that test suite consists of  2003 tests in contrast to the 722 reported by Surefire. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "RandomizedReadTest fails with OutOfMemoryError: PermGen space"
   },
   {
      "_id": "12684921",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-12-16 11:03:06",
      "description": "The contract for {{ObservationManager#removeEventListener}} mandates: \"A listener may be deregistered while it is being executed. The deregistration method will block until the listener has completed executing.\"\n\nHowever a strict implementation of this contract is prone to deadlocks: clients unregistering event listeners need to take care not to hold a lock that is also acquired from the event listener being unregistered as this will lead to a deadlock\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "ObservationManager#removeEventListener prone to deadlocks "
   },
   {
      "_id": "12684481",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-12-13 16:10:59",
      "description": "[~fmeschbe] had a look at the oak api and spotted the following problem:\n\nRoot#commit(String, CommitHook)\n\nBut the CommitHook interface is not part of the OAK API. we quickly searched for usages and found that this is only used for the Item#save case in oak-jcr to assert that the set of modifications is contained with the subtree defined by the specified target item.\n\nIMO we should get rid of the flavour of Root#commit again and solve the Item-save issue differently. For example we could change it to Root#commit(String, String absPath) where the absPath would be the path of the target item...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "api"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Root.commit(String, CommitHook) : CommitHook is not part of oak-api"
   },
   {
      "_id": "12684282",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-12-12 15:21:31",
      "description": "There are various overlapping RepositoryStub classes that need some clean up.\n\nA while ago we decided to switch to Oak+TarMK as default TCK setup. The TCK configuration still points to OakRepositoryStub, which is derived from OakRepositoryStubBase. In OAK-1207 we changed OakRepositoryStubBase to use the TarMK. This duplicates code in OakTarMKRepositoryStub.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Clean up RepositoryStub classes"
   },
   {
      "_id": "12682951",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-12-05 17:29:06",
      "description": "Failed tests:   observation[2](org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest): added nodes expected:<1000> but was:<442>\n\nTests run: 4, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 106.957 sec <<< FAILURE!\nobservation[3](org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest)  Time elapsed: 53.047 sec  <<< FAILURE!\njava.lang.AssertionError: added nodes expected:<1000> but was:<906>\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.failNotEquals(Assert.java:647)\n\tat org.junit.Assert.assertEquals(Assert.java:128)\n\tat org.junit.Assert.assertEquals(Assert.java:472)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest.observation(ObservationRefreshTest.java:119)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\n\tat org.junit.runners.Suite.runChild(Suite.java:24)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\n\tat java.lang.Thread.run(Thread.java:695)\nobservation[2](org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest)  Time elapsed: 58.379 sec  <<< FAILURE!\njava.lang.AssertionError: added nodes expected:<1000> but was:<396>\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.failNotEquals(Assert.java:647)\n\tat org.junit.Assert.assertEquals(Assert.java:128)\n\tat org.junit.Assert.assertEquals(Assert.java:472)\n\tat org.apache.jackrabbit.oak.jcr.observation.ObservationRefreshTest.observation(ObservationRefreshTest.java:119)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n\tat org.junit.runners.Suite.runChild(Suite.java:128)\n\tat org.junit.runners.Suite.runChild(Suite.java:24)\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\n\tat java.lang.Thread.run(Thread.java:695)\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Failure in ObservationRefreshTest "
   },
   {
      "_id": "12682124",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-12-02 12:30:23",
      "description": "Currently the {{AsynchIndexUpdate }} job which performs the indexing in background is run on every node in a cluster. This at times causes commit failures when running Oak in a cluster using Mongo MK. As merging of indexed content say Lucene is tricky to implement it would be better to restrict this job to run as a singleton in a cluster\n\nSee http://markmail.org/thread/qff2fj7nqtbuhr4i for more discussion",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "cluster"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Make AsynchIndexUpdate task to run only on a single node in a cluster"
   },
   {
      "_id": "12681562",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2013-11-27 12:45:23",
      "description": "While running Oak in a two node clutser following exception is seen. It basically comes because the AsynchUpdate tries to update async-status concurrently\n\n{noformat}\n27.11.2013 17:56:35.507 *ERROR* [pool-5-thread-1] org.apache.sling.commons.scheduler.impl.QuartzScheduler Exception during job execution of org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate@fcf98c2 : com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\ncom.google.common.util.concurrent.UncheckedExecutionException: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199) ~[na:na]\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:3932) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diff(MongoMK.java:165) ~[na:na]\n\tat org.apache.jackrabbit.oak.kernel.KernelNodeState.compareAgainstBaseState(KernelNodeState.java:481) ~[na:na]\n\tat org.apache.jackrabbit.oak.spi.commit.EditorDiff.process(EditorDiff.java:52) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate.run(AsyncIndexUpdate.java:103) ~[na:na]\n\tat org.apache.sling.commons.scheduler.impl.QuartzJobExecutor.execute(QuartzJobExecutor.java:105) ~[org.apache.sling.commons.scheduler:2.4.2]\n\tat org.quartz.core.JobRunShell.run(JobRunShell.java:207) [org.apache.sling.commons.scheduler:2.4.2]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_40]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_40]\n\tat java.lang.Thread.run(Thread.java:724) [na:1.7.0_40]\nCaused by: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2199) ~[na:na]\n\tat com.google.common.cache.LocalCache.get(LocalCache.java:3932) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4721) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.getNode(MongoNodeStore.java:507) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diffFewChildren(MongoMK.java:313) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK.diffImpl(MongoMK.java:229) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK$1.call(MongoMK.java:168) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoMK$1.call(MongoMK.java:165) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) ~[na:na]\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) ~[na:na]\n\t... 11 common frames omitted\nCaused by: java.lang.IllegalStateException: Revisioned values for property 1:/oak:index/async-status: First element of next iterator must be greater than previous iterator\n\tat org.apache.jackrabbit.oak.plugins.mongomk.util.MergeSortedIterators.fetchNextIterator(MergeSortedIterators.java:103) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.util.MergeSortedIterators.next(MergeSortedIterators.java:85) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.NodeDocument.getLatestValue(NodeDocument.java:1041) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.NodeDocument.getNodeAtRevision(NodeDocument.java:456) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.readNode(MongoNodeStore.java:653) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore.access$000(MongoNodeStore.java:80) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore$2.call(MongoNodeStore.java:510) ~[na:na]\n\tat org.apache.jackrabbit.oak.plugins.mongomk.MongoNodeStore$2.call(MongoNodeStore.java:507) ~[na:na]\n\tat com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4724) ~[na:na]\n\tat com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3522) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2315) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2278) ~[na:na]\n\tat com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2193) ~[na:na]\n\t... 23 common frames omitted\n{noformat}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "cluster"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "IllegalStateException in MergeSortedIterators"
   },
   {
      "_id": "12679183",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12328225",
            "id": "12328225",
            "name": "documentmk",
            "description": "DocumentNodeStore"
         }
      ],
      "created": "2013-11-14 09:15:19",
      "description": "Conflict handling is mostly implemented in MongoMK but it does not yet annotate conflicts on rebase.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "technical_debt"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "DocumentNodeStore: annotate conflicts"
   },
   {
      "_id": "12678216",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2013-11-08 12:45:14",
      "description": "Could we add generic (i.e. MK independent) interfaces that can be used by higher levels to trigger certain ops tasks? The the application could decide when would be a good time to run them.\nI am thinking especially about backup/restore (OAK-1158), MVCC revision cleanup (OAK-1158) and DSGC (OAK-377)",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Generic interfaces for operation tasks"
   },
   {
      "_id": "12676732",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12318531",
            "id": "12318531",
            "name": "commons",
            "description": "Oak Commons"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-10-30 22:30:24",
      "description": "Oak should provide an *extended and efficient JCR observation listener* mechanism to support common use cases not handled well by the restricted options of the JCR observation (only base path, node types and raw events). Those cases require listeners to register much more broadly and then filter out their specific cases themselves, thus putting too many events into the observation system and creating a huge overhead due to asynchronous access to the modified JCR data to do the filtering. This easily is a big performance bottleneck with many writes and thus many events.\n\nPrevious discussions [on the list|http://markmail.org/message/oyq7fnfrveceemoh] and in OAK-1120, and [latest discussion on the list|http://markmail.org/message/x2l6tv4m7bxjzqqq].\n\nThe goals should be:\n* performance: handle filtering as early as possible, during the commit, where access to the modified data is already present\n* provide robust implementation for typical filtering cases\n* provide an asynchronous listener mechanism as in JCR\n* minimize effect on the lower levels on Oak (a visible addition in oak-commons or oak-jcr should be enough)\n* for delete events, allow filtering on the to-be-deleted data (currently not possible in jcr listeners that run after the fact)\n* ignore external cluster events by default; have an extra option if you really want to register for external events\n* if possible: design as an extension of the jcr observation to simplify migration for existing code\n* if possible: provide an intelligent listener that can work with pure JCR (aka Jackrabbit 2) as well, by falling back to in-listener-filtering\n* maybe: synchronous option using the same simple interface (instead of raw Oak plugins itself); however, not sure if there is a benefit if they can only read data and not change or block the session commit\n\nTypical filtering cases:\n- paths with globbing support (for example /content/foo/*/something)\n- check for property values (equal, not equal, contains etc.), most importantly\nsling:resourceType in Sling apps\n- allow to check properties on child nodes as well, typically jcr:content\n- check for any parent/ancestor as well (e.g. change deep inside a node type = foo structure should be triggered, even if the node with the type wasn't modified; very important to support efficiently)\n- node types (already in jcr observation)\n- created/modified/deleted events, separate from move/copy\n- and more... a custom filter should be possible to pass through (with similar access as the {{Observer}})",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "observation",
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation listener PLUS"
   },
   {
      "_id": "12671609",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-10-01 16:19:55",
      "description": "Currently external events are only reported along with local changes. That is, when local changes are persisted external changes are detected and reported along with the local changes. This might cause external events to be delayed indefinitely on cluster nodes without writes. \n\nWe might want to implement a solution that regularly polls for external events. \nSee OAK-1055 for why a previous implementation didn't work. \n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Periodically poll for external events"
   },
   {
      "_id": "12671374",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-09-30 14:49:11",
      "description": "The test occasionally fails with\n{code}\nFailed tests:\nobservation[1](org.apache.jackrabbit.oak.jcr.observation.ObservationTest):\nUnexpected events: [EventImpl{type=8, jcrPath='/test_node/property',\nuserID='oak:unknown', identifier='/test_node', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=16,\njcrPath='/test_node/n1/p1', userID='oak:unknown',\nidentifier='/test_node/n1', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=4, jcrPath='/test_node/n1/p2',\nuserID='oak:unknown', identifier='/test_node/n1', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=2, jcrPath='/test_node/n3',\nuserID='oak:unknown', identifier='/test_node/n3', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=8,\njcrPath='/test_node/n3/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/n3', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=8, jcrPath='/test_node/n3/p3',\nuserID='oak:unknown', identifier='/test_node/n3', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=2, jcrPath='/test_node/{4}',\nuserID='oak:unknown', identifier='/test_node/{4}', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=8,\njcrPath='/test_node/{4}/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/{4}', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=1, jcrPath='/test_node/n2',\nuserID='oak:unknown', identifier='/test_node/n2', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=4,\njcrPath='/test_node/n2/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/n2', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=4, jcrPath='/test_node/property',\nuserID='oak:unknown', identifier='/test_node', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=16,\njcrPath='/test_node/n1/p1', userID='oak:unknown',\nidentifier='/test_node/n1', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=8, jcrPath='/test_node/n1/p2',\nuserID='oak:unknown', identifier='/test_node/n1', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=2, jcrPath='/test_node/n2',\nuserID='oak:unknown', identifier='/test_node/n2', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=8,\njcrPath='/test_node/n2/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/n2', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=1, jcrPath='/test_node/n3',\nuserID='oak:unknown', identifier='/test_node/n3', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=4,\njcrPath='/test_node/n3/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/n3', info={}, date=0, userData=null,\nexternal=true}, EventImpl{type=4, jcrPath='/test_node/n3/p3',\nuserID='oak:unknown', identifier='/test_node/n3', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=1, jcrPath='/test_node/{4}',\nuserID='oak:unknown', identifier='/test_node/{4}', info={}, date=0,\nuserData=null, external=true}, EventImpl{type=4,\njcrPath='/test_node/{4}/jcr:primaryType', userID='oak:unknown',\nidentifier='/test_node/{4}', info={}, date=0, userData=null,\nexternal=true}]\n{code}\n\nAs [noted before | http://markmail.org/message/lk3vrrcn5edib73d]  having {{external=true}} and also the event types indicate that the events are being seen \"in reverse\" (i.e. reverse diffing of the node states involved). ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Occasional test failure in ObservationTest.observation()"
   },
   {
      "_id": "12668260",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-09-12 14:20:44",
      "description": "As Jukka [mentioned | https://issues.apache.org/jira/browse/OAK-978?focusedCommentId=13751242&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13751242] on OAK-978, is often on the critical path and the changes done there had a bad impact on performance:\n\n{code}\nApache Jackrabbit Oak\n# ReadPropertyTest               min     10%     50%     90%     max       N\nJackrabbit                         4       5       5       6      14   11287\nOak-Tar                           14      15      16      16      27    3855\n{code}\n\nUntil we are able to come up with a better solution that separates parsing from name mapping, I suggest to use the following heuristic to shortcut path parsing: shortcut iff the JCR path does not start with a dot, does not contain any of {}[]/ and if it contains a colon the session does not have local re-mappings.\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Optimise path parsing"
   },
   {
      "_id": "12662067",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-08-06 08:31:18",
      "description": "Create JMX MBean to track Session and session related information:\n\n* stack trace from where the session has been acquired,\n* age of the session,\n* last (read/write) access to the session,\n* last refresh of the session,\n* conflict information (e.g. unresolved conflicts),\n* session attributes,\n* ...\n\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MBean to track sessions"
   },
   {
      "_id": "12659287",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-07-23 08:55:00",
      "description": "Chetan discovered that in some cases spurious observation events would be created when to sessions save concurrently. In a nutshell the problem occurs since the current implementation of observation expects a linear sequence of revisions (per cluster node). However on Root.commit there is a small race between rebasing and merging a branch: when another session saves inside this time frame, its branch will have the same base revision like that of the former session. In this case the sequence of revisions is effectively non linear.\n\nFull discussion: http://markmail.org/message/cbzrztagurplxo4r",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Concurrent commits may cause duplicate observation events"
   },
   {
      "_id": "12653704",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-06-19 13:45:39",
      "description": "Creating observation events is much more expensive when a transaction is broken down through intermediate save calls compared to only having a single save call. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Generating observation events takes too long when intermediate save calls are involved"
   },
   {
      "_id": "12652344",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-06-12 08:57:40",
      "description": "Observation listeners (OAK-144) might create backward compatibility issues. To ease the transition we should provide useful information about registered listeners e.g.:\n* Number of listeners\n* Session (user) a listener belongs to\n* Filter set for the listener\n* Number of events fired\n* Last couple of events fired\n* Size of pending queue\n* ...",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Mangement info and statistics for observation listeners"
   },
   {
      "_id": "12652343",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-06-12 08:50:15",
      "description": "We should come up with a way to expose repository management information and statistics. See JCR-2936 plus subtasks and JCR-3243 for how this is done in Jackrabbit 2. See [this discussion | http://apache-sling.73963.n3.nabble.com/Monitoring-and-Statistics-td4021905.html] for an alternative proposal.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Expose repository management data and statistics"
   },
   {
      "_id": "12652187",
      "assignee": "chetanm",
      "components": [],
      "created": "2013-06-11 09:37:58",
      "description": "To get a better picture around the usage of cache it would be helpful to enable the [statistics|http://code.google.com/p/guava-libraries/wiki/CachesExplained#Statistics] for various caches used in Oak\n\n{code:java}\nnodeCache = CacheBuilder.newBuilder()\n                        .weigher(...)\n                        .maximumWeight(...)\n                        .recordStats()\n                        .build();\n{code}\n\nOnce enabled it allows to get stats like below\n{noformat}\nCacheStats{hitCount=763322, missCount=51333, loadSuccessCount=0, loadExceptionCount=0, totalLoadTime=0, evictionCount=3496}\n{noformat}\n\nAs stats collection adds a very minor overhead we can look into making this setting configurable. \n\nUntill we expose the stats via JMX one can extract the value in Sling env via approach mentioned in [this gist|https://gist.github.com/chetanmeh/5748650]",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "monitoring"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Enable stats for various caches used in Oak by default"
   },
   {
      "_id": "12642260",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         },
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-04-12 15:44:22",
      "description": "As [discussed | http://markmail.org/message/6bqycmx6vbq7m25c] we might want look into implementing an alternative approach to observation, which trades some scalability for improved backward compatibility. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Implement backward compatible observation"
   },
   {
      "_id": "12637725",
      "assignee": "mreutegg",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2013-03-19 09:00:29",
      "description": "Apache Sling uses Session.getNamespacePrefixes() quite often. E.g. when reading content through a JcrPropertyMap:\n\n{code}\n   java.lang.Thread.State: RUNNABLE\n        at java.util.HashMap.put(HashMap.java:372)\n        at org.apache.jackrabbit.oak.plugins.name.Namespaces.getNamespaceMap(Namespaces.java:64)\n        at org.apache.jackrabbit.oak.plugins.name.ReadOnlyNamespaceRegistry.getPrefix(ReadOnlyNamespaceRegistry.java:116)\n        at org.apache.jackrabbit.oak.jcr.SessionImpl.getNamespacePrefix(SessionImpl.java:529)\n        - locked <0x00000007daf6c590> (a java.util.HashMap)\n        at org.apache.jackrabbit.oak.jcr.SessionImpl.getNamespacePrefixes(SessionImpl.java:495)\n        at org.apache.sling.jcr.resource.JcrPropertyMap.escapeKeyName(JcrPropertyMap.java:381)\n        at org.apache.sling.jcr.resource.JcrPropertyMap.read(JcrPropertyMap.java:344)\n        at org.apache.sling.jcr.resource.JcrPropertyMap.get(JcrPropertyMap.java:126)\n        at org.apache.sling.jcr.resource.JcrPropertyMap.get(JcrPropertyMap.java:147)\n{code}\n\nI'd like to optimize the case when there are not session re-mapped namespaces. In this case the prefixes can be returned from the namespace registry as is. This avoids the loop and reduces calls on the Oak API. Initial testing shows a performance improvement by a factor of 3.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimize Session.getNamespacePrefixes()"
   },
   {
      "_id": "12635546",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2013-03-06 10:46:34",
      "description": "Because there is no user id passed on to the events generated by the _ChangeProcessor_, the sling EventListener throws a bunch of NPEs when it receives the events.\n\n{code}\n06.03.2013 11:33:13.866 *ERROR* [pool-4-thread-1] org.apache.jackrabbit.oak.plugins.observation.ChangeProcessor Unable to generate or send events java.lang.NullPointerException\nat java.util.Hashtable.put(Hashtable.java:394)\nat org.apache.sling.jcr.resource.internal.JcrResourceListener.sendOsgiEvent(JcrResourceListener.java:298)\nat org.apache.sling.jcr.resource.internal.JcrResourceListener.onEvent(JcrResourceListener.java:218)\nat org.apache.jackrabbit.oak.plugins.observation.ChangeProcessor$EventGeneratingNodeStateDiff.sendEvents(ChangeProcessor.java:154)\nat org.apache.jackrabbit.oak.plugins.observation.ChangeProcessor.run(ChangeProcessor.java:117)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\nat java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:317)\nat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:150)\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:98)\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.runPeriodic(ScheduledThreadPoolExecutor.java:180)\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:204)\nat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\nat java.lang.Thread.run(Thread.java:662)\n{code}",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "observation"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Observation generates NPE in an existing EventListener"
   },
   {
      "_id": "12635349",
      "assignee": "mduerig",
      "components": [],
      "created": "2013-03-05 15:00:56",
      "description": "Currently {{TreeImpl.getBaseState()}} calculates the base state of the tree on the fly on each call. As it turns out this method ends up being called by nearly every JCR method call. As recalculation is somewhat expensive since it recursively needs to calculate the base states of all parent trees, an optimisation would be to pre calculate the base state on instance creation.",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "performance"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Optimise TreeImpl.getBaseState() "
   },
   {
      "_id": "12616917",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2012-11-20 11:27:02",
      "description": "The oak-mongomk bundle currently exports couple of packages which are not required to be exported. These exports should be removed",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/3",
         "id": "3",
         "description": "A task that needs to be done.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21148&avatarType=issuetype",
         "name": "Task",
         "subtask": false,
         "avatarId": 21148
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "Remove exported packages from Mongo MK Bundle"
   },
   {
      "_id": "12613758",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317803",
            "id": "12317803",
            "name": "core",
            "description": "Oak Core"
         }
      ],
      "created": "2012-10-27 13:36:16",
      "description": "Currently the OSGi related dependencies org.osgi.core and org.osgi.compendium are marked as optional. Due to this packages under org.osgi.* are marked as optional which is not correct. \n\nAs such dependencies are already marked as provided scope they would not be included as part of transient dependencies. For more details refer to [1]\n\nFix: The optional flag should be removed\n\n[1] http://markmail.org/thread/njukyten6fdipts3",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "OSGi related dependencies should be set to provided scoped and not marked as optional"
   },
   {
      "_id": "12610547",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12319913",
            "id": "12319913",
            "name": "mongomk",
            "description": "Mongo Store"
         }
      ],
      "created": "2012-10-05 11:55:43",
      "description": "Need to convert the oak-mongomk module to an OSGi bundle and expose the MongoMicroKernel as OSGi service",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/7",
         "id": "7",
         "description": "The sub-task of the issue",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21146&avatarType=issuetype",
         "name": "Sub-task",
         "subtask": true,
         "avatarId": 21146
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MongoDB microkernal integration with OSGi"
   },
   {
      "_id": "12603584",
      "assignee": "chetanm",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-08-15 13:42:24",
      "description": "MicroKernelService currently uses @Component annotation without enabling metatype. If metatype is enabled it would simply the configuration of home directory. ",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/4",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/minor.svg",
         "name": "Minor",
         "id": "4"
      },
      "projectname": "OAK",
      "summary": "MicroKernelService should set metatype to true to easier configuration"
   },
   {
      "_id": "12603581",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317814",
            "id": "12317814",
            "name": "mk",
            "description": "MikroKernel (deprecated)"
         }
      ],
      "created": "2012-08-15 13:34:53",
      "description": "The oak-mk bundle depends on H2 database. It internally uses Class.forName('org.h2.Driver\") to load the H2 driver. Due to usage of Class.forName Bnd is not able to add org.h2 package to Import-Package list. So it should have an explicit entry in the maven-bundle-plugin config as shown below\n\n{code:xml}\n<Import-Package>\n  org.h2;resolution:=optional,\n  *\n</Import-Package>\n{code}\n\nWithout this MicroKernalService loading would fail with a CNFE",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/1",
         "id": "1",
         "description": "A problem which impairs or prevents the functions of the product.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype",
         "name": "Bug",
         "subtask": false,
         "avatarId": 21133
      },
      "labels": [
         "osgi"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Add import for org.h2 in oak-mk bundle"
   },
   {
      "_id": "12549684",
      "assignee": "mduerig",
      "components": [],
      "created": "2012-04-05 12:01:30",
      "description": "For quick turn around cycles during development we should have a way to run the most important tests only during a build and exclude longer running tests. \n\nI propose to create a Maven profile \"smoke-test\" which excludes long running tests. This ensures all tests are run by default but smoke testing can be used during development. \n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/4",
         "id": "4",
         "description": "An improvement or enhancement to an existing feature or task.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21140&avatarType=issuetype",
         "name": "Improvement",
         "subtask": false,
         "avatarId": 21140
      },
      "labels": [
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "Create smoke-test build profile"
   },
   {
      "_id": "12546795",
      "assignee": "mduerig",
      "components": [],
      "created": "2012-03-16 14:59:39",
      "description": "Trans-session isolation differs from Jackrabbit 2. Snapshot isolation can result in write skew. See http://wiki.apache.org/jackrabbit/Transactional%20model%20of%20the%20Microkernel%20based%20Jackrabbit%20prototype",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/6",
         "id": "6",
         "description": "A new unit, integration or system test.",
         "iconUrl": "https://issues.apache.org/jira/images/icons/issuetypes/requirement.png",
         "name": "Test",
         "subtask": false
      },
      "labels": [
         "documentation",
         "test"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "MVCC causes write skew"
   },
   {
      "_id": "12545672",
      "assignee": "mduerig",
      "components": [
         {
            "self": "https://issues.apache.org/jira/rest/api/2/component/12317804",
            "id": "12317804",
            "name": "jcr",
            "description": "JCR Binding"
         }
      ],
      "created": "2012-03-08 16:32:39",
      "description": "One of the proposed goals for the 0.1 release is at least a basic JCR binding for Oak. Most of that already exists in /jackrabbit/sandbox, we just need to decide where and how to place it in Oak. I think we should either put it all under o.a.j.oak.jcr in oak-core, or create a separate oak-jcr component for the JCR binding.\n\nAs for functionality, it would be nice if the JCR binding was able to do at least the following:\n\n{code}\nRepository repository = JcrUtils.getRepository(...);\n\nSession session = repository.login(...);\ntry {\n    // Create\n    session.getRootNode().addNode(\"hello\")\n        .setProperty(\"world\",  \"hello world\");\n    session.save();\n\n    // Read\n    assertEquals(\n        \"hello world\",\n        session.getProperty(\"/hello/world\").getString());\n\n    // Update\n    session.getNode(\"/hello\").setProperty(\"world\", \"Hello, World!\");\n    session.save();\n    assertEquals(\n        \"Hello, World!\",\n        session.getProperty(\"/hello/world\").getString());\n\n    // Delete\n    session.getNode(\"/hello\").delete();\n    session.save();\n    assertTrue(!session.propertyExists(\"/hello/world\"));\n} finally {\n    create.logout();\n}\n{code}\n",
      "issuetype": {
         "self": "https://issues.apache.org/jira/rest/api/2/issuetype/2",
         "id": "2",
         "description": "A new feature of the product, which has yet to be developed.",
         "iconUrl": "https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21141&avatarType=issuetype",
         "name": "New Feature",
         "subtask": false,
         "avatarId": 21141
      },
      "labels": [
         "jcr"
      ],
      "priority": {
         "self": "https://issues.apache.org/jira/rest/api/2/priority/3",
         "iconUrl": "https://issues.apache.org/jira/images/icons/priorities/major.svg",
         "name": "Major",
         "id": "3"
      },
      "projectname": "OAK",
      "summary": "JCR bindings for Oak"
   }
]